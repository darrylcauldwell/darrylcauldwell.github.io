<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on </title>
    <link>https://darrylcauldwell.github.io/post/</link>
    <description>Recent content in Posts on </description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Fri, 30 Apr 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://darrylcauldwell.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>VMware Event Broker Appliance (VEBA) - Knative</title>
      <link>https://darrylcauldwell.github.io/post/veba-knative/</link>
      <pubDate>Fri, 30 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/veba-knative/</guid>
      <description>
        
          &lt;p&gt;When I worked as an architect working with AWS I used event-driven automation with AWS Lambda to integrate distributed systems. This event-driven automation allowed me to put complex systems in place very simply. The VMware Event Broker Appliance (VEBA) aims to facilitate event-driven automation based on vCenter Server events.&lt;/p&gt;
&lt;h2 id=&#34;vmware-event-broker-appliance&#34;&gt;VMware Event Broker Appliance&lt;/h2&gt;
&lt;p&gt;VMware provides the VMware Event Broker Appliance as a &lt;a href=&#34;https://flings.vmware.com/vmware-event-broker-appliance&#34;&gt;fling&lt;/a&gt;. The &lt;a href=&#34;https://vmweventbroker.io/kb/architecture&#34;&gt;system architecture&lt;/a&gt; shows that the appliance is built on a Photon OS running Kubernetes with Contour acting as ingress controller. The event broker appliance is composed of two components an event router and a choice of event stream processor Knative, OpenFaaS or AWS EventBridge.&lt;/p&gt;
&lt;h3 id=&#34;knative-eventing-configuration&#34;&gt;Knative Eventing Configuration&lt;/h3&gt;
&lt;p&gt;Since getting engaged with the Kubernetes community it seemed the biggest barrier to entry for most people was complexity.  Knative looks to obfuscate some of that complexity and provide an abstraction that allows more focus on business functionality. It offers two core functions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Serving - Run serverless containers on Kubernetes&lt;/li&gt;
&lt;li&gt;Eventing - Universal subscription, delivery, and management of events&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Knative Eventing is composed of Knative Broker and Trigger objects which make it easy to filter events based on event attributes. A Broker provides a bucket of events which can be selected by attribute. It receives events and forwards them to subscribers defined by one or more matching Triggers.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/veba-knative-broker-trigger-overview.svg&#34; alt=&#34;Broker Trigger Architecture&#34;&gt;&lt;/p&gt;
&lt;p&gt;The v0.6 default install generates configuration for binding to vCenter Server with embedded Knative eventing &amp;lsquo;config/event-router-config.yml&amp;rsquo;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;## SSH to appliance&lt;/span&gt;
&lt;span style=&#34;color:#ae81ff&#34;&gt;cat config/event-router-config.yml&lt;/span&gt;

&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;event-router.vmware.com/v1alpha1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;RouterConfig&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;router-config-knative&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;eventProcessor&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;veba-knative&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;type&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;knative&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;knative&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;insecureSSL&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;false&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;encoding&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;binary&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;destination&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;ref&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;eventing.knative.dev/v1&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Broker&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;default&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;namespace&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;vmware-functions&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;eventProvider&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;veba-vc-01&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;type&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;vcenter&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;vcenter&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;address&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;https://&amp;lt;MY VCENTER FQDN&amp;gt;/sdk&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;auth&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;basicAuth&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;password&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;lt;MY PASSWORD&amp;gt;&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;username&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;administrator@vsphere.local&amp;#34;&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;type&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;basic_auth&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;insecureSSL&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;true&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;checkpoint&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;false&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metricsProvider&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;default&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;bindAddress&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;0.0.0.0&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;8082&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;veba-metrics&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;type&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;default&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;eventProcessor&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;veba-knative&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;type&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;knative&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;knative&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;insecureSSL&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;false&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;encoding&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;binary&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;destination&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;ref&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;eventing.knative.dev/v1&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Broker&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;default&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;namespace&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;vmware-functions&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;consuming-example-knative-function&#34;&gt;Consuming Example Knative Function&lt;/h2&gt;
&lt;p&gt;The GitHub repository contains a folder containing &lt;a href=&#34;https://github.com/vmware-samples/vcenter-event-broker-appliance/tree/development/examples/knative&#34;&gt;example Knative functions&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If we look at the example function which triggers each of each all events to Pod console. To achieve this it defines a Knative eventing resource which has an unfiltered trigger on the default broker and defines Service named &amp;lsquo;kn-ps-echo&amp;rsquo; as subscriber.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;eventing.knative.dev/v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Trigger&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;veba-ps-echo-trigger&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;labels&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;app&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;veba-ui&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;broker&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;default&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;subscriber&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;ref&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;serving.knative.dev/v1&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Service&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;kn-ps-echo&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To perform action the example defines a Knative servicing Service resource which calls container image. We can see the service definition pulls a container from the VMware public container registry named &amp;lsquo;kn-ps-echo&amp;rsquo; version 1.0.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;serving.knative.dev/v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Service&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;kn-ps-echo&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;labels&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;app&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;veba-ui&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;template&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;annotations&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;autoscaling.knative.dev/maxScale&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;1&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;autoscaling.knative.dev/minScale&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;1&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;containers&lt;/span&gt;:
        - &lt;span style=&#34;color:#f92672&#34;&gt;image&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;projects.registry.vmware.com/veba/kn-ps-echo:1.0&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Within the example folder is the Dockerfile used to create the container. We can see this defines a Powershell runtime environment with the &lt;a href=&#34;https://www.powershellgallery.com/packages/CloudEvents.Sdk&#34;&gt;CloudEvents SDK&lt;/a&gt; and &lt;a href=&#34;https://www.powershellgallery.com/packages/ThreadJob&#34;&gt;ThreadJob&lt;/a&gt; modules installed. When running the container executes server.ps1 which starts a CloudEvent HTTP listener and if we look within that it calls handler.ps1 which in this case is what outputs event contents.  Both of these Powershell scripts are copied into the container at point of creation.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-dockerfile&#34; data-lang=&#34;dockerfile&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;FROM&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt; photon:3.0&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;ENV&lt;/span&gt; TERM linux&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;ENV&lt;/span&gt; PORT &lt;span style=&#34;color:#ae81ff&#34;&gt;8080&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Set terminal. If we don&amp;#39;t do this, weird readline things happen.&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;RUN&lt;/span&gt; echo &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/usr/bin/pwsh&amp;#34;&lt;/span&gt; &amp;gt;&amp;gt; /etc/shells &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;    echo &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/bin/pwsh&amp;#34;&lt;/span&gt; &amp;gt;&amp;gt; /etc/shells &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;    tdnf install -y powershell-7.0.3-2.ph3 unzip &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;    pwsh -c &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Set-PSRepository -Name PSGallery -InstallationPolicy Trusted&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;    find / -name &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;net45&amp;#34;&lt;/span&gt; | xargs rm -rf &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;    tdnf erase -y unzip &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;    tdnf clean all&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;RUN&lt;/span&gt; pwsh  -Command &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Install-Module ThreadJob -Force -Confirm:$false&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;RUN&lt;/span&gt; pwsh -Command &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Install-Module -Name CloudEvents.Sdk&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;COPY&lt;/span&gt; server.ps1 ./&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;COPY&lt;/span&gt; handler.ps1 handler.ps1&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;CMD&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;pwsh&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;./server.ps1&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To test the example we can first pull and execute the manifest file.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;curl -O https://github.com/vmware-samples/vcenter-event-broker-appliance/blob/development/examples/knative/powershell/kn-ps-echo/function.yaml
kubectl apply --filename &lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt;.yaml --namespace vmware-functions

service.serving.knative.dev/kn-ps-echo created
trigger.eventing.knative.dev/kn-ps-echo-trigger created
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We see the service and eventing resources are created and we can check the vmware-functions namespace to get the kn-ps-echo function pod names. There are two containers in the pod, the user-container runs the function so we can follow its logs and see the flow of vCenter events being echo&amp;rsquo;d.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get pods --namespace vmware-functions

NAME                                             READY   STATUS    RESTARTS   AGE
default-broker-ingress-5c98bf68bc-whmj4          1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          4d6h
kn-ps-echo-00001-deployment-6c9f77855c-ddz8w     2/2     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          18m
kn-ps-echo-trigger-dispatcher-7bc8f78d48-5cwc7   1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          18m
sockeye-65697bdfc4-n8ght                         1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          4d6h
sockeye-trigger-dispatcher-5fff8567fc-9v74l      1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          4d6h

kubectl logs --namespace vmware-functions kn-ps-echo-00001-deployment-6c9f77855c-ddz8w user-container --follow

Server start listening on &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;http://*:8080/&amp;#39;&lt;/span&gt;
Cloud Event
  Source: https://vcenter.cork.local/sdk
  Type: com.vmware.event.router/event
  Subject: UserLogoutSessionEvent
  Id: b2cb5b99-baf2-4b0b-93e7-33795e56ec88
CloudEvent Data:



Cloud Event
  Source: https://vcenter.cork.local/sdk
  Type: com.vmware.event.router/event
  Subject: UserLoginSessionEvent
  Id: 4256ead8-b86d-4bc0-96ac-92ccaae02605
CloudEvent Data:



Cloud Event
  Source: https://vcenter.cork.local/sdk
  Type: com.vmware.event.router/event
  Subject: UserLogoutSessionEvent
  Id: a160d7bd-542d-4729-98bd-bbb14d505373
CloudEvent Data:
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;So we can see all events are of the same Type: but the Subject: is populated with descriptive name. The subject contents maps to the vCenter Server event description a list of descriptions by vCenter Server version can be found &lt;a href=&#34;https://github.com/lamw/vcenter-event-mapping&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;creating-a-knative-function&#34;&gt;Creating A Knative Function&lt;/h2&gt;
&lt;p&gt;So we can see it is easy to consume a pre-built function but I wonder how hard it is to create one to meet a bespoke need.  Pleased to report that it turns out that is also pretty easy.&lt;/p&gt;
&lt;p&gt;If we start off by defining problem,  maybe maintaining the synchronicity of state between two systems. When performing ESXi host lifecycle operations it is useful to mark this state in multiple systems. Setting object state to maintenance mode in vCenter Server can trigger vMotion work away from host and prevent scheduling of new workload on host. Setting object state to maintenance mode in vRealize Operations helps reduce amount of false positive issues relating to lifecycle operations. Host lifecycle operations like patching are typically initiated via vCenter Server so its likely maintenance mode will be set enabled and disabled correctly. It might be easy to miss mirroring this operation in vRealize Operations.&lt;/p&gt;
&lt;p&gt;So the first thing we need to do is identify the vCenter Server event created when a host is placed in maintenance mode. Checking the event documentaion we can find the two events are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://vdc-repo.vmware.com/vmwb-repository/dcr-public/fe08899f-1eec-4d8d-b3bc-a6664c168c2c/7fdf97a1-4c0d-4be0-9d43-2ceebbc174d9/doc/vim.event.EnteredMaintenanceModeEvent.html&#34;&gt;EnteredMaintenanceModeEvent&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://vdc-repo.vmware.com/vmwb-repository/dcr-public/fe08899f-1eec-4d8d-b3bc-a6664c168c2c/7fdf97a1-4c0d-4be0-9d43-2ceebbc174d9/doc/vim.event.ExitMaintenanceModeEvent.html&#34;&gt;ExitMaintenanceModeEvent&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If we look first at EnteredMaintenanceModeEvent we can create a container image. We can reuse the example Dockerfile and server.ps1 without change.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;## Create folders and pull down reusable example files&lt;/span&gt;
mkdir veba-knative-mm
mkdir veba-knative-mm/enter
mkdir veba-knative-mm/exit
cd veba-knative-mm/enter
curl -O https://raw.githubusercontent.com/vmware-samples/vcenter-event-broker-appliance/master/examples/knative/powershell/kn-ps-echo/Dockerfile
curl -O https://raw.githubusercontent.com/vmware-samples/vcenter-event-broker-appliance/master/examples/knative/powershell/kn-ps-echo/server.ps1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The &lt;a href=&#34;https://code.vmware.com/apis/364/vrealize-operations&#34;&gt;vRealize Operations Manager Suite API&lt;/a&gt; shows the two API calls which control Maintenance Mode.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;## Enter Maintenance Mode&lt;/span&gt;
PUT /api/resources/&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;id&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;/maintained
DELETE /suite-api/api/resources/&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;id&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;/maintained
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If we look at the object definition for EnteredMaintenanceModeEvent we can see it has properties of event object and extends this with additional maintenance mode related properties. With these details we can update the handler.ps1 script to call vROps API. The &lt;a href=&#34;https://vman.ch/vrops-maintenance-mode-for-resources/&#34;&gt;blog post from vMAN.ch&lt;/a&gt; heavily influenced the following Powershell logic to control maintenance mode state.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;## handler.ps1&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;Function&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Process&lt;/span&gt;-Handler {
   &lt;span style=&#34;color:#66d9ef&#34;&gt;param&lt;/span&gt;(
      [&lt;span style=&#34;color:#66d9ef&#34;&gt;Parameter&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;Position&lt;/span&gt;=0,&lt;span style=&#34;color:#66d9ef&#34;&gt;Mandatory&lt;/span&gt;=$true)]&lt;span style=&#34;color:#66d9ef&#34;&gt;[CloudNative.CloudEvents.CloudEvent]&lt;/span&gt;$CloudEvent
   )

   Write-Host &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Cloud Event&amp;#34;&lt;/span&gt;
   Write-Host &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;  Source: &lt;/span&gt;$($cloudEvent.Source)&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;
   Write-Host &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;  Type: &lt;/span&gt;$($cloudEvent.Type)&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;
   Write-Host &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;  Subject: &lt;/span&gt;$($cloudEvent.Subject)&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;
   Write-Host &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;  Id: &lt;/span&gt;$($cloudEvent.Id)&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;
   Write-Host &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;  Host: &lt;/span&gt;$($cloudEvent.host)&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;

   &lt;span style=&#34;color:#75715e&#34;&gt;# Decode CloudEvent&lt;/span&gt;
   $cloudEventData = $cloudEvent | Read-CloudEventJsonData -ErrorAction SilentlyContinue -Depth 10
   &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt;($cloudEventData &lt;span style=&#34;color:#f92672&#34;&gt;-eq&lt;/span&gt; $null) {
      $cloudEventData = $cloudEvent | Read-CloudEventData
   }

   Write-Host &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;CloudEvent Data:&amp;#34;&lt;/span&gt;
   Write-Host &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;$($cloudEventData | Out-String)&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;With the Dockerfile and scripts it copies in ready we can look to build the container image locally and then push this to a public container registry.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;docker build --tag ghcr.io/darrylcauldwell/veba-ps-enter-mm:0.1 .
docker push ghcr.io/darrylcauldwell/veba-ps-enter-mm:0.1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We can then look at a Knative service resource which links to container image:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;serving.knative.dev/v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Service&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;enter-mm&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;labels&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;app&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;veba-ui&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;template&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;annotations&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;autoscaling.knative.dev/maxScale&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;1&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;autoscaling.knative.dev/minScale&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;1&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;containers&lt;/span&gt;:
        - &lt;span style=&#34;color:#f92672&#34;&gt;image&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;ghcr.io/darrylcauldwell/veba-ps-enter-mm:latest&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Finally we can create a Knative trigger resource with filter:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;eventing.knative.dev/v1&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Trigger&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;veba-ps-enter-mm-trigger&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;labels&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;app&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;veba-ui&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
  &lt;span style=&#34;color:#f92672&#34;&gt;broker&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;default&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;filter&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;attributes&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;type&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;com.vmware.event.router/event&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;subject&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;EnteredMaintenanceModeEvent&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;subscriber&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;ref&lt;/span&gt;:
      &lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;serving.knative.dev/v1&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Service&lt;/span&gt;
      &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;enter-mm&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
        
      </description>
    </item>
    
    <item>
      <title>VMware Cloud Foundation Lifecycle Management - VCF LCM</title>
      <link>https://darrylcauldwell.github.io/post/vcf-lcm/</link>
      <pubDate>Tue, 27 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/vcf-lcm/</guid>
      <description>
        
          &lt;p&gt;VMware Cloud Foundation provides automated initial deployment and ongoing lifecycle management upgrades. Here I am exploring lifecycle management upgrades and exploring ways to make this as efficient as possible.&lt;/p&gt;
&lt;h2 id=&#34;bundle-download&#34;&gt;Bundle Download&lt;/h2&gt;
&lt;p&gt;The SDDC Manager appliance controls the Cloud Foundation deployment. To upgrade the environment(s) requires the software packages. With each Cloud Foundation release, the required software packages are formed into bundles. The bundles are made available to download to licensed users via their &amp;lsquo;My VMware&amp;rsquo; account.&lt;/p&gt;
&lt;p&gt;There are two methods of downloading the bundles. SDDC Manager can be configured with &amp;lsquo;My VMware&amp;rsquo; account and the LCM service then polls the VMware depot to access update bundles. Alternatively, the Bundle Transfer utility can be used to manually download the bundles from the depot and then upload them to SDDC Manager.&lt;/p&gt;
&lt;p&gt;There is little control and limited UI visibility of bundle downloads using SDDC Manager. This is fine if you advanced plan and configure the account in time to poll available bundles and initiate downloads. The LCM service writes two files that can be useful in understanding progress.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;/var/log/vmware/vcf/lcm/lcm.log
/var/log/vmware/vcf/lcm/lcm-debug.log
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;When you have multiple Cloud Foundation deployments it can be more efficient to use the Bundle Transfer utility to download once and distribute internally. The Bundle Transfer utility is also useful to gain a little more control over the download process.&lt;/p&gt;
&lt;p&gt;The LCM Bundle Transfer utility is shipped with the SDDC Manager appliance. The utility can be used to download various bundle versions. The utility has two elements, to ensure the utility downloads the appropriate bundles for your deployment the first extract environmental metadata from SDDC Manager.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;## SSH to SDDC Manager&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;## Outputs required metadata in files&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;## ~/markerFile&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;## ~/markerFile.md5&lt;/span&gt;

cd /opt/vmware/vcf/lcm/lcm-tools/bin
./lcm-bundle-transfer-util --generateMarker
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The second step takes the metadata as input and performs the download. This step requires Java 8 (or later) to be installed but can be run on either Windows or Linux.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;mkdir F:&lt;span style=&#34;color:#ae81ff&#34;&gt;\3&lt;/span&gt;.5.1&lt;span style=&#34;color:#ae81ff&#34;&gt;\b&lt;/span&gt;undleDownload
scp -rp vcf@nest-1-sddc-manager.cork.local:/opt/vmware/vcf/lcm/lcm-tools F:&lt;span style=&#34;color:#ae81ff&#34;&gt;\3&lt;/span&gt;.5.1&lt;span style=&#34;color:#ae81ff&#34;&gt;\b&lt;/span&gt;undleDownload
scp -p vcf@nest-1-sddc-manager.cork.local:/home/vcf/markerFile F:&lt;span style=&#34;color:#ae81ff&#34;&gt;\3&lt;/span&gt;.5.1&lt;span style=&#34;color:#ae81ff&#34;&gt;\b&lt;/span&gt;undleDownload
scp -p vcf@nest-1-sddc-manager.cork.local:/home/vcf/markerFile.md5 F:&lt;span style=&#34;color:#ae81ff&#34;&gt;\3&lt;/span&gt;.5.1&lt;span style=&#34;color:#ae81ff&#34;&gt;\b&lt;/span&gt;undleDownload
cd F:&lt;span style=&#34;color:#ae81ff&#34;&gt;\3&lt;/span&gt;.5.1&lt;span style=&#34;color:#ae81ff&#34;&gt;\b&lt;/span&gt;undleDownload&lt;span style=&#34;color:#ae81ff&#34;&gt;\l&lt;/span&gt;cm-tools&lt;span style=&#34;color:#ae81ff&#34;&gt;\b&lt;/span&gt;in
lcm-bundle-transfer-util --download --outputDirectory F:&lt;span style=&#34;color:#ae81ff&#34;&gt;\3&lt;/span&gt;.5.1&lt;span style=&#34;color:#ae81ff&#34;&gt;\b&lt;/span&gt;undleDownload -depotUser &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;your my.vmware.com username&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt; --markerFile F:&lt;span style=&#34;color:#ae81ff&#34;&gt;\3&lt;/span&gt;.5.1&lt;span style=&#34;color:#ae81ff&#34;&gt;\b&lt;/span&gt;undleDownload&lt;span style=&#34;color:#ae81ff&#34;&gt;\m&lt;/span&gt;arkerFile --markerMd5File F:&lt;span style=&#34;color:#ae81ff&#34;&gt;\3&lt;/span&gt;.5.1&lt;span style=&#34;color:#ae81ff&#34;&gt;\b&lt;/span&gt;undleDownload&lt;span style=&#34;color:#ae81ff&#34;&gt;\m&lt;/span&gt;arkerFile.md5
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once the bundle downloads are complete we can copy them to SDDC Manager and import them into the repository.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;## From Windows device used to download&lt;/span&gt;
scp -pr F:&lt;span style=&#34;color:#ae81ff&#34;&gt;\3&lt;/span&gt;.5.1&lt;span style=&#34;color:#ae81ff&#34;&gt;\b&lt;/span&gt;undleDownload vcf@Snest-1-sddc-manager.cork.local:/nfs/vmware/vcf/nfs-mount/
&lt;span style=&#34;color:#75715e&#34;&gt;## SSH to SDDC Manager and set permissions&lt;/span&gt;
chmod -R &lt;span style=&#34;color:#ae81ff&#34;&gt;0777&lt;/span&gt; /nfs/vmware/vcf/nfs-mount/bundleDownload
cd /opt/vmware/vcf/lcm/lcm-tools/bin
./lcm-bundle-transfer-util --upload --bundleDirectory /nfs/vmware/vcf/nfs-mount/bundleDownload
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;update-pre-check&#34;&gt;Update Pre-check&lt;/h2&gt;
&lt;p&gt;Once the bundles are uploaded successfully to the repository we can look towards installing them. Upgrades can fail to apply if the environment isn&amp;rsquo;t healthy. Upgrades can take a while to apply so it is better to avoid failure and rollback. A series of environmental health pre-checks are included which can be run to avoid failure to successfully deploy bundles.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Domain Manager
&lt;ul&gt;
&lt;li&gt;Common services availability check&lt;/li&gt;
&lt;li&gt;Inventory status check&lt;/li&gt;
&lt;li&gt;SDDC Manager VM database data directory has enough disk space&lt;/li&gt;
&lt;li&gt;SDDC Manager VM has enough disk space&lt;/li&gt;
&lt;li&gt;SDDC Manager VM log directory has enough disk space&lt;/li&gt;
&lt;li&gt;SDDC Manager VM system directory has enough disk space&lt;/li&gt;
&lt;li&gt;Service availability check&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;SDDC Manager UI
&lt;ul&gt;
&lt;li&gt;Inventory status check&lt;/li&gt;
&lt;li&gt;SDDC Manager VM database data directory has enough disk space&lt;/li&gt;
&lt;li&gt;SDDC Manager VM has enough disk space&lt;/li&gt;
&lt;li&gt;SDDC Manager VM log directory has enough disk space&lt;/li&gt;
&lt;li&gt;SDDC Manager VM system directory has enough disk space&lt;/li&gt;
&lt;li&gt;Service availability check&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Operations Manager
&lt;ul&gt;
&lt;li&gt;Common services availability check&lt;/li&gt;
&lt;li&gt;Inventory status check&lt;/li&gt;
&lt;li&gt;SDDC Manager VM database data directory has enough disk space&lt;/li&gt;
&lt;li&gt;SDDC Manager VM has enough disk space&lt;/li&gt;
&lt;li&gt;SDDC Manager VM log directory has enough disk space&lt;/li&gt;
&lt;li&gt;SDDC Manager VM system directory has enough disk space&lt;/li&gt;
&lt;li&gt;Service availability check&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Platform Services Controllers
&lt;ul&gt;
&lt;li&gt;PSC health&lt;/li&gt;
&lt;li&gt;Credential availability&lt;/li&gt;
&lt;li&gt;Inventory status check&lt;/li&gt;
&lt;li&gt;LCM bundle repo available&lt;/li&gt;
&lt;li&gt;NTP sync&lt;/li&gt;
&lt;li&gt;PSC inventory status check&lt;/li&gt;
&lt;li&gt;PSC SSO connection check&lt;/li&gt;
&lt;li&gt;PSC vmdir service check&lt;/li&gt;
&lt;li&gt;LCM bundle repo free space&lt;/li&gt;
&lt;li&gt;SDDC Manager VM has enough disk space&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;NSX Manager
&lt;ul&gt;
&lt;li&gt;Backup availability&lt;/li&gt;
&lt;li&gt;Credential availability&lt;/li&gt;
&lt;li&gt;Enter maintenance dryrun check&lt;/li&gt;
&lt;li&gt;Inventory status check&lt;/li&gt;
&lt;li&gt;LCM bundle repo available&lt;/li&gt;
&lt;li&gt;NSX audit check&lt;/li&gt;
&lt;li&gt;NSX manager inventory status check&lt;/li&gt;
&lt;li&gt;NTP sync&lt;/li&gt;
&lt;li&gt;NSX for vSphere plugin connectivity check&lt;/li&gt;
&lt;li&gt;NSX precheck init&lt;/li&gt;
&lt;li&gt;LCM bundle repo free space&lt;/li&gt;
&lt;li&gt;SDDC Manager VM has enough disk space&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;vCenter
&lt;ul&gt;
&lt;li&gt;vCenter health&lt;/li&gt;
&lt;li&gt;Credential availability&lt;/li&gt;
&lt;li&gt;Inventory status check&lt;/li&gt;
&lt;li&gt;LCM bundle repo available&lt;/li&gt;
&lt;li&gt;NTP sync&lt;/li&gt;
&lt;li&gt;LCM bundle repo free space&lt;/li&gt;
&lt;li&gt;SDDC Manager VM has enough disk space&lt;/li&gt;
&lt;li&gt;vCenter inventory status&lt;/li&gt;
&lt;li&gt;VIM API&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Common Services
&lt;ul&gt;
&lt;li&gt;Credential availability&lt;/li&gt;
&lt;li&gt;Inventory status check&lt;/li&gt;
&lt;li&gt;LCM bundle repo available&lt;/li&gt;
&lt;li&gt;NGINX check&lt;/li&gt;
&lt;li&gt;NTP sync&lt;/li&gt;
&lt;li&gt;LCM bundle repo free space&lt;/li&gt;
&lt;li&gt;SDDC Manager VM has enough disk space&lt;/li&gt;
&lt;li&gt;SDDC Manager VM log directory has enough disk space&lt;/li&gt;
&lt;li&gt;SDDC Manager VM system directory has enough disk space&lt;/li&gt;
&lt;li&gt;Service availability check&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;vSAN
&lt;ul&gt;
&lt;li&gt;Advanced configuration sync health&lt;/li&gt;
&lt;li&gt;CLOMD liveness health&lt;/li&gt;
&lt;li&gt;Cluster health&lt;/li&gt;
&lt;li&gt;Encryption health&lt;/li&gt;
&lt;li&gt;HCL age&lt;/li&gt;
&lt;li&gt;HCL health&lt;/li&gt;
&lt;li&gt;Network health&lt;/li&gt;
&lt;li&gt;Object health&lt;/li&gt;
&lt;li&gt;Health summary&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;LCM
&lt;ul&gt;
&lt;li&gt;Depot connection&lt;/li&gt;
&lt;li&gt;Depot user&lt;/li&gt;
&lt;li&gt;LCM bundle repo available&lt;/li&gt;
&lt;li&gt;LCM database schema version&lt;/li&gt;
&lt;li&gt;LCM directory permissions&lt;/li&gt;
&lt;li&gt;SDDC Manager VM database data directory has enough disk space&lt;/li&gt;
&lt;li&gt;SDDC Manager VM has enough disk space&lt;/li&gt;
&lt;li&gt;SDDC Manager VM log directory has enough disk space&lt;/li&gt;
&lt;li&gt;SDDC Manager VM system directory has enough disk space&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;ESXi Hosts
&lt;ul&gt;
&lt;li&gt;Config check&lt;/li&gt;
&lt;li&gt;Enter maintenance dryrun check&lt;/li&gt;
&lt;li&gt;Inventory status&lt;/li&gt;
&lt;li&gt;NSX sync&lt;/li&gt;
&lt;li&gt;VIM API&lt;/li&gt;
&lt;li&gt;LCM bundle repo available&lt;/li&gt;
&lt;li&gt;LCM bundle repo freespace&lt;/li&gt;
&lt;li&gt;Local filesystem check&lt;/li&gt;
&lt;li&gt;vCenter Connection&lt;/li&gt;
&lt;li&gt;VUM Health&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Each check returns health state green, yellow or red if an issue is detected some information on impact and remediation is made available. Sometimes the information returned isn&amp;rsquo;t perfect. The LCM pre-checks output to two files which can be useful in the understanding issue.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;/var/log/vmware/vcf/lcm/lcm.log
/var/log/vmware/vcf/lcm/lcm-debug.log
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Not all issues require full remediation. In my nested lab environment, the vSAN HCL returns a red issue which can never be resolved. I can either just ignore the error and proceed or we can look to disable the particular check in the configuration.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;vi /opt/vmware/vcf/lcm/lcm-app/conf/application-prod.properties
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;bundle-apply&#34;&gt;Bundle Apply&lt;/h2&gt;
&lt;p&gt;When you are happy with environmental health next to move to apply bundles. To move between Cloud Foundation versions can require applying multiple bundles.  For example, when moving from 3.5.1 to 3.7.1 following bundles are required.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SDDC Manager
&lt;ul&gt;
&lt;li&gt;3.5.1-12050813 to 3.7.0-12696026 (bundle-9775.tar)&lt;/li&gt;
&lt;li&gt;3.7.0-12696026 to 3.7.0-12698020 (bundle-9776.tar)&lt;/li&gt;
&lt;li&gt;3.7.0-12698020 to 3.7.1 (bundle-11811)&lt;/li&gt;
&lt;li&gt;3.7.0-12698020 to 3.7.1 part 2 (bundle-11813)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Management domain
&lt;ul&gt;
&lt;li&gt;NSX 6.4.1 to 6.4.4 (bundle-6712)&lt;/li&gt;
&lt;li&gt;vCenter 6.5 to 6.7.0-10244745 (bundle-6713)&lt;/li&gt;
&lt;li&gt;vCenter 6.7.0-10244745 to vCenter 6.7.0-11726888 (bundle-9777)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Workload domain
&lt;ul&gt;
&lt;li&gt;NSX 6.4.1 to 6.4.4 (bundle-6712)&lt;/li&gt;
&lt;li&gt;vCenter 6.5 to 6.7.0-10244745 (bundle-6713)&lt;/li&gt;
&lt;li&gt;vCenter 6.7.0-10244745 to vCenter 6.7.0-11726888 (bundle-9777)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Some of the bundles can take a long time to apply and the UI isn&amp;rsquo;t very verbose. It is very useful to hold an SSH session to SDDC Manager to tail the summary log file to view progress when applying bundles.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;tail -f /var/log/vmware/vcf/lcm/lcm.log
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The main workflow process spawns other processes so those main upgrade log files sometimes aren’t that verbose and often don’t help identify the issue. It is useful to understand that the spawned processes also log to folder UUID of the bundle apply task. The different bundles create sub-folders and write various logs examples.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;/var/log/vmware/vcf/lcm/upgrades/&amp;lt;upgrade_ID&amp;gt;/thirdparty/sddc-migration-app/logs
/var/log/vmware/vcf/lcm/upgrades/&amp;lt;upgrade_ID&amp;gt;/sddcmanager-migration-app/logs/sddcmanager_migration_app_upgrade.log
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;skip-level-upgrades&#34;&gt;Skip Level Upgrades&lt;/h2&gt;
&lt;p&gt;As we found before moving between Cloud Foundation versions can lead to applying multiple bundles to the same product. The skip-level upgrade tool was introduced to allow easier uplift to 3.10.1.2 or 3.10.2. For NSX for vSphere based workload domains can uplift to 3.10 from 3.5 and for NSX-T can uplift from 3.7.1.&lt;/p&gt;
&lt;p&gt;Here I am using the skip level upgrade tool to uplift a 3.5.1 NSX-V environment to 3.10.2 some twenty six bundles.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/vcf-lcm-skip-download.png&#34; alt=&#34;Skip Level Download&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;apache-cassandra&#34;&gt;Apache Cassandra&lt;/h2&gt;
&lt;p&gt;The application uses a Apache Cassandra database to store data. When troubleshooting it can be useful to look through the contents.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;## SSH to SDDC manager and open client&lt;/span&gt;
cqlsh --cqlversion&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;3.4.4 127.0.0.1 &lt;span style=&#34;color:#ae81ff&#34;&gt;9042&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;## Get all keyspaces&lt;/span&gt;
describe keyspaces;

&lt;span style=&#34;color:#75715e&#34;&gt;## Change to lcmkeyspace&lt;/span&gt;
use lcmkeyspace;

&lt;span style=&#34;color:#75715e&#34;&gt;## Get all lcmkeyspace tables&lt;/span&gt;
describe tables;

&lt;span style=&#34;color:#75715e&#34;&gt;## Get all host entries from upgrade_activity_log table in json format&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;select&lt;/span&gt; json * from upgrade_activity_log;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
        
      </description>
    </item>
    
    <item>
      <title>Pi Supercomputer</title>
      <link>https://darrylcauldwell.github.io/post/homelab-pi-mpi/</link>
      <pubDate>Tue, 30 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/homelab-pi-mpi/</guid>
      <description>
        
          &lt;p&gt;Following on from &lt;a href=&#34;https://darrylcauldwell.github.io/post/homelab-pi&#34;&gt;base Ubuntu build&lt;/a&gt; here I begin to look at Parrallel Programming.&lt;/p&gt;
&lt;h2 id=&#34;parrallel-programming&#34;&gt;Parrallel Programming&lt;/h2&gt;
&lt;p&gt;Each Raspberry Pi is a small unit of compute, one of my goals is to understand how operating many in a cluster. There are various approaches to parallel computational models, message-passing has proven to be an effective one. MPI the Message Passing Interface, is a standardized and portable message-passing system designed to function on a wide variety of parallel computers.&lt;/p&gt;
&lt;p&gt;My prefered language is Python and usefully there is &lt;a href=&#34;https://mpi4py.readthedocs.io/en/stable/install.html&#34;&gt;MPI for Python&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo apt-get install -y libopenmpi-dev python-dev pip
sudo pip install mpi4py
mpirun --version
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;All the RPIs in the cluster will access each other via SSH, this communication needs to be passwordless. The first thing you need to do is generate an SSH key pair on first host.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ssh-keygen -t rsa -b 4096
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Once key generated to enable passwordless access, upload a copy of the public key to the other three servers.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ssh-copy-id ubuntu@[server_ip_address]
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Repeat keygen and copy public key process on all four hosts.&lt;/p&gt;
&lt;p&gt;In order for mpi to distribute workload the node where execution occurs needs to understand which nodes are available.  The machinename parameter can be used to point to a text file containing list of nodes.&lt;/p&gt;
&lt;p&gt;In order name we can use names we can add entries to hosts file.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo sh -c &#39;echo &amp;quot;192.168.1.100 rpi-0&amp;quot; &amp;gt;&amp;gt; /etc/hosts&#39;
sudo sh -c &#39;echo &amp;quot;192.168.1.101 rpi-1&amp;quot; &amp;gt;&amp;gt; /etc/hosts&#39;
sudo sh -c &#39;echo &amp;quot;192.168.1.102 rpi-2&amp;quot; &amp;gt;&amp;gt; /etc/hosts&#39;
sudo sh -c &#39;echo &amp;quot;192.168.1.103 rpi-3&amp;quot; &amp;gt;&amp;gt; /etc/hosts&#39;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We can then create a file in home directory listing nodes.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cat &amp;lt;&amp;lt;EOF &amp;gt;&amp;gt; ~/machinefile
rpi-0
rpi-1
rpi-2
rpi-3
EOF
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The easiest way to run commands or code is with the mpirun command. This command, run in a shell, will launch multiple copies of your code, and set up communications between them. As each Pi has four cores and we have four we can specify number of processors to run as sixteen.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mpirun -np 16 -machinefile ~/machinefile vcgencmd measure_temp
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/pi/mpirun_temp.png&#34; alt=&#34;MPIRUN Measure Temparature&#34;&gt;&lt;/p&gt;
&lt;p&gt;While its interesting running individual commands across nodes the MPI for Python module exposes options for programs to spread load.  A simple test of this is where we scatter a bunch of elements, like those in a list, to processing nodes.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cat &amp;lt;&amp;lt;EOF &amp;gt;&amp;gt; ~/scatter.py
from mpi4py import MPI

comm = MPI.COMM_WORLD
size = comm.Get_size()
rank = comm.Get_rank()

if rank == 0:
   data = [(x+1)**x for x in range(size)]
   print (&#39;we will be scattering:&#39;,data)
else:
   data = None
   
data = comm.scatter(data, root=0)
print (&#39;rank&#39;,rank,&#39;has data:&#39;,data)
EOF
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Once script created execute:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mpirun -np 16 -machinefile ~/machinefile python3 ~/scatter.py
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/pi/mpirun_scatter.png&#34; alt=&#34;MPIRUN Scatter&#34;&gt;&lt;/p&gt;
&lt;p&gt;While scattering elements of a list is interesting splitting up a processing problem and distributing to multiple processing nodes is more fun.  Calculating Pi is a nice example of this,  and its nice for a Pi cluster to calculate Pi with MPI.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#pi.py&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; mpi4py &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; MPI

comm &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; MPI&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;COMM_WORLD
rank &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; comm&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Get_rank()
size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; comm&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Get_size()

slice_size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1000000&lt;/span&gt;
total_slices &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;# This is the controller node.&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; rank &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:
    pi &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
    slice &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
    process &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;

    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; (size)

    &lt;span style=&#34;color:#75715e&#34;&gt;# Send the first batch of processes to the nodes.&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;while&lt;/span&gt; process &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; size &lt;span style=&#34;color:#f92672&#34;&gt;and&lt;/span&gt; slice &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; total_slices:
        comm&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;send(slice, dest&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;process, tag&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; (&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Sending slice&amp;#34;&lt;/span&gt;,slice,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;to process&amp;#34;&lt;/span&gt;,process)
        slice &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
        process &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;

    &lt;span style=&#34;color:#75715e&#34;&gt;# Wait for the data to come back&lt;/span&gt;
    received_processes &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;while&lt;/span&gt; received_processes &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; total_slices:
        pi &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; comm&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;recv(source&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;MPI&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ANY_SOURCE, tag&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
        process &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; comm&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;recv(source&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;MPI&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ANY_SOURCE, tag&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; (&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Recieved data from process&amp;#34;&lt;/span&gt;, process)
        received_processes &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;

        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; slice &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; total_slices:
            comm&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;send(slice, dest&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;process, tag&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
            &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; (&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Sending slice&amp;#34;&lt;/span&gt;,slice,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;to process&amp;#34;&lt;/span&gt;,process)
            slice &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;

    &lt;span style=&#34;color:#75715e&#34;&gt;# Send the shutdown signal&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; process &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,size):
        comm&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;send(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, dest&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;process, tag&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)

    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; (&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Pi is&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4.0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; pi)

&lt;span style=&#34;color:#75715e&#34;&gt;# These are the worker nodes, where rank &amp;gt; 0. They do the real work&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
    &lt;span style=&#34;color:#66d9ef&#34;&gt;while&lt;/span&gt; True:
        start &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; comm&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;recv(source&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, tag&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; start &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;break&lt;/span&gt;

        i &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
        slice_value &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;while&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; slice_size:
            &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; i&lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:
                slice_value &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;(start&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;slice_size&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;i)&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
            &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
                slice_value &lt;span style=&#34;color:#f92672&#34;&gt;-=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;(start&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;slice_size&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;i)&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
            i &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;

        comm&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;send(slice_value, dest&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, tag&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
        comm&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;send(rank, dest&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, tag&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Execute script with mpi and watch it distribute the calculation around the nodes and aggregate these to final answer.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mpirun -np 16 -machinefile ~/machinefile python3 pi.py
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/pi/pi_with_mpi_on_pi.png&#34; alt=&#34;Pi with MPI on Pi&#34;&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Comparing SD and USB 3 Storage Performance With Raspberry Pi4B</title>
      <link>https://darrylcauldwell.github.io/post/homelab-pi-storage/</link>
      <pubDate>Mon, 29 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/homelab-pi-storage/</guid>
      <description>
        
          &lt;p&gt;Following on from &lt;a href=&#34;https://darrylcauldwell.github.io/post/homelab-pi&#34;&gt;base Ubuntu build&lt;/a&gt; here I look at the comparing the storage performance of SD and USB.&lt;/p&gt;
&lt;h2 id=&#34;sd-card-performance&#34;&gt;SD Card Performance&lt;/h2&gt;
&lt;p&gt;Linux FIO tool will be used to measure sequential write performance of a 4GB file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=4G --readwrite=write
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/pi/sd_reads.png&#34; alt=&#34;SD Card Read Performance&#34;&gt;&lt;/p&gt;
&lt;p&gt;The tool output shows sequential read rate:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;IOPS=10.1k, BW=39.5MiB/s&lt;/li&gt;
&lt;li&gt;IOPS=10.1k, BW=39.3MiB/s&lt;/li&gt;
&lt;li&gt;IOPS=10.1k, BW=39.4MiB/s&lt;/li&gt;
&lt;li&gt;IOPS=10.1k, BW=39.3MiB/s&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Similarly, the tool will be used to measure sequential read performance of a 4GB file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=4G --readwrite=read
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/pi/sd_writes.png&#34; alt=&#34;SD Card Write Performance&#34;&gt;&lt;/p&gt;
&lt;p&gt;The tool output shows sequential write rate:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;IOPS=5429, BW=21.2MiB/s&lt;/li&gt;
&lt;li&gt;IOPS=5128, BW=20.0MiB/s&lt;/li&gt;
&lt;li&gt;IOPS=5136, BW=20.1MiB/s&lt;/li&gt;
&lt;li&gt;IOPS=5245, BW=20.5MiB/s&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;With the SD card the performance bottleneck is the reader which supports peak bandwidth 50MiB/s. To test this I has a lower spec SanDisk Ultra card so I repeated test and got near exact throughput to the SanDisk Extreme.&lt;/p&gt;
&lt;p&gt;The tool output shows sequential read rate:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;IOPS=10.1k, BW=39.4MiB/s&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The tool output shows sequential write rate:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;IOPS=5245, BW=20.5MiB/s&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;usb-flash-performance&#34;&gt;USB Flash Performance&lt;/h2&gt;
&lt;p&gt;The USB flash drive should deliver improved performance, first check it can be seen by the system and note its device.&lt;/p&gt;
&lt;p&gt;Then repeated the same performance tests using fio on the SSD. Linux FIO tool will be used to measure sequential write/read performance of a 4GB file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd /mnt/ssd
fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=4G --readwrite=write
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/pi/usb_writes.png&#34; alt=&#34;USB Write Performance&#34;&gt;&lt;/p&gt;
&lt;p&gt;The tool output shows sequential write rate:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;IOPS=14.5k, BW=56.6MiB/s&lt;/li&gt;
&lt;li&gt;IOPS=14.4k, BW=56.4MiB/s&lt;/li&gt;
&lt;li&gt;IOPS=14.4k, BW=56.2MiB/s&lt;/li&gt;
&lt;li&gt;IOPS=11.9k, BW=46.6MiB/s&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;cd /mnt/ssd
fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=/mnt/ssd/test --bs=4k --iodepth=64 --size=4G --readwrite=read
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/pi/usb_reads.png&#34; alt=&#34;USB Read Performance&#34;&gt;&lt;/p&gt;
&lt;p&gt;The tool output shows sequential read rate:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;IOPS=33.3k, BW=130MiB/s&lt;/li&gt;
&lt;li&gt;IOPS=37.0k, BW=148MiB/s&lt;/li&gt;
&lt;li&gt;IOPS=42.6k, BW=166MiB/s&lt;/li&gt;
&lt;li&gt;IOPS=42.5k, BW=166MiB/s&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;
&lt;p&gt;So for a very small investment in the USB Flash Drives we&amp;rsquo;ve increased sequential read potential by 4X and write potential by 3X over the SD card.  The Pi 4 firmware doesn&amp;rsquo;t presently offer option for USB boot so the SD cards are needed but hopefully soon the firmware will get updated.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Raspberry Pi Cluster Ubuntu Base</title>
      <link>https://darrylcauldwell.github.io/post/homelab-pi-ubuntu/</link>
      <pubDate>Sun, 28 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/homelab-pi-ubuntu/</guid>
      <description>
        
          &lt;p&gt;Following on from &lt;a href=&#34;https://darrylcauldwell.github.io/post/homelab-pi&#34;&gt;Raspberry Pi Cluster&lt;/a&gt; here I look at the base Ubuntu build.&lt;/p&gt;
&lt;h2 id=&#34;install-and-configure&#34;&gt;Install and Configure&lt;/h2&gt;
&lt;p&gt;I used &lt;a href=&#34;https://www.raspberrypi.org/software/&#34;&gt;Raspberry Pi imager&lt;/a&gt; to install the Ubuntu 20.10 64bit on each SD Card.  Insert these into the Pi&amp;rsquo;s and power them on.&lt;/p&gt;
&lt;p&gt;The image is configured with DHCP client, &lt;a href=&#34;https://maclookup.app/macaddress/DCA632&#34;&gt;Pi device MAC addresses are prefixed DC:A6:32&lt;/a&gt;. I connected to my router which acts as DHCP server and found the four leases sorting by MAC. With the DHCP addresses can connect via SSH, the Ubuntu image has default username of &lt;code&gt;ubuntu&lt;/code&gt; and password &lt;code&gt;ubuntu&lt;/code&gt;. You&amp;rsquo;re prompted to change password at first connect.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/pi/ubuntu-pw.png&#34; alt=&#34;Ubuntu Password&#34;&gt;&lt;/p&gt;
&lt;p&gt;I want to reliably know how to connect to these and like to change from dynamic to a staticly asssigned IP address. To do this for Ubuntu 20.10 we update Netplan configuration.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo vi /etc/netplan/50-cloud-init.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Here is example of how I update this to reflect static IP.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;network:
    ethernets:
        eth0:
            addresses: [192.168.1.100/24]
            gateway4: 192.168.1.254
            nameservers:
              addresses: [8.8.8.8,8.8.4.4]
            dhcp4: no
            match:
                driver: bcmgenet smsc95xx lan78xx
            optional: true
            set-name: eth0
    version: 2
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;With the configuration file updated can have netplan load the config.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo netplan --debug apply
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;With any new install its useful to apply latest patches.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo apt update
sudo apt upgrade -y
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;install-tools&#34;&gt;Install Tools&lt;/h2&gt;
&lt;p&gt;The VideoCore packages provide command line utilities that can get various pieces of information from the VideoCore GPU on the Raspberry Pi. The linux flexible I/O tester tool is  easy to use and useful for understanding storage sub-system performance.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo apt install -y libraspberrypi-bin
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;# Storage Performance&lt;/p&gt;
&lt;p&gt;The linux flexible I/O tester tool is  easy to use and useful for understanding storage sub-system performance.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo apt install -y fio
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;usb-flash-disk&#34;&gt;USB Flash Disk&lt;/h2&gt;
&lt;p&gt;The SD card on the Pi will normally show as /dev/mmcblk0. The USB drive will normally show as /dev/sda. The following could be data destructive so check the enumeration before proceeding.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo fdisk -l
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/pi/usb_dev.png&#34; alt=&#34;USB Device&#34;&gt;&lt;/p&gt;
&lt;p&gt;Then create primary partition on USB device&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo sfdisk /dev/sda &amp;lt;&amp;lt; EOF
;
EOF
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/pi/usb_dev.png&#34; alt=&#34;USB Partition&#34;&gt;&lt;/p&gt;
&lt;p&gt;Then format and label the partition then mount and set permissions for the parition&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo mkfs.ext4 -L SSD /dev/sda1
sudo mkdir /mnt/ssd
sudo mount /dev/sda1 /mnt/ssd
echo &amp;quot;LABEL=SSD  /mnt/ssd  ext4  defaults 0 2&amp;quot; | sudo cat /etc/fstab -
sudo chmod 777 .
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/pi/usb_ext4.png&#34; alt=&#34;USB Mount&#34;&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Raspberry Pi Cluster Hardware</title>
      <link>https://darrylcauldwell.github.io/post/homelab-pi/</link>
      <pubDate>Sat, 27 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/homelab-pi/</guid>
      <description>
        
          &lt;p&gt;I have worked most of my professional life with systems built with Intel x86, x64 and ia64 chips. Intel processors use Complex Instruction Set Computing while Arm uses Reduced Instruction Set Computing. Processors with CISC architecture look to move complexity to hardware to simlify code, so small code sizes with high cycles per second. Processors with RISC architecture invert the relationship larger code size with low cycles per second.&lt;/p&gt;
&lt;p&gt;Anyone who has worked in a data center has an awareness of importance of the amount of heat generated by Intel powered servers. There isn’t much heat generated from allowing electricity to flow through something (unless there is A LOT of electricity). All of Arm’s designs are energy efficient which is why they have become popular for running in smartphones, tablets and other embedded devices. If Arm processors can get traction used in servers this can only be good news for data center electricity usage.&lt;/p&gt;
&lt;p&gt;I enjoy learning by doing and to begin to better understand Arm looked to build a cluster of Raspberry Pi. My goals of cluster include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Understanding more about Raspberry Pi hardware&lt;/li&gt;
&lt;li&gt;Understanding how an distributed application might work across physical hosts using MPI. MPI is a programming model that is widely used for parallel programming in a cluster.&lt;/li&gt;
&lt;li&gt;Understanding how micro-servies application may work in Edge locations running Kubernetes on low-cost hardware.&lt;/li&gt;
&lt;li&gt;Understanding how ESXi on Arm development is progressing&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Project repository: &lt;a href=&#34;https://github.com/darrylcauldwell/piCluster&#34;&gt;https://github.com/darrylcauldwell/piCluster&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;pi-cluster-rack-hardware&#34;&gt;Pi Cluster Rack Hardware&lt;/h1&gt;
&lt;h2 id=&#34;power-over-ethernet&#34;&gt;Power over Ethernet&lt;/h2&gt;
&lt;p&gt;One of my goals for the cluster was the hardware self-contained and easy to connect to network and power. Out of the box the Raspberry Pi 4b is powered over USB-C and operates at 5.1V upto 3A so has maximum draw (5.1*3=) 15.3watt. While I could use one official Raspberry Pi USB-C 15.3watt power supply for each this would require four power sockets. A cleaner cabling solution is to equip each Pi 4b with a PoE HAT and power each using a Power over Ethernet–enabled network. When the Pi is cabled to a PoE network switch port the power gets routed to four PoE pins on the Pi board. The PoE switch ports deliver between 27-57volts. The PoE HAT connects to the four PoE pins and has onboard transformer which converts input voltage to 5volt and then routes this to the GPIO power pins.&lt;/p&gt;
&lt;h2 id=&#34;network-switch&#34;&gt;Network Switch&lt;/h2&gt;
&lt;p&gt;For selecting the PoE network switch there are two important factors I considered.  PoE has two specifications the initial 802.3af (upto 15watt) and revised 802.3at (upto 30watt), the Pi 4b has 15.3watt maximum draw so ports supporting 802.3af.  Another important factor to consider is maximum draw across  all PoE ports here our maximum draw would be (15.3*4=) 61.2watts. The Netgear GS305P has five ports with four supported for 802.3af or 802.3at and is rated for 63W power draw, it is also compact with dimensions 158 x 101 x 29 mm.&lt;/p&gt;
&lt;h2 id=&#34;storage&#34;&gt;Storage&lt;/h2&gt;
&lt;p&gt;For storage selection the SanDisk Extreme offers sequential read up to 160MB/sec and sequential write up to 90MB/sec. The SanDisk Ultra offers sequential read up to 100MB/sec and sequential write up to 90MB/sec. The Pi4B has a dedicated SD card socket which suports 1.8V, DDR50 mode (at a peak bandwidth of 50 Megabytes / sec). The Pi 4h as a USB 3 interface which has peak bandwidth 620 Megabytes / sec. The Arcanite 128GB USB 3.1 Flash Drive has a small formfactor and low cost and offers read speeds up to 400 MB/s and write speeds up to 100 MB/s.&lt;/p&gt;
&lt;h2 id=&#34;mounting-rack&#34;&gt;Mounting Rack&lt;/h2&gt;
&lt;p&gt;Towards goal of keeping cluster self contained I wanted to house the network switch and four Pi 4b in a rack. There are vaious off the shelf options for stacking Pi&amp;rsquo;s but I couldn&amp;rsquo;t find a great solution for my specific requirement. I&amp;rsquo;d not done a project using custom cut metal before and thought this would be a  good opportunity to explore. I thought aluminium would be good to polish to a nice finish so I decided to use 3mm medium strength 5251 aluminium.&lt;/p&gt;
&lt;p&gt;I found a UK based mail-order laser cutting provider &lt;a href=&#34;https://lasered.co.uk/&#34;&gt;Lasered&lt;/a&gt;. To make the order required drawing in either Drawing Interchange Format (DXF), AutoCAD (DWG) of Mastercam Numerical Control File (NC) format to  create this I used open-source LibreCAD software. I&amp;rsquo;d not used CAD software before so there was a learning curve but this was not large and within few hours I&amp;rsquo;d created two drawings. The cluster will primarily be used  as Kubernetes cluster so I designed all the plates shaped as heptagons, the top and base plates also have Raspberry Pi logo. For attaching plates together allowing enough space for airflow I chose 35mm standoffs with M4 thread to accept M4 I gave holes a 4.2mm radius. For mounting the Pi the board has 2.7mm holes to accept M2.5 thread screws so I mirror these on the plate with 2.7mm radius and use 5mm standoff to lift slightly. I added a rectangular hole behin Pi on each shelf to allow for internal PoE cable routing. The rack dimensions when assembled, widest points the heptagon is 210mm and (6x3mm=)18mm plates plus (5x40mm)=200 standoffs gives total height of 218mm.
&lt;img src=&#34;https://darrylcauldwell.github.io/images/pi/cut_plates.jpeg&#34; alt=&#34;Laser cut plates&#34;&gt;&lt;/p&gt;
&lt;p&gt;I got the plates cut and they looked better than expected except the standoff holes looked rather large. I checked the the calipers and noticed my planned 4.2mm holes were 8.4mm and my 2.7mm holes 5.4mm. Seems I had entered diameter as value for circle radius parameter. Luckily I hadn&amp;rsquo;t ordered the standoffs, nuts or bolts. It was easy to switched from M4 to M6 for the between layer standoffs but as the Pi board only accepts M2.5 I kept these and added a washer to prevent bolt going straight through the mount hole on the shelf.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/pi/radius_diameter.jpeg&#34; alt=&#34;Oops radius != diameter&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/pi/first_assembly.jpeg&#34; alt=&#34;First assembly&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;rack-cabling&#34;&gt;Rack Cabling&lt;/h2&gt;
&lt;p&gt;To keep the internal rack cabling tidy I decided to create each cable with custom length. The PoE standards require category 3 cable or better for 802.3af (upto 15watt) and category 5 cable for better for 802.3at (upto 30watt). The Raspberry Pi NIC can operate at 1Gb/s, category 5 is cable rated for 100Mb/s, category 5e is cable rated for 1Gb/s, category 6 is cable rated for 10Gb/s. To operate the Pi&amp;rsquo;s over PoE at full potential I use category 5e cable and crimped RJ45 connectors.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/pi/custom_cables.jpeg&#34; alt=&#34;Custom cable lengths&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;finished-rack&#34;&gt;Finished Rack&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/pi/rack_full.jpeg&#34; alt=&#34;Pi Rack Full&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/pi/rack_side.jpeg&#34; alt=&#34;Pi Rack Side&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;hardware-bill-of-materials&#34;&gt;Hardware Bill of materials&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;35mm M6 Standoffs (Bag 50) £30&lt;/li&gt;
&lt;li&gt;10mm M6 screws (Bag 100) £6.45&lt;/li&gt;
&lt;li&gt;M6 hexagonal nuts (Bag 250) £6&lt;/li&gt;
&lt;li&gt;5mm M2.5 Standoffs (Bag 20) £5&lt;/li&gt;
&lt;li&gt;6mm M2.5 screws (Bag 100) £3.50&lt;/li&gt;
&lt;li&gt;Custom laser cut aluminium plates £60&lt;/li&gt;
&lt;li&gt;&amp;lt;1m Cat5e cable&lt;/li&gt;
&lt;li&gt;RJ45 cable crimping tool kit £20&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Total rack parts cost ~£130&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;4x Raspberry Pi 4B WITH 8GB RAM (4X £73.50=) £294&lt;/li&gt;
&lt;li&gt;4x Raspberry Pi PoE HAT (4x £18=) £72&lt;/li&gt;
&lt;li&gt;4x 128GB SanDisk Extreme (4x £24=) £96&lt;/li&gt;
&lt;li&gt;4x Arcanite 128GB USB 3.1 Flash Drive (4x £20=) £80&lt;/li&gt;
&lt;li&gt;Netgear GS305P £45&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Total cluster parts cost ~£717&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Customizing Zsh Prompt</title>
      <link>https://darrylcauldwell.github.io/post/zsh/</link>
      <pubDate>Wed, 27 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/zsh/</guid>
      <description>
        
          &lt;p&gt;macOS 10.15 Catalina changed default Terminal from bash to zsh. When I first moved I tried Powerline extension but it was always a bit slow and really I all I need is a custom prompt. So today I revisited this and created a custom prompt for Zsh and learned a little along the way.&lt;/p&gt;
&lt;p&gt;First I create an empty ~/.hushlogin to suppress the status message at the start of each Terminal session.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;touch ~/.hushlogin
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;a href=&#34;http://zsh.sourceforge.net/Doc/Release/Prompt-Expansion.html&#34;&gt;Prompt expansion&lt;/a&gt; can be used to customize the experience. The default prompt in zsh is %n%m%#.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;%n username&lt;/li&gt;
&lt;li&gt;%m hostname&lt;/li&gt;
&lt;li&gt;%# shell state, # when privileges, otherwise %&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So my default login prompt would show&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;dcauldwell@dcauldwell-a01 ~ %
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;PROMPT is variable so can be be set interactively give you immediate feedback and when you&amp;rsquo;re happy add to a startup script like ~/.zshrc so it loads automagically every time.&lt;/p&gt;
&lt;p&gt;The options I choose to set:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;%(?.%F{green}√.%F{red}?%?) will show  previous Exit Code&lt;/li&gt;
&lt;li&gt;%F{blue} defines foreground colour&lt;/li&gt;
&lt;li&gt;%/ current working directory&lt;/li&gt;
&lt;li&gt;%F{cyan} defines foreground colour&lt;/li&gt;
&lt;li&gt;%# shell state&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Zsh ships with a framework for getting information from version control systems, called vcs_info. When working within Git repositories in Terminal its useful to know which is active branch your editing.&lt;/p&gt;
&lt;p&gt;We make the vcs_info framework by loading it:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;autoload -Uz vcs_info
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Run vcs_info just before a prompt is displayed (precmd)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;precmd_vcs_info() { vcs_info }
precmd_functions+=( precmd_vcs_info )
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Enable option for PROMPT_SUBST which turns on command substitution in the prompt:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;setopt prompt_subst
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We can then call its methods and consume within prompt, my new ~/.zshrc file looks like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cat ~/.zshrc
autoload -Uz vcs_info
precmd_vcs_info() { vcs_info }
precmd_functions+=( precmd_vcs_info )
setopt prompt_subst
PROMPT=&#39;%(?.%F{green}√.%F{red}?%?)%F{blue} %/ %F{yellow}${vcs_info_msg_0_}%F{magenta} %# &#39;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/zsh-profile.jpg&#34; alt=&#34;This is the end state&#34;&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Running Linux on iPhone</title>
      <link>https://darrylcauldwell.github.io/post/ish/</link>
      <pubDate>Fri, 06 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/ish/</guid>
      <description>
        
          &lt;p&gt;iSH is a &lt;a href=&#34;https://github.com/ish-app/ish&#34;&gt;project&lt;/a&gt; which offers a Linux shell environment on iOS using a usermode x86 emulator.&lt;/p&gt;
&lt;p&gt;The emulator is based on Alpine Linux but does not ship with SSH or APK the Alpine Linux package manager. To install the package manager with iSH and ultimately other tools we can download this with Safari from following URL.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;http://dl-cdn.alpinelinux.org/alpine/latest-stable/main/x86/apk-tools-static-2.10.5-r1.apk
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The emulator does not by default have access to iCloud Drive files, but this can be mounted by running following.  Note when mounting iCloud Drive you get prompted which folder,  you can select root or Downloads folder where APK install file would be located.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mount -t ios . /mnt
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;With the iCloud Drive mounted to emulator we can look to unpack and then create a symbolic link.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd /mnt/Downloads
tar xvzf apk-tools-static-2.10.5-r1.apk -C /
ln -s /sbin/apk.static /sbin/apk
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;With the package manager client installed we can install things like OpenSSH.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;apk add --no-cache openssh 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We can then use the SSH client to connect to any network reachable IP running SSH server.&lt;/p&gt;
&lt;p&gt;While exploring iSH I found another interesting thing is that it seems to share the network stack.  So if you run a web server within iSH like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;apk add --no-cache python3
echo &#39;Hello from iSH&#39; &amp;gt;&amp;gt; index.html
python3 -m http.server
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;When you see the ‘Serving HTTP on 0.0.0.0 port 8000’ message, you can then switch to safari and browse localhost.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;http://127.0.0.1:8000
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Pretty cool.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Avi Load Balancer</title>
      <link>https://darrylcauldwell.github.io/post/avi/</link>
      <pubDate>Wed, 12 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/avi/</guid>
      <description>
        
          &lt;p&gt;Here we will explore an example of how an application can be secured using NSX Advanced Load Balancer. The application is deployed to Cloud Foundation on-premises and is extended to other geographic regions using both Amazon Web Services and Azure public clouds. The application is two tier, Ant Media servers provide a user facing presentation tier and MooseFS servers provide storage.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/avi-1.jpg&#34; alt=&#34;Multi-Cloud Ant Media&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;what-is-a-layer-7-load-balancer&#34;&gt;What is a layer 7 load balancer?&lt;/h1&gt;
&lt;p&gt;Traditional load balancers operate at layer 4 and offers traffic management of transactions at the network protocol layer (TCP/UDP). A layer 4 load balancer distributes traffic to pool members with a load balancing algorithm (i.e. round-robin) and by calculating the best server based on fewest connections and fastest server response time.&lt;/p&gt;
&lt;p&gt;The Avi Load Balancer operates at layer 7 which means you can make routing decisions on various characteristics of the HTTP/HTTPS header, the content of the message, the URL type, and information in cookies. A device that performs Layer 7 load balancing is sometimes referred to as a reverse proxy server or in Kubernetes terminology an ingress controller.&lt;/p&gt;
&lt;h1 id=&#34;avi-load-balancer-architecture&#34;&gt;Avi Load Balancer Architecture&lt;/h1&gt;
&lt;p&gt;The Avi Load Balancer (ALB) uses a software-defined architecture that separates the central control plane (Controller) from the distributed data plane (Service Engines).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/avi-2.jpg&#34; alt=&#34;Avi Load Balancer Architecture&#34;&gt;&lt;/p&gt;
&lt;p&gt;The Controller acts as a single point of intelligence, management, and control for the data plane. This control plane can be self-hosted or consumed as managed software-as-a-service (SaaS). When deploying the software-as-a-service architecture model the data plane remains deployed in each environment.&lt;/p&gt;
&lt;p&gt;The Service Engines represent the data-plane and provide full-featured, enterprise-grade load balancers, WAF, or analytics that manage and secure application traffic, and collect real-time telemetry from the traffic flows. Virtual Services are deployed to the data-plane which provide virtual IP address to a pool of application servers. Pools maintain the list of servers assigned to them and perform health monitoring, load balancing, persistence, web application firewall and SSL offload. A typical virtual service will point to one pool; however, more advanced configurations may have a virtual service content switching across multiple pools.&lt;/p&gt;
&lt;p&gt;The Controllers need to continually exchange information securely with Service Engines. The Service Engines hold communications channel with controller over TCP port 22 (SSH), 8443 (HTTPS) and UDP port 123 (NTP).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/avi-3.jpg&#34; alt=&#34;Service Engine to Cntroller Communications&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;web-application-firewall&#34;&gt;Web Application Firewall&lt;/h1&gt;
&lt;p&gt;A web application firewall (or WAF) filters, monitors, and blocks HTTP traffic to and from a web application. A network firewall filters traffic at Layer 4 a web application firewall filters traffic at Layer 7. A web application firewall is a type of reverse-proxy, protecting the server from exposure by having clients pass through the WAF before reaching the server. The capability to inspecting HTTP traffic allows filtering rules which can prevent attacks stemming from web application security flaws, such as SQL injection, cross-site scripting (XSS), file inclusion, and security misconfigurations.&lt;/p&gt;
&lt;h1 id=&#34;avi-load-balancer-iwaf&#34;&gt;Avi Load Balancer iWAF&lt;/h1&gt;
&lt;p&gt;The Avi Load Balancer provides capability to configure Virtual Services with Intelligent Web Application Firewall (iWAF) capabilities.&lt;/p&gt;
&lt;p&gt;The WAF configuration is stored as profile and policy objects. These objects can be logically associated to one or many virtual services. Using this approach, an application specific profile and policy can be created and maintained which is logically to any Virtual Services in any cloud.&lt;/p&gt;
&lt;p&gt;The WAF can be set to either detect or enforce a ruleset. In detection mode the policy will evaluate the request and log request matching ruleset, in enforcement mode the policy will evaluate the request, block and log request matching ruleset. Paranoia mode can be set for each WAF policy which defines its rigidity. Specific rules are enabled or disabled based on the set paranoia mode.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/avi-4.jpg&#34; alt=&#34;Avi Load Balancer iWAF&#34;&gt;&lt;/p&gt;
&lt;p&gt;The iWAF comes with a ruleset which provides signatures to provide Core Rule Set (CRS) protection, support for compliance regulations such as PCI DSS, HIPAA, and GDPR.&lt;/p&gt;
&lt;h1 id=&#34;demonstrating-waf-ruleset&#34;&gt;Demonstrating WAF Ruleset&lt;/h1&gt;
&lt;p&gt;Core Rule Set protection primarily consists of regular expressions, and it decides for each request whether it is legitimate, an attack, or an information leak. There are various commercial and open source tools to test if WAFs are working. The testing tools can target many aspects of the WAF ruleset. It is possible to perform basic test using a web browser and look to target CRS rule 920350 ‘Host header is numeric IP address’. To be valid the Host header field must be sent in all HTTP/1.1 request messages. When the rule is enabled any traffic to IP address would be caught and only access via FQDN would be allowed.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/avi-5.jpg&#34; alt=&#34;CRS rule 920350&#34;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Within the default ‘System-WAF-Policy’ this signature is disabled by default. We cannot edit the default policy but if we duplicate it and name like ‘ANT-Media-WAF-Policy’ and change policy mode to Enforcement. Ensure the CRS 920350 signature check is disabled (default).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;With this policy applied to a Virtual Service we can direct browser to website via IP or FQDN and web page is displayed.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;When we update the policy and enable the CRS 920350 signature check requests via IP are blocked and web page can only be accessed via FQDN.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;demonstrating-waf-logging-and-exception&#34;&gt;Demonstrating WAF Logging and Exception&lt;/h1&gt;
&lt;p&gt;When a WAF policy is attached to a virtual service, specific WAF logs are generated. When WAF blocks traffic the request details get logged.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/avi-6.jpg&#34; alt=&#34;WAF Block Detected Log Graph&#34;&gt;&lt;/p&gt;
&lt;p&gt;It maybe that a rule is implemented which has unintended consequences and is blocking traffic we want to allow. Clicking on the + sign at the end of each log entry will expand the panel to provide more details. If we look through the extended details, we can see specific WAF signature which caused the log entry. There is also a button to add an WAF policy exception directly from the log view.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/avi-7.jpg&#34; alt=&#34;WAF Block Detected Log Detail&#34;&gt;&lt;/p&gt;
&lt;p&gt;This opens a wizard where we can confirm the details of the exception.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/avi-8.jpg&#34; alt=&#34;Add Exception&#34;&gt;&lt;/p&gt;
&lt;p&gt;Making an exception in this way alters the behaviour of policy immediately, in our example to allow access via IP address. In the policy itself the exception is clearly marked which can allow retrospective security change records to be created.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/avi-9.jpg&#34; alt=&#34;Exception Highlighted&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;lab-hybrid-cloud-networking&#34;&gt;Lab Hybrid Cloud Networking&lt;/h1&gt;
&lt;p&gt;The lab configuration used for testing was comprised of a Cloud Foundation on-premises cloud,  AWS and Azure. The Cloud Foundation deployment hosts an Ubuntu VM with SSL CPN client installed and is configured to maintain VPN to both AWS and Azure. Static routing is configured, and Virtual Machines and Virtual Services on the Cloud Foundation network can communicate with Virtual Machines and Virtual Services in both public clouds.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/avi-10.jpg&#34; alt=&#34;Multi-Cloud Site-to-Site VPNs&#34;&gt;&lt;/p&gt;
&lt;p&gt;Multi-cloud and hybrid cloud are closely related but are not the same. A multi-cloud approach would be hosting some services on-premises and other services in public cloud and the services operate independently. A hybrid-cloud approach would be hosting services across multiple clouds but having them integrated, communicating and exchanges data with each other. When integrating services applying consistent configuration is key, integrating services across multiple clouds is challenging.&lt;/p&gt;
&lt;h1 id=&#34;demonstrating-hybrid-cloud&#34;&gt;Demonstrating Hybrid Cloud&lt;/h1&gt;
&lt;p&gt;Another use case we can explorer is where an on-premises application is made available in its local geography but also made available in other geographies. Provide application proxy services adjacent to clients to improve performance and security.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/avi-11.jpg&#34; alt=&#34;Edge Proxy&#34;&gt;&lt;/p&gt;
&lt;p&gt;For this scenario we can deploy Virtual Service on-premises which has business application as pool members. We can deploy additional Virtual Services in public cloud which have on-premises Virtual Service as pool member. The network routing across private and public clouds is all within VPN tunnel.&lt;/p&gt;
&lt;p&gt;The separation of NSX Advanced Load Balancer control and data plane allows us to manage the Virtual Services and Web Application Firewalls deployed to multiple clouds as a hybrid-cloud. The WAF profile and policy are defined as logical objects within the control plane. These objects then have logical association to Virtual Services deployed to private and public cloud data planes. We can apply the same policy as in previous test to the Virtual Services across clouds and test the WAF rules function exactly the same.&lt;/p&gt;
&lt;h1 id=&#34;application-latency-analysis&#34;&gt;Application Latency Analysis&lt;/h1&gt;
&lt;p&gt;When operating web applications, it is essential to understand where network latency is introduced to the user experience. Out of the box when a Virtual Service is deployed you can a very easy to understand view of end-to-end latency.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/avi-12.jpg&#34; alt=&#34;Application Latency Analysis&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;traffic-capture&#34;&gt;Traffic Capture&lt;/h1&gt;
&lt;p&gt;When operating web applications, it good to understand the traffic flowing towards it. Typically to achieve this packet capture is required to be turned on at network side,  for whole VM or specific VM NIC. For NSX Advanced Load Balancer any Virtual Service can have packet capture turned on and packets captured as they flow through the Virtual Service which can be used to analysed to get a security insight.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/avi-13.jpg&#34; alt=&#34;Traffic Capture&#34;&gt;&lt;/p&gt;
&lt;p&gt;The packets are captured in PCAP Next Generation file format ( *.pcapng files ) so any analyser can be used to open and view.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/avi-14.jpg&#34; alt=&#34;Traffic Capture Analysis&#34;&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Introduction To Kubernetes Cluster Networking with Antrea</title>
      <link>https://darrylcauldwell.github.io/post/antrea/</link>
      <pubDate>Wed, 12 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/antrea/</guid>
      <description>
        
          &lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/antrea-logo.png&#34; alt=&#34;Antrea Logo&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;what-is-antrea&#34;&gt;What is Antrea&lt;/h2&gt;
&lt;p&gt;Antrea is Container Network Interface (CNI) plugin for Kubernetes. The Antrea CNI leverages Open vSwitch (OVS) to provides an overlay network and security services for a Kubernetes cluster. The overlay encapsulation uses Virtual Extensible LAN (VXLAN) by default, although Generic Network Virtualization Encapsulation (GENEVE), Generic Routing Encapsulation (GRE) or Stateless Transport Tunneling (STT) encapsulation can be configured. Antrea is an open source project hosted on GitHub &lt;a href=&#34;https://github.com/vmware-tanzu/antrea&#34;&gt;here&lt;/a&gt;. Using OVS also introduces other standard network management capabilities such NetFlow, sFlow, IP Flow Information Export (IPFIX) and Remote SPAN (RSPAN).&lt;/p&gt;
&lt;h2 id=&#34;architecture&#34;&gt;Architecture&lt;/h2&gt;
&lt;p&gt;Antrea is composed of several components deployed as Pods in the kube-system namespace of the cluster. The Antrea Conroller monitors the addition and deletion of objects by watching the Kubernetes API. A daemonset is deployed which druns Antrea Agent on each node the Agent applys flow configuration to Open vSwitch (OVS).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/antrea-architecture.png&#34; alt=&#34;Antrea Logo&#34;&gt;&lt;/p&gt;
&lt;p&gt;The network configration required by Kubernetes is configured in a collection of Open vSwitch (OVS) flow tables. To make it easy to interpret each type of network traffic is classified and each traffic classification is stored in its own flow table.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/antrea-ovs-pipeline.svg&#34; alt=&#34;OVS Pipeline&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;creating-a-simple-antrea-lab&#34;&gt;Creating A Simple Antrea Lab&lt;/h2&gt;
&lt;p&gt;We can create a lab to look at Antrea anywhere we can run some VMs so on either a public cloud or a homelab. Create three Ubuntu 19.10 VMs with 2x CPU, 4GB RAM and 50GB vHDD, use Netplan to configure NIC to static IP addressing like.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cat /etc/netplan/01-netcfg.yaml 

network:
  version: 2
  renderer: networkd
  ethernets:
    ens160:
      addresses: 
      - 192.168.1.27/24
      gateway4: 192.168.1.254
      nameservers:
          search:
          - darrylcauldwell.com
          addresses: 
          - 192.168.1.10
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Antrea requires Kubernetes 1.16 or later. Install Docker, Open vSwitch and Kubernetes by running the following.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo apt update -y
sudo apt upgrade -y
sudo apt install docker.io python apt-transport-https openvswitch-switch -y
sudo gpasswd -a $USER docker
sudo systemctl start docker
sudo systemctl enable docker
curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
sudo apt-add-repository &amp;quot;deb http://apt.kubernetes.io/ kubernetes-xenial main&amp;quot;
sudo apt-get update
sudo swapoff -a 
sudo sed -i &#39;/ swap / s/^\(.*\)$/#\1/g&#39; /etc/fstab
sudo apt-get install -y kubelet=1.16.4-00 kubeadm=1.16.4-00 kubectl=1.16.4-00
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;To form the overlay network Antrea requires an IP address block to allocate IP addresses (&amp;ndash;pod-network-cidr). We can use kubeadm to configure the IP address block and bootstrap the cluster by running the following:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo kubeadm init --pod-network-cidr=172.16.0.0/16
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In order to easily run kubectl from the master we can copy the kube config to our user profile by running the following.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;With the control plane initiatlised  we can now get the cluster token from the master we can use this to add the two worker Nodes to the cluster.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo kubeadm join 192.168.1.27:6443 --token 4bp2f0.ppfjk7mfee89j2kd \
&amp;gt;     --discovery-token-ca-cert-hash sha256:5e79610f28840c15be46895340c4a5535b9a0d003741ed657961891a05987ccd 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;All the Antrea components are containerized and can be installed using the Kubernetes deployment manifest. We can apply the default Antrea manifest supplied in GitHub repository which will deploy all necessary components.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl apply -f https://raw.githubusercontent.com/vmware-tanzu/antrea/master/build/yamls/antrea.yml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The Antrea components are deployed to the kube-system Namespace. The components include Deploymentm, Pods, Daemonset and ConfigMap.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl get all --namespace kube-system
kubectl get configmap --namespace kube-system
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The ConfigMap defines antrea-agent.conf this is used by Daemonset on each Node to configure Open vSwitch for use with CNI we can see some key information like.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl describe configmap antrea-config-tm7bht9mg6

Integration Bridge name (default: br-int)
DataPath type (default: system)
Interface name to communicate with host (default: gw0)
Tunnel (Encapsulation) type (default: vxlan)
MTU value (default: 1450)
Service CIDR (default 10.96.0.0/12)
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;exploring-the-open-vswitch-overlay-network&#34;&gt;Exploring The Open vSwitch Overlay Network&lt;/h2&gt;
&lt;p&gt;With Antrea in place we can look at exploring the overlay network it has put in place. We create a Kubernetes Namespace and deploy an simple stateless application like &lt;a href=&#34;https://kubernetes.io/docs/tutorials/stateless-application/guestbook/&#34;&gt;guestbook&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl create -f https://k8s.io/examples/admin/namespace-dev.json
kubectl config set-context --current --namespace=development
kubectl apply -f https://k8s.io/examples/application/guestbook/redis-master-deployment.yaml
kubectl apply -f https://k8s.io/examples/application/guestbook/redis-master-service.yaml
kubectl apply -f https://k8s.io/examples/application/guestbook/redis-slave-deployment.yaml
kubectl apply -f https://k8s.io/examples/application/guestbook/redis-slave-service.yaml
kubectl apply -f https://k8s.io/examples/application/guestbook/frontend-deployment.yaml
kubectl apply -f https://k8s.io/examples/application/guestbook/frontend-service.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;When running we can view the Pods IP addressing.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl get pods --output wide

NAME                            READY   STATUS    RESTARTS   AGE     IP           NODE              NOMINATED NODE   READINESS GATES
frontend-6cb7f8bd65-25qv4       1/1     Running   0          5m47s   172.16.2.4   antrea-worker-2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
frontend-6cb7f8bd65-mn5jk       1/1     Running   0          5m47s   172.16.1.5   antrea-worker-1   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
frontend-6cb7f8bd65-nr9zk       1/1     Running   0          5m47s   172.16.2.5   antrea-worker-2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
redis-master-7db7f6579f-4wdnj   1/1     Running   0          5m51s   172.16.2.2   antrea-worker-2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
redis-slave-7664787fbc-5xrvj    1/1     Running   0          5m49s   172.16.1.4   antrea-worker-1   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
redis-slave-7664787fbc-nj6m5    1/1     Running   0          5m49s   172.16.2.3   antrea-worker-2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We can see that IPs from 172.16.1.0/24 are issued to Pods running on Node antrea-worker-1 and 172.16.2.0/24 are issued to Pods running on Node antrea-worker-2. To facilitate communications between Pods the antrea-agent configures flows on Open vSwitch on each Node. If we connect to a Antrea Agent container we can see that an OVS bridge is created called br-int and the bridge has a vxlan tunnel port called tun0 and a gateway port called gw0. The internal port gw0 is allocated the role of gateway of the Node&amp;rsquo;s subnet and is allocated the first IP address in subnet.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl config set-context --current --namespace=kube-system
kubectl get pods --selector=component=antrea-agent --output wide

NAME                 READY   STATUS    RESTARTS   AGE   IP             NODE              NOMINATED NODE   READINESS GATES
antrea-agent-czksb   2/2     Running   0          14m   192.168.1.28   antrea-worker-1   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
antrea-agent-gwkmr   2/2     Running   0          14m   192.168.1.27   antrea-master     &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
antrea-agent-x9xjk   2/2     Running   0          14m   192.168.1.29   antrea-worker-2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;

kubectl exec -it antrea-agent-czksb -c antrea-ovs bash

ovs-vsctl list-br
ovs-vsctl show

3cf39eec-f64c-49ed-ad86-48f203b215a4
    Bridge br-int
        Port &amp;quot;tun0&amp;quot;
            Interface &amp;quot;tun0&amp;quot;
                type: vxlan
                options: {key=flow, remote_ip=flow}
        Port &amp;quot;coredns--886217&amp;quot;
            Interface &amp;quot;coredns--886217&amp;quot;
        Port &amp;quot;redis-sl-b32512&amp;quot;
            Interface &amp;quot;redis-sl-b32512&amp;quot;
        Port &amp;quot;coredns--3d5851&amp;quot;
            Interface &amp;quot;coredns--3d5851&amp;quot;
        Port &amp;quot;gw0&amp;quot;
            Interface &amp;quot;gw0&amp;quot;
                type: internal
        Port &amp;quot;frontend-1ee3a9&amp;quot;
            Interface &amp;quot;frontend-1ee3a9&amp;quot;
    ovs_version: &amp;quot;2.11.1&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We can also see that ArpResponderTable (20) and L3ForwardingTable (70) have flow records relating to the pod network.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl config set-context --current --namespace=kube-system
kubectl exec -it antrea-agent-czksb -c antrea-ovs bash
ovs-ofctl dump-flows br-int | grep 172.16.2

 cookie=0xf70e020000000000, duration=820.733s, table=20, n_packets=1, n_bytes=42, idle_age=585, priority=200,arp,arp_tpa=172.16.2.1,arp_op=1 actions=move:NXM_OF_ETH_SRC[]-&amp;gt;NXM_OF_ETH_DST[],mod_dl_src:aa:bb:cc:dd:ee:ff,load:0x2-&amp;gt;NXM_OF_ARP_OP[],move:NXM_NX_ARP_SHA[]-&amp;gt;NXM_NX_ARP_THA[],load:0xaabbccddeeff-&amp;gt;NXM_NX_ARP_SHA[],move:NXM_OF_ARP_SPA[]-&amp;gt;NXM_OF_ARP_TPA[],load:0xac100201-&amp;gt;NXM_OF_ARP_SPA[],IN_PORT

 cookie=0xf70e020000000000, duration=820.733s, table=70, n_packets=649, n_bytes=63996, idle_age=0, priority=200,ip,nw_dst=172.16.2.0/24 actions=dec_ttl,mod_dl_src:06:d1:bb:d3:bc:fa,mod_dl_dst:aa:bb:cc:dd:ee:ff,load:0x1-&amp;gt;NXM_NX_REG1[],load:0x1-&amp;gt;NXM_NX_REG0[16],load:0xc0a8011d-&amp;gt;NXM_NX_TUN_IPV4_DST[],resubmit(,105)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We can look to test the IP routing and connectivity between Pods on same Node and also between Nodes,&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl config set-context --current --namespace=development
kubectl get pods --output wide | grep frontend

frontend-6cb7f8bd65-25qv4       1/1     Running   0          12m   172.16.2.4   antrea-worker-2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
frontend-6cb7f8bd65-mn5jk       1/1     Running   0          12m   172.16.1.5   antrea-worker-1   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
frontend-6cb7f8bd65-nr9zk       1/1     Running   0          12m   172.16.2.5   antrea-worker-2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;

kubectl exec -it frontend-6cb7f8bd65-25qv4 -- ping -c 1 172.16.2.5
kubectl exec -it frontend-6cb7f8bd65-25qv4 -- ping -c 1 172.16.1.5
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;exploring-network-policy&#34;&gt;Exploring Network Policy&lt;/h2&gt;
&lt;p&gt;Antrea implements NetworkPolicy using OVS Flows. Flows are organized in tables, and they are applied on each node by the Antrea agent. Before applying a network policy, we can check flow table IngressDefault (100) and IngressRuleTable (90)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl config set-context --current --namespace=kube-system
kubectl get pods | grep antrea-agent

kubectl exec -it antrea-agent-czksb -c antrea-agent ovs-ofctl dump-flows br-int | grep table=100

cookie=0xcac6000000000000, duration=9103.902s, table=100, n_packets=102, n_bytes=9696, priority=0 actions=resubmit(,105)
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;kubectl exec -it antrea-agent-czksb -c antrea-agent ovs-ofctl dump-flows br-int | grep table=90

cookie=0xcac6000000000000, duration=4059.159s, table=90, n_packets=32493, n_bytes=6556290, priority=210,ct_state=-new+est,ip actions=resubmit(,105)

cookie=0xcac6000000000000, duration=4059.159s, table=90, n_packets=1634, n_bytes=122104, priority=210,ip,nw_src=172.16.1.1 actions=resubmit(,105)

cookie=0xcac6000000000000, duration=4059.159s, table=90, n_packets=37, n_bytes=3768, priority=0 actions=resubmit(,100)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We can confirm that frontend can ping the backend.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl config set-context --current --namespace=development
kubectl get pods -o wide
kubectl exec -it frontend-6cb7f8bd65-25qv4 -- ping -c 1 172.16.2.27
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We can create a network policy to deny all ingress.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cat &amp;lt;&amp;lt;EOF &amp;gt;/tmp/deny-all.yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-deny
spec:
  podSelector: {}
  policyTypes:
  - Ingress
EOF

kubectl create -f /tmp/deny-all.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If we test again we can test and ensure that the policy is applied and the frontend can no longer ping backend.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl exec -it frontend-6cb7f8bd65-25qv4 -- ping -c 1 172.16.2.27
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We can then check IngressDefault (100) flow table and see that our network policy has added action to drop.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl config set-context --current --namespace=kube-system

kubectl exec -it antrea-agent-czksb -c antrea-agent ovs-ofctl dump-flows br-int | grep table=100
 cookie=0xcac6000000000000, duration=3.427s, table=100, n_packets=0, n_bytes=0, priority=200,ip,reg1=0xa actions=drop

 cookie=0xcac6000000000000, duration=3.427s, table=100, n_packets=0, n_bytes=0, priority=200,ip,reg1=0x8 actions=drop

 cookie=0xcac6000000000000, duration=9226.746s, table=100, n_packets=137, n_bytes=12966, priority=0 actions=resubmit(,105)
&lt;/code&gt;&lt;/pre&gt;
        
      </description>
    </item>
    
    <item>
      <title>Programaticly configuring VMware Storage Profile API with Python</title>
      <link>https://darrylcauldwell.github.io/post/python_spbm/</link>
      <pubDate>Wed, 12 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/python_spbm/</guid>
      <description>
        
          &lt;p&gt;I was looking to programaticly configuring VMware Storage Profile recently. My scripting language of choice is Python, VMware maintain &lt;a href=&#34;https://github.com/vmware/pyvmomi&#34;&gt;pyVmomi&lt;/a&gt; is which is the Python SDK for the VMware vSphere API. pyVmomi can be used to form binding and configure the &lt;a href=&#34;https://code.vmware.com/apis/968/vsphere&#34;&gt;vSphere Web Services API&lt;/a&gt; and the &lt;a href=&#34;https://code.vmware.com/apis/971&#34;&gt;VMware Storage Policy API&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The Storage Policy API is exposed as a Web service, running on VMware vCenter server systems.  When I approached the requirement it wasn&amp;rsquo;t clear to me how to connect to the Storage Policy API Web service. I read the &lt;a href=&#34;https://code.vmware.com/docs/11900/vmware-storage-policy-sdk-programming-guide&#34;&gt;VMware Storage Policy SDK Programming Guide&lt;/a&gt; section on forming connection which describes using the session cookie from a vCenter Server session to establish the Storage Policy session.&lt;/p&gt;
&lt;p&gt;pyVim is a client-side Python API which wraps pvVmomi these are made available as a package.  These are published to PyPI repository and as such can be installed easily with pip.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install --upgrade pyvmomi
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It we look at pyVmomi in GitHub we can see that &lt;a href=&#34;https://github.com/vmware/pyvmomi/blob/master/pyVim/connect.py&#34;&gt;pyVim.connect&lt;/a&gt; defines a function SmartConnect which can be used to form connection to the vSphere Web Services API.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#!/usr/bin/env python3
# Connect to a VMOMI ServiceInstance.

import ssl argparse atexit getpass
from pyVim.connect import SmartConnect

def get_args():
    parser = argparse.ArgumentParser(
        description=&#39;Arguments for talking to vCenter&#39;)

    parser.add_argument(&#39;-s&#39;, &#39;--host&#39;,
                        required=True,
                        action=&#39;store&#39;,
                        help=&#39;vCenter Server FQDN or IP address&#39;)

    parser.add_argument(&#39;-o&#39;, &#39;--port&#39;,
                        type=int,
                        default=443,
                        action=&#39;store&#39;,
                        help=&#39;vCenter Server TCP port&#39;)

    parser.add_argument(&#39;-u&#39;, &#39;--user&#39;,
                        required=True,
                        action=&#39;store&#39;,
                        help=&#39;Username to login to vCenter Server&#39;)

    parser.add_argument(&#39;-p&#39;, &#39;--password&#39;,
                        required=False,
                        action=&#39;store&#39;,
                        help=&#39;Password to login to vCenter Server&#39;)

    args = parser.parse_args()

    if not args.password:
        args.password = getpass.getpass(prompt=&#39;Enter password:&#39;)

    return args

def main():
    args = get_args()

    &amp;quot;&amp;quot;&amp;quot; connect to vcenter service instance &amp;quot;&amp;quot;&amp;quot;

    context = None
    if hasattr(ssl, &amp;quot;_create_unverified_context&amp;quot;):
        context = ssl._create_unverified_context()

    serviceInstance = SmartConnect(
                    host=args.host,
                    user=args.user,
                    pwd=args.password,
                    port=args.port,
                    sslContext=context)

    atexit.register(Disconnect, serviceInstance)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;To connect to the VMware Storage Policy API we need to get the session cookie. The &lt;a href=&#34;https://github.com/vmware/pyvmomi/blob/master/pyVmomi/VmomiSupport.py&#34;&gt;VmomiSupport&lt;/a&gt; provides us helper functions to do things like gather the context which includes session cookie details. With this we can form a stub session to the Storage Policy API.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    &amp;quot;&amp;quot;&amp;quot; connect to pbm service instance &amp;quot;&amp;quot;&amp;quot;

    VmomiSupport.GetRequestContext()[&amp;quot;vcSessionCookie&amp;quot;] = \
    serviceInstance._stub.cookie.split(&#39;&amp;quot;&#39;)[1]
    hostname = serviceInstance._stub.host.split(&amp;quot;:&amp;quot;)[0]
    pbmStub = SoapStubAdapter(
        host=hostname,
        version=&amp;quot;pbm.version.version1&amp;quot;,
        path=&amp;quot;/pbm/sdk&amp;quot;,
        poolSize=0,
        sslContext=ssl._create_unverified_context())
    pbmServiceInstance = pbm.ServiceInstance(&amp;quot;ServiceInstance&amp;quot;, pbmStub)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;With this connection in place we can make our request, in this example pull back all of the Storage Profiles.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
    &amp;quot;&amp;quot;&amp;quot; get profiles &amp;quot;&amp;quot;&amp;quot;

    profileManager = pbmServiceInstance.RetrieveContent().profileManager
    profiles = profileManager.PbmQueryProfile(resourceType=pbm.profile.ResourceType(resourceType=&amp;quot;STORAGE&amp;quot;))
    print(profiles)

if __name__ == &#39;__main__&#39;:
    main()
&lt;/code&gt;&lt;/pre&gt;
        
      </description>
    </item>
    
    <item>
      <title>Orchestrating configuration of vROps via REST API with Postman</title>
      <link>https://darrylcauldwell.github.io/post/vrops_rest/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/vrops_rest/</guid>
      <description>
        
          &lt;p&gt;vRealize Operations Manager (vROps) exposes some of its configuration via RESTful API. With this we can look to programatically control its configuration. My workflow is to use a REST client to explore API and validate payload formatting before moving to script the steps. My REST client of choice is &lt;a href=&#34;https://www.postman.com/&#34;&gt;Postman&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Performing any REST configuration in vRealize Operations Manager requires at least two steps:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Authenticate&lt;/li&gt;
&lt;li&gt;Perform action, like configure a new vCenter adapter&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To faciliate running a sequence of actions I start by creating a POSTMAN collection. Requests stored within the collection can be played in sequence. Using the example of configuring a new vCenter adapter we might create a collection called &amp;lsquo;vROps - New vCenter Adapter&amp;rsquo;.&lt;/p&gt;
&lt;p&gt;In case we have multiple environments and want to export our collection and reuse we  want to store environmental specifics as variables. To faciliate this we can create a POSTMAN envrionment. For example we might create a environment called &amp;lsquo;Homelab&amp;rsquo; which has variable vrops-fqdn and both initial and current value of vrops01.example.local&lt;/p&gt;
&lt;p&gt;vRealize Operations Manager REST API documentation describes how we can &lt;a href=&#34;https://docs.vmware.com/en/vRealize-Operations-Manager/8.1/com.vmware.vcom.api.doc/GUID-C3F0A911-A587-40F7-9998-13D4880A0C2B.html&#34;&gt;aquire an authentication token&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Create new reques in Postman with name &amp;lsquo;Aquire token&amp;rsquo;, set the request method to POST and set URL to use environment variable like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{% raw %}
https://{{vrops-fqdn}}/suite-api/api/auth/token/acquire
{% endraw %}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The documentation shows that two headers are required to be supplied so we must configure our request to pass these:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Content-Type: application/json
Accept: application/json
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The documentation also describes that we need to POST the vROps logon credentials as the body. Within Postman change body type to raw and paste below substrituing credentials appropriate to your environment.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{
  &amp;quot;username&amp;quot;: &amp;quot;vRealize-username&amp;quot;,
  &amp;quot;password&amp;quot;: &amp;quot;vRealize-password&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Successul processing of credential by the REST method returns a JSON body containing the token parameter. We want to capture this to use in the next step in our process. We can do this in Postman by running a script after the request is made which extracts the token value and sets this an environment variable. Change to the Test tab and add the following script.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;var jsonData = JSON.parse(responseBody);
postman.setEnvironmentVariable(&amp;quot;bearerToken&amp;quot;, jsonData.token);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We can now look at the next step in our example is to add a vCenter adapter which is documented &lt;a href=&#34;https://docs.vmware.com/en/vRealize-Operations-Manager/8.1/com.vmware.vcom.api.doc/GUID-18D17D09-628F-4974-AFE4-E94446E3462D.html&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Create new reques in Postman with name &amp;lsquo;Aquire token&amp;rsquo;, set the request method to POST and set URL to use environment variable like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{% raw %}
https://{{vrops-fqdn}}/suite-api/api/adapters
{% endraw %}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We require to apply three headers to this request, the ones to describe payload is in JSON format and an authentication header which passes the token value environment variable from previous step.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{% raw %}
Content-Type: application/json
Accept: application/json
Authentication: vRealizeOpsToken {{bearerToken}}
{% endraw %}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The documentation supplies an example body to post with some optional parameters. Similar to aquire step we place this in request body tab and ensure raw format is selected (ensuring you set envioronmentally values).&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{
  &amp;quot;name&amp;quot; : &amp;quot;New VC Adapter Instance&amp;quot;,
  &amp;quot;collectorId&amp;quot; : &amp;quot;1&amp;quot;,
  &amp;quot;adapterKindKey&amp;quot; : &amp;quot;VMWARE&amp;quot;,
  &amp;quot;resourceIdentifiers&amp;quot; : [ 
    {
      &amp;quot;name&amp;quot; : &amp;quot;VCURL&amp;quot;,
      &amp;quot;value&amp;quot; : &amp;quot;https://vcenter.example.local&amp;quot;
    } 
  ],
  &amp;quot;credential&amp;quot; : {
    &amp;quot;id&amp;quot; : null,
    &amp;quot;name&amp;quot; : &amp;quot;VC-Credential-1&amp;quot;,
    &amp;quot;adapterKindKey&amp;quot; : &amp;quot;VMWARE&amp;quot;,
    &amp;quot;credentialKindKey&amp;quot; : &amp;quot;PRINCIPALCREDENTIAL&amp;quot;,
    &amp;quot;fields&amp;quot; : [ 
      {
        &amp;quot;name&amp;quot; : &amp;quot;USER&amp;quot;,
        &amp;quot;value&amp;quot; : &amp;quot;administrator@vsphere.local&amp;quot;
      }, 
      {
        &amp;quot;name&amp;quot; : &amp;quot;PASSWORD&amp;quot;,
        &amp;quot;value&amp;quot; : &amp;quot;VC-dummy-passwd&amp;quot;
      } 
    ],
  },
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It is not essential but it is useful for troubleshooting of our request to output the token environment variable value to log prior to attempting to make the request. To do this we can use the &amp;lsquo;Pre-request script&amp;rsquo; tab and add the follwoing script.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;console.log(pm.environment.get(&amp;quot;bearerToken&amp;quot;));
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We can now run the collection which will open &amp;lsquo;Postman runner&amp;rsquo; which will make the two requests. The summary detail is output to &amp;lsquo;Postman running&amp;rsquo; and you can get more detailed output in &amp;lsquo;Postman console&amp;rsquo; view.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Peloton bike on a budget</title>
      <link>https://darrylcauldwell.github.io/post/peloton/</link>
      <pubDate>Tue, 16 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/peloton/</guid>
      <description>
        
          &lt;p&gt;I&amp;rsquo;d heard lots of great things about Peloton however it the basic bike costs £1,990. I really wanted to see what I had been missing out but couldn&amp;rsquo;t justify the cost so set about creating a custom solution.&lt;/p&gt;
&lt;h2 id=&#34;peloton-membership&#34;&gt;Peloton Membership&lt;/h2&gt;
&lt;p&gt;Peloton membership is required to provide access to their live workout classes and back catalogue of cycling, running, strength, yoga, meditation workout classes.&lt;/p&gt;
&lt;p&gt;Their are two types of membership, all-access £39 per month and digital £12.99 per month. The all-access membership allows you to create multiple user accounts, the digial membership is single user. The all-access membership also gives access to the Peloton leaderboard feature. Access to all-access membership is only available to owners of Peloton Bike or Tread. Access to the digital membership is with the &lt;a href=&#34;https://www.onepeloton.co.uk/app&#34;&gt;Peloton App&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;donor-bike&#34;&gt;Donor Bike&lt;/h2&gt;
&lt;p&gt;Like most people I had in garage an old mountain bike, GT Tempest circa 1995. I gave it a basic service and got it back to being road rideable without much trouble.&lt;/p&gt;
&lt;h2 id=&#34;turbo-trainer&#34;&gt;Turbo Trainer&lt;/h2&gt;
&lt;p&gt;The Peloton workouts require capability of varying pedaling resistence multiple times during the workout, so the turbo-trainer I chose had to have a handlebar mounted resistance dial. From what I had read the Peloton bike has 100 levels of resistance, the bike I was using 24 gears so in theory if my turbo-trainer had at least four levels of resistance I would be able to be close enough. I chose for the Elite Volare Mag from &lt;a href=&#34;https://www.evanscycles.com/elite-volare-mag-turbo-trainer-00104161&#34;&gt;Evans Cycles £99&lt;/a&gt; which has five levels of resistance. For level 100 I use level five resistance and am in highest gear 3:8. For level 1 I use level one resistance and am in lowest gear 1:1.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/pelo-turbo-train.jpeg&#34; alt=&#34;Volare Turbo Trainer&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;phone-mount&#34;&gt;Phone Mount&lt;/h2&gt;
&lt;p&gt;The app presents the cycling workouts with a video stream of the instructor, paricipant list and stream of metrics around your heartrate, cadence and estimate of burned calories. The official Peloton bike comes with a huge screen yo display this, the app is available for Apple TV, iPad and iPhone. I wanted to use the solution in the garage or home office neither of these have a Apple TV or a TV, so this wasn&amp;rsquo;t an option for me. It is possible to get mounting bracket to attach iPad to bike handlebars.  I chose a phone mount so I could use this if ever I went for an outdoor bike ride. The Peloton app can be viewed in landscape or portrait so I opted to get the Visun mount which allowed 360 rotation for &lt;a href=&#34;https://www.amazon.co.uk/gp/product/B01JLX8N1O&#34;&gt;Amazon £18&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/pelo-phone-mount.jpeg&#34; alt=&#34;Phone Mount&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;heart-rate-monitor&#34;&gt;Heart Rate Monitor&lt;/h2&gt;
&lt;p&gt;During workout the app can display your heart rate this gets sampled and at the end of the workout presents this data as a graph. To enable this in the app requires a compatible heart rate monitor. I wear an Apple Watch which has an in-built heart rate monitor so quickly able to enable permissions to the app to enable the data feed.&lt;/p&gt;
&lt;h2 id=&#34;cadence-sensor&#34;&gt;Cadence Sensor&lt;/h2&gt;
&lt;p&gt;Like a spinning class the instructors suggest cadence and resistance value changes for different sections of workout. I control resistance using combination of the turbo trainer and bike gears. To have the app display the cadence I needed a solution to stream this in format the app supports. I chose the  Wantacme MOOFIT Bicycle Cadence from &lt;a href=&#34;https://www.amazon.co.uk/gp/product/B085NMQ5QR&#34;&gt;Amazon £19.90&lt;/a&gt;. This clips to the crank arm, and when you push the pedals it activates the sensor and streams data over Bluetooth Low Energy 4.0. No bluetooth pairing required, the Peloton app just picks up he cadence data stream.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/pelo-cadence.jpeg&#34; alt=&#34;Moofit Cadence Sensor&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;seat-padding&#34;&gt;Seat Padding&lt;/h2&gt;
&lt;p&gt;I aim to do a cycling workout every day even if its a quick 20 minute. Its not always practical to switch to cycling shorts to add a bit of padding. After a bit of research I found a great alternative, a gel seat cover. I went for the Ancocs silica gel and foam cushion &lt;a href=&#34;https://www.amazon.co.uk/gp/product/B07K9PS472&#34;&gt;Amazon £14.99&lt;/a&gt;, this slips over the seat and secured with a pair of velcro straps.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/pelo-pad.jpeg&#34; alt=&#34;Seat Pad&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;
&lt;p&gt;Overal I&amp;rsquo;m really pleased with how the solution turned out. I do miss out on the Peloton leaderboard feature. Over the Peloton bike my solution has flexibility of me using one bike for both indoor or oudoor workout. The total for one-off costs was £153 so dramatic difference to £1,990 and recurring monthly £12.99 rather than £39.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/pelo-full.jpeg&#34; alt=&#34;Budget Peloton&#34;&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>vSphere with Kubernetes Homelab Build</title>
      <link>https://darrylcauldwell.github.io/post/vsphere-k8s/</link>
      <pubDate>Wed, 29 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/vsphere-k8s/</guid>
      <description>
        
          &lt;p&gt;I&amp;rsquo;d been exploring Project Pacific during its beta in my homelab for a while. When vSphere 7 and NSX-T 3.0 went GA I took chance to rebuild lab and consolidate much of the configuration I&amp;rsquo;d been applying iteratively.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/tanzu-vsphere.png&#34; alt=&#34;vSphere with Tanzu&#34;&gt;&lt;/p&gt;
&lt;p&gt;My lab hardware specification is a constraint so I&amp;rsquo;ve had to deviate from documentation in a few areas of configuration. During stand up and power up hosts experience CPU and RAM pressure but once everything is running in steady state it is tight but just fits.&lt;/p&gt;
&lt;h2 id=&#34;single-vlan--subnet-lab-network&#34;&gt;Single VLAN / subnet Lab Network&lt;/h2&gt;
&lt;p&gt;My lab has a very simple physical network namely a single subnet (192.168.1.0/24) with DHCP enabled and which has default route to the internet.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Host&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Allocation&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;ad&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;192.168.1.10&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;esx1&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;192.168.1.11&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;esx2&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;192.168.1.12&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;esx3&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;192.168.1.13&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;vcenter&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;192.168.1.14&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;nsx&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;192.168.1.15&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;edge&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;192.168.1.16&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;t0-uplink&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;192.168.1.17&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;tep-pool&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;192.168.1.20-24&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;workload control plane&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;192.168.1.30-34&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Kubernetes Ingress&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;192.168.1.48-63&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Kubernetes Egress&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;192.168.1.64-79&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;DHCP&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;192.168.1.64-253&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Gateway&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;192.168.1.254&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;I look to configure subnets on the NSX overlay network using the other RFC1918 private address range. The physical router does not support dynamic routing protocol so I configure static routes for these two CIDR with next hop as tier-0 uplink IP 192.168.1.17.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;CIDR&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;IP Range&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;10.0.0.0/8&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;10.0.0.0 – 10.255.255.255&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;172.16.0.0/12&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;172.16.0.0 – 172.31.255.255&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;compute-resource-nodes&#34;&gt;Compute Resource Nodes&lt;/h2&gt;
&lt;p&gt;Lab compute resources are provided by three &lt;a href=&#34;https://ark.intel.com/content/www/us/en/ark/products/89190/intel-nuc-kit-nuc6i5syh.html&#34;&gt;Intel NUC6i5SYH&lt;/a&gt; hardware, each provides 2x 1.8Ghz CPU and 32GB RAM. I install ESXi boot partition on USB drives. To create a bootable USB for ESXi on macOS by creating a new VM in VMware Fusion with ESXi ISO attached as CD/DVD. It is only possible to connect USB to a running VM so power on VM and connect USB drive, work through ESXi installation via Fusion console.&lt;/p&gt;
&lt;p&gt;At the end of installation message to disconnect the CD/DVD and reboot VM.  I remain connected for reboot, using remote console navigate Troubleshoot menu to enable ESXi Shall and SSH, then configure networking to reflect homelab IP allocation.&lt;/p&gt;
&lt;h2 id=&#34;ensure-unique-system-uuid-and-mac-address&#34;&gt;Ensure unique System UUID and MAC address&lt;/h2&gt;
&lt;p&gt;Once ESXi has a basic network configuration I power down the VM and move USB to the Intel NUC and power on. During installation of ESXi the System UUID and MAC address are formed from the MAC address of the NIC. When  using Fusion to create multiple ESXi VMs this scenario can lead to duplicatation of System UUID and MAC address. We can configure ESXi to move to physical NIC MAC address and form new ESXi System UUID by running commands like.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;esxcli system settings advanced set -o /Net/FollowHardwareMac -i 1
sed -i &#39;s#/system/uuid.*##&#39; /etc/vmware/esx.conf
/sbin/auto-backup.sh
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;add-external-usb-nic-drivers&#34;&gt;Add external USB NIC drivers&lt;/h2&gt;
&lt;p&gt;The Intel NUC has a single onboard 1GB NIC, I add an external USB NIC to each NUC. ESXi doesn&amp;rsquo;t ship with required drivers for these external USB NIC, for labs these are provides via &lt;a href=&#34;https://flings.vmware.com/usb-network-native-driver-for-esxi&#34;&gt;VMware Flings&lt;/a&gt;. I copy the downloaded driver bundle to the /tmp folder on ESXi via an SFTP client like CyberDuck. Once the bundle is uploaded I following command to install the bundle.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;esxcli software vib install -d /tmp/ESXi700-VMKUSB-NIC-FLING-34491022-component-15873236.zip
esxcli system maintenanceMode set --enable true
esxcli system shutdown reboot --reason &amp;quot;USB NIC driver&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;suppress-warnings&#34;&gt;Suppress Warnings&lt;/h2&gt;
&lt;p&gt;When booting ESXi from USB the system logs and coredumps can not persist to local storage. I also prefer to leave SSH enabled in lab so get warnings. Both of these choices gives me warnings which I prefer to suppress.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vim-cmd hostsvc/advopt/update UserVars.SuppressShellWarning long 1
vim-cmd hostsvc/advopt/update UserVars.SuppressCoredumpWarning long 1
vim-cmd hostsvc/advopt/update Syslog.global.logHost string 127.0.0.1
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;form-vsan-cluster&#34;&gt;Form vSAN Cluster&lt;/h2&gt;
&lt;p&gt;Two of the Intel NUC I use each have SSD the third is used to provide compute resources only. The ESXi installation allows Management traffic only on VMkernel port so need to bind vSAN to VMkernel port. In my lab only two devices contribute disk to vSAN the default storage policy for will prevent any VM deployment. To configure this I run the following on each host in cluster.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;esxcli system maintenanceMode set --enable false
esxcli vsan network ip add -i vmk0
esxcli vsan policy setdefault -c cluster -p &amp;quot;((\&amp;quot;hostFailuresToTolerate\&amp;quot; i0)&amp;quot;
esxcli vsan policy setdefault -c vdisk -p &amp;quot;((\&amp;quot;hostFailuresToTolerate\&amp;quot; i0)&amp;quot;
esxcli vsan policy setdefault -c vmnamespace -p &amp;quot;((\&amp;quot;hostFailuresToTolerate\&amp;quot; i0)&amp;quot;
esxcli vsan policy setdefault -c vmswap -p &amp;quot;((\&amp;quot;hostFailuresToTolerate\&amp;quot; i0) (\&amp;quot;forceProvisioning\&amp;quot; i1))&amp;quot;
esxcli vsan policy setdefault -c vmem -p &amp;quot;((\&amp;quot;hostFailuresToTolerate\&amp;quot; i0) (\&amp;quot;forceProvisioning\&amp;quot; i1))&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;With the pre-requists in place a new vSAN cluster can be formed on first host using command like.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;esxcli vsan cluster new 
esxcli vsan cluster get | grep &amp;quot;Sub-Cluster UUID&amp;quot;
    Sub-Cluster UUID: 5291783f-77a6-c1dc-2ed8-6cfc200618b1
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Add other nodes to the cluster using output of Sub-Cluster Master UUID using command like.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;esxcli vsan cluster join -u 5291783f-77a6-c1dc-2ed8-6cfc200618b1
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;At this stage vSAN cluster while nodes are looking to form the quorum cannot be formed. Prior to vSAN 6.6 the cluster can discover members using multicast. Forming cluster without vCenter requires formation of unicast networking from the command line by manually building table &lt;a href=&#34;https://kb.vmware.com/s/article/2150303&#34;&gt;kb2150303&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;active-directory&#34;&gt;Active Directory&lt;/h2&gt;
&lt;p&gt;At this stage I upload Windows Server 2019 ISO to vSAN and use this to deploy a VM which acts as a environment Remote Desktop, File Store, DNS server, NTP source and Active Directory. Before proceeding create DNS A &amp;amp; PTR records for the environment.&lt;/p&gt;
&lt;h2 id=&#34;vcenter-server&#34;&gt;vCenter Server&lt;/h2&gt;
&lt;p&gt;I use the Active Directory jump server to mount the vCenter ISO and use UI installer to deploy a &amp;lsquo;Tiny&amp;rsquo; sized vCenter Server to existing Datastore. This creates a cluster with the move deployed to, at this stage I attach remaining hosts to cluster.&lt;/p&gt;
&lt;p&gt;We can then pass ownership of vSAN cluster membership back to vCenter by running following on each host.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;esxcfg-advcfg -s 0 /VSAN/IgnoreClusterMemberListupdates
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The Workload Control Plane feature requires DRS and HA are required to be enabled on clusters it manages. Ensure these are enabled and HA admission control is disabled to maintain capacity.&lt;/p&gt;
&lt;h2 id=&#34;default-vsan-storage-policy&#34;&gt;Default vSAN Storage Policy&lt;/h2&gt;
&lt;p&gt;During the setup of VSAN cluster we configured the local policies to FTT=0 as I only have 2x hosts providing disk capacity. To deploy VMs and appliances via vCenter similarly need to adjust the &amp;lsquo;vSAN Default Storage Policy&amp;rsquo; to &amp;lsquo;No data redundancy&amp;rsquo;.&lt;/p&gt;
&lt;h2 id=&#34;nsx-installation&#34;&gt;NSX Installation&lt;/h2&gt;
&lt;p&gt;Deploy NSX-T 3.0 appliance sized Small, I need to remove CPU reservation to power on.&lt;/p&gt;
&lt;h2 id=&#34;connect-nsx-and-vcenter&#34;&gt;Connect NSX and vCenter&lt;/h2&gt;
&lt;p&gt;Connect to NSX appliance navigate to System &amp;gt; Fabric &amp;gt; Compute Managers and create bindng to vCenter. In order vCenter Workload Platform services can communicate with NSX ensure Enable Trust option is checked.&lt;/p&gt;
&lt;h2 id=&#34;vsphere-distributed-switch&#34;&gt;vSphere Distributed Switch&lt;/h2&gt;
&lt;p&gt;Prior to release of vSphere 7 and NSX-T 3.0 to install NSX required the creation of a N-VDS host switch on each ESXi host. While segments created on N-VDS where visible in vSphere they were not as rich as VDS. It is a constraint that physical NIC uplinks cannot be assigned to both a VDS and N-VDS.&lt;/p&gt;
&lt;p&gt;It was possible to have hosts with two pNIC which initially get built as VDS and then migrate to N-VDS and remove VDS. When running only with N-VDS the segments show in vCenter as Opaque networks. Not many 3rd party products support Opaque networks, automation became more complex as the network could not be correctly gathered via vCenter. Many production deployments moved to hosts with four pNIC two assigned to N-VDS and two assigned to VDS to hold the VMkernel ports.&lt;/p&gt;
&lt;p&gt;With these latest product versions the VDS and N-VDS capabilities converge to singluar VDS construct for use as host switch on ESXi the N-VDS remains for Edge and non-ESXi Transport Node types. The converged VDS for ESXi improves pNIC design and also makes operational management much easier as there is a singluar place for configuring NIOC, MTU and LLDP configuration.&lt;/p&gt;
&lt;p&gt;The lab hosts have two pNIC I leave onboard to vSphere Standard Switch with VMkernel ports attached. I create a VDS Version 7 configured with 1 uplink,  NIOS enabled but without default port group. The default VDS is created with MTU 1500, to support NSX I increase this to Advanced configuration option for MTU 1700.&lt;/p&gt;
&lt;p&gt;Once VDS is created I add usb0 NIC from all cluster hosts to be assigned to Uplink1.  I do not migrate VMkernel or VM networking to VDS.&lt;/p&gt;
&lt;h2 id=&#34;create-a-tunnel-endpoint-ip-address-pool&#34;&gt;Create a Tunnel Endpoint IP Address Pool&lt;/h2&gt;
&lt;p&gt;System &amp;gt; Networking &amp;gt; IP Management &amp;gt; IP Address Pools &amp;gt; Add IP Address Pool&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Name:             tep-pool
IP Range:         192.168.1.20-192.168.1.24
CIDR:             192.168.1.0/24
Gateway IP:       192.168.1.254
DNS Server:       192.168.1.10
DNS Suffix:       darrylcauldwell.com
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;configure-esxi-hosts-as-transport-nodes&#34;&gt;Configure ESXi hosts as Transport Nodes&lt;/h2&gt;
&lt;p&gt;To consistently configure ESXi hosts as NSX Transport Nodes I create a Transport Node Profile.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Name                           Host Transport Node Profile
Host Switch - Type             VDS
Host Switch - Mode             Standard
Host Switch - Name             vCenter \ DSwitch
Host Switch - Transport Zone   nsx-overlay-transportzone &amp;amp; nsx-vlan-transportzone
Host Switch - Uplink Profile   nsx-default-uplink-hostswitch-profile
Host Switch - IP Assignment    IP Pool - tep-pool
Host Switch - Teaming Policy   uplink1 (active)= Uplink 1
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Once created using Host Transport Nodes menu select cluster and apply profile. Once completed it is possible to view the NSX components installed on all ESXi hosts using:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;esxcli software vib list | grep nsx
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;configure-nsx-edge&#34;&gt;Configure NSX Edge&lt;/h2&gt;
&lt;p&gt;The NSX Edge provides a Layer 3 routing capability the NSX Container Plugin requires at least a medium sized Edge to deploy a small loadbalancer.&lt;/p&gt;
&lt;p&gt;Deploy a medium sized Edge node&lt;/p&gt;
&lt;p&gt;System &amp;gt; Fabric &amp;gt;  Nodes &amp;gt; Edge Transport Nodes &amp;gt; Add Edge VM&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Name:                   nsxEdge
FQDN:                   edge
Size:                   Large
Shares:                 Normal
Memory Reservation:     0
IP Assignment:          Static
Management Interface:   VM Network
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Node Switch&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Name:                       nvds1
Transport Zone:             nsx-overlay-transportzone
Uplink Profile:             nsx-edge-single-nic-uplink-profile
IP Pool:                    tep-pool
DPDK Fastpath Interfaces:   VM Network

Name:                       nvds2
Transport Zone:             nsx-vlan-transportzone
Uplink Profile:             nsx-edge-single-nic-uplink-profile
DPDK Fastpath Interfaces:   VM Network
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;configure-edge-cluster&#34;&gt;Configure Edge Cluster&lt;/h2&gt;
&lt;p&gt;When Edge has fully deployed create Edge Cluster&lt;/p&gt;
&lt;p&gt;System &amp;gt; Fabric &amp;gt; Nodes &amp;gt; Edge Clusters &amp;gt; Add&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Name:                       edgeCluster
Transport Nodes:            nsxEdge
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;uplink-network-segment&#34;&gt;Uplink Network Segment&lt;/h2&gt;
&lt;p&gt;A network segment is required to to connect Tier0 router uplink to VLAN&lt;/p&gt;
&lt;p&gt;Networking &amp;gt; Segments &amp;gt;  Add Segment&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Segment Name:               edgeUplink
Connectivity:               None
Transport Zone:             nsx-vlan-transportzone
VLAN:                       0
Multicast:                  Disabled
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;tier0-router&#34;&gt;Tier0 Router&lt;/h2&gt;
&lt;p&gt;A logical router is required I create one like:&lt;/p&gt;
&lt;p&gt;Networking &amp;gt; Tier-0 Gateways &amp;gt; Add Gateway &amp;gt; Tier0&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Name:                       tier0
HA Mode:                    Active-Standby
Failover:                   non preemptive
Edge Cluster:               edgeCluster
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Add Interface&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Name:                       tier0uplink
Type:                       External
IP Address:                 192.168.1.17/24
Connected To:               edgeUplink
Edge Node:                  nsxEdge
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Once interface is added you can test it works as it will now be able to ping.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;ping 192.168.1.17 -c &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;enable-a-cluster-as-workload-control-plane-wcp&#34;&gt;Enable a cluster as Workload Control Plane (WCP)&lt;/h2&gt;
&lt;p&gt;With all of the pre-requists in place we can now use wizard to enable integrated Kubernetes.&lt;/p&gt;
&lt;p&gt;[EDIT 4th May] since initial publication I found another &lt;a href=&#34;https://www.virtuallyghetto.com/2020/04/deploying-a-minimal-vsphere-with-kubernetes-environment.html&#34;&gt;blog post&lt;/a&gt; around deploying minimal lab. By default when enabling Workload Control Plane this deploys a 3x VMs which form the Kubernetes supervisor cluster. This can be reduced to 2x by updating &lt;code&gt;/etc/vmware/wcp/wcpsvc.yaml&lt;/code&gt; on the VCSA and changing the minmasters and maxmasters properties from 3 to 2. Then restarting the wcp service &lt;code&gt;service-control --restart wcp&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Menu &amp;gt; Workload Management &amp;gt; Enable&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Select a Cluster&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If cluster does not show available check reason via GUI and or these vCenter logs for clues.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;/var/log/vmware/wcp/wcpsvc.log
/var/log/vmware/wcp/nsxd.log
&lt;/code&gt;&lt;/pre&gt;&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Cluster Settings&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;Cluster Size:                  Tiny
&lt;/code&gt;&lt;/pre&gt;&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Network&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The management network refers to the control plane needs to communicate with vCenter and NSX.  The workload network will come from the RFC1918 addressable space. Enter network details&lt;/p&gt;
&lt;p&gt;Workload Control Plane Networking&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Network:                        VM Network
Starting IP Address:            192.168.1.30
Subnet Mask:                    255.255.255.0
Gateway:                        192.168.1.254
DNS Server:                     192.168.1.10
NTP Server:                     192.168.1.10
DNS Search Domains:             darrylcauldwell.com
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Workload Network&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vDS:                            DSwitch
Edge Cluster:                   edgeCluster
DNS Server:                     192.168.1.10
Pod CIDRs:                      10.244.0.0/21 (default)
Service CIDRS:                  10.96.0.0/24 (default)
Ingress CIDR:                   192.168.1.48/28
Egress CIDR:                    192.168.1.64/28
&lt;/code&gt;&lt;/pre&gt;&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;Configure storage to use&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;Control Plane Node              vSAN Default Storage Policy
Ephemeral Disks                 vSAN Default Storage Policy
Image Cache                     vSAN Default Storage Policy
&lt;/code&gt;&lt;/pre&gt;&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;Review and confirm&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Once submitted we see in vCenter a resource pool named Namespaces and three virtual appliances named WcpAPIServerAgent each is allocated 2CPU and 8GB RAM.  An installation occurs on the three virtual appliances which,  these attempt to run before appliances deploy it is normal to see install failures during this phase.&lt;/p&gt;
&lt;p&gt;The progress messages available via UI aren&amp;rsquo;t superb its useful to SSH to VCSA and tail the log:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;tail -f /var/log/vmware/wcp/wcpsvc.logtail -f /var/log/vmware/wcp/wcpsvc.log
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If all has goes to plan an hour and a half or so later and if all gone to plan.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/tanzu-wcp.png&#34; alt=&#34;WCP Success&#34;&gt;&lt;/p&gt;
&lt;p&gt;From here I can begin to create and consume native Kubernetes namespaces and resources.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Sustainable Shopping</title>
      <link>https://darrylcauldwell.github.io/post/sustainable-shopping/</link>
      <pubDate>Wed, 22 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/sustainable-shopping/</guid>
      <description>
        
          &lt;p&gt;Our shopping affects people, animals and the environment. Every purchase we make has huge repercussions down the supply chain socially, economically and environmentally. Over recent years we have all become much more aware of our impact to the planet.&lt;/p&gt;
&lt;h2 id=&#34;shop-locally&#34;&gt;Shop Locally&lt;/h2&gt;
&lt;p&gt;I was raised in rural UK where my parents where shopkeepers. During this time I came to realize the power of community at the heart of which is typically small, independent businesses. When shopping locally you regularly share a communal space with other people in the community this naturally leads to communication and forming of relationships. Small, independent businesses are sources of employment and providers and consumers of goods and services that sustain the local economy. When you shop at chain retailers, most of the money will go back to the business elsewhere, whereas the money you spend at local businesses will directly go back into the local economy.&lt;/p&gt;
&lt;p&gt;My wife and I are lucky enough to live in a small market town which has a good collection of small, local businesses. Most people who are grew up in the town are cogizant to the importance of small, independent businesses and support them with their custom. However as more people move to the rural town from cities their culture of supermarkets and then low-cost supermarkets has spread outwards too. This has led to the collapse of many small, local businesses.&lt;/p&gt;
&lt;p&gt;To retain our unique communities and maintain a healthy local economy we should all look to shop and support small, local businesses.&lt;/p&gt;
&lt;h2 id=&#34;shop-sustainably&#34;&gt;Shop Sustainably&lt;/h2&gt;
&lt;p&gt;Shopping sustainably means shopping at ethical brands and retailers - and not just those that brand themselves as &amp;lsquo;ethical&amp;rsquo; without actually being too kind to the environment. Standad shopping practices, especially the clothing industry is largely opaque, exploitative and environmentally damaging.&lt;/p&gt;
&lt;p&gt;When buying clothes, it is important to always read the fine print to see what materials your clothing is actually made of. Synthetic materials like polyester, nylon, and acrylic take hundreds of years to decompose. Those materials account for a large chunk of the clothing that’s currently sitting in landfills. Plus, synthetics require plastic and chemicals to make, and these directly contaminate water supplies. Choosing all-natural fabrics is one way to work toward a more sustainable wardrobe but also a more economical wardrobe as these pieces will last far longer. Look for organic cotton, hemp, Tencel, ethically-raised wool, and other natural fibres!&lt;/p&gt;
&lt;p&gt;While there are some options for sustainable shopping local to where I live there are much more options available for home delivery.&lt;/p&gt;
&lt;p&gt;When its not possible to shop locally rather than travel to a city I generally turn to the internet. While investigating sustainable living I&amp;rsquo;ve collected a series of bookmarks as I&amp;rsquo;ve shopped.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.fairtrader.info/&#34;&gt;Fair trader&lt;/a&gt; is a volunteer-run co-operative shop in Holmfirth, West Yorkshire. They stock an exciting range of fashion accessories, jewellery, food and drink, clothing, homewares, toiletries, greetings cards and toys.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.miterro.com/&#34;&gt;Mi Terro&lt;/a&gt; re-engineers food waste into sustainable materials for example waste milk into t-shirts.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.ethicalsuperstore.com/&#34;&gt;Ethical Superstore&lt;/a&gt; offers products across multiple product categories.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://bambooclothing.co.uk&#34;&gt;Bamboo Clothing&lt;/a&gt; offers clothing made from bamboo really good for yoga and gym wear.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.lefrik.com&#34;&gt;Lefrik&lt;/a&gt; offers bags and backpacks made from recycled plastic bottles.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.weavergreen.com/&#34;&gt;Weaver Green&lt;/a&gt; offers rugs and textiles made from recycled plastic bottles.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.veloculture.co.uk&#34;&gt;Velo Culture&lt;/a&gt; offers belts and wallets made from recycled bicycle innertubes.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.cycleofgood.com&#34;&gt;Cycle For Good&lt;/a&gt; operates the Elephant Bike initative where if you buy a recycled bike from them they give one to someone in Malawi via their social enterprise scheme.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.yogabloke.co.uk/&#34;&gt;Yoga Bloke&lt;/a&gt; offers various sustainable yoga equipment.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://global.prana.com&#34;&gt;PrAna&lt;/a&gt; offers sustainable yoga clothing, US but ships to UK.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.napapijri.co.uk&#34;&gt;Napapijri&lt;/a&gt; offers sustainable clothing including some really nice coats.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://rapanuiclothing.com&#34;&gt;Rapanui&lt;/a&gt; offers sustainable clothing range.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.seatowel.eu&#34;&gt;SeaTowel&lt;/a&gt; offers towels made from platic collected by fishermen from the sea during fishing.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://mamoq.com&#34;&gt;momoq&lt;/a&gt; offers sustainable clothing range.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://finisterre.com&#34;&gt;finisterre&lt;/a&gt; offers sustainable clothing range.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.komodo.co.uk&#34;&gt;komodo&lt;/a&gt; offers sustainable clothing range.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.nomadsclothing.com&#34;&gt;nomads&lt;/a&gt; offers sustainable clothing range.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.wearethought.com&#34;&gt;thought&lt;/a&gt; offers sustainable clothing range.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://williamlennon.co.uk/&#34;&gt;William Lennon&lt;/a&gt; englands last working boot maker.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://veganoutfitters.com/&#34;&gt;Vegan Outfitters&lt;/a&gt; general clothing.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.livecoco.com/&#34;&gt;LiveCoco&lt;/a&gt; eco dental care products.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://bbcearth.teemill.com/circular-collection/&#34;&gt;BBC Earth&lt;/a&gt; recycled tshirts.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.twisted-creations.co.uk/&#34;&gt;Twisted Willow Creations&lt;/a&gt; garden willow sculptures.&lt;/p&gt;
&lt;p&gt;These are not endorsements, just a collection of online stores I have either bought or considered buying something from.  If you have any recomendations of good places to shop online for delivery to UK do let me know.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Working From Home In Pandemic</title>
      <link>https://darrylcauldwell.github.io/post/homeworking/</link>
      <pubDate>Wed, 08 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/homeworking/</guid>
      <description>
        
          &lt;p&gt;When I was co-located in office with the other members of my team I never really had to put much thought into the structure of the working day. I turned up around 9am, took 30m lunch at 12noon and left around 5:00pm. My work is delivering solutions which often span several weeks or months as such I have a great deal of flexibility on how I structure my day.&lt;/p&gt;
&lt;p&gt;Around ten years ago I moved to be a remote worker based at home. During the years I&amp;rsquo;ve had many learning opportunities for how best to work and get into a routine where I am equally as productive as I was when based in the office. As more people are now forced to become remote workers ( at least temporarily ) it seemed a good time to write out my thoughts.&lt;/p&gt;
&lt;h2 id=&#34;my-perception-of-what-others-think&#34;&gt;My Perception Of What Others Think&lt;/h2&gt;
&lt;p&gt;When I first moved to remote working I felt being out of physical sight of colleagues they would think I was slacking off. I thought my work was less visible so I looked to increase my output by piling on the hours, a typical day would be something like.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;06:30 - 07:00   Turn laptop on in kitchen while making coffee, read emails over coffee
07:00 - 07:30   Breakfast while thinking about replies for emails
07:30 - 08:30   Reclocate laptop to dinning room table write replies for emails and form daily to do list
08:30 - 09:00   Wash, brush teeth etc
09:00 - 17:00   Laptop in spare bedroom, work tasks
17:00 - 19:00   Dinner with my wife I&#39;d try and switch off but typically would have something work related going on so would be maybe only 80-90% present
19:00 - 22:00   Spending maybe 50% of time catching up on tech news or personal projects
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I quickly recognised that being at work to some extent every waking hour was unhealthy. I&amp;rsquo;d never had to speak about topics like this with my manager or colleagues, so I was unsure how to even raise the topic.  I gradually tried to introduce exploratory questions when we were talking about other things. Talking around the subject with my colleagues and manager I found cathartic for me and I soon realized this whole thing I had constructed in in my mind only. Becoming aware of this allowed me to proceed without guilt towards a much more normal working life remotely. If I had not done this one thing, I would have certainly needed to have moved back to a co-location workspace.&lt;/p&gt;
&lt;h2 id=&#34;separating-home-and-work&#34;&gt;Separating Home and Work&lt;/h2&gt;
&lt;p&gt;The secondary cause I identified was that I didn&amp;rsquo;t have a dedicated working space so wherever I was became a temporary working space. While I used laptop with a monitor, keyboard and mouse in the office  these were not things which I could take home for remote working. At home I had a desk in a spare bedroom for my personal computer, monitor, keyboard and mouse. When I started remote working, I used laptop only so I could have it on the counter in the kitchen, use at dinner table for most of day and then take to the couch for the evening.&lt;/p&gt;
&lt;p&gt;My first attempt at improving this was to remove personal computer and use desk monitor/keyboard/mouse and use the spare bedroom as home office. Having two monitors increased my productivity during core office hours I still ended up with laptop in the kitchen over breakfast and on the couch in the evening.&lt;/p&gt;
&lt;p&gt;I spent the next year saving up for a summer house to act as a home office. This has proved to be an invaluable solution which really has enabled a practical long term way of working. From day one of having the summer house my family noticed a massive difference in me. Albeit only 100feet from the house the separation of home and work life is incredible, I now keep laptop powered off until I go to work and power it off when I leave. I still have access email via smart phone for anything urgent.&lt;/p&gt;
&lt;h2 id=&#34;smarter-working&#34;&gt;Smarter Working&lt;/h2&gt;
&lt;p&gt;When I was working the longer hours I got projects finished quicker, studied so was always at front of new technology, both of which got me recognised as a high performer. Being a high performer got more complex and interesting projects. When I moved to a have clear separation between work and home I had less hours to work. I began exploring techniques for better time management with goal of maintaining high performance.&lt;/p&gt;
&lt;p&gt;A friend recommended I explore the pomodoro technique, at a high level you break your workday into 25minutes intervals separated by short breaks. The premise didn’t seem like it would be right for me. But I was wrong I actually ended up really liking this and was very productive. It does become difficult to do every day to do planning correctly especially when attending calls and meetings.&lt;/p&gt;
&lt;p&gt;The biggest drawback I found of the pomodoro technique is that my concentration capabilities vary through the day. I have various types of tasks I need to complete during the day which for me require different approaches. When I am doing a complex task such as writing software or deeply thinking about design it takes me 20-30minutes to get into a rhythm and I can only sustain that for maybe an hour and a half. I need to spend the time immediately before and after these two hours doing work which doesn&amp;rsquo;t require as much deep concentration. I don&amp;rsquo;t always have concentration work for two blocks every day, personally I feel more effective in a morning so where possible use the morning time block over the afternoon.&lt;/p&gt;
&lt;p&gt;When external actors allow a home office day optimized for high performance for me looks like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;06:30 - 07:00   coffee and drive to gym
07:00 - 07:30   HIIT session at gym
07:30 - 08:30   family breakfast then walk my daughter to school with dog
09:00 - 10:00   process email, schedule meetings, scrum team stand-up
10:00 - 10:15   clear mind and take coffee
10:15 - 12:00   perform focussed concentration work
12:00 - 12:30   take lunch
12:30 - 13:30   low concentration work
13:30 - 15:30   perform focussed concentration work or low concentration work
15:30 - 15:45   clear mind and take coffee
15:45 - 17:00   low concentration work
17:00 - 19:30   family dinner, family dog walk, daughter book and bed
19:30 - 20:30   self-study OR tech meetups OR gym session
20:30 - 22:00   family time
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;project-management-lite&#34;&gt;Project Management Lite&lt;/h2&gt;
&lt;p&gt;When your sat in an office with team it is very easy to keep up to date with what everyone is doing through general chit-chat. When your remote from the rest of team it is easy to have two people working on same thing.  Its equally east for no one working on something which is needed, and everyone assumes someone else is doing it.&lt;/p&gt;
&lt;p&gt;While full project management of a team&amp;rsquo;s tasks is overkill, a form of project management lite is useful. Technology can really help here, many teams I&amp;rsquo;ve worked on towards a common goal have used Jira. The product owner managed requirements and forms well defined epics/stories which they can track visibility of progress. The feature lead takes the story breaks into sub-tasks and engineers with right skills and cycles picks them up. A daily 5-10minute stand-up call between people working together at the start of every day ensures everyone is aware of progress and status.&lt;/p&gt;
&lt;h2 id=&#34;collaboration&#34;&gt;Collaboration&lt;/h2&gt;
&lt;p&gt;Writing scripts and other assets for solutions delivery can be done in isolation but typically talking things through really helps. When working on knarly issues in an office we would typically sit at same desk to maintain a dialogue and both watch same screen when writing the code. This pair programming is super useful way of getting better quality and faster with more chance of things working right first time. When everyone is remote this style of working could be really difficult and lead to inefficiency.&lt;/p&gt;
&lt;p&gt;I was an early adopter of Visual Studio Code as it fitted a very specific use case I had. My use case was that I used to regularly switch between text editing on Windows Server RDP and laptop local on macOS. VS Code was a free and lightweight tool which offered same UI and shortcuts on both OS. It is very extensible and in last few years the &lt;a href=&#34;https://marketplace.visualstudio.com/items?itemName=MS-vsliveshare.vsliveshare&#34;&gt;Live Share&lt;/a&gt; extension was released. Live Share allows you to collaboratively edit and debug with others in real time. When used in conjunction with a phone call its perfect way to enable remote pair programming.&lt;/p&gt;
&lt;h2 id=&#34;pet-therapy&#34;&gt;Pet Therapy&lt;/h2&gt;
&lt;p&gt;One of the key challenges for remote working is the lack of social interaction. For the first few weeks and months I wasn&amp;rsquo;t aware that I was missing social interaction. Before long I began feeling a little different, a general feeling of loneliness, I think maybe even I was suffering a mild depression.&lt;/p&gt;
&lt;p&gt;As a child growing up my parents had always been dog owners. We hadn&amp;rsquo;t been able to have a dog before as we both out at work. Being a remote worker meant now I was home many more days. I still had to travel to customers meetings but found a local kennel offered doggy day-care. We ended up getting an english cocker spaniel, he keeps me company in the empty house. A spaniel has many character flaws but is an entertainer who has boundless enthusiasm and keeps me sane. He is also very friendly with other dogs and so his regular walks typically lead to me talking to other owners while he plays with their dog.&lt;/p&gt;
&lt;h2 id=&#34;exercise&#34;&gt;Exercise&lt;/h2&gt;
&lt;p&gt;When I worked in an office regularly attending gym was a really easy way to stay in shape. There was a little group of three of four of us who looked to go together. There always challenges to attend, meeting schedule, not feeling like it, busy with work but the encouragement of each other we made it much more often than not.&lt;/p&gt;
&lt;p&gt;Working from home it is very easy to fall out of the habit of exercise. We live in a rural area with many footpaths and bridleways which means for most of the year we can easily do walking, running and cycling. In the winter when day light hours are much shorter the weather is cold and rainy/snowy it easy to drop back.&lt;/p&gt;
&lt;p&gt;To help maintain some exercise during winter when I got the home office built it gave space for some indoor exercise space. As part of my gym routine I&amp;rsquo;d always liked to include some time on the Concept2 rower so bought one for home from eBay. The rower was great but after a year or two I found indoor rowing as primary form of exercise a little tedious. I sold the Concept2 rower on and bought a Nordic Trak treadmill.&lt;/p&gt;
&lt;p&gt;While I&amp;rsquo;ve always enjoyed running outdoors, I never really enjoyed the treadmill in the gym. I tend to stand when I&amp;rsquo;m watching recordings of conference calls to avoid the temptation of getting sidetracked by the computer and loosing focus. The treadmill is useful as now I can be walking instead of standing. It is also really useful when need to step away from a problem for a few minutes, I do a 1km jog which takes about five to six minutes. With outdoor running there is the scenery and you lose track of time on the treadmill the dynamic is very different and while I do occasionally do longer runs they are very rarely more than an hour.&lt;/p&gt;
&lt;h2 id=&#34;pandemic-adjustments&#34;&gt;Pandemic Adjustments&lt;/h2&gt;
&lt;p&gt;Since the global pandemic our now seven year old daughter school has closed, my wife has been furloughed from her job and the gym has closed. We always spoke to our daughter about school, approached homework and read books together. As the situation developed and we faced with this unexpected home schooling opportunity my wife and I realized we really didn&amp;rsquo;t know what she did for the 7hours of the day she is at school. My wife and I were apprehensive at first as how to home school our daughter.&lt;/p&gt;
&lt;p&gt;Having both my wife and daughter off at the same time has meant his has affected my schedule too much. Becoming a teacher is a challenge for my wife so I&amp;rsquo;ve try and give her as much personal time as possible. I do an lesson first thing in morning before I start work which gives my wife an hour to walk dog and get ready. The lessons aren&amp;rsquo;t back to back, so this also allows a good transition for us both. We also take advantage of them being around by taking breaks together.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;06:30 - 07:00   Coffee
07:00 - 08:00   Family breakfast
08:00 - 09:00   Home school while wife walks the dog
09:00 - 10:00   Process email, schedule meetings, scrum team stand-up
10:00 - 10:15   Family snack break
10:15 - 12:00   Perform focussed concentration work
12:00 - 12:30   Take lunch
12:30 - 13:30   Low concentration work
13:30 - 15:30   Perform focussed concentration work or low concentration work
15:30 - 15:45   Family snack break
15:45 - 17:00   Low concentration work
17:00 - 19:30   Family dinner, after which I take over with daughter dog walk, book and bed etc
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Since the pandemic I found the Peleton was offering three months of membership for free. Previously I had only ever thought you needed the Peleton equipment to do the sessions. There are two membership levels one for using your own bike/ treadmill and the other which requires their equipment. The class based Peleton treadmill workouts have proved to be really enjoyable alternative while the gyms are closed.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Introduction To Kubernetes Cluster Networking with NSX-T</title>
      <link>https://darrylcauldwell.github.io/post/k8s-nsxt/</link>
      <pubDate>Tue, 31 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/k8s-nsxt/</guid>
      <description>
        
          &lt;p&gt;When developing a cloud native application using Docker containers she soon needs to understand how Docker containers communicate. In previous &lt;a href=&#34;https://darrylcauldwell.github.io/post/docker-networking&#34;&gt;post&lt;/a&gt; I looked at how Docker containers communicate on a single host. When the developer wants to scaleout capacity of the hosting across multiple hosts or increase abailability she might look at deploying this on a Kubernetes cluster. The move from single Docker host to multiple hosts managed as Kubernetes Cluster introduces changes to the container networking model. The four distinct networking problems a Kubernetes Cluster needs to address:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Highly-coupled container-to-container communications&lt;/li&gt;
&lt;li&gt;Pod-to-Pod communications&lt;/li&gt;
&lt;li&gt;Pod-to-Service communications&lt;/li&gt;
&lt;li&gt;External-to-Service communications: this is covered by services&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;what-is-a-kubernetes-pod&#34;&gt;What Is A Kubernetes Pod&lt;/h2&gt;
&lt;p&gt;A Docker container is great for deploying a single atomic unit of software. This model can become a bit cumbersome when you want to run multiple pieces of software together. You often see this when developers create Docker images that use &lt;a href=&#34;https://docs.docker.com/config/containers/multi-service_container/&#34;&gt;supervisord&lt;/a&gt; as an entrypoint to start and manage multiple processes. Many have found that it is instead more useful to deploy those applications in groups of containers that are partially isolated and partially share an environment. It is possible to configure Docker to control the level of sharing between groups of containers by creating a parent container and manage the lifetime of those containers, however this is administratively complex. Kubernetes provides an abstraction called Pods for just this use case.&lt;/p&gt;
&lt;p&gt;A Kubernetes Pod implements a &amp;lsquo;pause&amp;rsquo; container as the managing parent container, the Pod also contains one or more of  application containers. The &amp;lsquo;pause&amp;rsquo; container serves as the basis of Linux namespace sharing in the Pod the other containers are starterd within that namespace. Sharing a namespace includes sharing network stack and other resources such as volumes. Sharing a network namespace means containers within a Pod share an IP address and all containers within a Pod can all reach each other’s ports on localhost.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/k8s-nsxt-pod.png&#34; alt=&#34;Kubernets Pod&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;what-is-a-kubernetes-service&#34;&gt;What Is A Kubernetes Service&lt;/h2&gt;
&lt;p&gt;Typically a Kubernetes Deployment is used to When a Kubernetes Pod is deployed Pods. A Deployment describes a desired state it can create and destroy Pods dynamically. While each Pod gets its own IP address, the set of Pods running can change. A Kubernetes Service (sometimes called a micro-service) is an abstraction which defines a logical set of Pods. The Kubernetes API provides Service discovery to Pods, it also offers a method of exposing Services via network port or load balancer to external systems.&lt;/p&gt;
&lt;h2 id=&#34;what-is-container-networking-interface-cni&#34;&gt;What Is Container Networking Interface (CNI)&lt;/h2&gt;
&lt;p&gt;Container-centric infrastructure needs a network and this network must be dynamic. Container networking is designed to be plugable, the Container Networking Interface is a defined &lt;a href=&#34;https://github.com/containernetworking/cni/blob/master/SPEC.md&#34;&gt;specification&lt;/a&gt;. Various open source projects and vendors provide CNI compliant plugins which provide dynamic networking solution for containers.&lt;/p&gt;
&lt;h2 id=&#34;what-is-nsx-t-container-plugin-ncp&#34;&gt;What Is NSX-T Container Plugin (NCP)&lt;/h2&gt;
&lt;p&gt;The NSX-T Container Plug-in (NCP) provides a CNI plugin and an integration with container orchestrators such as Kubernetes and OpenShift.&lt;/p&gt;
&lt;p&gt;NSX-T bring advanced features which can enrich Kubernetes cluster networking &lt;a href=&#34;https://blogs.vmware.com/networkvirtualization/2017/03/kubecon-2017.html/&#34;&gt;including&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Fine-grained traffic control and monitoring&lt;/li&gt;
&lt;li&gt;Fine-grained security policy (firewall rules)&lt;/li&gt;
&lt;li&gt;Automated creation of network topology&lt;/li&gt;
&lt;li&gt;Integration with enterprise networking&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The main component of NCP runs in a container and communicates with NSX Manager and with the Kubernetes control plane. NCP monitors changes to containers and other resources and manages networking resources such as logical ports, switches, routers, and security groups for the containers by calling the NSX API.&lt;/p&gt;
&lt;h2 id=&#34;nsx-t-container-plug-in-release-25&#34;&gt;NSX-T Container Plug-in Release 2.5&lt;/h2&gt;
&lt;p&gt;I looked at the &lt;a href=&#34;http://darrylcauldwell.com/nsx-openshift/&#34;&gt;NCP initially for integration with OpenShift&lt;/a&gt; in mid-2018. I am revisiting this now to refresh my understanding and explore some of the new features introduced with the &lt;a href=&#34;https://blogs.vmware.com/networkvirtualization/2019/09/nsx-t-2-5-what-is-new-for-kubernetes.html/&#34;&gt;2.5 release&lt;/a&gt; including:&lt;/p&gt;
&lt;h3 id=&#34;policy-api-object-support&#34;&gt;Policy API Object Support&lt;/h3&gt;
&lt;p&gt;Prior to the 2.5 release all NSX objects which the NCP interacted with had to be created via the Advanced Networking &amp;amp; Security tab in the UI or the old imperative APIs. The imperative API was harder than it could have been to control programatically so with the NSX-T 2.4 release VMware introduced a new intent-based Policy API and corresponding Simplified UI. The NCP now supports either the imperative or the intent-based API,  to use the intent-based API a new parameter in the NCP configmap (ncp.ini) policy_nsxapi needs to be set to True.&lt;/p&gt;
&lt;h3 id=&#34;simplified-installation&#34;&gt;Simplified Installation&lt;/h3&gt;
&lt;p&gt;Another change I am interested in exploring is the simplified installation. In the past, an admin had to login to every k8s node and perform multiple steps to bootstrap it. She had to install the NSX CNI Plug-in and OpenVSwitch, to create OVS bridge and to add one vNic to the bridge. The 2.5 release introduces a second DaemonSet nsx-ncp-bootstrap Pod this now handles the deployment and lifecycle management of these components and we don’t need to login to every node. This should make it easier to scale out a cluster with additional nodes.&lt;/p&gt;
&lt;h2 id=&#34;lab-hardware-configuration&#34;&gt;Lab Hardware Configuration&lt;/h2&gt;
&lt;p&gt;To explore Kubernetes networking and the NCP I am using my homelab. My homelab has a very simple physical network namely a single subnet (192.168.1.0/24) with DHCP enabled and which has default route to the internet. Connected to the physical network are three Intel NUCs each has two 1G NIC an onboard and an additional 1G USB3 NIC.&lt;/p&gt;
&lt;h2 id=&#34;lab-vsphere-configuration&#34;&gt;Lab vSphere Configuration&lt;/h2&gt;
&lt;p&gt;The hosts run vSphere 6.7 Update 3 and have the onboard NIC configure as a vSphere Standard Switch hosting Management and vSAN VMkernels and the USB3 NIC is unused. The hosts are added to a vCenter appliance (192.168.1.13) and formed into a VSAN enabled cluster. The cluster also hosts a Windows 2019 Server VM running Active Directory (192.168.1.10) this also acts as DNS server and NTP source for lab.&lt;/p&gt;
&lt;h2 id=&#34;lab-nsx-t-configuration&#34;&gt;Lab NSX-T Configuration&lt;/h2&gt;
&lt;p&gt;An extra-small NSX Manager appliance (192.168.1.14) is deployed.  All esxi hosts are configured as Transport Nodes using vusb0 interface to Transport Zone named &amp;lsquo;overlayTransport&amp;rsquo;. A medium sized NSX Edge called &amp;lsquo;nsxEdge&amp;rsquo; is deployed which is a member of &amp;lsquo;overlayTransport&amp;rsquo; and &amp;lsquo;vlanTransport&amp;rsquo; Transport Zones. A Edge Cluster named &amp;lsquo;edgeCluster&amp;rsquo; and add &amp;lsquo;nsxEdge&amp;rsquo; is a member.&lt;/p&gt;
&lt;h2 id=&#34;kubernetes-ip-address-space&#34;&gt;Kubernetes IP Address Space&lt;/h2&gt;
&lt;p&gt;A Kubernetes Cluster requires all Pods on a node to communicate with all Pods on all nodes in the cluster without NAT these are refered to as CluterIP. To support this a range of IP addresses must be defined to be issued to Pods and Services within a cluster. Even though the range is used for both Pods and Services, it is called the Pod address range. The last /20 of the Pod address range is used for Services. A /20 range has 212 = 4096 addresses. So 4096 addresses are used for Services, and the rest of the range is used for Pods.&lt;/p&gt;
&lt;p&gt;The address range I will be using to issue ClusterIP for this lab cluster is 10.0.0.0/16.&lt;/p&gt;
&lt;p&gt;As well as internal communicatins using ClusterIP some parts of your application may need to be exposed as a Service to be accessible on an externally routable IP address. There are two methods for exposing Service onto an externally routable IP address, NodePort and LoadBalancer. Source NAT is used for translating private ClusterIP address to a public routable address.&lt;/p&gt;
&lt;p&gt;The external address range I will be using to issue ExternalIP for this lab cluster is 172.16.0.0/16.&lt;/p&gt;
&lt;h2 id=&#34;ncp---nsx-object-identification&#34;&gt;NCP - NSX Object Identification&lt;/h2&gt;
&lt;p&gt;There can be many objects deployed within NSX-T, the NCP needs to understand which of these objects to interact with. The NSX objects which the NCP needs to interact with include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Overlay transport zone&lt;/li&gt;
&lt;li&gt;Tier-0 logical router&lt;/li&gt;
&lt;li&gt;Logical switch to connect the node VMs&lt;/li&gt;
&lt;li&gt;IP Block for internal ClusterIP addressing&lt;/li&gt;
&lt;li&gt;IP Pool for ExternalIP addressing&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The NCP configuration is stored in ncp.ini file. It is possible to put the UUID of NSX objects in the ncp.ini but this an administrative pain. The mapping of which NSX objects for NCP to interact with is better achieved by applying tags to the appropriate NSX objects.&lt;/p&gt;
&lt;p&gt;An NSX-T instance can support multiple Kubernetes clusters to ensure correct object mapping a cluster name is used. The cluster name is specified in NCP configuration and the appopriate NSX objects must have tag of same name applied.&lt;/p&gt;
&lt;p&gt;For this lab environment I am configuring with cluster name &amp;lsquo;pandora&amp;rsquo;.&lt;/p&gt;
&lt;h2 id=&#34;deploy-and-configure-tier-0&#34;&gt;Deploy and Configure Tier-0&lt;/h2&gt;
&lt;p&gt;The NCP deploys application centric network topology at the top of that topology is a Tier-0 router which provides uplink to the physical network.&lt;/p&gt;
&lt;p&gt;Use the Policy UI to deploy a Tier-0 Logical Router with High-Availability mode Active-Passive. In order the NCP knows the correct Tier-0 Logical Router a tag like this needs to be applied:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Tag&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Scope&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;pandora&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;ncp/cluster&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;When applied it should look like:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/k8s-nsxt-tier0.png&#34; alt=&#34;NSX-T Tier-0 Router&#34;&gt;&lt;/p&gt;
&lt;p&gt;To communicate with the physical network the Tier-0 requires an uplink IP address.  In order to add uplink IP address we require creating a network segment backed by VLAN.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/k8s-nsxt-physical-segment.png&#34; alt=&#34;VLAN Backed Segment&#34;&gt;&lt;/p&gt;
&lt;p&gt;We can now configure an interface on the Tier-0 with IP address 192.168.1.17.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/k8s-nsxt-tier0-uplink.png&#34; alt=&#34;NSX-T Tier-0 Uplink&#34;&gt;&lt;/p&gt;
&lt;p&gt;To enable ExternalIP routing from physical network add a static route to physical router directing 172.16.0.0/16 to 192.168.1.17.&lt;/p&gt;
&lt;h3 id=&#34;nsx-ip-block-for-internal-clusterip&#34;&gt;NSX IP Block for internal ClusterIP&lt;/h3&gt;
&lt;p&gt;NSX-T has an inbuilt capability for IP Management, in which we can allocate blocks of IP Addresses and create IP Pools.&lt;/p&gt;
&lt;p&gt;The NCP requires an IP Block for issuing internal ClusterIP. Create the 10.0.0.0/16 IP address block named &amp;lsquo;k8s-1-internal&amp;rsquo; with tags applied like this:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Tag&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Scope&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;pandora&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;ncp/no_snat&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;pandora&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;ncp/cluster&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;When applied it should look like:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/k8s-nsxt-internal-block.png&#34; alt=&#34;Internal Block&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;nsx-ip-pool-for-externalip&#34;&gt;NSX IP Pool for ExternalIP&lt;/h2&gt;
&lt;p&gt;The NCP requires an IP Pool for issuing internal ExternalIP. First create an IP Block named &amp;lsquo;k8s-1-external&amp;rsquo; with CIDR 172.16.0.0/16. This IP Block is not accessed directly by NCP so does not need any tags.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/k8s-nsxt-external-block.png&#34; alt=&#34;External Block&#34;&gt;&lt;/p&gt;
&lt;p&gt;Once the IP Block is in place create an IP Pool named &amp;lsquo;k8s-1-loadbalancer&amp;rsquo; which has a subnet issued from IP Block &amp;lsquo;k8s-1-external&amp;rsquo; which is sized at 128 the IP Pool.  The External IP Pool can be shared but should at least have tag applied like this:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Tag&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Scope&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;true&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;ncp/external&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;When applied it should look like:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/k8s-nsxt-external-pool.png&#34; alt=&#34;External Block Tag&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;node-logical-switch&#34;&gt;Node Logical Switch&lt;/h2&gt;
&lt;p&gt;Network connectivity to the containers running in Kubernetes is provided by a NSX-T logical switch segment which is often referred to as the node logical switch. For this create a new segment called &amp;lsquo;node-logical-switch&amp;rsquo; within the &amp;lsquo;overlayTransportZone&amp;rsquo; connected to no gateway.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/k8s-nsxt-node-logical-switch.png&#34; alt=&#34;Node Logical Switch&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;kubernetes-master-vm&#34;&gt;Kubernetes Master VM&lt;/h2&gt;
&lt;p&gt;Create a Ubuntu 18.04 VM with 2x CPU, 4GB RAM and 50GB vHDD named &amp;lsquo;k8s-master&amp;rsquo;. The VM should have two vNIC one which is used to communicate with NSX API and which will host Kubernetes API. The second connected to the node logical switch which will have the Open vSwitch (OVS) bridge configured to give connectivity to the Pods. In my lab first connected to &amp;lsquo;VM Network&amp;rsquo; enumerates as ens160 and the scond connected to &amp;lsquo;node-logical-switch&amp;rsquo; enumerates as ens192.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cat /etc/netplan/01-netcfg.yaml 

network:
  version: 2
  renderer: networkd
  ethernets:
    ens160:
      addresses: 
      - 192.168.1.27/24
      gateway4: 192.168.1.254
      nameservers:
          search:
          - darrylcauldwell.com
          addresses: 
          - 192.168.1.10
    ens192: {}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In order the NCP know which vNIC to configure the VM vNIC connected &amp;lsquo;node-logical-switch&amp;rsquo; creates a segment port object in NSX-T this port must have tag applied like this:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Tag&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Scope&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;k8s-master&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;ncp/node_name&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;pandora&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;ncp/cluster&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;When applied it should look like:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/k8s-nsxt-segment-port-tags.png&#34; alt=&#34;Segment Port Tags&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;install-and-configure-kubernetes&#34;&gt;Install and Configure Kubernetes&lt;/h2&gt;
&lt;p&gt;Docker and Kubernetes require installation do this by running the following.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo apt update -y
sudo apt upgrade -y
sudo apt install docker.io python apt-transport-https -y
sudo gpasswd -a $USER docker
sudo systemctl start docker
sudo systemctl enable docker
curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
sudo apt-add-repository &amp;quot;deb http://apt.kubernetes.io/ kubernetes-xenial main&amp;quot;
sudo apt-get update
sudo swapoff -a 
sudo sed -i &#39;/ swap / s/^\(.*\)$/#\1/g&#39; /etc/fstab
sudo apt-get install -y kubelet=1.16.4-00 kubeadm=1.16.4-00 kubectl=1.16.4-00
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Initialize the Kubernetes cluster by running the following:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo kubeadm init
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In order to easily run kubectl as a user we need to copy the cluster configuration to the user profile, do this by running the following.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We can now connect to cluster and check the state of the nodes, do this by running the following on the Master node.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl get nodes
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/k8s-nsxt-init-get-nodes.png&#34; alt=&#34;Init Get Nodes&#34;&gt;&lt;/p&gt;
&lt;p&gt;The status of each Node will show &amp;lsquo;NotReady&amp;rsquo;,  we can get more details of why it is in this state by running the following on the Master node.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl describe nodes k8s-master | grep Conditions -A9
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/k8s-nsxt-init-describe-node.png&#34; alt=&#34;Init Describe Nodes&#34;&gt;&lt;/p&gt;
&lt;p&gt;With this we can see this reason for the error is &amp;lsquo;NetworkPluginNotReady&amp;rsquo; that the cni plugin is not initiated.&lt;/p&gt;
&lt;h2 id=&#34;install-and-configure-nsx-container-plug-in-ncp&#34;&gt;Install and Configure NSX Container Plug-in (NCP)&lt;/h2&gt;
&lt;p&gt;The NSX Container Plug-in (NCP) provides integration between NSX-T and Kubernetes, it is a containerised application which manages communicates between NSX Manager and the Kubernetes control plane. The NSX Container Plug-in (NCP) application runs in Kubernetes it is supplied as .zip download. The configuration of the NCP applications is maintained in a Kubernetes manifest file.&lt;/p&gt;
&lt;p&gt;The NCP application ships a container image file we could deploy this to a container registry but here we will just upload the image file to VM and import the image to the local docker repository. The default container image name specified in the manifest is nsx-ncp so we can apply that as tag on the image.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo docker load -i /home/ubuntu/nsx-ncp-ubuntu-2.5.1.15287458.tar
sudo docker image tag registry.local/2.5.1.15287458/nsx-ncp-ubuntu nsx-ncp
sudo docker images | grep ncp
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Prior to the 2.5 release there were multiple  manifest files each targetting a specific area of configuration.  These are now merged into a single manifest file with multiple sections with multiple resource specifications the sections can be identified by the separator &lt;code&gt;---&lt;/code&gt;. The resources are created in the order they appear in the file.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Resource Kind&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Resource Name&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Comments&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;CustomResourceDefinition&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;nsxerrors.nsx.vmware.com&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CustomResourceDefinition&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;nsxlocks.nsx.vmware.com&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Namespace&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;nsx-system&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ServiceAccount&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;ncp-svc-account&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ClusterRole&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;ncp-cluster-role&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ClusterRole&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;ncp-patch-role&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ClusterRoleBinding&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;ncp-cluster-role-binding&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ClusterRoleBinding&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;ncp-patch-role-binding&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ServiceAccount&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;nsx-node-agent-svc-account&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ClusterRole&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;nsx-node-agent-cluster-role&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ClusterRoleBinding&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;nsx-node-agent-cluster-role-binding&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ConfigMap&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;nsx-ncp-config&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Must update Kubernetes API and NSX API parameters&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Deployment&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;nsx-ncp&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ConfigMap&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;nsx-node-agent-config&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Must update Kubernetes API and NSX API parameters&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;DaemonSet&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;nsx-ncp-bootstrap&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;DaemonSet&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;nsx-node-agent&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;For this lab I will use mostly default configuration from the supplied manifest file template. The settings I change from what is in template are the environment specifics such as details for connecting to NSX API including whether to use imperative API or intent-based API, the &amp;lsquo;cluster&amp;rsquo; name and the Node vNIC on which the OVS bridge gets created on.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[nsx_v3]
policy_nsxapi = True

nsx_api_managers = 192.168.1.14
nsx_api_user = admin
nsx_api_password = VMware1!

insecure = True

[coe]
cluster = pandora

[k8s]
apiserver_host_ip = 192.168.1.27
apiserver_host_port = 6443

[nsx_kube_proxy]
ovs_uplink_port = ens192
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Once the manifest file is updated and docker image in local registry we can apply the NCP manifest. Applying the manifest takes a couple of minutes while as it creates various Pods we can watch their creation to view progress.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl apply --filename /home/ubuntu/ncp-ubuntu.yaml
kubectl get pods --output wide --namespace nsx-system --watch
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/k8s-nsxt-deploy-ncp.png&#34; alt=&#34;Deploy NCP&#34;&gt;&lt;/p&gt;
&lt;p&gt;If all has gone well we can take a look at the objects created within the namespace.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl get all --namespace nsx-system
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/k8s-nsxt-deployed-ncp.png&#34; alt=&#34;Deployed NCP&#34;&gt;&lt;/p&gt;
&lt;p&gt;Now its running we can check health of the NCP, the NCP has a &lt;a href=&#34;https://docs.vmware.com/en/VMware-NSX-T-Data-Center/2.5/ncp-kubernetes/GUID-EA8E6CEE-36F4-423C-AD1E-DD6421A5FB1C.html&#34;&gt;CLI&lt;/a&gt; where we can run various commands including health checks.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl exec -it nsx-ncp-6978b9cb69-dj4k2 --namespace nsx-system -- /bin/bash 
nsxcli
get ncp-k8s-api-server status
get ncp-nsx status
exit
exit
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/k8s-nsxt-ncp-health.png&#34; alt=&#34;NCP Health&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;nsx-policy-ui-object-creation&#34;&gt;NSX Policy UI Object Creation&lt;/h2&gt;
&lt;p&gt;With NSX integration when we deploy a Kubernetes namespace the NCP creates a corresponding segment, IP Pool (from internet 10.0.0.0/8 range), subnet and Tier-1 router.  If you open NSX Manager and view one of the object categories which should have objects created. Then create two Kubernetes namespaces one called development and one called production.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl create --filename https://k8s.io/examples/admin/namespace-dev.json
kubectl create --filename https://k8s.io/examples/admin/namespace-prod.json
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If you refresh view in NSX Manager you will see the new objects appear in the Policy UI.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/k8s-nsxt-tier1s.png&#34; alt=&#34;NSX-T Tier-1&#34;&gt;&lt;/p&gt;
&lt;p&gt;We can then remove these two namespaces the NCP removes the corresponding segment, IP Pool (from internet 10.0.0.0/8 range), subnet and Tier-1 router.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl delete -f https://k8s.io/examples/admin/namespace-dev.json
kubectl delete -f https://k8s.io/examples/admin/namespace-prod.json
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;ncp-bootstrap-scaleout-cluster&#34;&gt;NCP Bootstrap Scaleout Cluster&lt;/h2&gt;
&lt;p&gt;We started this lab with a single node cluster to look at the nsx-ncp-bootstrap Daemonset. When Nodes are added to the cluster this should install and configure the Node with NCP.&lt;/p&gt;
&lt;p&gt;Create a second and third VM with same hardware configuration as k8s-master but name these k8s-worker-1 / k8s-worker-2 and give IPs 192.168.1.28  / 192.168.1.29.  Ensure the NSX segment port attached to  VMs is tagged correctly. Ensure the NCP docker image is uploaded, imported to local docker registry and has tag applied.&lt;/p&gt;
&lt;p&gt;To add the additional Node to the cluster first step is to create a token on master.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubeadm token create --print-join-command
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/k8s-nsxt-token.png&#34; alt=&#34;Token&#34;&gt;&lt;/p&gt;
&lt;p&gt;We use the output of command from the master to add the additional worker nodes to the cluster. The nsx-ncp-bootstap and nsx-node-agent are DaemonSets this ensures that all Nodes run a copy of a Pod. When we add the worker nodes to the cluster we can see the nsx-ncp-bootstrap Pods initialize and configure the Node and the nsx-node-agent Pods initialize.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl get pods -o wide --namespace nsx-system --watch
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/k8s-nsxt-ncp-scale-out.png&#34; alt=&#34;NCP Scale Out&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;ip-assignments&#34;&gt;IP Assignments&lt;/h2&gt;
&lt;p&gt;When a Pod is deployed it can be exposed as a Service, the service&lt;/p&gt;
&lt;p&gt;If we deploy an simple stateless application example like &lt;a href=&#34;https://kubernetes.io/docs/tutorials/stateless-application/guestbook/&#34;&gt;guestbook&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl create -f https://k8s.io/examples/admin/namespace-dev.json
kubectl config set-context --current --namespace=development
kubectl apply -f https://k8s.io/examples/application/guestbook/redis-master-deployment.yaml
kubectl apply -f https://k8s.io/examples/application/guestbook/redis-master-service.yaml
kubectl apply -f https://k8s.io/examples/application/guestbook/redis-slave-deployment.yaml
kubectl apply -f https://k8s.io/examples/application/guestbook/redis-slave-service.yaml
kubectl apply -f https://k8s.io/examples/application/guestbook/frontend-deployment.yaml
kubectl apply -f https://k8s.io/examples/application/guestbook/frontend-service.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;When we configures the lab we created NSX managed IP Block 10.0.0.0/16. When created the development namespace got allocated a /24 subnet from this block. If we view the Pods get IP in correct range.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl get pods --output wide
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/k8s-nsxt-internal-ip-allocation.png&#34; alt=&#34;Internal IP Allocation&#34;&gt;&lt;/p&gt;
&lt;p&gt;As well as Pod deployments the guestbook application installation also creates Service resources. A Service is an abstraction which defines a logical set of Pods. Our application runs three frontend pods and two Redis slaves the Service provides virtual IP. The kube-proxy is responsible for implementing the virtual IP for Services. We can see the ClusterIP are issued from the last /20 of the Pod address range. If we look in more detail at the Service resource we can see the three internal IP addresses behind it.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl get services --namespace development
kubectl cluster-info dump | grep -m 1 service-cluster-ip-range
kubectl describe service frontend
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/k8s-nsxt-clusterip.png&#34; alt=&#34;Cluster IP&#34;&gt;&lt;/p&gt;
&lt;p&gt;To facilitate communications between Pods the NCP is configuring the Open vSwitch on each Node. The Open vSwitch user space daemon runs on a container named nsx-ovs within the nsx-node-agent Pods. The Open vSwitch bridge name can be specified in the ncp.ini but defaults to br-int. If we connect to this container we can view the Open vSwitch flows .&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl exec -it nsx-node-agent-llf2c -c nsx-ovs bash --namespace nsx-system
ovs-ofctl dump-flows br-int
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/k8s-nsxt-ovs-flows.png&#34; alt=&#34;OVS Flows&#34;&gt;&lt;/p&gt;
&lt;p&gt;We can then remove the namespace and all objects within.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl delete -f https://k8s.io/examples/admin/namespace-dev.json
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;nsx-loadbalancer&#34;&gt;NSX Loadbalancer&lt;/h2&gt;
&lt;p&gt;NSX provides an load balancer capability to Kubernetes we can use this by creating service resource with type LoadBalancer.  If we create a simple replicaset of five pods and expose this we can see it gets issued with IP Address from the IP Pool tagged with ncp/external = True. We can also see this in NSX Loadbalancer configuration.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl create -f https://k8s.io/examples/admin/namespace-dev.json
kubectl config set-context --current --namespace=development
kubectl apply -f https://k8s.io/examples/service/load-balancer-example.yaml
kubectl get replicasets
kubectl expose deployment hello-world --type=LoadBalancer --name=hello-world-nsx-lb
kubectl get services hello-world-nsx-lb --watch

NAME                 TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE
hello-world-nsx-lb   LoadBalancer   10.110.64.115   &amp;lt;pending&amp;gt;     8080:32091/TCP   7s
hello-world-nsx-lb   LoadBalancer   10.110.64.115   172.16.0.13   8080:32091/TCP   7s
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We can then remove the namespace and all objects within.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl delete -f https://k8s.io/examples/admin/namespace-dev.json
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;kubernetes-pods-micro-segmentation&#34;&gt;Kubernetes Pods Micro-Segmentation&lt;/h2&gt;
&lt;p&gt;One of the great usecases for NSX with vSphere has been the is the Distributed Firewall which protects VM workload at the Hypervisor layer. When we extend NSX into the Kubernetes container we also extend the Distributed Firewall capability. We can create firewall rules which contain members of groups, the groups can be dynamically populated by use of NSX tags. Kubernetes objects can have labels attached a label attached to a Pod is reflected in NSX as a tag on the segement port of the Pod.&lt;/p&gt;
&lt;p&gt;A simple test might be to deploy a two tier app where frontend can talk to backend but frontend cannot talk to other frontend. If we create a NSX group called Web with membership criteria Segement Port, Tag, Equals web Scope secgroup. We then create a NSX DFW rule with Web as source and destination and action of drop.&lt;/p&gt;
&lt;p&gt;With this in place we can ping test from one frontend pod to another frontend and backend and see this works.  We can then apply the label to the three frontend web Pods so they become members of the NSX group and are affected by the firewall rule.  With these in place we can retest ping from one frontend pod to another frontend and see that this is now blocked.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl create -f https://k8s.io/examples/admin/namespace-dev.json
kubectl config set-context --current --namespace=development
kubectl apply -f https://k8s.io/examples/application/guestbook/redis-master-deployment.yaml
kubectl apply -f https://k8s.io/examples/application/guestbook/frontend-deployment.yaml
kubectl get pods --output wide --watch

NAME                            READY   STATUS    RESTARTS   AGE   IP         NODE           NOMINATED NODE   READINESS GATES
frontend-6cb7f8bd65-4mctt       1/1     Running   0          13m   10.0.6.4   k8s-worker-1   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
frontend-6cb7f8bd65-8wkhr       1/1     Running   0          13m   10.0.6.2   k8s-worker-1   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
frontend-6cb7f8bd65-rtgc9       1/1     Running   0          13m   10.0.6.3   k8s-worker-1   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
redis-master-7db7f6579f-zlx26   1/1     Running   0          3s    10.0.6.5   k8s-worker-1   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;

kubectl exec -it frontend-6cb7f8bd65-4mctt ping 10.0.6.2
PING 10.0.6.2 (10.0.6.2): 56 data bytes
64 bytes from 10.0.6.2: icmp_seq=0 ttl=64 time=0.083 ms

kubectl exec -it frontend-6cb7f8bd65-4mctt ping 10.0.6.5
PING 10.0.6.5 (10.0.6.5): 56 data bytes
64 bytes from 10.0.6.5: icmp_seq=0 ttl=64 time=3.191 ms

kubectl label pod frontend-6cb7f8bd65-4mctt secgroup=web
kubectl label pod frontend-6cb7f8bd65-8wkhr secgroup=web
kubectl label pod frontend-6cb7f8bd65-rtgc9 secgroup=web

kubectl exec -it frontend-6cb7f8bd65-4mctt ping 10.0.6.2
PING 10.0.6.2 (10.0.6.2): 56 data bytes
^C--- 10.0.6.2 ping statistics ---
2 packets transmitted, 0 packets received, 100% packet loss
command terminated with exit code 1

kubectl exec -it frontend-6cb7f8bd65-4mctt ping 10.0.6.5
PING 10.0.6.5 (10.0.6.5): 56 data bytes
64 bytes from 10.0.6.5: icmp_seq=0 ttl=64 time=5.672 ms
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We can then remove the namespace and all objects within.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl delete -f https://k8s.io/examples/admin/namespace-dev.json
&lt;/code&gt;&lt;/pre&gt;
        
      </description>
    </item>
    
    <item>
      <title>Vegetarianuary 2020</title>
      <link>https://darrylcauldwell.github.io/post/vegetarianuary/</link>
      <pubDate>Tue, 31 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/vegetarianuary/</guid>
      <description>
        
          &lt;p&gt;I have under taken my personal challenges over the years and the occasion of a new decade seemed a good reason to undertake another. I was inspired to look at doing this by my daughter who is an avid fan of science and is very data-driven.&lt;/p&gt;
&lt;p&gt;Last year in the middle of summer at the Bluedot science and music festival we found out about the impact of dairy om the planet and took the &lt;a href=&#34;https://www.oatly.com/uk/ditch-milk&#34;&gt;Oatly ditch-milk&lt;/a&gt; pledge and both went dairy-free for 72 hours. A day or so later while playing in the park with all of her friends they all had ice-cream but she stood by her pledge and refused, I was very proud.&lt;/p&gt;
&lt;p&gt;The experienc of going dairy-free led to us as a family spoking around the subject alot and researched some facts and figures. Ultimatley we as a family didn&amp;rsquo;t &amp;lsquo;ditch dairy&amp;rsquo;. It did influence us and we moved to regularly use almond milk for cereals albeit maintaining a smaller supply of cows milk for hot drinks.&lt;/p&gt;
&lt;p&gt;My goal is to move to a plant-based diet for January to encourages further discussion within our family about what we eat and the pro&amp;rsquo;s and con&amp;rsquo;s of a plant-based diet. We will hopefully all learn something from this and will maintain some aspects for the longer term.&lt;/p&gt;
&lt;p&gt;Types of plant-based diets include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Lacto-ovo vegetarians ( plant based but includes dairy foods and eggs )&lt;/li&gt;
&lt;li&gt;Ovo vegetarians ( plant based but includes eggs )&lt;/li&gt;
&lt;li&gt;Vegans ( plant based only )&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;My original thought was to take part in &lt;a href=&#34;https://uk.veganuary.com/&#34;&gt;veganuary&lt;/a&gt;. After reading around the full extent of what going vegan means and looking at our current &amp;lsquo;normal&amp;rsquo; lifestyle. With any form of goal-setting the goals have to be specific, measurable, achievable, relavent and time bound. I am not sure it is achievable to change so much overnight to become vegan, but maybe this experience will better equip for a future endeavour.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Measurable Goal&lt;/strong&gt; - Lacto-ovo vegetarian between 1st and 31st January&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/veg-family.jpg&#34; alt=&#34;Family Vegtarian Meal&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;12000-steps-daily-average&#34;&gt;12,000 Steps Daily Average&lt;/h2&gt;
&lt;p&gt;I an lucky enough to live in a natually beautiful location. It is easy during the winter months when it is dark both before and after work to reduce what we do. Jogging and running when it is slippery can easily lead to minor injury. By leaving the car and walking I think it should be possible for me to average walking 6 miles / &lt;a href=&#34;https://www.verywellfit.com/how-many-walking-steps-are-in-a-mile-3435916&#34;&gt;12,000 steps&lt;/a&gt; per day.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Measurable Goal&lt;/strong&gt; - Average 12,000 steps per day between 1st and 31st January&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/veg-12k.jpg&#34; alt=&#34;Jogging&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;detoxification&#34;&gt;Detoxification&lt;/h2&gt;
&lt;p&gt;I have tried some very focussed detox programs over the years. I do not intend to follow a particular defined program during January. I do intend to take opportunity to do something in this area. Detoxification is about resting, cleansing and nourishing the body from the inside out. Processing alcohol and cafine puts a strain on the organs. It is easy to increase drinking alcohol and cafine over time and useful every now and then to abstain. Whichever detox program I have followed they all have all included &amp;lsquo;lemon water&amp;rsquo; for helping your digestion, flushes out toxins and cleanses the liver.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Measurable Goal&lt;/strong&gt; - Zero alcohol per day between 1st and 31st January&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Measurable Goal&lt;/strong&gt; - No more than one cup of coffee per day between 1st and 31st January&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Measurable Goal&lt;/strong&gt; - Glass of lemon water per day between 1st and 31st January&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/veg-detox.jpg&#34; alt=&#34;Detox&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;yoga&#34;&gt;Yoga&lt;/h2&gt;
&lt;p&gt;I tried yoga first while working in India some fifteen years ago. Being on the tall side I&amp;rsquo;ve always been conscious of my back health and found yoga helped. I used to regularly attend yoga sessions in evenings. I changed jobs and for a while was a remote member of a team based on the US West Coast and team meetings clashed.  More recently our team has restructured and I am now part of a team based in EMEA. Since the re-organization I had not got around to re-joining the yoga sessions.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Measurable Goal&lt;/strong&gt; - Attend at least three of the four weekly yoga sessions between 1st and 31st January&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/veg-yoga.jpg&#34; alt=&#34;Yoga&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;fitism&#34;&gt;FITISM&lt;/h2&gt;
&lt;p&gt;I am a member of local gym called &lt;a href=&#34;http://www.fitism.co.uk/&#34;&gt;FITISM&lt;/a&gt; I have a balanced membership focussing on &lt;a href=&#34;http://www.fitism.co.uk/classes&#34;&gt;classes&lt;/a&gt; and &lt;a href=&#34;http://www.fitism.co.uk/blog/nutrition&#34;&gt;nutrition&lt;/a&gt;. I focussed on high intensity circuit type training classes. Three weeks ago I slipped on some ince and fell down some steps cracking a rib and a tooth. Soft tissue damage to the chest meant it was painful to do any classes. As the soft tissue has repaired I have been able to progress from walking to light jogging. I am now mostly comfortable but the cracked rib still makes me aware of its displeasure if I laugh, sneeze, cough or over extend a twist. One of the class types offered is RIDE which looks to be essentially spinning, I am hopeful this class type should be achievable in January. I am lucky to train in such a fun, energetic, competitive, yet encouraging environment, I feel confident together we will find a suitable class I can regularly attend.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Measurable Goal&lt;/strong&gt; - Attend at least two FITISM classes per week between 1st and 31st January&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/veg-fitism.png&#34; alt=&#34;FITISM&#34;&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Introduction To Docker Container Networking</title>
      <link>https://darrylcauldwell.github.io/post/docker-networking/</link>
      <pubDate>Mon, 18 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/docker-networking/</guid>
      <description>
        
          &lt;p&gt;When developing a cloud native application using Docker containers understanding network connectivity between containers and non-Docker workloads such as other servers and cloud APIs is essential. Docker’s networking subsystem is pluggable using drivers, several drivers exist by default, and others can be added easily.&lt;/p&gt;
&lt;h2 id=&#34;linking-containers-legacy&#34;&gt;Linking Containers (legacy)&lt;/h2&gt;
&lt;p&gt;Linking containers by name is a simple method of enabling communications between containers. To link a an app server to a DB we simply reference the db container name in the command we execute to run app server container.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker run -d --name my_mongodb mongo
docker run -d --link my_mongodb --name my_nodeapp -it node
docker ps -l

    CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES
    5dc2aa4d8542        node                &amp;quot;docker-entrypoint.s…&amp;quot;   7 seconds ago       Up 6 seconds                            my_nodeapp
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In order to facilitate communications Docker automatically creates environment variables in the target container. It also exposes all environment variables originating from Docker from the source container. If we view the IP address of the two containers and then view the environment variables of the app server we can see the details for the db server.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker inspect --format &#39;{{ .ID }} - {{ .Name }} - {{ .NetworkSettings.IPAddress }}&#39; my_mongodb
docker inspect --format &#39;{{ .ID }} - {{ .Name }} - {{ .NetworkSettings.IPAddress }}&#39; my_nodeapp

docker exec my_nodeapp env

    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
    HOSTNAME=a88e6e3f1107
    MY_MONGODB_PORT=tcp://172.17.0.2:27017
    MY_MONGODB_PORT_27017_TCP=tcp://172.17.0.2:27017
    MY_MONGODB_PORT_27017_TCP_ADDR=172.17.0.2
    MY_MONGODB_PORT_27017_TCP_PORT=27017
    MY_MONGODB_PORT_27017_TCP_PROTO=tcp
    MY_MONGODB_NAME=/my_nodeapp/my_mongodb
    MY_MONGODB_ENV_GOSU_VERSION=1.11
    MY_MONGODB_ENV_JSYAML_VERSION=3.13.0
    MY_MONGODB_ENV_GPG_KEYS=E162F504A20CDF15827F718D4B7C549A058F8B6B
    MY_MONGODB_ENV_MONGO_PACKAGE=mongodb-org
    MY_MONGODB_ENV_MONGO_REPO=repo.mongodb.org
    MY_MONGODB_ENV_MONGO_MAJOR=4.2
    MY_MONGODB_ENV_MONGO_VERSION=4.2.1
    NODE_VERSION=13.1.0
    YARN_VERSION=1.19.1
    HOME=/root
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Container linking is a legacy method of connecting containers it is much more likely today that communications on single host will use a bridge network.&lt;/p&gt;
&lt;h2 id=&#34;container-networking-with-a-bridge-driver&#34;&gt;Container Networking With A Bridge Driver&lt;/h2&gt;
&lt;p&gt;A bridge network can be used on Docker host to enable communications between containers. The first step is to create a custom bridge network on the Docker host which the containers will connect to. Each Docker network gets assigned a CIDR range and has a IPAM capability, we can view these by inspecting the network.&lt;/p&gt;
&lt;p&gt;The default bridge network is present on all Docker hosts, if you do not specify a different network, new containers are automatically connected to the default bridge network. More than likely you will want to separate containers to different networks and so will want to create multiple networks and attach different containers to each.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker network create --driver bridge my_isolated_network
docker network ls
docker network inspect my_isolated_network

    [
        {
            &amp;quot;Name&amp;quot;: &amp;quot;my_isolated_network&amp;quot;,
            &amp;quot;Id&amp;quot;: &amp;quot;76e440d68a136ffe1ab9a4dd4977a7dc0499167814de14bf4bedfaffb646197b&amp;quot;,
            &amp;quot;Created&amp;quot;: &amp;quot;2019-11-18T09:59:09.8310474Z&amp;quot;,
            &amp;quot;Scope&amp;quot;: &amp;quot;local&amp;quot;,
            &amp;quot;Driver&amp;quot;: &amp;quot;bridge&amp;quot;,
            &amp;quot;EnableIPv6&amp;quot;: false,
            &amp;quot;IPAM&amp;quot;: {
                &amp;quot;Driver&amp;quot;: &amp;quot;default&amp;quot;,
                &amp;quot;Options&amp;quot;: {},
                &amp;quot;Config&amp;quot;: [
                    {
                        &amp;quot;Subnet&amp;quot;: &amp;quot;172.18.0.0/16&amp;quot;,
                        &amp;quot;Gateway&amp;quot;: &amp;quot;172.18.0.1&amp;quot;
                    }
                ]
            },
            &amp;quot;Internal&amp;quot;: false,
            &amp;quot;Attachable&amp;quot;: false,
            &amp;quot;Ingress&amp;quot;: false,
            &amp;quot;ConfigFrom&amp;quot;: {
                &amp;quot;Network&amp;quot;: &amp;quot;&amp;quot;
            },
            &amp;quot;ConfigOnly&amp;quot;: false,
            &amp;quot;Containers&amp;quot;: {},
            &amp;quot;Options&amp;quot;: {},
            &amp;quot;Labels&amp;quot;: {}
        }
    ]
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;When networks are created you can start containers in those bridge networks.  The containers in same isolated network can then communicate by referencing name. When containers are running and connected we can inspect the network again and get the container IP address assignments etc.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker run -d --net=my_isolated_network --name my_mongodb mongo
docker run -d --net=my_isolated_network --name my_nodeapp -it node
docker network inspect my_isolated_network

    [
        {
            &amp;quot;Name&amp;quot;: &amp;quot;my_isolated_network&amp;quot;,
            &amp;quot;Id&amp;quot;: &amp;quot;76e440d68a136ffe1ab9a4dd4977a7dc0499167814de14bf4bedfaffb646197b&amp;quot;,
            &amp;quot;Created&amp;quot;: &amp;quot;2019-11-18T09:59:09.8310474Z&amp;quot;,
            &amp;quot;Scope&amp;quot;: &amp;quot;local&amp;quot;,
            &amp;quot;Driver&amp;quot;: &amp;quot;bridge&amp;quot;,
            &amp;quot;EnableIPv6&amp;quot;: false,
            &amp;quot;IPAM&amp;quot;: {
                &amp;quot;Driver&amp;quot;: &amp;quot;default&amp;quot;,
                &amp;quot;Options&amp;quot;: {},
                &amp;quot;Config&amp;quot;: [
                    {
                        &amp;quot;Subnet&amp;quot;: &amp;quot;172.18.0.0/16&amp;quot;,
                        &amp;quot;Gateway&amp;quot;: &amp;quot;172.18.0.1&amp;quot;
                    }
                ]
            },
            &amp;quot;Internal&amp;quot;: false,
            &amp;quot;Attachable&amp;quot;: false,
            &amp;quot;Ingress&amp;quot;: false,
            &amp;quot;ConfigFrom&amp;quot;: {
                &amp;quot;Network&amp;quot;: &amp;quot;&amp;quot;
            },
            &amp;quot;ConfigOnly&amp;quot;: false,
            &amp;quot;Containers&amp;quot;: {
                &amp;quot;996b590f206dded3db3a653e554167e046fe3852f55a78d6d983eaa0f7f7fc3d&amp;quot;: {
                    &amp;quot;Name&amp;quot;: &amp;quot;my_mongodb&amp;quot;,
                    &amp;quot;EndpointID&amp;quot;: &amp;quot;e78b23529f29b2a6f5291f06fb1875cac9958888ca0eb95cae814dc8b631613a&amp;quot;,
                    &amp;quot;MacAddress&amp;quot;: &amp;quot;02:42:ac:12:00:02&amp;quot;,
                    &amp;quot;IPv4Address&amp;quot;: &amp;quot;172.18.0.2/16&amp;quot;,
                    &amp;quot;IPv6Address&amp;quot;: &amp;quot;&amp;quot;
                },
                &amp;quot;eebe0a3bf7116eab4731ef68da445f24c15b185efc8d7cea20937736702b93f8&amp;quot;: {
                    &amp;quot;Name&amp;quot;: &amp;quot;my_nodeapp&amp;quot;,
                    &amp;quot;EndpointID&amp;quot;: &amp;quot;6903d08b5942c71b5afd09caf535d4abb818ded97742fe324d54bb6396b595a5&amp;quot;,
                    &amp;quot;MacAddress&amp;quot;: &amp;quot;02:42:ac:12:00:03&amp;quot;,
                    &amp;quot;IPv4Address&amp;quot;: &amp;quot;172.18.0.3/16&amp;quot;,
                    &amp;quot;IPv6Address&amp;quot;: &amp;quot;&amp;quot;
                }
            },
            &amp;quot;Options&amp;quot;: {},
            &amp;quot;Labels&amp;quot;: {}
        }
    ]

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The docker daemon implements an embedded DNS server (127.0.0.11) which provides built-in service discovery for any container created with a valid name. The containers are able to use this by docker overlay three crucial /etc files inside the container with virtual files. This arrangement allows Docker to do clever things like keep resolv.conf up to date across all containers.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker exec my_nodeapp mount

    ...
    /dev/sda1 on /etc/resolv.conf type ext4 (rw,relatime,data=ordered)
    /dev/sda1 on /etc/hostname type ext4 (rw,relatime,data=ordered)
    /dev/sda1 on /etc/hosts type ext4 (rw,relatime,data=ordered)
    ...
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If we view the DNS settings of one of the containers we see that it is set by default to 127.0.0.11.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker exec -it my_nodeapp cat /etc/resolv.conf

    nameserver 127.0.0.11
    options ndots:0
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We can therefore ping the database container by using its container name from the app server.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker exec -it my_nodeapp ping -c 1 my_mongodb

    PING my_mongodb (172.18.0.2) 56(84) bytes of data.
    64 bytes from my_mongodb.my_isolated_network (172.18.0.2): icmp_seq=1 ttl=64 time=0.177 ms

    --- my_mongodb ping statistics ---
    1 packets transmitted, 1 received, 0% packet loss, time 0ms
    rtt min/avg/max/mdev = 0.177/0.177/0.177/0.000 ms
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It can be a relatively common requirement for me to have different container names for same application function in different environments e.g. dev_mongodb, qa_mongodb, prod_mongodb. While I could configuring connection strings in the app server it might be more useful to give the database a connection alias e.g. mongodb. Docker run command has flag &amp;ndash;network-alias so we can use a common alias between environments.&lt;/p&gt;
&lt;p&gt;If we run the two containers and specify an alias for the database we can see we can ping the alias name from app container.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker run -d --net=my_isolated_network --name my_mongodb --network-alias mongodb mongo 
docker run -d --net=my_isolated_network --name my_nodeapp -it node
docker exec -it my_nodeapp ping -c 1 mongodb

    PING mongodb (172.18.0.2) 56(84) bytes of data.
    64 bytes from my_mongodb.my_isolated_network (172.18.0.2): icmp_seq=1 ttl=64 time=0.136 ms

    --- mongodb ping statistics ---
    1 packets transmitted, 1 received, 0% packet loss, time 0ms
    rtt min/avg/max/mdev = 0.136/0.136/0.136/0.000 ms
&lt;/code&gt;&lt;/pre&gt;
        
      </description>
    </item>
    
    <item>
      <title>Cloudbased-init For vSphere</title>
      <link>https://darrylcauldwell.github.io/post/cloudbased-init/</link>
      <pubDate>Thu, 26 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/cloudbased-init/</guid>
      <description>
        
          &lt;p&gt;vRealize Automation Cloud and 8.x allows you to deploy and configure cloud agnostic virtual machines. To achieve agnostic in-guest OS customization capability across for on-premises vSphere, AWS, GCP and Azure endpoints &lt;a href=&#34;https://cloud-init.io/&#34;&gt;cloud-init&lt;/a&gt; is used for Linux guests and &lt;a href=&#34;https://cloudbase.it/cloudbase-init/&#34;&gt;cloudbase-init&lt;/a&gt; is used for Windows guests.&lt;/p&gt;
&lt;h2 id=&#34;inital-attempt-all-defaults&#34;&gt;Inital Attempt All Defaults&lt;/h2&gt;
&lt;p&gt;In vSphere I created a Windows 2019 VM with defaults except for mapping ISO as CD/ROM. I then ran through installer to install Standard edition with Desktop experience, installed VMware Tools, disabled firewall and enabled Remote Desktop. I installed Cloudbased- init 0.9.12.dev76 and optional Carbon PowerShell module to default location. For configuration options I left the default Admin user be created into Administrators group, in addition I selected option to ‘Run Cloudbased-Init service as LocalSystem’. I chose options to &amp;lsquo;Run Sysprep to create a generalized image&amp;rsquo; and &amp;lsquo;Shutdown when Sysprep terminates&amp;rsquo;. When complete I change virtual machine to be a virtual machine template.&lt;/p&gt;
&lt;p&gt;I connect to vRealize Automation Cloud &amp;gt; Infrastructure &amp;gt; Cloud Accounts &amp;gt; {my account} and run &amp;lsquo;Sync Images&amp;rsquo;.  Once image sync is completed vRealize Automation Cloud &amp;gt; Infrastructure &amp;gt; Image Mappings and create &amp;lsquo;New Image Mapping&amp;rsquo;. Create a Blueprint with single Cloud Agnostic Machine linked to the image mapping.&lt;/p&gt;
&lt;p&gt;When I provision a vRA Cloud blueprint to deploy a VM&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;formatVersion: 1
inputs: {}
resources:
Cloud_Machine_1:
    type: Cloud.Machine
    properties:
    image: dc-win2019
    flavor: small
    cloudConfig: |
        #cloud-config
        hostname: i-got-a-new-name
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The VM powers on and cloud-data gets passed by vRealize Automation Cloud as an OVF which is mounted as CDROM with CDROM contents ovf-env.xml in its root.&lt;/p&gt;
&lt;p&gt;Cloud-init runs on startup but appears to fail to do what it is asked, Cloudbase-init.log contains error.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;2019-09-26 16:00:15.041 4360 ERROR cloudbaseinit.metadata.services.base [-] HTTPConnectionPool(host=&#39;169.254.169.254&#39;, port=80): Max retries exceeded with url: /openstack/latest/meta_data.json
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;adding-ovf-metadata-service&#34;&gt;Adding OVF Metadata Service&lt;/h2&gt;
&lt;p&gt;Looking at the error suggested to me that Cloudbase-Init was not finding the OVF and file. I read through some of the Cloudbase-Init documentation and found that metadata service configuration was specified in,&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;C:\Program Files\Cloudbase Solutions\Cloudbase-Init\conf\cloudbase-init-unattend.conf
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Checking the default configuration file does not include the &lt;a href=&#34;https://cloudbase-init.readthedocs.io/en/latest/services.html&#34;&gt;OvfService metadata service&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;metadata_services=cloudbaseinit.metadata.services.configdrive.ConfigDriveService,cloudbaseinit.metadata.services.httpservice.HttpService,cloudbaseinit.metadata.services.ec2service.EC2Service,cloudbaseinit.metadata.services.maasservice.MaaSHttpService
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If I follow similar steps to before to creeate templat but during install of Cloudbase-init but DO NOT chose wizard options &amp;lsquo;Sysprep and Shutdown&amp;rsquo;.  Instead I update the metadata_services entry in the cloudbase-init-unattend.conf file include OvfService like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;metadata_services=cloudbaseinit.metadata.services.ovfservice.OvfService
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Other Cloudbase-Init &lt;a href=&#34;https://cloudbase-init.readthedocs.io/en/latest/plugins.html#plugins&#34;&gt;plugins&lt;/a&gt; which require reading metadata, such that which sets the hostname, pickup their configuration from this config file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;C:\Program Files\Cloudbase Solutions\Cloudbase-Init\conf\cloudbase-init.conf
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The default installation of cloudbase-init.conf does not have a metadata_services entry at all. To allow the plugins be capable of reading metadata from OVF source add the following line to the file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;metadata_services=cloudbaseinit.metadata.services.ovfservice.OvfService
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;When both files have been updated execute sysprep passing the same parameters as the Cloudbase-Init installer wizard would:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd “C:\Program Files\Cloudbase Solutions\Cloudbase-Init\conf\”
C:\Windows\System32\Sysprep\Sysprep.exe /quiet /generalize /oobe /shutdown /unattend:unattend.xml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Performing a deployment of thee vRealize Automation Cloud blueprint example from earlier now deploys a VM with its hostname updated.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Understanding VMware Guest OS Customization</title>
      <link>https://darrylcauldwell.github.io/post/guest-customization/</link>
      <pubDate>Wed, 11 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/guest-customization/</guid>
      <description>
        
          &lt;p&gt;I recently began looking more closely at cloud-init for customizing VMware guest VMs. This caused me some heachaches! I took various notes while troubleshooting and researching around this.&lt;/p&gt;
&lt;h2 id=&#34;why-guest-os-customization-is-needed&#34;&gt;Why Guest OS Customization Is Needed&lt;/h2&gt;
&lt;p&gt;When you clone a virtual machine or deploy a virtual machine from a template it clones the virtual hard disk and all guest operating system settings. In many deployment scenarios if virtual machines with identical settings are deployed conflicts can occur, such as duplicate computer names. Typically for this deployment scenario during deployment guest operating system customization is required to be performed to give them uniqueness.&lt;/p&gt;
&lt;h2 id=&#34;vm-guest-os-customization-approach&#34;&gt;VM Guest OS Customization Approach&lt;/h2&gt;
&lt;p&gt;VMware has long provided the facility to perform guest operating system customization through a combination of vCenter Server and VMware Tools. This gives the option to choose to launch the Guest Customization wizard during the cloning or deployment process,  or can create standard customization specifications and apply these during the cloning or deployment process.&lt;/p&gt;
&lt;p&gt;When the virtual machine template is Linux the VMware guest operating system customization is performed using a combination of cloud-init and a collection of perl scripts packaged with open-vm-tools.&lt;/p&gt;
&lt;h2 id=&#34;logfiles-and-log-configuration&#34;&gt;Logfiles and Log Configuration&lt;/h2&gt;
&lt;p&gt;Guest OS can be complex and things can go wrong during guest OS customization. When they do its useful to understand where to look for clues as to cause.&lt;/p&gt;
&lt;p&gt;If there were any problems with the extraction and deployment of the customization package onto the guest operating system these are written to:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;/var/log/vmware-imc/toolsDeployPkg.log
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;VMware guest operating system customization steps performed using the perl scripts output to default location of /var/log/messages. There are many other things in this log file so can use grep to view only the customization steps:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;grep &amp;quot;customize-guest&amp;quot; /var/log/messages 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;There are many options for configuring cloud-init logging. These can be configured these within your template virtual machine. The configuration settings are stored in:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;/etc/cloud/cloud.cfg.d/05_logging.cfg
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Within this configuration file we can identify that by default cloud-init directs the main handler output to a file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;/var/log/cloud-init.log
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We can also see that by default the stdout and stderr of the specific we tell it to perform is written to:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;/var/log/cloud-init-output.log
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;customization-guest-customatization-configuration&#34;&gt;Customization Guest Customatization Configuration&lt;/h2&gt;
&lt;p&gt;There are many options which cloud-init can be configured with. These can be configured these within your template virtual machine. The configuration settings are stored in:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;/etc/cloud/cloud.cfg
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;One of the options which can be configured is whether VMware tools perl scripts are ran. How to enable or disable this is documented in this article:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;https://kb.vmware.com/s/article/59557
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It is useful to note here that there is currently a known issue when cloud-init calls the open-vm-tools perl scripts for &amp;lsquo;Ubuntu 18.04&amp;rsquo;. The boot sequence and bring up order can cause the perl scripts to fail. A high level cause and workaround are described here:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;https://kb.vmware.com/s/article/56409 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;A more detailed description of the bug including some very interesting detail about how cloud-init and open-vm-tools perl scripts are called is described here:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;https://bugs.launchpad.net/ubuntu/+source/open-vm-tools/+bug/1793715
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;cloud-init-user-data&#34;&gt;Cloud-Init User-Data&lt;/h2&gt;
&lt;p&gt;One of the more useful enhancements of using cloud-init is the ability to instruct the guest operating system to run things such as custom scripts during boot.&lt;/p&gt;
&lt;p&gt;User-Data content supports the following types of content &amp;lsquo;gzip compressed&amp;rsquo; or &amp;lsquo;mime multi-part archive&amp;rsquo;. With a mime multi-part file, the user can specify more than one type of data within the content.  For full details on the User-Data content format see here:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;https://cloudinit.readthedocs.io/en/latest/topics/format.html
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The two most common data types I use at the moment are Cloud Config Data or simple shell scripts. To differentiate sections when using a &amp;lsquo;mime multi-part archive&amp;rsquo; begin each section with data type for example  &lt;code&gt;#!&lt;/code&gt; for shell script or &lt;code&gt;#cloud-config&lt;/code&gt; for cloud config data.&lt;/p&gt;
&lt;p&gt;Cloud-init can be fussy about syntax of the file contents once created you can validate the syntaxt using a command like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cloud-init devel schema --config-file /tmp/user-data
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;vcenter-deploy-ova-import&#34;&gt;vCenter Deploy OVA Import&lt;/h2&gt;
&lt;p&gt;Some operating systems packages which include cloud-init expose options to confiure during deployment.  For example Ubuntu which can be found here:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;https://cloud-images.ubuntu.com/releases/18.04/release/ubuntu-18.04-server-cloudimg-amd64.ova
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The Ubunutu image includes property &amp;lsquo;Encoded user-data&amp;rsquo; this has property description &lt;em&gt;&amp;ldquo;In order to fit into a xml attribute, this value is base64 encoded . It will be decoded, and then processed normally as user-data&amp;rdquo;&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;I like to keep a file copy of the un-encoded and encoded user-data. To do this I use text editior to create a file with the required cloud-init user-data contents.  I then use &lt;a href=&#34;https://linux.die.net/man/1/base64&#34;&gt;base64&lt;/a&gt; to output contents into a file appended with .b64.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;base64 --input /tmp/user-data --output /tmp/user-data.b64
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If encoded user-data is passed during deployment of OVA file in this way this will run when the VM boots.&lt;/p&gt;
&lt;h2 id=&#34;cloud-assembly&#34;&gt;Cloud Assembly&lt;/h2&gt;
&lt;p&gt;Other VMware products such as Cloud Assembly can utilize open-vm-tools and cloud-init to perform guest customization.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;https://docs.vmware.com/en/VMware-Cloud-Assembly/services/Using-and-Managing/GUID-70EA052D-FABF-4CE5-875D-9B52FED08AA3.html
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;https://blogs.vmware.com/management/2018/11/customizing-cloud-assembly-deployments-with-cloud-init.html
&lt;/code&gt;&lt;/pre&gt;
        
      </description>
    </item>
    
    <item>
      <title>Cloud Assembly VM Guest Management With Ansible</title>
      <link>https://darrylcauldwell.github.io/post/ansible-cloud-assembly/</link>
      <pubDate>Thu, 01 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/ansible-cloud-assembly/</guid>
      <description>
        
          &lt;p&gt;VMware &lt;a href=&#34;https://cloud.vmware.com/cloud-automation-services&#34;&gt;Cloud Automation Services&lt;/a&gt; is a product suite comprising three products, &lt;a href=&#34;https://cloud.vmware.com/cloud-assembly&#34;&gt;Cloud Assembly&lt;/a&gt;, &lt;a href=&#34;https://cloud.vmware.com/service-broker&#34;&gt;Service Broker&lt;/a&gt; and &lt;a href=&#34;https://cloud.vmware.com/code-stream&#34;&gt;Code Stream&lt;/a&gt;. Cloud Assembly provides a blueprinting engine and manages connectivity to multiple cloud endpoints. Service Broker provides a unified catalog for publishing blueprints with role-based policies. Code Stream provides a release pipeline with analytics.&lt;/p&gt;
&lt;p&gt;The Cloud Assembly blueprinting engine can be used to consistently deliver VMs and applications.  To deliver VM guest configuration Cloud Assembly natively uses &lt;a href=&#34;https://cloudinit.readthedocs.io/en/latest/&#34;&gt;cloud-init&lt;/a&gt;. This native VM guest configuration capability can be extended with desired state management tools &lt;a href=&#34;https://puppet.com/&#34;&gt;Puppet&lt;/a&gt; and &lt;a href=&#34;https://www.ansible.com/&#34;&gt;Ansible&lt;/a&gt;. A major difference between the Puppet and Ansible is that Puppet requires an in-guest agent where Ansible operates agentless.&lt;/p&gt;
&lt;h2 id=&#34;ansible&#34;&gt;Ansible&lt;/h2&gt;
&lt;p&gt;In this blog post I am going to focus on Cloud Assembly integration with Ansible.  The Ansible engine is &lt;a href=&#34;https://github.com/ansible/ansible&#34;&gt;fully open source&lt;/a&gt;, but OSS RedHat also offers a &lt;a href=&#34;https://www.ansible.com/products/engine&#34;&gt;license model and support package&lt;/a&gt; for Ansible engine. In addition to the Ansible engine RedHat provides support for &lt;a href=&#34;https://www.ansible.com/products/tower&#34;&gt;Ansible Tower&lt;/a&gt; which offers many enterprise grade features. A useful comparison can be found in the blog &lt;a href=&#34;https://www.ansible.com/blog/red-hat-ansible-automation-engine-vs-tower&#34;&gt;Red Hat Ansible Automation: Engine, Tower or Both&lt;/a&gt;. Cloud Assembly supports integration directly with Ansible engine and does not depend on Ansible Tower.&lt;/p&gt;
&lt;p&gt;The Ansible control node connects to managed nodes and pushing out small programs, called &amp;ldquo;Ansible modules&amp;rdquo; to them. These programs are written to be resource models of the desired state of the system. Ansible then executes these modules (over SSH by default), and removes them when finished.&lt;/p&gt;
&lt;h2 id=&#34;ansible-headless-deployment-model&#34;&gt;Ansible Headless Deployment Model&lt;/h2&gt;
&lt;p&gt;Ansible does not require a single controlling machine. Any Linux machine can run Ansible. A headless deployment model is where each machine runs as both the Ansible control node role and the Ansible controlled node. The absence of a central management server requirement can greatly increase availability, simplify disaster-recovery planning and enhance security (no single point of control).&lt;/p&gt;
&lt;p&gt;When we use this deployment model each server has Ansible installed and has inventory file with a single entry named localhost. We create a Cloud Assembly blueprint which includes cloud-init configuration to pull an Ansible playbook from a repository and execute it locally. Here the Ansible playbook is specific to the server role on which it will be ran.&lt;/p&gt;
&lt;p&gt;An example of how to deploy an application using this deployment architecture using Cloud Assembly is described &lt;a href=&#34;https://github.com/darrylcauldwell/titoAnsibleHeadless&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;central-ansible-control-node&#34;&gt;Central Ansible Control Node&lt;/h2&gt;
&lt;p&gt;While running Ansible without a central control node can be useful for some deployment scenarios, others are better suited to having a central Ansible controller node controlling multiple clients.&lt;/p&gt;
&lt;p&gt;Typical factors which would drive a deployment architecture with a central control node would be the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Windows guests as Ansible control node can only runs on Linux&lt;/li&gt;
&lt;li&gt;Large deployments that require centralized control for day two operations&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;When we use this deployment model we deploy a central Ansible control node and on this we create SSH authorization private public key pair. We then configure this to be integrated with Cloud Assembly.&lt;/p&gt;
&lt;p&gt;We create a Cloud Assembly blueprint which includes on each VM resource cloud-init configuration to create a local account named ansible which has a SSH public key of key pair on the Ansible control node. The Cloud Assembly blueprint then has Ansible resource added with details of the Ansible control node, the private key to use to connect and which playbook to execute. Within the blueprint the Ansible resouece has a relationship formed with the appropriate VM resources. When the blueprint is deployed the VM resources get added dynamically to the Ansible server inventory file and the playbook executed. In this model the Ansible playbook can be application rather than server role specific.&lt;/p&gt;
&lt;p&gt;An example of how to deploy an application with this deployment architecture using Cloud Assembly is described &lt;a href=&#34;https://github.com/darrylcauldwell/titoAnsible&#34;&gt;here&lt;/a&gt;.  This also includes a simplified example of how Ansible server can be used for day two operations for servers of a specific type.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>NSX-T for Planespotter</title>
      <link>https://darrylcauldwell.github.io/post/nsx-planespotter/</link>
      <pubDate>Thu, 14 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/nsx-planespotter/</guid>
      <description>
        
          &lt;p&gt;Moving towards application centric infrastructure suitable for microservices applications requires a good example application to work with.  I saw an NSX demo presented by &lt;a href=&#34;https://github.com/yfauser&#34;&gt;Yves Fauser&lt;/a&gt; where he used just such an application called planespotter.&lt;/p&gt;
&lt;p&gt;My first task towards understanding this more was to get this setup in my homelab and look at it in context of NSX-T.&lt;/p&gt;
&lt;h2 id=&#34;homelab-core&#34;&gt;Homelab Core&lt;/h2&gt;
&lt;p&gt;My homelab networking is very simple, I have a domestic BT broadband router, this connects a Cisco SB200 8-port L2 only switch. Each port connected to ESXi is configured with MTU 9216 and has the VLAN passed untagged.&lt;/p&gt;
&lt;p&gt;Connected to this are a pair of Intel NUCs each has onboard 1GB NIC and two USB 1GB NICs.  The lab is used for other things so the on-board vmnic0 NIC is assigned to a VSS which has default &amp;lsquo;VM Network&amp;rsquo; portgroup. This leaves both vusb0 and vusb1 free to be used for N-VDS.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/planespotter-esxi.png&#34; alt=&#34;ESXi Networking&#34;&gt;&lt;/p&gt;
&lt;p&gt;The NUCs are single socket, dual core i5s running at 1.8GHz and each has only 32GB of RAM, these currently run vSphere 6.7 Update 1 and shared storage is all-flash VSAN with no data protection.&lt;/p&gt;
&lt;h2 id=&#34;nsx-t-base&#34;&gt;NSX-T Base&lt;/h2&gt;
&lt;p&gt;Download OVA&amp;rsquo;s and perform initial deployment of NSX Manager,  NSX Controller and NSX Edge.  As lab only has a single L2 all get deployed with all vNICs connected to the portgroup &amp;lsquo;VM Network&amp;rsquo;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/planespotter-edge.png&#34; alt=&#34;NSX-T Base&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;nsx-t-routing&#34;&gt;NSX-T Routing&lt;/h2&gt;
&lt;p&gt;One of the biggest differences between NSX for vSphere and NSX-T is the routing architecture. The services are split between service router (SR) and distributed router (DR), the service router functions are run on the NSX edge and the distributed router (DR) is a kernel module running on the ESXi hosts. My lab setup uses defaults for all transit switches, it is importanrt to understand the relationship when we look at packets flow through these various hops.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/planespotter-edge-arch.png&#34; alt=&#34;NSX-T Routing&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;planespotter&#34;&gt;Planespotter&lt;/h2&gt;
&lt;p&gt;The planespotter application is made up of various microservices and database. For this NSX-T setup each is installed on a VM. The application can be installed by following &lt;a href=&#34;https://github.com/darrylcauldwell/planespotter/blob/master/docs/vm_deployment/README.md&#34;&gt;this guide&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/planespotter-logical-switches.png&#34; alt=&#34;NSX-T Logical Switches&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;planespotter-fe-to-api-traceflow&#34;&gt;Planespotter FE to API Traceflow&lt;/h2&gt;
&lt;p&gt;One neat feature of NSX-T and geneve is to inject data into the header and use this to trace flows. The traceflow feature helps inspect the path of a packet as it travels from one logical port to a single or multiple logical ports.&lt;/p&gt;
&lt;p&gt;So if we select the port connected to planespotter frontend and port connected to planespotter api, we get a nice visual represenation of the path.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/planespotter-traceflow.png&#34; alt=&#34;NSX-T Logical Switches&#34;&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Controlling NSX-T with Terraform</title>
      <link>https://darrylcauldwell.github.io/post/nsx-terraform/</link>
      <pubDate>Mon, 07 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/nsx-terraform/</guid>
      <description>
        
          &lt;p&gt;Hashicorp Terraform is a tool which enables you to safely and predictably create, change, and improve infrastructure by defining its configuration as code.&lt;/p&gt;
&lt;p&gt;VMware NSX-T is a product which enables software defined network infrastructure.&lt;/p&gt;
&lt;p&gt;The Terraform NSX-T provider allows us to deliver and maintain NSX-T configuration as code.&lt;/p&gt;
&lt;p&gt;This is a walkthrough of how in a very few commands you can begin to control NSX-T configuration using NSX-T.&lt;/p&gt;
&lt;p&gt;If starting from scratch &lt;a href=&#34;https://learn.hashicorp.com/terraform/getting-started/install.html&#34;&gt;install a simple terraform server&lt;/a&gt;,  on CentOS / RHEL you would use these commands.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;yum update -y
yum install wget net-tools unzip -y
cd /tmp
wget https://releases.hashicorp.com/terraform/0.11.11/terraform_0.11.11_linux_amd64.zip
mkdir /terraform
unzip terraform_0.11.11_linux_amd64.zip -d /terraform
cd /terraform
./terraform --version
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once we have this installed we can configure the  NSX-T Manager connection details as variables in a reusable variables file.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cat &amp;gt; /terraform/variables.tf &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;lt;&amp;lt; &amp;#39;__EOF__&amp;#39;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;variable &amp;#34;nsx_manager&amp;#34; {}
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;variable &amp;#34;nsx_username&amp;#34; {}
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;variable &amp;#34;nsx_password&amp;#34; {}
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;__EOF__&lt;/span&gt;

cat &amp;gt; /terraform/terraform.tfvars &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;lt;&amp;lt; &amp;#39;__EOF__&amp;#39;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;nsx_manager = &amp;#34;192.168.1.15&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;nsx_username = &amp;#34;admin&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;nsx_password = &amp;#34;VMware1!&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;__EOF__&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We can then create a very basic Terraform configuration file which uses these variables and then performs a simple action like creating a NSX IP Set.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cat &amp;gt; /terraform/nsx.tf &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;lt;&amp;lt; &amp;#39;__EOF__&amp;#39;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;provider &amp;#34;nsxt&amp;#34; {
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  host                  = &amp;#34;${var.nsx_manager}&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  username              = &amp;#34;${var.nsx_username}&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  password              = &amp;#34;${var.nsx_password}&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  allow_unverified_ssl  = true
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  max_retries           = 10
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  retry_min_delay       = 500
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  retry_max_delay       = 5000
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  retry_on_status_codes = [429]
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;}
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;resource &amp;#34;nsxt_ip_set&amp;#34; &amp;#34;ip_set1&amp;#34; {
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  description  = &amp;#34;IP Set provisioned by Terraform&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  display_name = &amp;#34;IP Set&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  tag {
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    scope = &amp;#34;color&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    tag   = &amp;#34;blue&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  }
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  ip_addresses = [&amp;#34;1.1.1.1&amp;#34;, &amp;#34;2.2.2.2&amp;#34;]
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;}
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;__EOF__&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;With this in place we can initialize Terraform and get it to pull down the NSX-T provider.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;./terraform init
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If all has gone well Terraform should initialize successfully.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;We can now look at the changes our Terraform configuration file will make to NSX.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;./terraform plan
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We should see the single resource defined in the Terraform configuration file.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;Now we have verified it does what we hope we can then look to apply the change.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;./terraform apply
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Not as this is changing configuration we get asked to confirm action.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;Once ran successfully we can then check in NSX GUI and confirm the IP Set is created.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;If we would like to launch and destroy application specific NSX network infrastructure when we deploy our application. We would do this with a CI/CD pipeline tool like Jenkins will walk through this. If starting from scratch &lt;a href=&#34;https://wiki.jenkins.io/display/JENKINS/Installing+Jenkins+on+Red+Hat+distributions&#34;&gt;install a simple jenkins server&lt;/a&gt;, on CentOS / RHEL you would use these commands.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;yum update -y
yum install wget net-tools unzip -y
wget -O /etc/yum.repos.d/jenkins.repo http://pkg.jenkins-ci.org/redhat-stable/jenkins.repo
rpm --import https://jenkins-ci.org/redhat/jenkins-ci.org.key
yum install jenkins java -y
service jenkins start
chkconfig jenkins on
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once installed and running we would normally load the &lt;a href=&#34;https://wiki.jenkins.io/display/JENKINS/Terraform+Plugin&#34;&gt;Terraform plugin&lt;/a&gt;,  however this does not presently work as Terraform prompts for confirmation.  There is a &lt;a href=&#34;https://github.com/jenkinsci/terraform-plugin/pull/4/commits/47d6d3da54dd2cc437c1efb5df89cdccdb0f3eb0&#34;&gt;pending pull request to fix this&lt;/a&gt; until this gets merged we need a workaround.&lt;/p&gt;
&lt;p&gt;To workaround this issue we can still control Terraform with Jenkins by calling a shell script from within Jenkins job.  To do this we will create a folder and give Jenkins user account permissions by running following.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;mkdir /terraform
sudo usermod -a -G root jenkins
chmod -R g+w /terraform
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We can then create a Jenkins job with Build contents which creates a Terraform file and applies this.  A simple example would be.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cd /terraform

cat &amp;gt; /terraform/nsx.tf &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;lt;&amp;lt; &amp;#39;__EOF__&amp;#39;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;provider &amp;#34;nsxt&amp;#34; {
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  host                  = &amp;#34;192.168.1.15&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  username              = &amp;#34;admin&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  password              = &amp;#34;VMware1!&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  allow_unverified_ssl  = true
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  max_retries           = 10
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  retry_min_delay       = 500
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  retry_max_delay       = 5000
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  retry_on_status_codes = [429]
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;}
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;resource &amp;#34;nsxt_ip_set&amp;#34; &amp;#34;ip_set1&amp;#34; {
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  description  = &amp;#34;IP Set provisioned by Terraform&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  display_name = &amp;#34;IP Set&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  tag {
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    scope = &amp;#34;color&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    tag   = &amp;#34;blue&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  }
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  ip_addresses = [&amp;#34;1.1.1.1&amp;#34;, &amp;#34;2.2.2.2&amp;#34;]
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;}
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;__EOF__&lt;/span&gt;

./terraform init

./terraform apply -auto-approve

rm -f nsx.tf
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This is an overly simple example and more likely we would pull a config file from distributed source control such as github.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>NSX-T for OpenShift</title>
      <link>https://darrylcauldwell.github.io/post/nsx-openshift/</link>
      <pubDate>Sat, 28 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/nsx-openshift/</guid>
      <description>
        
          &lt;p&gt;While looking at the various documentation sets I found it difficult to understand the NSX-T and OpenShift integration. A lot was masked by configuration performed by Ansible scripts. Here I try and record my understanding of the technology and then work through getting this running in a capacity constrained lab environment.&lt;/p&gt;
&lt;h2 id=&#34;nsx-t&#34;&gt;NSX T&lt;/h2&gt;
&lt;p&gt;NSX-T (NSX Transformers) can provide network virtualization for multi-hypervisor environments, including both vSphere and KVM. It is also designed to address emerging application frameworks and architectures that have heterogeneous endpoints and technology stacks such as OpenStack, Red Hat OpenShift, Pivotal Cloud Foundry, Kubernetes, and Docker. NSX-V (NSX for vSphere) Manager integrates into vCenter and leverages a vSphere dvSwitch to form an overlay. NSX-T Manager can be used with vSphere it does not integrate with vCenter or dvSwitch, instead NSX is managed via its API, and its overlay is formed by each member having Open vSwitch (OVS) installed.&lt;/p&gt;
&lt;h2 id=&#34;red-hat-openshift&#34;&gt;Red Hat OpenShift&lt;/h2&gt;
&lt;p&gt;OpenShift helps you to develop, deploy, and manage container-based applications. It provides you with a self-service platform to create, modify, and deploy applications on demand, thus enabling faster development and release life cycles. OpenShift is built around a core of application containers powered by Docker, with orchestration and management provided by Kubernetes.&lt;/p&gt;
&lt;h2 id=&#34;container-networking-framework-background&#34;&gt;Container Networking Framework Background&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/docker/libnetwork/blob/master/docs/design.md&#34;&gt;Libnetwork&lt;/a&gt; is the canonical implementation Container Network Model (CNM) which formalizes the steps required to provide networking for containers while providing an abstraction that can be used to support multiple network drivers. Libnetwork provides an interface between the Docker daemon and network drivers. Container Network Model (CNM) is designed to support the Docker runtime engine only.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/containernetworking/cni&#34;&gt;Container Network Interface&lt;/a&gt; (CNI), consists of a specification and libraries for writing plugins to configure network interfaces in Linux containers, along with a number of supported plugins. Container Network Interface (CNI) supports integration with any container runtime.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift-cni.jpeg&#34; alt=&#34;Container Network Interface (CNI) Integration&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;vmware-nsx-and-kubernetes-integration&#34;&gt;VMware NSX and Kubernetes Integration&lt;/h2&gt;
&lt;p&gt;VMware provide an &lt;a href=&#34;https://my.vmware.com/group/vmware/details?downloadGroup=NSX-T-PKS-221&amp;amp;productId=673&#34;&gt;NSX Container Plugin package&lt;/a&gt; which contains the required modules to integrate NSX-T with Kubernetes.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;NSX Container Plugin (NCP) - is a container image which watches the Kubernetes API for changes to Kubernetes Objects (namespaces, network policies, services etc.). It calls the NSX API to creates network constructs based on object addition and changes.&lt;/li&gt;
&lt;li&gt;NSX DaemonSet
&lt;ul&gt;
&lt;li&gt;NSX Node Agent - is a container image which manages the container network interface&lt;/li&gt;
&lt;li&gt;NSX Kube-Proxy - is a container image which replaces the native distributed east-west load balancer in Kubernetes with the NSX load-balancer based on Open vSwitch (OVS).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;NSX Container Network Interface (CNI) - is an executable which allow the integration of NSX into Kubernetes.&lt;/li&gt;
&lt;li&gt;Open vSwitch&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift-ncp.jpeg&#34; alt=&#34;NSX and Kubernetes Integration&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;nsx-for-openshift&#34;&gt;NSX For OpenShift&lt;/h2&gt;
&lt;p&gt;NSX implements a discreet network topology per Kubernetes namespace. NSX maps logical network elements like logical switches and distributed logical router to Kubernetes namespaces. Each of those network topologies can be directly routed, or privately addressed and behind NAT.&lt;/p&gt;
&lt;h2 id=&#34;nsx-for-openshift-homelab&#34;&gt;NSX For OpenShift Homelab&lt;/h2&gt;
&lt;p&gt;For the rest of this blog post I am aiming to create a NSX OpenShift integration. I aiming for two namespaces, each with a logical router and three subnets. The namespaces will use private address ranges and the tier-0 router will provide SNAT connectivity to the routed network.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift-nsx-topology.jpeg&#34; alt=&#34;NSX Topology&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;starting-point-homelab-configuration&#34;&gt;Starting point homelab configuration&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;1GbE Switch (Layer 2 only)
&lt;ul&gt;
&lt;li&gt;VLAN 0 - CIDR 192.168.1.0/24&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;vSphere vCenter Appliance 6.7&lt;/li&gt;
&lt;li&gt;3x vSphere ESXi 6.7 Update 1 hosts (Intel NUC - 3x 1.8GHz CPU &amp;amp; 32GB RAM)
&lt;ul&gt;
&lt;li&gt;Onboard NIC is connected to a vSphere Standard Switch&lt;/li&gt;
&lt;li&gt;USB3 NIC is unused and will be used for NSX&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;VSAN&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The following resources are required&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Small NSX-T Manager is a VM sized 8GB vRAM, 2x vCPU and 140GB vHDD&lt;/li&gt;
&lt;li&gt;Small NSX Controller is a VM sized 8GB vRAM, 2x vCPU and 120GB vHDD&lt;/li&gt;
&lt;li&gt;Small NSX Edge is a VM sized 4GB vRAM, 2x vCPU and 120GB vHDD&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;nsx-management-plane&#34;&gt;NSX Management Plane&lt;/h2&gt;
&lt;p&gt;Deploy a small NSX unifed appliance specifying the nsx-manager role. Once deployed link this to vCenter, to do this add vCenter in &amp;lsquo;Fabric / Compute Manager&amp;rsquo;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift-nsx-compute-manager.jpeg&#34; alt=&#34;NSX-T Management Plane&#34;&gt;&lt;/p&gt;
&lt;p&gt;With the manager in place we now need to create the management plane, to do this we need to install the management plane agent (MPA) on each host so they are added as usable Fabric Nodes.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift-nsx-nodes.jpeg&#34; alt=&#34;NSX-T Fabric Nodes&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;tunnel-endpoint-ip-pool&#34;&gt;Tunnel Endpoint IP Pool&lt;/h2&gt;
&lt;p&gt;We create an IP pool one for the Transort Nodes to communicate for my scenario the three ESXi hosts and an edge will all participate so I create an IP Pool with four addresses. Navigate to Inventory &amp;gt; Groups &amp;gt; IP Pools and click add.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift-nsx-ip-pool.png&#34; alt=&#34;NSX-T IP Pool&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;nsx-control-plane&#34;&gt;NSX Control Plane&lt;/h2&gt;
&lt;p&gt;In order to create an overlay network we need an NSX Controller to manage the hosts. NSX Controllers serve as the central control point got all hosts, logical switches, and logical routers.&lt;/p&gt;
&lt;p&gt;While NSX Manager can deploy and configure NSX Controllers the size cannot be selected. As lab is resource constrained I only want a small NSX Controller, the &amp;lsquo;NSX Controller for VMware ESXi&amp;rsquo; is a separate OVA download where size can be selected.&lt;/p&gt;
&lt;p&gt;Once the controller appliance is deployed we need to facilitate communications between it and nsx manager.  To do this open an SSH session with admin user to NSX Manager and run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;get certificate api thumbprint
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Open an SSH session to NSX Controller with admin user and run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;join management-plane &amp;lt;NSX-Manager&amp;gt; username admin thumbprint &amp;lt;NSX-Managers-thumbprint&amp;gt;

set control-cluster security-model shared-secret

initialize control-cluster
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift-nsx-mgr-ctrl-thumb.jpeg&#34; alt=&#34;NSX-T Controller&#34;&gt;&lt;/p&gt;
&lt;p&gt;This should then be viewable in NSX Manager&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift-nsx-control-cluster.jpeg&#34; alt=&#34;NSX-T Controller Cluster&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;overlay-transport-zone&#34;&gt;Overlay Transport Zone&lt;/h2&gt;
&lt;p&gt;All the virtual network objects will need to communicate across an overlay network. To faciliate this the three esxi hosts and edges need to be part of an Overlay Transport Zone.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift-nsx-transport.jpeg&#34; alt=&#34;NSX-T Transport Zone&#34;&gt;&lt;/p&gt;
&lt;p&gt;Once we have a Transport Zone we can add our NSX fabric nodes as transport nodes. Navigate menu to Select Fabric &amp;gt; Transport Nodes and click Add.  A wizard will open on the general tab select first Node (host), give appropriate name for that host and select the openshift transport zone.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift-nsx-transport-node.jpeg&#34; alt=&#34;NSX-T Transport Node&#34;&gt;&lt;/p&gt;
&lt;p&gt;Change to N-VDS tab, create N-VDS for openshift, select default NIOC, select default hostswitch Uplink profile, select transport IP Pool and enter Physical NIC identifier for Uplink-1.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift-nsx-host-vds.jpeg&#34; alt=&#34;NSX-T Transport Zone N-VDS&#34;&gt;&lt;/p&gt;
&lt;p&gt;In order that the NSX Container Plugin can find the correct NSX objects all of the NSX objects created require a tag applying. For this lab build I am using tag dc-openshift. Navigate within NSX Manager to Fabric &amp;gt; Transport Zones, select overlay network then Actions &amp;gt; Manage Tags and apply tag.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Scope = ncp/cluster and Tag = dc-openshift
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift-ncp-tags.jpeg&#34; alt=&#34;NSX-T Openshift Tags&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;vlan-transport-zone&#34;&gt;VLAN Transport Zone&lt;/h2&gt;
&lt;p&gt;As well as connecting to the overlay network the Edges running Tier-0 routing functions also needs to be able to connect to the physical network. This connectivity is achieved by using a Transport Zone of type VLAN.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift-nsx-vlan-transport.png&#34; alt=&#34;NSX-T VLAN Transport Zone&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;nsx-edge&#34;&gt;NSX Edge&lt;/h2&gt;
&lt;p&gt;We need some way for the logical container overlay network to communicate with the physical network. AN NSX Edge can host services which provide this connectivity.&lt;/p&gt;
&lt;p&gt;The NSX Edge has 4 network adapters, the first is used by the management network, the other 3 interfaces (fp-eth0, fp-eth1 and fp-eth2) can then be used for connecting to overlay networks or for routing. Within my lab I have a single flat physical network so all NSX Edge interfaces connect to the same Port Group.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;GUI Reference&lt;/th&gt;
&lt;th&gt;VM vNIC&lt;/th&gt;
&lt;th&gt;NIC&lt;/th&gt;
&lt;th&gt;Lab Function&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Managewment&lt;/td&gt;
&lt;td&gt;Network adapter 1&lt;/td&gt;
&lt;td&gt;eth0&lt;/td&gt;
&lt;td&gt;Management&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Datapath #1&lt;/td&gt;
&lt;td&gt;Network adapter 2&lt;/td&gt;
&lt;td&gt;fp-eth0&lt;/td&gt;
&lt;td&gt;Overlay&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Datapath #2&lt;/td&gt;
&lt;td&gt;Network adapter 3&lt;/td&gt;
&lt;td&gt;fp-eth1&lt;/td&gt;
&lt;td&gt;Uplink&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Datapath #3&lt;/td&gt;
&lt;td&gt;Network adapter 4&lt;/td&gt;
&lt;td&gt;fp-eth2&lt;/td&gt;
&lt;td&gt;Unused&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift-nsx-edge.jpeg&#34; alt=&#34;NSX-T Add Edge&#34;&gt;&lt;/p&gt;
&lt;p&gt;The NSX Edge needs to participate in the Overlay Transport Zone so we need to first configure this as Transport Node.  This is very similar process to how we setup ESXi hosts as Transport Nodes except on N-VDS tab we add to both overlay and vlan transport zones,  we use the edge-vm Uplink profile and for Virtual NIC select appropriate NIC as per table above.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift-nsx-edge-nvds.png&#34; alt=&#34;NSX-T Edge N-VDS&#34;&gt;&lt;/p&gt;
&lt;p&gt;In order we can deploy Tier-0 router the Edge needs to be a member of an Edge Cluster.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift-nsx-edge-cluster.jpeg&#34; alt=&#34;NSX-T Add Edge Cluster&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;tier-0-router&#34;&gt;Tier-0 Router&lt;/h2&gt;
&lt;p&gt;Once the Edge Cluster is created we can create the tier-0 router.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift-nsx-tier0.jpeg&#34; alt=&#34;NSX-T Add Edge Tier-0 Router&#34;&gt;&lt;/p&gt;
&lt;p&gt;In my lab I have 192.168.1.0 /24 and will be using the 172.16.0.0 /16 address space for NSX. I would like to use network address translation (NAT) and allocate a separate SNAT IP on the 192.168.1.0 network for each OpenShift namespace on the 172.16.0.0 network.  To achieve this I need to configure a redistribution criteria of type Tier-0 NAT.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift-nsx-tier0-route-redist.jpeg&#34; alt=&#34;NSX-T Add Edge Tier-0 Route Redist&#34;&gt;&lt;/p&gt;
&lt;p&gt;The next step requires an NSX Logical Switch so we create that.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift-nsx-logical-switch.jpeg&#34; alt=&#34;NSX-T Add Logical Switch&#34;&gt;&lt;/p&gt;
&lt;p&gt;We can now configure the Router Port,  selecting the Transport Node and Logical Switch.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift-nsx-tier0-route-port.jpeg&#34; alt=&#34;NSX-T Add Tier-0 Router Port&#34;&gt;&lt;/p&gt;
&lt;p&gt;This will be used by OpenShift to once created navigate to Actions &amp;gt; Manage Tags and apply tag.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Scope = ncp/cluster and Tag = dc-openshift
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift-ncp-tags.jpeg&#34; alt=&#34;NSX-T Add NCP Tags&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;ip-block-kubernetes-pods&#34;&gt;IP Block Kubernetes Pods&lt;/h2&gt;
&lt;p&gt;In order to create the topology we are aiming for we need to create an IP Blocks for each of our two namespaces.  Within each IP Block we need to create the three subnets. In the end you should end up with something which looks like this, and all IP Block needs to have the ncp/cluster tag.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift-nsx-ddi-blocks.jpeg&#34; alt=&#34;NSX-T Add NCP Tags&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;ip-pool-snat&#34;&gt;IP Pool SNAT&lt;/h2&gt;
&lt;p&gt;We create an IP pool for the tier-0 router to issue SNAT and provide external (floating) IPs to OpenShift.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift-nsx-snat-pool.jpeg&#34; alt=&#34;NSX-T SNAT Pool&#34;&gt;&lt;/p&gt;
&lt;p&gt;Once created add the following two tags,&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Scope = ncp/cluster and Tag = dc-openshift
Scope = ncp/external and Tag = true
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;red-hat-openshift-origin&#34;&gt;Red Hat OpenShift Origin&lt;/h2&gt;
&lt;p&gt;OpenShift Origin is a computer software product from Red Hat for container-based software deployment and management. It is a supported distribution of Kubernetes using Docker containers and DevOps tools for accelerated application development.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift.jpeg&#34; alt=&#34;Openshift Stack&#34;&gt;&lt;/p&gt;
&lt;p&gt;OpenShift Origin is the upstream community project used in &lt;a href=&#34;https://www.openshift.com/products/online/&#34;&gt;OpenShift Online&lt;/a&gt;, &lt;a href=&#34;https://www.openshift.com/products/dedicated/&#34;&gt;OpenShift Dedicated&lt;/a&gt;, and &lt;a href=&#34;https://www.openshift.com/products/container-platform/&#34;&gt;OpenShift Container Platform (formerly known as OpenShift Enterprise)&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;VMware provides &lt;a href=&#34;https://github.com/vmware/nsx-integration-for-openshift&#34;&gt;Red Hat Ansible playbooks for installing NSX-T for OpenShift Container Platform&lt;/a&gt;. However, OpenShift Container Platform is a licensed product and this deploys a scaled-out deployment. Neither of these lend itself to a home lab deployment, my goal for the rest of this blog post is to detail the steps I follow for a cutdown installation.&lt;/p&gt;
&lt;h2 id=&#34;create-openshift-origin-base-vm&#34;&gt;Create OpenShift Origin Base VM&lt;/h2&gt;
&lt;p&gt;The OpenShift Container Platform is Red Hat Enterprise Linux based, I don&amp;rsquo;t have a Red Hat Enterprise Linux subscription license. As such I created a CentOS 7 (64-bit) virtual machine, as the library versions are the same, so binaries that work on one will work on the other.&lt;/p&gt;
&lt;p&gt;Each OpenShift node needs to be managed and also provide connectivity to NSX, it is possible to perform these two functions on same vNIC however, I give my VM two vNICs one for management on VLAN backed dvPortgroup and one for NSX on VXLAN backed dvPortgroup. I used the CentOS minimal installation ISO set static IP address on management vNIC, and create DNS A &amp;amp; PTR records for this.&lt;/p&gt;
&lt;p&gt;Once built I run following commands to install Docker, some other basic tools and apply latest patches.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cat &amp;gt; /etc/yum.repos.d/docker.repo &amp;lt;&amp;lt; &#39;__EOF__&#39;
[docker]
name=Docker Repository
baseurl=https://yum.dockerproject.org/repo/main/centos/7/
enabled=1
gpgcheck=1
gpgkey=https://yum.dockerproject.org/gpg
__EOF__
yum install -y https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm
yum install -y git open-vm-tools wget docker-engine net-tools python-pip
pip install docker-py
systemctl enable docker.service
yum update -y
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;default-kubernetes-service-addresses&#34;&gt;Default Kubernetes Service Addresses&lt;/h2&gt;
&lt;p&gt;OpenShift leverages the Kubernetes concept of a pod, which is one or more containers deployed together on one host, and the smallest compute unit that can be defined, deployed, and managed. A Kubernetes service address serves as an internal load balancer. It identifies a set of replicated pods in order to proxy the connections it receives to them. Services are assigned an IP address and port pair that, when accessed, proxy to an appropriate backing pod. These service addresses are assigned and managed by OpenShift. By default they are assigned out of the 172.30.0.0/16 network.&lt;/p&gt;
&lt;p&gt;To setup our environment we can configure the Docker daemon with an insecure registry parameter of 172.30.0.0/16.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;systemctl start docker
touch /etc/docker/daemon.json
cat &amp;gt; /etc/docker/daemon.json &amp;lt;&amp;lt; &#39;__EOF__&#39;
{
&amp;quot;insecure-registries&amp;quot;: [
    &amp;quot;172.30.0.0/16&amp;quot;
    ]
}
__EOF__
systemctl daemon-reload
systemctl restart docker
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;add-openshift-client&#34;&gt;Add OpenShift Client&lt;/h1&gt;
&lt;p&gt;The OpenShift client is used to manage the OpenShift installation and configuration it is supplied as a package. Download this, unpack and add to runtime path.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd /tmp
wget https://github.com/openshift/origin/releases/download/v3.10.0-rc.0/openshift-origin-client-tools-v3.10.0-rc.0-c20e215-linux-64bit.tar.gz
tar -xvf /tmp/openshift-origin-client-tools-v3.10.0-rc.0-c20e215-linux-64bit.tar.gz -C /bin
mv /bin/openshift* /home/openshift
echo &#39;PATH=$PATH:/home/openshift&#39; &amp;gt; /etc/profile.d/oc-path.sh
chmod +x /etc/profile.d/oc-path.sh
. /etc/profile
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;start-openshift-origin-as-all-in-one-cluster&#34;&gt;Start OpenShift Origin as all-in-one Cluster&lt;/h2&gt;
&lt;p&gt;For next steps we need a basic OpenShift stack. Rather than build something custom we can simply start a local OpenShift all-in-one cluster with a configured registry, router, image streams, and default templates, by running the following command (where openshift.darrylcauldwell.com is the FQDN which points to IP address of management interface of your VM),&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;oc cluster up --public-hostname=openshift.darrylcauldwell.com
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We should also be able to logon and see all of the OpenShift services listed&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;oc login -u system:admin
oc get services --all-namespaces
&lt;/code&gt;&lt;/pre&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;NAMESPACE&lt;/th&gt;
&lt;th&gt;NAME&lt;/th&gt;
&lt;th&gt;TYPE&lt;/th&gt;
&lt;th&gt;CLUSTER-IP&lt;/th&gt;
&lt;th&gt;EXTERNAL-IP&lt;/th&gt;
&lt;th&gt;PORT(S)&lt;/th&gt;
&lt;th&gt;AGE&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;default&lt;/td&gt;
&lt;td&gt;docker-registry&lt;/td&gt;
&lt;td&gt;ClusterIP&lt;/td&gt;
&lt;td&gt;172.30.1.1&lt;/td&gt;
&lt;td&gt;none&lt;/td&gt;
&lt;td&gt;5000/TCP&lt;/td&gt;
&lt;td&gt;9m&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;default&lt;/td&gt;
&lt;td&gt;kubernetes&lt;/td&gt;
&lt;td&gt;ClusterIP&lt;/td&gt;
&lt;td&gt;172.30.0.1&lt;/td&gt;
&lt;td&gt;none&lt;/td&gt;
&lt;td&gt;443/TCP,53/UDP,53/TCP&lt;/td&gt;
&lt;td&gt;10m&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;default&lt;/td&gt;
&lt;td&gt;router&lt;/td&gt;
&lt;td&gt;ClusterIP&lt;/td&gt;
&lt;td&gt;172.30.88.3&lt;/td&gt;
&lt;td&gt;none&lt;/td&gt;
&lt;td&gt;80/TCP,443/TCP,1936/TCP&lt;/td&gt;
&lt;td&gt;9m&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;kube-dns&lt;/td&gt;
&lt;td&gt;kube-dns&lt;/td&gt;
&lt;td&gt;ClusterIP&lt;/td&gt;
&lt;td&gt;172.30.0.2&lt;/td&gt;
&lt;td&gt;none&lt;/td&gt;
&lt;td&gt;53/UDP,53/TCP&lt;/td&gt;
&lt;td&gt;10m&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;openshift-apiserver&lt;/td&gt;
&lt;td&gt;api&lt;/td&gt;
&lt;td&gt;ClusterIP&lt;/td&gt;
&lt;td&gt;172.30.85.121&lt;/td&gt;
&lt;td&gt;none&lt;/td&gt;
&lt;td&gt;443/TCP&lt;/td&gt;
&lt;td&gt;10m&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;openshift-web-console&lt;/td&gt;
&lt;td&gt;webconsole&lt;/td&gt;
&lt;td&gt;ClusterIP&lt;/td&gt;
&lt;td&gt;172.30.83.178&lt;/td&gt;
&lt;td&gt;none&lt;/td&gt;
&lt;td&gt;443/TCP&lt;/td&gt;
&lt;td&gt;9m&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;We should also be able to see all of the OpenShift pods listed&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;oc get pod --all-namespaces
&lt;/code&gt;&lt;/pre&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;NAMESPACE&lt;/th&gt;
&lt;th&gt;NAME&lt;/th&gt;
&lt;th&gt;READY&lt;/th&gt;
&lt;th&gt;STATUS&lt;/th&gt;
&lt;th&gt;RESTARTS&lt;/th&gt;
&lt;th&gt;AGE&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;default&lt;/td&gt;
&lt;td&gt;docker-registry-1-4l59n&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;10m&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;default&lt;/td&gt;
&lt;td&gt;persistent-volume-setup-grm9s&lt;/td&gt;
&lt;td&gt;0/1&lt;/td&gt;
&lt;td&gt;Completed&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;10m&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;default&lt;/td&gt;
&lt;td&gt;router-1-5xtqg&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;10m&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;kube-dns&lt;/td&gt;
&lt;td&gt;kube-dns-bj5cq&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;11m&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;kube-proxy&lt;/td&gt;
&lt;td&gt;kube-proxy-9l8ql&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;11m&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;kube-system&lt;/td&gt;
&lt;td&gt;kube-controller-manager-localhost&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;10m&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;kube-system&lt;/td&gt;
&lt;td&gt;kube-scheduler-localhost&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;10m&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;kube-system&lt;/td&gt;
&lt;td&gt;master-api-localhost&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;10m&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;kube-system&lt;/td&gt;
&lt;td&gt;master-etcd-localhost&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;11m&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;openshift-apiserver&lt;/td&gt;
&lt;td&gt;openshift-apiserver-ptk5j&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;11m&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;openshift-controller-manager&lt;/td&gt;
&lt;td&gt;openshift-controller-manager-vg7gm&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;10m&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;openshift-core-operators&lt;/td&gt;
&lt;td&gt;openshift-web-console-operator-78ddf7cbb7-r8dhd&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;10m&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;openshift-web-console&lt;/td&gt;
&lt;td&gt;webconsole-847bc4ccc4-hgsv4&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;10m&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Once running we can open browser to OpenShift Origin&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;https://openshift.darrylcauldwell.com:8443/console/catalog
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Default credentials username &amp;lsquo;system&amp;rsquo; password &amp;lsquo;admin&amp;rsquo;&lt;/p&gt;
&lt;h2 id=&#34;nsx-t-open-vswitch&#34;&gt;NSX-T Open vSwitch&lt;/h2&gt;
&lt;p&gt;The NSX-T Container Plug-in (NCP) relies on Open vSwitch (OVS) providing a bridge to the NSX Logical Switch. VMware provide an Open vSwitch (OVS)  in the &lt;a href=&#34;https://my.vmware.com/web/vmware/details?downloadGroup=NSX-T-PKS-220&amp;amp;productId=673&#34;&gt;NSX Container Plugin 2.2.0&lt;/a&gt;, package.  Download expand and copy to OpenShift VM /tmp folder. Once uploaded install the following packages.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;yum install -y /tmp/nsx-container-2.2.0.8740202/OpenvSwitch/rhel74_x86_64/kmod-openvswitch-2.9.1.8614397.rhel74-1.el7.x86_64.rpm
yum install -y /tmp/nsx-container-2.2.0.8740202/OpenvSwitch/rhel74_x86_64/openvswitch-2.9.1.8614397.rhel74-1.x86_64.rpm
yum install -y /tmp/nsx-container-2.2.0.8740202/OpenvSwitch/rhel74_x86_64/openvswitch-kmod-2.9.1.8614397.rhel74-1.el7.x86_64.rpm
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Once installed start the Open vSwitch&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;service openvswitch start
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Once the Open vSwitch is running we can create a bridge network interface, and then connect this to the VM network interface located on the NSX-T Logical Switch. You can do this by running the following command (where eno33559296 is the devicename of NIC on NSX Logical Switch),&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ovs-vsctl add-br br-int
ovs-vsctl add-port br-int eno33559296 -- set Interface eno33559296 ofport_request=1
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;These connections are created with link state DOWN in order to use them we need to set link status is up for both,&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ip link set br-int up
ip link set eno33559296 up
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Update the network configuration file to ensure that the network interface is up after a reboot.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vi /etc/sysconfig/network-scripts/ifcfg-eno33559296
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Ensure has a line reading,&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ONBOOT=yes
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;nsx-t-container-network-interface-cni&#34;&gt;NSX-T Container Network Interface (CNI)&lt;/h2&gt;
&lt;p&gt;The NSX-T Container Plug-in (NCP) provides integration between NSX-T and container orchestrators such as Kubernetes. The installation files are in same package as the NSX Open vSwitch (OVS). Install using command.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;yum install -y /tmp/nsx-container-2.2.0.8740202/Kubernetes/rhel_x86_64/nsx-cni-2.2.0.8740202-1.x86_64.rpm
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;nsx-t-container-plug-in-ncp-replicationcontroller-rc&#34;&gt;NSX-T Container Plug-in (NCP) ReplicationController (RC)&lt;/h2&gt;
&lt;p&gt;There are a few accounts used for rights assignments, the project, users and roles are defined in NCP RBAC file. To create the users within the project run,&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;oc login -u system:admin
oc create -f /tmp/nsx-container-2.2.0.8740202/nsx-ncp-rbac.yml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The RBAC creates two service account users, the tokens for these are required by NCP in folder /etc/nsx-ujo. This gets mounted as config-volume and these tokens used for authentication.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;oc project nsx-system
mkdir -p /etc/nsx-ujo
SVC_TOKEN_NAME=&amp;quot;$(oc get serviceaccount ncp-svc-account -o yaml | grep -A1 secrets | tail -n1 | awk {&#39;print $3&#39;})&amp;quot;
oc get secret $SVC_TOKEN_NAME -o yaml | grep &#39;token:&#39; | awk {&#39;print $2&#39;} | base64 -d &amp;gt; /etc/nsx-ujo/ncp_token
NODE_TOKEN_NAME=&amp;quot;$(oc get serviceaccount nsx-node-agent-svc-account -o yaml | grep -A1 secrets | tail -n1 | awk {&#39;print $3&#39;})&amp;quot;
oc get secret $NOD_TOKEN_NAME -o yaml | grep &#39;token:&#39; | awk {&#39;print $2&#39;} | base64 -d &amp;gt; /etc/nsx-ujo/node_agent_token
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The pods which NSX-T Container Plug-in (NCP) ReplicationController (RC) run in need to use the host networking so we need to allow then this right by loading the NCP Security Context Constraints for NCP and NSX Node Agent.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;oc apply -f /tmp/nsx-container-2.2.0.8740202/Kubernetes/rhel_x86_64/ncp-os-scc.yml
oc adm policy add-scc-to-user ncp-scc -z ncp-svc-account
oc adm policy add-scc-to-user ncp-scc -z nsx-node-agent-svc-account
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Edit the ReplicationController (RC) YML file,&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vi /tmp/nsx-container-2.2.0.8740202/Kubernetes/ncp-rc.yml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Ensure the following lines are configured thus,&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;serviceAccountName: ncp-svc-account
apiserver_host_port = 8443
apiserver_host_ip = 192.168.1.20
nsx_api_managers = 192.168.1.15
insecure = True
nsx_api_user = admin
nsx_api_password = VMware1!
cluster = dc-openshift
adaptor = openshift
enable_snat = True
tier0_router = 0d772616-4c44-47ae-ac9e-06f3c0222211
overlay_tz = 5eeefd4c-bd7d-4871-9eba-d7ed02394dec
container_ip_blocks = 562c85de-8675-4bb2-b211-3f95a6342e0e, f225d518-2fe3-4f8d-a476-a4697bff3ea6
external_ip_pools = d5095d53-c7f8-4fcd-9fad-3032afd080a4
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The NSX-T Container Plug-in (NCP) is a docker image which we import into the local registry.  The image is referenced by later script by different tag name so we add an additional tag.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker load -i /tmp/nsx-container-2.2.0.8740202/Kubernetes/nsx-ncp-rhel-2.2.0.8740202.tar
docker image tag registry.local/2.2.0.8740202/nsx-ncp-rhel nsx-ncp
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Then we can create NSX ReplicationController&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;oc project nsx-system
oc create -f /tmp/nsx-container-2.2.0.8740202/Kubernetes/ncp-rc.yml
oc describe rc/nsx-ncp
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We should now see the container running within pod namespace nsx-system.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;oc get pod --all-namespaces
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If all has gone well we can now connect to the NCP container and use the &lt;a href=&#34;https://docs.vmware.com/en/VMware-NSX-T/2.2/com.vmware.nsxt.ncp_openshift.doc/GUID-12F44CD5-0518-41C3-BB14-5507224A5D60.html&#34;&gt;nsxcli&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;oc exec -it nsx-ncp-6k5t2 nsxcli
get ncp-nsx status
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;nsx-t-container-plug-in-ncp-node-agent-daemonset-ds&#34;&gt;NSX-T Container Plug-in (NCP) Node Agent DaemonSet (DS)&lt;/h2&gt;
&lt;p&gt;Edit the nsx-node-agent-ds.yml file,&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vi /tmp/nsx-container-2.2.0.8740202/Kubernetes/rhel_x86_64/nsx-node-agent-ds.yml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Ensure the following is set,&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;serviceAccountName: nsx-node-agent-svc-account
cluster = dc-openshift
apiserver_host_port = 8443
apiserver_host_ip = 192.168.1.20
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Once updated create the Node Agent Daemonset (DS),&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;oc login -u system:admin
oc apply -f /tmp/nsx-container-2.2.0.8740202/Kubernetes/rhel_x86_64/nsx-node-agent-ds.yml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Check the Node Agent Daemonset is there,&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;oc describe daemonset.apps/nsx-node-agent
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We should also be able to see all of the OpenShift pods listed including our two NSX ones.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;oc get pod --all-namespaces
&lt;/code&gt;&lt;/pre&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;NAMESPACE&lt;/th&gt;
&lt;th&gt;NAME&lt;/th&gt;
&lt;th&gt;READY&lt;/th&gt;
&lt;th&gt;STATUS&lt;/th&gt;
&lt;th&gt;RESTARTS&lt;/th&gt;
&lt;th&gt;AGE&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;default&lt;/td&gt;
&lt;td&gt;docker-registry-1-4l59n&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1h&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;default&lt;/td&gt;
&lt;td&gt;persistent-volume-setup-grm9s&lt;/td&gt;
&lt;td&gt;0/1&lt;/td&gt;
&lt;td&gt;Completed&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1h&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;default&lt;/td&gt;
&lt;td&gt;router-1-5xtqg&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1h&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;kube-dns&lt;/td&gt;
&lt;td&gt;kube-dns-bj5cq&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1h&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;kube-proxy&lt;/td&gt;
&lt;td&gt;kube-proxy-9l8ql&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1h&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;kube-system&lt;/td&gt;
&lt;td&gt;kube-controller-manager-localhost&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1h&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;kube-system&lt;/td&gt;
&lt;td&gt;kube-scheduler-localhost&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1h&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;kube-system&lt;/td&gt;
&lt;td&gt;master-api-localhost&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;1h&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;kube-system&lt;/td&gt;
&lt;td&gt;master-etcd-localhost&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1h&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;nsx-system&lt;/td&gt;
&lt;td&gt;nsx-ncp-9m2jl&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;10m&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;nsx-system&lt;/td&gt;
&lt;td&gt;nsx-node-agent-jlt5t&lt;/td&gt;
&lt;td&gt;2/2&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;4m&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;openshift-apiserver&lt;/td&gt;
&lt;td&gt;openshift-apiserver-ptk5j&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1h&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;openshift-controller-manager&lt;/td&gt;
&lt;td&gt;openshift-controller-manager-vg7gm&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1h&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;openshift-core-operators&lt;/td&gt;
&lt;td&gt;openshift-web-console-operator-78ddf7cbb7-r8dhd&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1h&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;openshift-web-console&lt;/td&gt;
&lt;td&gt;webconsole-847bc4ccc4-hgsv4&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1h&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;testing&#34;&gt;Testing&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;oc create namespace my-first
oc logs nsx-ncp-9m2jl | grep ERROR
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;nsx_ujo.k8s.ns_watcher Failed to create NSX topology for project my-first: Unexpected error from backend manager ([&amp;lsquo;192.168.1.15&amp;rsquo;]) for Allocate subnet from IP block&lt;/p&gt;
&lt;p&gt;more commands for working OpenShift here&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://static.rainfocus.com/vmware/vmworldus17/sess/148924638739800152Do/finalpresentationPDF/NET1522BU_FORMATTED_FINAL_1507910147966001nlDx.pdf&#34;&gt;https://static.rainfocus.com/vmware/vmworldus17/sess/148924638739800152Do/finalpresentationPDF/NET1522BU_FORMATTED_FINAL_1507910147966001nlDx.pdf&lt;/a&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Calling the NSX REST API with vRO and Navigating The XML Response</title>
      <link>https://darrylcauldwell.github.io/post/vro-nsx-rest/</link>
      <pubDate>Wed, 20 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/vro-nsx-rest/</guid>
      <description>
        
          &lt;p&gt;While the NSX for vSphere plugin for vRealize Orchestrator is useful, occasionally there are limitations. For example when creating an NSX Edge Services Gateway we use this method.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;NSXEdgeTrinityBasicController.createEdgeV4
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That method returns void,  so next you need to make a second method call using filter by name to get the object and obtain object ID which is typically the input to other methods.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;NSXEdgeTrinityBasicController.getAllEdgeSummariesV4
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;When creating NSX Distributed Logical Router it is the same method to create. However the second method to get the object fails as it cannot handle the additional property LogicalRouterScope which DLRs have, so throws an error.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;java.lang.NoSuchMethodException:com.vmware.vshield.edge.dto.trinity.LogicalRouterScope.&amp;lt;init&amp;gt;()
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;After trying various other NSX plugin methods all have same issue so I changed approach. NSX offers all its capabilities via &lt;a href=&#34;https://docs.vmware.com/en/VMware-NSX-for-vSphere/6.4/nsx_64_api.pdf&#34;&gt;REST API&lt;/a&gt;. vRealize Orchestrator comes with a HTTP-REST plugin, so in theory we can add NSX Managers as HTTP-REST endpoint and call everything direct.&lt;/p&gt;
&lt;p&gt;If you have multiple REST HTTP hosts added you would want to bring back a list of these.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;restHosts = RESTHostManager.getHosts();
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This returns an array of UUIDs of each REST host, we can use these UUIDs to get the REST host objects. We could normally loop to find the specific &lt;a href=&#34;http://www.vroapi.com/Class/REST/2.2.2/RESTHost&#34;&gt;RESThost&lt;/a&gt; object we are looking for, but for ease here we would use the first item from array.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;host = RESTHostManager.getHost(restHosts[0]);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;So we have the target &lt;a href=&#34;http://www.vroapi.com/Class/REST/2.2.2/RESTHost&#34;&gt;RESThost&lt;/a&gt; object look at forming the request using the &lt;a href=&#34;http://www.vroapi.com/Method/REST/2.2.2/RESTHost/createRequest&#34;&gt;createRequest&lt;/a&gt; method.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;request = host.createRequest(&#39;GET&#39;,&#39;/api/4.0/edges&#39;,&#39;&#39;);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Once we have our request formed we can look to make the call using the &lt;a href=&#34;http://www.vroapi.com/Method/REST/2.2.2/RESTHost/executeRequestWithCredentials&#34;&gt;executeRequestWithCredentials&lt;/a&gt; method. Here I store username and password as Secure String variables.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;responseStr = request.executeWithCredentials(username,password);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This returns a &lt;a href=&#34;http://www.vroapi.com/Class/REST/2.2.2/RESTResponse&#34;&gt;RESTResponse&lt;/a&gt; object, this has attribute contentAsString to navigate this XML we first convert this string to a &lt;a href=&#34;https://www.w3schools.com/XML/dom_document.asp&#34;&gt;XML DOM Document Object&lt;/a&gt;. vRealize Orchestrator comes with a &lt;a href=&#34;http://www.vroapi.com/Plugin/XML/7.0.1&#34;&gt;XML plugin&lt;/a&gt; we can use the &lt;a href=&#34;http://www.vroapi.com/Method/XML/7.0.1/XMLManager/fromString&#34;&gt;XMLManager.fromString&lt;/a&gt; method to perform this converstion.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;responseXml = XMLManager.fromString(responseStr.contentAsString);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If we look inside of the XML which is returned from /api/4.0/edges we can see each the hierachy that each NSX Edge is a XML Node called edgeSummary and within that Node are child nodes for all of its attributes.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;pagedEdgeList&amp;gt;
    &amp;lt;edgePage&amp;gt;
        &amp;lt;edgeSummary&amp;gt;
            &amp;lt;objectId&amp;gt;
            &amp;lt;objectTypeName&amp;gt;
            &amp;lt;vsmUuid&amp;gt;
            &amp;lt;nodeId&amp;gt;
            &amp;lt;Revision&amp;gt;
            &amp;lt;type&amp;gt;
            &amp;lt;name&amp;gt;
            ...
        &amp;lt;edgeSummary&amp;gt;
            &amp;lt;objectId&amp;gt;
            &amp;lt;objectTypeName&amp;gt;
            &amp;lt;vsmUuid&amp;gt;
            &amp;lt;nodeId&amp;gt;
            &amp;lt;Revision&amp;gt;
            &amp;lt;type&amp;gt;
            &amp;lt;name&amp;gt;
            ...
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;So we need to bring back all the edgeSummary Nodes and create a &lt;a href=&#34;http://www.vroapi.com/Class/XML/7.0.1/XMLNodeList&#34;&gt;XMLNodeList&lt;/a&gt; object containing all of out Edges.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;edgeNodeList = responseXml.getElementsByTagName(&amp;quot;edgeSummary&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Once we have this we can loop around the children of this and find the correct Edge entry and then get the objectId. We know the child order is always the same so we can choose data from positon in list and output the text content of Node.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;for (var i = 0 ; i &amp;lt; edgeNodeList.length ; i++) {
    var node = edgeNodeList.item(i) ;
    edgeChildNodeList = node.getChildNodes();
    if (edgeChildNodeList.item(6).textContent == edgeName) {
        var objectId = edgeChildNodeList.item(0).textContent ;
        System.log(&amp;quot;Edge named &amp;quot; + edgeName + &amp;quot; has objectId &amp;quot; + objectId) ;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;With this technique we should be able to get around any vRealize Orchestrator NSX Plugin limitation. This would also be useful for calling other RESTful APIs in absence of a specific vRealize Orchestrator plugin.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>VCDX6-DCV Defence Experience</title>
      <link>https://darrylcauldwell.github.io/post/vcdx-fail/</link>
      <pubDate>Thu, 07 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/vcdx-fail/</guid>
      <description>
        
          &lt;p&gt;In 2013 I was a systems engineer,  I worked mostly on automation scripting for consistently delivering virtualized infrastructure on VMware. A job I&amp;rsquo;d enjoyed but was ready to move my career forwards, my at the time colleague &lt;a href=&#34;https://twitter.com/virtRich&#34;&gt;Richard Dowling&lt;/a&gt; and I started looked into pursuing advanced VMware certification. In early 2014 we attended a VCDX workshop hosted by &lt;a href=&#34;https://twitter.com/vcdx001&#34;&gt;John Arrasjid&lt;/a&gt; at VMware EMEA HQ in Frimley. Also in the workshop was &lt;a href=&#34;https://twitter.com/pmcsharry&#34;&gt;Paul McSharry&lt;/a&gt; who John knew and who had recently had published &lt;a href=&#34;https://www.amazon.co.uk/VCAP5-DCD-Official-Cert-Guide-Certification/dp/078975018X&#34;&gt;VCAP5-DCD Official Cert Guide&lt;/a&gt;.  I ordered the book that evening and this began my journey from engineer to architect.&lt;/p&gt;
&lt;p&gt;During the four and a half years since I&amp;rsquo;ve continued with our goal of pursuing advanced VMware certification and passed VCAP5-DCA, VCAP5-DCD, VCAP5-DCV Design and VCIX6-NV. I&amp;rsquo;d also began contributeing much more to architecture design documentation but still had engineering duties. In 2016 I moved jobs to take on a role where I was a dedicated architect and co-authored a complex NSX for vSphere design with &lt;a href=&#34;https://www.linkedin.com/in/kyle-mcmaster-a0995917/&#34;&gt;Kyle McMaster&lt;/a&gt;. I had every intention of submitting this for VCDX6-NV but on delivery of the project, I moved to work on Amazon Web Services and could not dedicate the time the VCDX process needed.&lt;/p&gt;
&lt;p&gt;I changed job again to take another architect role, which aligned to business transformation program. Moving away from specific technology and closer to using various technologies as business enablers. As part of this I created a vSphere design for un-differentiated configuration, like a VVD but without vRA, smaller starting foootprint and tailed for our specific delivery org.&lt;/p&gt;
&lt;p&gt;I speculative submitted this design exactly as was written for production with no tailoring for VCDX, and expected that it would be rejected but I would get good feedback on what needed to improve for a actual submission. From point of speculative submission I began writing a VCDX tailed document, after four weeks of working on new document set I got a surprise email reading, &lt;strong&gt;&amp;ldquo;We are happy to inform you that you achieved a high enough score to allow you to proceed to the defence stage of the process.&amp;quot;&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Mistake One  - Never assume failure, and begin work not required. As with &lt;a href=&#34;http://darrylcauldwell.com/devops-architecture/&#34;&gt;Lean Architecture&lt;/a&gt; design only what is needed, enough but never more.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;My acceptance letter arrived on Wedneday 9th May, defence day Wednesday 6th June, so exactly four weeks to prepare. Called out to the community, &lt;a href=&#34;https://twitter.com/matjovanovic&#34;&gt;Mat Jovanovic&lt;/a&gt; and &lt;a href=&#34;https://twitter.com/Dark_KnightUK&#34;&gt;Bilal Ahmed VCDX-251&lt;/a&gt; both pointed me to &lt;a href=&#34;xhttps://twitter.com/GreggRobertson5&#34;&gt;Gregg Robertson VCDX-205&lt;/a&gt; who runs the &lt;a href=&#34;https://vcdxprepgroup.slack.com&#34;&gt;VCDX Prep Slack Group&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;d made presentations of the design before to various people within a work context so had a lot of slides already. The community rallied and setup a mock defence for Monday 14th May. Albeit a short time , I had the whole weekend to refactor the slides&amp;hellip; how hard could it be&amp;hellip; oh it was my daughters 6th birthday on the Saturday and her party on Sunday. This is the point time became my greatest enemy, it all of course stemed from &amp;lsquo;Mistake One&amp;rsquo;. The mock got completed, but I had planned to spend first 10-15m providing the C-level overview of the visio, conceptual design and then to logical. Then move on to questions, however as the mock panelists hadn&amp;rsquo;t seen my design we somewhat deviated to a general technology walkthrough. My design is by its nature a re-usable design agnostic of a specific customer, my biggest takeaway was despite this I had to present from a customer context.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Mistake Two - Even if design is customer agnositc, present in context of a customer story.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I spent the evenings of the next week, updating slide deck based on 1st mock. Had regular dialogue with &lt;a href=&#34;https://twitter.com/Dark_KnightUK&#34;&gt;Bilal Ahmed VCDX-251&lt;/a&gt; was was giving me mentorship, as my design was DCV it also included a chunk of NV so he put me in touch with &lt;a href=&#34;https://twitter.com/ShadyMalatawey&#34;&gt;Shady ElMalatawey VCDX-249&lt;/a&gt; and they both provided great mentorship.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Tip One - Mentorship helps enorously, from the very basics like where to park grab luch etc, to the mental coaching and encouragement. Bilal was first person to say I was there on merit, and indeed the last person to remind me prior to entering room. There is a mental hurdle as well as technical, and personal coaching helps this side .. a lot.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Tip Two - I am a naturally talkative guy, I love my design I have a lot invested in it, I naturally want to talk about technology when given chance. Bilal was very frank with me, and said basically &lt;strong&gt;don&amp;rsquo;t ramble&lt;/strong&gt;, aim for a 30s answer focussed on business aspects Recoverability, Aavailability, Managemability, Performance, Security and Cost. If they want more detail, they will ask,  answer succictly and move on.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The week 21-25th I arranged a mock defence with people internal to company I work for, I got six people to spend four hours and read design docs as submitted and held three mocks each with two panelists. I was very lucky to have lots of people who would spend time to help and so get very different feedback types, a three of deeply technical, a product manager, and two service architects. As well as answering their questions during session I noted these in an issues log, as I revised the presentation I closed out issues. Prior to defence I went back over the issues log as a whole to understand balance of areas people touched upon.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tip Three - Record all feedback and notes, its a great asset to review, conversations can be lost in the moment so having text reference help.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There was a 4hr &lt;a href=&#34;https://www.youtube.com/watch?v=Llty1D1yFII&amp;amp;t=1728s&#34;&gt;VCDX workshop&lt;/a&gt; on 25th, this is a relatively standard workshop which I had attended before. However the work I was doing meant I could listen in as I worked so I did. During this it became clear that a week after acceptance I should have had a &amp;lsquo;Candidate Prep Call&amp;rsquo;, this had never been scheduled. I mentioned on call and &lt;a href=&#34;https://twitter.com/VMPrime&#34;&gt;Joe Silvagi&lt;/a&gt; the workshop presenter setup a call directly after workshop (6pm Friday), I had personal engagement so spend a very few minutes on call where Joe made himself avbailable for any questions. I&amp;rsquo;ve no idea what is covered in a &amp;lsquo;Candidate Prep Call&amp;rsquo; but would guess its useful.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tip Four - Make sure Candidate Prep Call gets scheduled within one week of acceptance, chase up if it doesn&amp;rsquo;t.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;During next two weeks I had a lot on at work, I held no more mocks, I barely managed to complete the slide deck up at 4am on day of defence updating.  I had no time to work at all on design workshop. This was a choice of course, I could have spent less time on defence and made sometime, I just couldn&amp;rsquo;t see how this could be rehearsed effectively.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Mistake Three - Don&amp;rsquo;t be like Darryl, spend some time thinking and planning for design workshop&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A few days prior to defence I had two emails, one with address to attend in Frimley and one with address to attend in Staines. I was pretty sure the Frimley office closed a year or two ago, but I never visit so couldn&amp;rsquo;t be sure. Quick phone call to reception at Staines office confirmed I was booked and had parking space on site.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tip Five - Parking in Staines can be problematic, a call to reception got me an on-site space&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The day of defence, I was up at 4am fussing about powerpoint, its a long drive for me so set off early and arrived two and half hours early for my 2pm slot. This time turned out to be very useful to reset the mind, had a walk by river, grabbed a leisurely lunch and forgot about the carnage of M25 traffic. VMware have great offices with large public spaces.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tip Six - Arrive early and reset the mind&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The defence itself, nice well appointed room, four whiteboards each large, relatively new Windows laptop with USB-A ports only. I&amp;rsquo;ve been USB-C only for a while, but had guessed the supplied laptop might not be so had brought both USB-A and USB-C. On entering I was very nervous, the panelists could have taken advantage of this but let me get into a rhythm before asking questions. Joe Silvagi had said during VCDX workshop that the panelists asked questions to help you score points in areas they see weakness. This was really proved to be the case, the questions were asked in a way which seemed encouraging rather than confrontational. I made one possibly one possibly two assertions where they had asked a very technical question, I explained up to the point I was confident, then made caveate that next part I was relatively confident in but we should research the explicit detail around this. This is how I would approached with a customer and then followed up with detailed research, I expect same applies to this scenario. In hindsight this could be incorrect approach and better to speak up to point of explicit knowledge. I had mixed feelings about the backup slides through out, people had said they created but a waste of time, other people that they a great asset. I had created backup slides covering most areas of the design, the mock teams had said best layout for them a diagram on right and bullets on left. I spend a lot &amp;hellip; a very lot, of time creating these, in the end I used maybe 10-15 of them to help answer questions, if I was doing again I&amp;rsquo;d drop the text and have bigger pictures from backups.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Tip Seven - Attend the vcdx workshop, listen to Joe&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Tip Eight - Pictures tell a thousand words, backup slides less text more diagrams, no pre-written text can cover the question&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Tip Nine - Pictures tell a thousand words but, presenting can be nervous having bulleted text can help you ensure you cover all the points you want to on that topic.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;After defence and prior to design workshop I felt good, I love talking about my work, the team made me comfortable. I felt I gave a good account of design and business reasons behind, all in all it was a pleasant experience.&lt;/p&gt;
&lt;p&gt;So the workshop, in VCDX workshop Joe had explicitly said you get to see the scenario slides, then when you start writting or ask first question the timer begins. As such I bearly listened as moderator read slides as I believed I had time to read at leisure, digest then, compose myself and then begin.  I had planned to create four large sections for Requiremnt, Assumption, Risk and Constraint,  and draw out the common parts of conceptual vSphere design while talking about establishing first requirement.&lt;/p&gt;
&lt;p&gt;However, moderator stopped speaking then bang they started timer, this panicked me and I had a time limit to read which put me well and truely on the back foot from being relaxed. As such I forgot my planned approach and this became hinderance very soon as I wrote my requirements and constraints too close together and was hard to write, putting me further onto the back foot. It took me 5min or so to get back to where I wanted to start, and all because of incosistency in what I told prior and actions of moderator on the day (sigh). I never really got into a rhythm and just when I was starting to the moderator began laughing uncontrallably which made panelist laugh too, and me also, moderator left room to compose himself. This whole episode really made me loose my train of thought.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Tip Ten - Attend the vcdx workshop, listen to Joe but don&amp;rsquo;t expect the moderator to play by the rules&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Tip Elephen - Formulate a strategy and carry it out, don&amp;rsquo;t allow yourself be distracted&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;On returning home late that night, my wife asked how did it go?  I said I enjoy talking about a design I&amp;rsquo;d invested so much in and which I was very proud of to a bunch of inteligent people.&lt;/p&gt;
&lt;p&gt;She then asked do you think you&amp;rsquo;ll pass? I thought about this, then said I&amp;rsquo;ve very little interest in the outcome. I set off on a journey four and a half years ago to transition to a new career, I now work in a team who design and engineer solutions which made a direct contribution to the success of my company. Obviously it would be the icing to the cake to get the certification, but whatever the outcome the vcdx journey itself has already given me all that I set out to achieve.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ve heard all leading up to this the failure rate extremely high, people even said close to 90%, so probability says that this my first attempt will be failure. So question is would I submit a 2nd, well I guess this is architecture so we could say what would ROI be, on the investment side it would cost $4000 + VAT in application fees, it would cost probably 30-40 hours of my time to prepare and a 10 hour day of defense. The interesting aspect now is what tangible return would I get over and above what I have today.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>VMware Certified Advanced Professional - Data Center Virtualization Design</title>
      <link>https://darrylcauldwell.github.io/post/vcap-dcv-design/</link>
      <pubDate>Thu, 07 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/vcap-dcv-design/</guid>
      <description>
        
          &lt;p&gt;Having passed the VCAP5-DCD exam with little to no studying only eighteen months ago and VCIX6-NV since. All things considered I was pretty confident of doing well in the VCAP6-DCV Design exam, and when I completed exam I was pretty sure I&amp;rsquo;d passed. To my surprise I failed the exam with a 285, to make matters worse during the drive home I couldn&amp;rsquo;t fathom in my mind where it had gone wrong.
Luckily on readin the score report it highlights the blueprint objectives relating the area&amp;rsquo;s of weakness. For me that was,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Objective 1.2 - Gather and Analyze Application Requirements&lt;/li&gt;
&lt;li&gt;Objective 1.3 - Determine risks, requirements, constraints and assumptions&lt;/li&gt;
&lt;li&gt;Objective 3.4 - Determine Appropriate Compute Resources for a vSphere 6.x Physical Design&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here I focus on these three objectives, and how I revisited my study and revision to fill my knowledge gap.&lt;/p&gt;
&lt;h1 id=&#34;objective-12---gather-and-analyze-application-requirements&#34;&gt;Objective 1.2 - Gather and Analyze Application Requirements&lt;/h1&gt;
&lt;p&gt;Blueprint Defined Skills and Abilities&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Gather and analyze application requirements for a given scenario.&lt;/li&gt;
&lt;li&gt;Determine the requirements for a set of applications that will be included in the design.&lt;/li&gt;
&lt;li&gt;Collect information needed in order to identify application dependencies.&lt;/li&gt;
&lt;li&gt;Given one or more application requirements, determine the impact of the requirements on the design.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Resources I used&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=ilUrNRY_foI&#34;&gt;vBrownBag VCAP6-DCV Design Objective 1.2 with Mark Gabryjelski&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;objective-13---determine-risks-requirements-constraints-and-assumptions&#34;&gt;Objective 1.3 - Determine risks, requirements, constraints and assumptions&lt;/h1&gt;
&lt;p&gt;Blueprint Defined Skills and Abilities&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Differentiate between the concepts of risks, requirements, constraints, and assumptions.&lt;/li&gt;
&lt;li&gt;Given a statement, determine whether it is a risk, requirement, constraint, or an assumption.&lt;/li&gt;
&lt;li&gt;Analyze impact of VMware best practices to identified risks, constraints, and assumptions.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Resources I used&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=S_9Al_Tvm5U&#34;&gt;vBrownBag VCAP6-DCV Design Objective 1.3 with Rebecca Fitzhugh&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;objective-34---determine-appropriate-compute-resources-for-a-vsphere-6x-physical-design&#34;&gt;Objective 3.4 - Determine Appropriate Compute Resources for a vSphere 6.x Physical Design&lt;/h1&gt;
&lt;p&gt;Blueprint Defined Skills and Abilities&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Analyze best practices with respect to CPU family choices.&lt;/li&gt;
&lt;li&gt;Evaluate NUMA and vNUMA with ESXi hosts and Virtual machines in a given design.&lt;/li&gt;
&lt;li&gt;Analyze the following in a vSphere design:
&lt;ul&gt;
&lt;li&gt;Enhanced vMotion compatibility&lt;/li&gt;
&lt;li&gt;Implications of vSMP in virtual machines&lt;/li&gt;
&lt;li&gt;Transparent Page Sharing (TPS) and large pages&lt;/li&gt;
&lt;li&gt;Resource overcommitment&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Based on the service catalog and given functional requirements:
&lt;ul&gt;
&lt;li&gt;Determine the most appropriate compute technologies for the design&lt;/li&gt;
&lt;li&gt;Implement the service based on the required infrastructure qualities.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Determine the impact of a technical design on the choice of server density:
&lt;ul&gt;
&lt;li&gt;Scale Up/Out&lt;/li&gt;
&lt;li&gt;Auto Deploy&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Calculate the required number of nodes in an HA cluster based upon host failures and resource guarantees&lt;/li&gt;
&lt;li&gt;Evaluate the implications of using reservations, limits, and shares on the physical design.&lt;/li&gt;
&lt;li&gt;Specify the resource pool and vApp configuration based upon resource requirements.&lt;/li&gt;
&lt;li&gt;Size the following resources appropriately:
&lt;ul&gt;
&lt;li&gt;Memory&lt;/li&gt;
&lt;li&gt;CPU&lt;/li&gt;
&lt;li&gt;I/O devices&lt;/li&gt;
&lt;li&gt;Internal storage&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Given a constraint to use existing hardware, determine suitability of the hardware for the design.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Resources I used&lt;br&gt;
&lt;a href=&#34;https://www.prepressure.com/library/technology/raid&#34;&gt;RAID&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;http://www.yellow-bricks.com/2013/08/26/introduction-to-vsphere-flash-read-cache-aka-vflash/&#34;&gt;vSphere Flash Read Cache aka vFlash&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;http://www.yellow-bricks.com/2013/09/11/frequently-asked-questions-vsphere-flash-read-cache/&#34;&gt;vSphere Flash Read Cache aka vFlash - FAQs&lt;/a&gt;
&lt;a href=&#34;https://www.vmware.com/pdf/vi_architecture_wp.pdf&#34;&gt;VMware Infrastructure Architecitecture Overview&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;general&#34;&gt;General&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://kb.vmware.com/selfservice/microsites/search.do?language=en_US&amp;amp;cmd=displayKC&amp;amp;externalId=2105500&#34;&gt;Site Recovery Manager Maximums&lt;/a&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>VMware Data Encryption At Rest</title>
      <link>https://darrylcauldwell.github.io/post/encryption-at-rest/</link>
      <pubDate>Fri, 13 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/encryption-at-rest/</guid>
      <description>
        
          &lt;p&gt;Encryption of data at rest is a requirement for many customers,  with VMware hosted Virtual Machines (VMs) there are two ways to achieve this. VM data can be encrypted using vSAN whole-datastore encryption or using Storage Policy (VMcrypt). Both VM Encryption and vSAN Encryption require a Key Management Interoperability Protocol (KMIP) 1.1 compliant Key Management Server (KMS), the same KMS provider can be used for both types of encryption.&lt;/p&gt;
&lt;p&gt;There are important differences between these two encryption methods.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Feature/Function&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;VSAN Encryption&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;VMcrypt Encryption&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;External key-management server (KMS)&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;√&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;√&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Per VM Encryption&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;x&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;√&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Datastore Encryption&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;√&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;x&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Data At Rest Encryption&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;√&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;√&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;End To End Encryption&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;x&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;√&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;VMs Encrypted By&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Placement on datastore&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Storage Policy&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Encryption Occurs&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;After Deduplication&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Before Deduplication&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;vm-encryption-vmcrypt&#34;&gt;VM Encryption (VMcrypt)&lt;/h2&gt;
&lt;p&gt;Encryption is done in the hypervisor, “beneath” the virtual machine. As I/O comes out of the virtual disk controller in the VM it is immediately encrypted by a module in the kernel before being send to the kernel storage layer. Because encryption happens at the hypervisor level and not in the VM, the Guest OS and datastore type are not a factor. The encyrption is hardware accelerated when host CPU support &lt;a href=&#34;https://software.intel.com/en-us/articles/intel-advanced-encryption-standard-instructions-aes-ni&#34;&gt;Intel Advanced Encryption Standard Instructuctions (AES-NI)&lt;/a&gt;. The encryption option is exposed via Storage Policy, therefore it can be applied to only those VMs or groups of VMs which require it.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/encryption.jpg&#34; alt=&#34;VMware Encryption&#34;&gt;&lt;/p&gt;
&lt;p&gt;VM Encryption is implemented through &lt;a href=&#34;https://code.vmware.com/programs/vsphere-apis-for-io-filtering&#34;&gt;vSphere APIs for IO Filters (VAIO)&lt;/a&gt;. The VAIO framework allows a filter driver to intercept IO that a VM sends down to a storage device. Ecryption occurs before any data is send across the wire.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/encryption-vaio-architecture.png&#34; alt=&#34;vSphere APIs for IO Architecture&#34;&gt;&lt;/p&gt;
&lt;p&gt;## VMcrypt VSAN Efficiency Consideration
An important consideration when using VSAN is that, VMcrypt writes an encrypted data stream whereas vSAN encryption receives an unencrypted data stream and encrypts it during the write process. As the encrypted data written by VMcrypt appears to be random, it does not deduplicate well. If using VMcrypt with VSAN deduplication, expect deduplication efficiency to approach zero for encrypted VMs.&lt;/p&gt;
&lt;h2 id=&#34;vsan-encyption&#34;&gt;VSAN Encyption&lt;/h2&gt;
&lt;p&gt;With vSAN Encryption we can achieve “data encryption at rest” however the data travels to the destination unencrypted then when it reaches its destination it is encrypted, and it will be encrypted after it is deduplicated and/or compressed again. This allows the benefit of deduplicated and/or compressed space saving functionality.&lt;/p&gt;
&lt;p&gt;Thie data encyption at rest method is a cluster wide option, which means that every VM will be encrypted.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/encryption-vsan-hytrust.png&#34; alt=&#34;VMware Encryption&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;key-management-server-kms-topologies&#34;&gt;Key Management Server (KMS) Topologies&lt;/h2&gt;
&lt;p&gt;Key Management Server (KMS) availability is a critical component when deploying encryption as without it all data access is not allowed. If you lose the keys, you’ve lost the data (unless you’ve backed it up).&lt;/p&gt;
&lt;p&gt;Key Managers today are usually set up in a way that they replicate keys to one another. If I have three instances of a key manager, KMS-A, KMS-B and KMS-C, they replicate the keys between them. If I create a key on KMS-A it will show up in KMS-B &amp;amp; KMS-C at some point. Using this example, in vCenter I would create a key manager cluster/alias. In this example I’ll call it “KMSCluster” and add KMS-A, KMS-B and KMS-C into that KMS Cluster. I would then establish a trust with each of the key managers.&lt;/p&gt;
&lt;p&gt;KMS can either be purchased as hardware appliances or virtual appliances. When using KMS virtual appliances avoid circular dependancy where the datastore hosting the appliance is encrypted using itself. The same is true for vCenter and PSC’s in a VM Encryption scenario. You shouldn’t encrypt them using VM Encryption because they would then need to boot up to get their encryption key to boot up.&lt;/p&gt;
&lt;p&gt;If you have a single site then you probably want to have, at minimum, two replicating key managers. For multi-site,  you want all the KMS servers running and replicating across the sites.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/encryption-multisite.png&#34; alt=&#34;VMware Encryption&#34;&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>vRealize Orchestrator NSX Plug-in Troubleshooting</title>
      <link>https://darrylcauldwell.github.io/post/vro-nsx-logging/</link>
      <pubDate>Tue, 06 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/vro-nsx-logging/</guid>
      <description>
        
          &lt;p&gt;The NSX-V Plug-in for vRealize Orchestrator offers some great functionally, however creating custom workflows caused me some headaches.&lt;/p&gt;
&lt;p&gt;When building some custom workflows using the vRO API explorer there are inconsistencies, I&amp;rsquo;ve learned to not rely on the vRO API explorer for NSX plug-in documentation and instead use &lt;a href=&#34;http://www.vroapi.com/Plugin/NSX/1.2.0&#34;&gt;www.vroapi.com&lt;/a&gt; which is more complete.&lt;/p&gt;
&lt;p&gt;Problems manifest themselves as failures to execute methods, but very little detail is returned with the error message. Within vRealize Orchestrator is a JavaScript runtime environment therefore we can install a plug-in such as &lt;a href=&#34;https://labs.vmware.com/flings/vco-cli&#34;&gt;vCO-CLI&lt;/a&gt; to get an exploratory programming interface and try the commands directly to see the return values. While this was useful it didn&amp;rsquo;t help with all issues.&lt;/p&gt;
&lt;p&gt;The NSX plug-in talks to NSX Manager via the REST API, so another avenue to follow is that you can enable HttpClient logging which captures the REST calls made by the Plug-in in real-time. After some searching &lt;a href=&#34;https://www.vcoteam.info/articles/learn-vco/199-how-to-handle-vcenter-orchestrator-logs.html&#34;&gt;I found vRealize Orchestrator&lt;/a&gt; uses &lt;a href=&#34;https://logging.apache.org/log4j/2.x/&#34;&gt;Apache log4j&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We can edit the log4j configuration file&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;/etc/vco/app-server/log4j.xml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Within this configuration file we find section for the HttpClient org.apache.http&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;category&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;additivity=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;true&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;name=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;org.apache.http&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;priority&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;value=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;INFO&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/&amp;gt;&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;/category&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We can enable HttpClient debugging by amending this to have value of DEBUG.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;category&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;additivity=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;true&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;name=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;org.apache.http&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;priority&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;value=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;DEBUG&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/&amp;gt;&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;/category&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once the vRealize Orchestrator server services are restarted the logging level will change and events will be written to the following log file.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;/var/log/vco/app-server/integration-server.log
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Using a combination of these methods has enabled resolution of all issues experienced up to now. To note putting a vRealize Orchestrator server into debug mode will slow down the vRealize Orchetrator server considerably. It is recommended to use DEBUG mode temporarily.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Controlling vSphere &amp; NSX-V With Python</title>
      <link>https://darrylcauldwell.github.io/post/nsx-python/</link>
      <pubDate>Mon, 15 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/nsx-python/</guid>
      <description>
        
          &lt;p&gt;My former colleagues had made me aware of pyVmomi an open source library which VMware provide and mostly maintain for managing vSphere, so its here I shall start. Since then NSX for vSphere has also an open source library NSX RAML Client provided by VMware so I&amp;rsquo;ll then move to that.&lt;/p&gt;
&lt;p&gt;I am performing this learning exercise in my home lab  using is vSphere 6.5, vSAN 6.5, NSX6.3, with Python 2.7.10, although this should work the same with other versions.&lt;/p&gt;
&lt;p&gt;Install pyVmomi and open vCenter connection and then initiate an interactive python environment&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;git clone https://github.com/vmware/pyvmomi.git
sudo pip install -r ~/pyvmomi/requirements.txt
python
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Import the pyVim, pyVmomi &amp;amp; SSL libraries we are using,&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; ssl
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; pyVim &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; connect
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; pyVmomi &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; vim, vmodl
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Open connection to vCenter then gather contents as an object&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;vcenter &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; connect&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;SmartConnect(
    host&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;192.168.1.13&amp;#39;&lt;/span&gt;,
    user&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;administrator@vsphere.local&amp;#39;&lt;/span&gt;,
    pwd&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;VMware1!&amp;#39;&lt;/span&gt;,
    port&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;443&lt;/span&gt;,
    sslContext&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;ssl&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;_create_unverified_context()
)
content &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; vcenter&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;RetrieveContent()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;basic-get-of-information&#34;&gt;Basic get of information&lt;/h1&gt;
&lt;p&gt;Once we have vCenter Object Model as content object we can output any part of this data&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;content.about.fullName
&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;VMware vCenter Server 6.5.0 build-5178943&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We can also explore the Object Model which is well descrived here in the &lt;a href=&#34;http://pubs.vmware.com/vsphere-65/topic/com.vmware.wssdk.apiref.doc/right-pane.html&#34;&gt;vSphere SDK API Docs&lt;/a&gt; and when we know what we want to look for we can search and display anything we like, for example the list of virtual machines.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;objView &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; content&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;viewManager&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;CreateContainerView(content&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;rootFolder,[vim&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;VirtualMachine],True)
vmList &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; objView&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;view
objView&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Destroy()
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt;  vm &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; vmList:
    vm&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;config&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;name
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;basic-put-of-configuration-information&#34;&gt;Basic put of configuration information&lt;/h1&gt;
&lt;p&gt;As well as getting information from the Object Model we can just as easily apply configuration to items within (assuming the account we connect with has sufficient rights),  for example if we gather the list of hosts and set a advanced option on all of them.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;objView &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; content&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;viewManager&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;CreateContainerView(content&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;rootFolder,[vim&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;HostSystem],True)
hostList &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; objView&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;view
objView&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Destroy()
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; host &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; hostList:
    optionManager &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; host&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;configManager&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;advancedOption
    option &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; vim&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;option&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;OptionValue(key&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;VSAN.ClomRepairDelay&amp;#39;&lt;/span&gt;, value&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;long(&lt;span style=&#34;color:#ae81ff&#34;&gt;120&lt;/span&gt;))
    optionManager&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;UpdateOptions(changedValue&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[option])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;nsx-for-vsphere&#34;&gt;NSX for vSphere&lt;/h1&gt;
&lt;p&gt;So we have the pyVmomi library for vSphere, in addition to this VMware have provided open source library for &lt;a href=&#34;https://github.com/vmware/nsxramlclient&#34;&gt;NSX for vSphere&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;ll first make sure the packages are installed along with the additional packages for managing NSX.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;sudo pip install nsxramlclient pyvim pyvmomi lxml requests
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The NSX for vSphere REST API changes with each version, so in order to use the nsxramlclient library we will need a RAML file specific to version of NSX-V we are connecting to. The RAML file also produces nice &lt;a href=&#34;https://htmlpreview.github.io/?https://github.com/vmware/nsxraml/blob/6.3/html-version/nsxvapi.html&#34;&gt;dynamic documentation of the NSX APIs&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;git clone https://github.com/vmware/nsxraml
cd nsxraml
git checkout 6.3
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;So now we can try and connect and get some information about anything described in the API document, like NSX Controllers.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; nsxramlclient.client &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; NsxClient
nsx_manager &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;192.168.1.18&amp;#34;&lt;/span&gt;
nsx_username &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;admin&amp;#34;&lt;/span&gt;
nsx_password &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;VMware1!VMware1!&amp;#34;&lt;/span&gt;
nsxraml_file &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;nsxvapi.raml&amp;#39;&lt;/span&gt;
nsx_manager_session &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; NsxClient(nsxraml_file, nsx_manager, nsx_username, nsx_password)
nsx_controllers &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nsx_manager_session&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;nsxControllers&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;read&amp;#39;&lt;/span&gt;)
nsx_controllers
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;When it comes to putting and posting information getting the formatting right can be a challenge. To this end with the library it is possible to create a template python dictionary using extract_resource_body_example.  Once we have this we can display the output structure but more usefully we can also substitute values into the template.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;new_ls &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nsx_manager_session&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;extract_resource_body_example(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;logicalSwitches&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;create&amp;#39;&lt;/span&gt;)
nsx_manager_session&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;view_body_dict(new_ls)
new_ls[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;virtualWireCreateSpec&amp;#39;&lt;/span&gt;][&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;name&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;TestLogicalSwitch1&amp;#39;&lt;/span&gt;
new_ls[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;virtualWireCreateSpec&amp;#39;&lt;/span&gt;][&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;description&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;TestLogicalSwitch1&amp;#39;&lt;/span&gt;
new_ls[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;virtualWireCreateSpec&amp;#39;&lt;/span&gt;][&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;tenantId&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Tenant1&amp;#39;&lt;/span&gt;
new_ls[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;virtualWireCreateSpec&amp;#39;&lt;/span&gt;][&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;controlPlaneMode&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;UNICAST_MODE&amp;#39;&lt;/span&gt;
nsx_manager_session&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;view_body_dict(new_ls)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once we have out body template correctly describing what we want we can post this and if all goes to plan create a new Logical Switch. In this example I am passing in the scopeId (transport zone) manually to keep it a simple example.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;new_ls_response &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nsx_manager_session&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;create(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;logicalSwitches&amp;#39;&lt;/span&gt;, uri_parameters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;{&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;scopeId&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;vdnscope-1&amp;#39;&lt;/span&gt;}, request_body_dict&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;new_ls)
nsx_manager_session&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;view_response(new_ls_response)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;summary&#34;&gt;Summary&lt;/h1&gt;
&lt;p&gt;It looks like with our new found friend the VMware Python libraries we can easily create and deploy a VMware configuration &amp;lsquo;infrastructure as code&amp;rsquo;.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>DynamoDB Python Test Environment with Cloud Formations</title>
      <link>https://darrylcauldwell.github.io/post/dynamodb-python/</link>
      <pubDate>Fri, 31 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/dynamodb-python/</guid>
      <description>
        
          &lt;p&gt;The goal of this post is to walk through the creation of a AWS test environment which I use to explore the Python SDK interactions with DyanmoDB. For learning I use the free tier and so used to create the environment as needed manually. After doing this once I decided to encapsulate the configuration in a Cloud Formations template and then deploy the stack when I needed it.&lt;/p&gt;
&lt;h1 id=&#34;environment-configuration&#34;&gt;Environment Configuration&lt;/h1&gt;
&lt;p&gt;The resources I require the Cloud Formation template to create&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DynamoDB Table&lt;/li&gt;
&lt;li&gt;Identify Access Management Policy Documents with rights to Put items into DDB and Scan items in DDB&lt;/li&gt;
&lt;li&gt;Identify Access Management Role linked to the policy document&lt;/li&gt;
&lt;li&gt;EC2 Security Group allowing SSH inbound from any IP address&lt;/li&gt;
&lt;li&gt;EC2 Instance with the IAM Role and EC2 Security Group attached, which on boot performs a yum update and installs the AWS Python SDK&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The Cloud Formation template I created to meet this requirement is &lt;a href=&#34;https://s3-eu-west-1.amazonaws.com/cfpythdynamo/PythonDynamoDict.json&#34;&gt;here on s3&lt;/a&gt;,  so we can first get this.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl https://s3-eu-west-1.amazonaws.com/cfpythdynamo/PythonDynamoDict.json -o PythonDynamoDict.json
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;To note in order to use this CF template it requires an EC2 access key,  if you pull down the json then search and replace &amp;ldquo;MyEC2&amp;rdquo; with the name of your EC2 access key before creating a stack. Assuming your laptop has AWS credentials configured to allow you rights to deploy Cloud Formation templates and create IAM.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;aws cloudformation deploy --template-file PythonDynamoDict.json --stack-name &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;PythonDDB&amp;#34;&lt;/span&gt; --capabilities &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;CAPABILITY_IAM&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This should take less than five minutes and output&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;Waiting &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; changeset to be created..
Waiting &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; stack create/update to complete
Successfully created/updated stack - PythonDDB
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;connect-python-session-to-ddb&#34;&gt;Connect Python session to DDB&lt;/h1&gt;
&lt;p&gt;Open an SSD session to the EC2 instance, once session is open,  open a interactive python session&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;python
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Then within the python session we can connect to and do stuff with DDB, I&amp;rsquo;ve included some simple transactions.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Import the boto3 and json library&lt;/span&gt;

&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; boto3&lt;span style=&#34;color:#f92672&#34;&gt;,&lt;/span&gt; json

&lt;span style=&#34;color:#75715e&#34;&gt;# Create an object to DynamoDB created by Cloud Formations in Ireland&lt;/span&gt;

dynamodb &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; boto3&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resource(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dynamodb&amp;#39;&lt;/span&gt;, region_name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;eu-west-1&amp;#39;&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# Create an object to the DDB Table created by Cloud Formations&lt;/span&gt;

table &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; dynamodb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Table(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;myTestDB&amp;#39;&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# Clear any previously created values from items object&lt;/span&gt;

items &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
item_dict &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; dict()

&lt;span style=&#34;color:#75715e&#34;&gt;# Define a helper class to convert a DynamoDB item to JSON&lt;/span&gt;

&lt;span style=&#34;color:#66d9ef&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;DecimalEncoder&lt;/span&gt;(json&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;JSONEncoder):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;default&lt;/span&gt;(self, o):
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; isinstance(o, decimal&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Decimal):
            &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; o &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:
                &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; float(o)
            &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
                &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; int(o)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; super(DecimalEncoder, self)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;default(o)

&lt;span style=&#34;color:#75715e&#34;&gt;# Create some DDB Table items&lt;/span&gt;

table&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;put_item(
   Item&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;{
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;ForeName&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Bobby&amp;#39;&lt;/span&gt;,
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;FamilyName&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Johnson&amp;#39;&lt;/span&gt;,
    },
)
table&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;put_item(
    Item&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;{
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;ForeName&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Sam&amp;#39;&lt;/span&gt;,
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;FamilyName&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Smith&amp;#39;&lt;/span&gt;,
    }
)

&lt;span style=&#34;color:#75715e&#34;&gt;# Perform a table scan to return all items&lt;/span&gt;

response &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; table&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;scan()
items &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; response[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Items&amp;#39;&lt;/span&gt;]

&lt;span style=&#34;color:#75715e&#34;&gt;# Cycle through item decobe the json and store the decoded item in a python dictionary named item_dict&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# here also updating formatting so only the values are stored.&lt;/span&gt;

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; item &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; items:
    decoded_item &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (json&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dumps(item, cls&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;DecimalEncoder))
    item_part_format &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; decoded_item&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;replace(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#34;FamilyName&amp;#34;: &amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;)
    item_str_formatted &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; item_part_format&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;replace(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;, &amp;#34;ForeName&amp;#34;: &amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;:&amp;#39;&lt;/span&gt;)
    item_dict&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;update(json&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loads(item_str_formatted))

&lt;span style=&#34;color:#75715e&#34;&gt;# If we print the dictionary we get the two key pairs&lt;/span&gt;

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; item_dict
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
        
      </description>
    </item>
    
    <item>
      <title>Simple REST API For DynamoDB Using Lambda</title>
      <link>https://darrylcauldwell.github.io/post/lambda-dynamodb/</link>
      <pubDate>Thu, 29 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/lambda-dynamodb/</guid>
      <description>
        
          &lt;p&gt;My goal here is to setup a simple RESTful API which accepts GET and POST methods to trigger a Lambda Function to read and put information into DynamoDB.&lt;/p&gt;
&lt;p&gt;First we&amp;rsquo;ll create a test DynamoDB table and put some items into it,&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;aws dynamodb create-table --table-name &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;MyTable&amp;#39;&lt;/span&gt; --attribute-definitions &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;[{&amp;#34;AttributeName&amp;#34;: &amp;#34;Name&amp;#34;, &amp;#34;AttributeType&amp;#34;: &amp;#34;S&amp;#34;}]&amp;#39;&lt;/span&gt; --key-schema &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;[{&amp;#34;AttributeName&amp;#34;: &amp;#34;Name&amp;#34;, &amp;#34;KeyType&amp;#34;: &amp;#34;HASH&amp;#34;}]&amp;#39;&lt;/span&gt; --provisioned-throughput &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{&amp;#34;ReadCapacityUnits&amp;#34;: &amp;#39;&lt;/span&gt;5&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;, &amp;#34;WriteCapacityUnits&amp;#34;: &amp;#39;&lt;/span&gt;5&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;}&amp;#39;&lt;/span&gt;

aws dynamodb put-item --table-name &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;MyTable&amp;#39;&lt;/span&gt; --item &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{&amp;#34;Name&amp;#34;: {&amp;#34;S&amp;#34;: &amp;#34;David&amp;#34;},&amp;#34;Age&amp;#34;: {&amp;#34;S&amp;#34;: &amp;#34;42&amp;#34;}}&amp;#39;&lt;/span&gt;

aws dynamodb put-item --table-name &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;MyTable&amp;#39;&lt;/span&gt; --item &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{&amp;#34;Name&amp;#34;: {&amp;#34;S&amp;#34;: &amp;#34;Brian&amp;#34;},&amp;#34;Age&amp;#34;: {&amp;#34;S&amp;#34;: &amp;#34;22&amp;#34;}}&amp;#39;&lt;/span&gt;

aws dynamodb put-item --table-name &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;MyTable&amp;#39;&lt;/span&gt; --item &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{&amp;#34;Name&amp;#34;: {&amp;#34;S&amp;#34;: &amp;#34;Sean&amp;#34;},&amp;#34;Age&amp;#34;: {&amp;#34;S&amp;#34;: &amp;#34;35&amp;#34;}}&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Then if we select Lambda in AWS console, and create a new function, then at &amp;lsquo;Select blueprint&amp;rsquo; select the blueprint named &amp;lsquo;Blank Function&amp;rsquo;. At next page click dashed box to configure a API Gateway trigger and change it to have Open security. Specify the name as &amp;lsquo;myTestLambda&amp;rsquo;, the runtime as &amp;lsquo;Python 2.7&amp;rsquo;, the Role as &amp;lsquo;Create new role from template(s), the role name as &amp;lsquo;myTestLambdaRole&amp;rsquo;, the Policy template as &amp;lsquo;Simple Microservice permissions&amp;rsquo; and the handler as &amp;lsquo;lambda_function.handler&amp;rsquo;.&lt;/p&gt;
&lt;p&gt;Paste the following as Lambda code&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; __future__ &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; print_function
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; boto3
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; json
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Loading function&amp;#39;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;handler&lt;/span&gt;(event, context):
    operation &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; event[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;operation&amp;#39;&lt;/span&gt;]
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;tableName&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; event:
        dynamo &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; boto3&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resource(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dynamodb&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Table(event[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;tableName&amp;#39;&lt;/span&gt;])
    operations &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;create&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x: dynamo&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;put_item(&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;x),
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;read&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x: dynamo&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_item(&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;x),
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;update&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x: dynamo&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;update_item(&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;x),
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;delete&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x: dynamo&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;delete_item(&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;x),
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;list&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x: dynamo&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;scan(&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;x),
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;echo&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x: x,
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;ping&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pong&amp;#39;&lt;/span&gt;
    }
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; operation &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; operations:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; operations[operation](event&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;payload&amp;#39;&lt;/span&gt;))
    &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;raise&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ValueError&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Unrecognized operation &amp;#34;{}&amp;#34;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(operation))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We can then test that we can pull back a specific database item for example the Brian record, select &amp;lsquo;Action \ Configure test event&amp;rsquo; and paste in the following.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;{
    &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;operation&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;read&amp;#34;&lt;/span&gt;,
    &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;tableName&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;MyTable&amp;#34;&lt;/span&gt;,
    &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;payload&amp;#34;&lt;/span&gt;: { &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;Key&amp;#34;&lt;/span&gt;: {&lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;Name&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Brian&amp;#34;&lt;/span&gt;}}
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;By clicking Test we can do an internal test of the function and pull back the DynamoDB item.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;{
&lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;Item&amp;#34;&lt;/span&gt;: {
    &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;Age&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;22&amp;#34;&lt;/span&gt;,
    &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;Name&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Brian&amp;#34;&lt;/span&gt;
}
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To do a table scan rather than targetted get,&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;{
    &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;operation&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;list&amp;#34;&lt;/span&gt;,
    &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;tableName&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;MyTable&amp;#34;&lt;/span&gt;,
    &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;payload&amp;#34;&lt;/span&gt;: { &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;TableName&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;MyTable&amp;#34;&lt;/span&gt;}
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The query can be adjusted to perform any operation on the database.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>The DevOps Infrastructure Architect</title>
      <link>https://darrylcauldwell.github.io/post/devops-architect/</link>
      <pubDate>Thu, 29 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/devops-architect/</guid>
      <description>
        
          &lt;p&gt;One common critisism of Agile teams is they are architecturally weak and disconnected from the operational realities of complex enterprise environments. Traditional enterprise architecture processes are viewed focusing on delivering documentation rather than delivering a working solution, slow, and focussed on delivering monolith design rather than continuous delivery of small incremental updates.&lt;/p&gt;
&lt;h2 id=&#34;traditional-infrastructure-lifecycle&#34;&gt;Traditional Infrastructure Lifecycle&lt;/h2&gt;
&lt;p&gt;Traditional infrastructure architecture development metholodies are a series of cyclical processes which culminate in a set of detailed documentation, including conceptual design, logical design and physical design. These are developed by an architect or architectural team in relative isolation to day-to-day operational activities. Typically in a traditional large enterprise architectural disciplines are aligned to technoligies wintel, security, network, storage, &amp;amp; *nix and each prepares there own documentation set.&lt;/p&gt;
&lt;p&gt;At the point of delivery it is often found that the documentation sets are so large that they are often delivered incomplete of the full detail needed to deliver the solution. Cross discipline highly skilled engineers with deep technical product knowledge then engineer the solution design to make the component pieces work together. The engineers then delivers automation scripts to deliver the exact settings needed for the solution to operate. At this point the carefully prepared architectural documentation set is out of date.&lt;/p&gt;
&lt;p&gt;Enterprise solutions are usually intended to plugin to existing operational tooling, and the enterprise architect usually assume this tooling will have suitable functionality built in to support the solution they design. Once deployed it is often found that the integration to operational tooling works at a very basic level but does not out of the box meet the management complexities of the solution delivered. At this point cross discipline highly skilled engineers with deep technical product knowledge have to get together with the operational tooling team and engineer a solution to make the solution work. These changes to the solution make the architectural documentation further out of date. Day two operations of any delivered solution will naturally lead to more change and the document set becoming more obsolete. All of these changes require high skilled people at every stage of delivery.&lt;/p&gt;
&lt;h2 id=&#34;agile-infrastructure-architecture&#34;&gt;Agile Infrastructure Architecture&lt;/h2&gt;
&lt;p&gt;Pre-virtualisation the requirement for up front design was partially justified as the hardware required for the application needed to be specced, procured, delivered, racked and powered before it could be consumed. Virtualization de-coupled these two processes and pools of compute resources could be pre-provisioned and consumed elastically, the public cloud provides further elasticity in delivery.&lt;/p&gt;
&lt;p&gt;Agile development techniques such as ExtremeProgramming revolve around &amp;lsquo;You Aren&amp;rsquo;t Going to Need It (YAGNI)&amp;rsquo;. This principle relates to the notion of &amp;lsquo;incremental design&amp;rsquo; rather than carefully considered planned development encompassing all possible future need. In lean this is refered to as just-in-time. Agile architecture should be a collaborative activity which enables agile development to progress features and improvements in a timely manner to produce artifacts to meet the immediate requirement, and iterated just-in-time. The use of architecture model storming can be used between, architecture and operational engineering teams to agree solutions collaboratively.&lt;/p&gt;
&lt;p&gt;The agile infrastructure architect still has the primary goal of designing solutions which are deployable, scalable, secure, maintainable, managable, standards compliant, fault tolerant, testable, upgradable and recoverable.&lt;/p&gt;
&lt;p&gt;When architectcure design is designed and delivered in small units, the feedback loop to deploying engineer is much shorter, issues are found and fixed and all stakeholders are kept in the loop. The use of collaboration tools to store documentation such as Github WiKi&amp;rsquo;s or Atlassian Confluence means that documention can be kept up to date collabortaively and be kept close to the automation scipts.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.guru99.com/agile-vs-kanban.html&#34;&gt;Agile Vs Kanban: What’s the Difference?&lt;/a&gt;
&lt;a href=&#34;http://www.agilearchitect.org/agile/role.htm&#34;&gt;Agile Architect: Role&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;http://martinfowler.com/bliki/Yagni.html&#34;&gt;Martin Fowler: YAGNI&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;http://agilemodeling.com/essays/agileArchitecture.htm&#34;&gt;Agile Modeling: Agile Architecture&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;http://www.agilemodeling.com/&#34;&gt;Agile Modeling&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.gilb.com/blog/what-every-successful-project-manager-should-know&#34;&gt;What Every Successful Product Manager (Owner) Should Know&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;http://blog.xebia.com/lean-architecture-principle-5-just-in-time-just-enough/&#34;&gt;Lean Architecture: Just In Time, Just Enough&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;http://www.extremeprogramming.org/&#34;&gt;Extreme Programming: A Gentle Introduction&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;http://www.scaledagileframework.com/agile-architecture/&#34;&gt;Scaled Agile: Agile Architectuere Abstract&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;http://martinfowler.com/articles/designDead.html&#34;&gt;Martin Fowler: Is Design Dead&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;http://agilemodeling.com/essays/modelStorming.htm&#34;&gt;Agile Modeling: Model Storming&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;http://shapingsoftware.com/2009/03/02/agile-architecture-method/&#34;&gt;Shaping Software: Agile Architecture Method&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;www.agiledata.org/essays/enterpriseArchitecture.html#AgileApproach&#34;&gt;Agile Data: Agile Enterprise Architecture Approach&lt;/a&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Patching Windows EC2 Instances</title>
      <link>https://darrylcauldwell.github.io/post/ec2-win-patching/</link>
      <pubDate>Wed, 28 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/ec2-win-patching/</guid>
      <description>
        
          &lt;p&gt;Amazon EC2 Systems Manager is a collection of capabilities that helps you automate management tasks such as collecting system inventory, applying operating system (OS) patches, automating the creation of Amazon Machine Images (AMIs), and configuring operating systems (OSs) and applications at scale.&lt;/p&gt;
&lt;p&gt;Amazon EC2 Systems Manager relies on the Amazon Simple Systems Management Service (SSM) agent being installed on the guests. The SSM agent is pre-installed on Windows Server 2016 instances or Windows Server 2003-2012 R2 instances created from AMI&amp;rsquo;s published after November 2016, if you created your own or used earlier AMI you&amp;rsquo;ll need to install. The SSM agent can be installed on other instances by following this &lt;a href=&#34;http://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/sysman-install-ssm-win.html&#34;&gt;install guide&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Patch Management is always an operational pain point so its welcome that AWS offers a solution. You create groups of computers to patch by applying a tag &amp;lsquo;Patch Group&amp;rsquo; and specifying a group name as the value. You create a group of patches by forming a patch baseline containing and excluding the patches you require. You then specify a maintenance window and specify task like patch this group of servers to this patch baseline.&lt;/p&gt;
&lt;h2 id=&#34;how-to&#34;&gt;How To&lt;/h2&gt;
&lt;p&gt;The guest agent requires permissions to connect to EC2 Systems Manager, we give these rights by create an EC2 Service role with the policy document &amp;lsquo;AmazonEC2RoleforSSM&amp;rsquo; attached. We then provision the EC2 instance to be patched with this role attached. If you have instance already deployed you can add the policy document to a role which is added already,  or clone the instance to a new AMI attach role and power on.&lt;/p&gt;
&lt;p&gt;Here I create a new role named &amp;lsquo;EC2-Systems-Manager-Role&amp;rsquo; with the policy document &amp;lsquo;AmazonEC2RoleforSSM&amp;rsquo; attached, attached it to a new test Windows 2016 EC2 instance.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;aws iam create-role --role-name EC2-Systems-Manager-Role --assume-role-policy-document &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{&amp;#34;Version&amp;#34;:&amp;#34;2012-10-17&amp;#34;,&amp;#34;Statement&amp;#34;:[{&amp;#34;Effect&amp;#34;:&amp;#34;Allow&amp;#34;,&amp;#34;Principal&amp;#34;:{&amp;#34;Service&amp;#34;:[&amp;#34;ssm.amazonaws.com&amp;#34;]},&amp;#34;Action&amp;#34;:[&amp;#34;sts:AssumeRole&amp;#34;]}]}&amp;#39;&lt;/span&gt;

aws iam create-instance-profile --instance-profile-name EC2-Systems-Manager-Profile

aws iam add-role-to-instance-profile --instance-profile-name EC2-Systems-Manager-Profile --role-name EC2-Systems-Manager-Role

aws ec2 create-security-group --group-name systemsManagerTest --description &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;EC2 Systems Manager Test Security Group&amp;#34;&lt;/span&gt;

aws ec2 run-instances --image-id ami-771b4504 --count &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; --instance-type t2.micro --key-name MyEC2 --security-groups systemsManagerTest --iam-instance-profile Name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;EC2-Systems-Manager-Profile
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The &amp;lsquo;Systems Manager Service&amp;rsquo; requires a Patch Group tag adding to the EC2 instances to patch,  so here we add a tag to the instance we just created.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;aws ec2 create-tags --resources &amp;lt;ec2-instance-id&amp;gt; --tags Key&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Patch Group&amp;#39;&lt;/span&gt;,Value&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Test-Patch&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The &amp;lsquo;Systems Manager Service - Maintenance Window&amp;rsquo; task requires rights on the EC2 instances to apply patches and also to task to the &amp;lsquo;Systems Manager Service&amp;rsquo;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;aws iam create-user --user-name ssmPatchUser
aws iam create-policy --policy-name ssmPassRole --policy-document &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{&amp;#34;Version&amp;#34;: &amp;#34;2012-10-17&amp;#34;,&amp;#34;Statement&amp;#34;: [{&amp;#34;Effect&amp;#34;: &amp;#34;Allow&amp;#34;,&amp;#34;Action&amp;#34;: [&amp;#34;iam:PassRole&amp;#34;],&amp;#34;Resource&amp;#34;: &amp;#34;*&amp;#34;}]}&amp;#39;&lt;/span&gt;
aws iam attach-user-policy --policy-arn arn:aws:iam::&amp;lt;your-acc-number&amp;gt;:policy/ssmPassRole  --user-name ssmPatchUser
aws iam attach-user-policy --policy-arn arn:aws:iam::aws:policy/AmazonSSMFullAccess --user-name ssmPatchUser
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We can then setup a patch baseline, this baseline auto approves all Critical, Important and Moderate patches of all classifications to be deployed seven days after they released.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;aws ssm create-patch-baseline --name &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;testBaseline&amp;#34;&lt;/span&gt; --approval-rules &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;PatchRules=[{PatchFilterGroup={PatchFilters=[{Key=MSRC_SEVERITY,Values=[Critical,Important,Moderate]},{Key=CLASSIFICATION,Values=[SecurityUpdates,Updates,UpdateRollups,CriticalUpdates]}]},ApproveAfterDays=7}]&amp;#34;&lt;/span&gt; --description &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;myBaseline&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We then take the baseline ID output and link the patch baseline with the patch group.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;aws ssm register-patch-baseline-for-patch-group --baseline-id &amp;lt;baseline-id&amp;gt; --patch-group &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Test-Patch&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once the baseline and patch groups are created and linked,  we create a SSM Maintenance Window with a task to deploy.  Here we create a schedule which starts every week day 6pm to midnight and stops scheduling tasks at 11pm. To format the cron expression is a little complex but its documented &lt;a href=&#34;https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/sysman-maintenance-cron.html?icmpid=docs_ec2_console&#34;&gt;here&lt;/a&gt; in my example we have a window at 6pm for six hours Monday through Friday.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;aws ssm create-maintenance-window --name myFirstMaintenanceWindow --schedule &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;cron(0 00 18 ? * MON-FRI)&amp;#34;&lt;/span&gt; --duration &lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt; --cutoff &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; --allow-unassociated-targets
aws ssm register-target-with-maintenance-window --window-id &amp;lt;maint-window-id&amp;gt; --targets &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Key=tag:Patch Group,Values=Test-Patch&amp;#34;&lt;/span&gt; --owner-information &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Test server&amp;#34;&lt;/span&gt; --resource-type &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;INSTANCE&amp;#34;&lt;/span&gt; 
aws ssm register-task-with-maintenance-window --window-id &amp;lt;your-maintenance-window-id&amp;gt; --targets &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Key=WindowTargetIds,Values=&amp;lt;your-target-group-id&amp;gt;&amp;#34;&lt;/span&gt; --task-arn &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;AWS-ApplyPatchBaseline&amp;#34;&lt;/span&gt; --service-role-arn &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;arn:aws:iam::&amp;lt;your-acc-id&amp;gt;:policy/ssmPassRole&amp;#34;&lt;/span&gt; --task-type &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;RUN_COMMAND&amp;#34;&lt;/span&gt; --max-concurrency &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; --max-errors &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; --priority &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; --task-parameters &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{\&amp;#34;Operation\&amp;#34;:{\&amp;#34;Values\&amp;#34;:[\&amp;#34;Install\&amp;#34;]}}&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Another useful little tool for making operating EC2 instances that little bit easier.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>DynamoDB With Powershell</title>
      <link>https://darrylcauldwell.github.io/post/dynamodb-powershell/</link>
      <pubDate>Tue, 20 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/dynamodb-powershell/</guid>
      <description>
        
          &lt;p&gt;AWS dynamoDB is a really useful key-value store which is really easy to consume from scripts. However while the AWS Powershell module contains functions for &amp;lsquo;Managing Tables&amp;rsquo; it does not contain functions for &amp;lsquo;Reading Data&amp;rsquo; or &amp;lsquo;Modifying Data&amp;rsquo;.  I had found Julian Biddle had written a &lt;a href=&#34;https://anoriginalidea.wordpress.com/2015/01/20/using-amazon-aws-dynamodb-from-powershell/&#34;&gt;blog post&lt;/a&gt; about how this might be done by making direct calls to AWS AmazonDynamoDBClient SDK for .net. While this was a useful starting point I had to read around this alot to get it to work how I needed, this post is an explaination of my understanding.&lt;/p&gt;
&lt;p&gt;The script this blog post documents is stored &lt;a href=&#34;https://github.com/darrylcauldwell/dynamoDB-powershell/blob/master/dynamoDB.ps1&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The first thing to do is setup your Powershell session with credentials which have permissions to Read and Write AWS dynamoDB. Here we create a profile and then set this as the default profile to be used.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;Import-Module AWSPowershell
Set-AWSCredentials -AccessKey &amp;lt;my-access-key&amp;gt; -SecretKey &amp;lt;my-access-key-secret&amp;gt; -StoreAs DynamoDB
Initialize-AWSDefaults -ProfileName DynamoDB -Region eu-west-1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We can then use the AWS cmdlets to create a test dynamoDB table.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;$exampleSchema = New-DDBTableSchema | Add-DDBKeySchema -KeyName &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Name&amp;#34;&lt;/span&gt; -KeyDataType &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;S&amp;#34;&lt;/span&gt;
$exampleTable = New-DDBTable &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;myExample&amp;#34;&lt;/span&gt; -Schema $exampleSchema -ReadCapacity 5 -WriteCapacity 5
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Then within our script we add the AmazonDynamoDB .net framework class.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;Add-Type -Path (${env&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;:&lt;/span&gt;ProgramFiles(x86)}+&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;\AWS SDK for .NET\bin\Net45\AWSSDK.DynamoDBv2.dll&amp;#34;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We then create a session to dynamoDB, in this example script we are running from within a Powershell session which already has permissions to DynamoDB. As such we need to specify which region our tables are in so we form a RegionEndpoint object for Ireland and pass this to form a session to that region.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;$regionName = &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;eu-west-1&amp;#39;&lt;/span&gt;
$regionEndpoint=&lt;span style=&#34;color:#66d9ef&#34;&gt;[Amazon.RegionEndPoint]&lt;/span&gt;::GetBySystemName($regionName)
$dbClient = New-Object Amazon.DynamoDBv2.AmazonDynamoDBClient($regionEndpoint)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If we wanted to authenticate within script we would form a credential object and pass that to the command to create the session for example.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;$dbClient = New-Object Amazon.DynamoDBv2.AmazonDynamoDBClient($creds, $regionEndpoint).
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;As we would typically make various put operations to DynamoDB we create a reuable function which takes parameters. In this example we have a function creating a single Item with two key-value pairs.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; putDDBItem{
    &lt;span style=&#34;color:#66d9ef&#34;&gt;param&lt;/span&gt; (
        &lt;span style=&#34;color:#66d9ef&#34;&gt;[string]&lt;/span&gt;$tableName,
        &lt;span style=&#34;color:#66d9ef&#34;&gt;[string]&lt;/span&gt;$key,
        &lt;span style=&#34;color:#66d9ef&#34;&gt;[string]&lt;/span&gt;$val,
        &lt;span style=&#34;color:#66d9ef&#34;&gt;[string]&lt;/span&gt;$key1,
        &lt;span style=&#34;color:#66d9ef&#34;&gt;[string]&lt;/span&gt;$val1
        )
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We create an object for the PutItemRequest operation, we then assign our tableName parameter as the string value for the TableName property.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;$req = New-Object Amazon.DynamoDBv2.Model.PutItemRequest
$req.TableName = $tableName
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We also need to populate the Item property, this is a dictionary which requires both a string value for the key name and an AttributeValue object. Here we add two key-value pairs to the item object request.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;$req.Item = New-Object &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;system.collections.generic.dictionary[string,Amazon.DynamoDBv2.Model.AttributeValue]&amp;#39;&lt;/span&gt;
$valObj = New-Object Amazon.DynamoDBv2.Model.AttributeValue
$valObj.S = $val
$req.Item.Add($key, $valObj)
$val1Obj = New-Object Amazon.DynamoDBv2.Model.AttributeValue
$val1Obj.S = $val1
$req.Item.Add($key1, $val1Obj)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once our object item request is formed we run this against the PutItem method of our dynamoDB database connection&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;$dbClient.PutItem($req)
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;As we would typically make various read operations to DynamoDB we create a reuable function which takes parameters.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; getDDBItem{
    &lt;span style=&#34;color:#66d9ef&#34;&gt;param&lt;/span&gt; (
            &lt;span style=&#34;color:#66d9ef&#34;&gt;[string]&lt;/span&gt;$tableName,
            &lt;span style=&#34;color:#66d9ef&#34;&gt;[string]&lt;/span&gt;$key,
            &lt;span style=&#34;color:#66d9ef&#34;&gt;[string]&lt;/span&gt;$keyAttrStr
            )

&lt;span style=&#34;color:#75715e&#34;&gt;## We create an object for the GetItemRequest operation, we then assign our tableName parameter as the string value for the TableName property. &lt;/span&gt;

$req = New-Object Amazon.DynamoDBv2.Model.GetItemRequest
$req.TableName = $tableName

&lt;span style=&#34;color:#75715e&#34;&gt;## We also need to populate the Key property, this is a dictionary which requires both a string value for the key name and an AttributeValue object for the value matching the Item we want to extract. The full command syntax can be found [here](http://docs.aws.amazon.com/sdkfornet/v3/apidocs/items/DynamoDBv2/TDynamoDBv2GetItemRequest.html).&lt;/span&gt;

$req.Key = New-Object &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;system.collections.generic.dictionary[string,Amazon.DynamoDBv2.Model.AttributeValue]&amp;#39;&lt;/span&gt;
$keyAttrObj = New-Object Amazon.DynamoDBv2.Model.AttributeValue
$keyAttrObj.S = $keyAttrStr
$req.Key.Add($key, $keyAttrObj.S)

&lt;span style=&#34;color:#75715e&#34;&gt;## Once we have our request object populated we then run the GetItem method and pass it the object we have formed. Here I adjust the scope of the object to script so this can be used within the script outside of the function.&lt;/span&gt;

$script:resp = $dbClient.GetItem($req)
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If we now call the set function and ask it to create an item,&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;putDDBItem -tableName &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;myExample&amp;#39;&lt;/span&gt; -key &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Name&amp;#39;&lt;/span&gt; -val &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Bob&amp;#39;&lt;/span&gt; -key1 &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Age&amp;#39;&lt;/span&gt; -val1 &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;21&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We can repeat this to populate a little more data into the table.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;putDDBItem -tableName &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;myExample&amp;#39;&lt;/span&gt; -key &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Name&amp;#39;&lt;/span&gt; -val &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Bert&amp;#39;&lt;/span&gt; -key1 &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Age&amp;#39;&lt;/span&gt; -val1 &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;22&amp;#39;&lt;/span&gt;
putDDBItem -tableName &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;myExample&amp;#39;&lt;/span&gt; -key &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Name&amp;#39;&lt;/span&gt; -val &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Sid&amp;#39;&lt;/span&gt; -key1 &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Age&amp;#39;&lt;/span&gt; -val1 &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;23&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Oncew we have some data in we can then call the query function to pull back the the Item where Name matches Bob.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;getDDBItem -tableName &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;myExample&amp;#39;&lt;/span&gt; -key &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Name&amp;#39;&lt;/span&gt; -keyAttrStr &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Bob&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The item is returned as an object, we can then display the contents of any key value pair such as Hugh&amp;rsquo;s age,  note the key value pair are also objects so we view the .S string attribute.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;$script:resp.Item.&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Age&amp;#39;&lt;/span&gt;.S
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;As for this example I scoped the object to script it will not be cleaned so we reset this to $null once we have consumed it.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;$script:resp = $null
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
        
      </description>
    </item>
    
    <item>
      <title>Setup VPC Peering With Ansible</title>
      <link>https://darrylcauldwell.github.io/post/vpc-ansible/</link>
      <pubDate>Mon, 14 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/vpc-ansible/</guid>
      <description>
        
          &lt;p&gt;In this post I look at setting up &lt;a href=&#34;http://docs.aws.amazon.com/AmazonVPC/latest/PeeringGuide/vpc-peering-overview.html&#34;&gt;AWS VPC peering&lt;/a&gt; using Ansible. To do this we will start simple and add complexity to our configuration, we will start with peering within a single account and then move to script across accounts.&lt;/p&gt;
&lt;h2 id=&#34;local-peering&#34;&gt;Local Peering&lt;/h2&gt;
&lt;p&gt;I&amp;rsquo;ll start by configuring two VPCs within the same account a single account, and configure peering between them. The Ansible host will sit within the same account which we create the new VPCs and peering. In order that Ansible can manage the AWS VPC services create an IAM Role named Ansible and assign it to the AdmistratorAccess policy. Once the IAM role is created we can then create a RHEL7 EC2 instance with this IAM role attached.&lt;/p&gt;
&lt;p&gt;The Ansible AWS modules manages AWS via the API by use of the &lt;a href=&#34;http://boto.cloudhackers.com/&#34;&gt;Python boto library&lt;/a&gt;, presently the boto project is migrating from v2 to v3, the Ansible VPC module relies on both versions.  In order for boto to function correctly we also need locally installed AWSCLI. Once the RHEL instance is running connect and run the following commands to install Ansible and the boto and AWS CLI python library.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;sudo yum install wget -y
wget http://dl.fedoraproject.org/pub/epel/7/x86_64/e/epel-release-7-8.noarch.rpm
sudo rpm -ivh epel-release-7-8.noarch.rpm
sudo yum install ansible git python python-devel python-pip -y
sudo pip install boto boto3 awscli
sudo yum update -y
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;What we&amp;rsquo;ll do is use the &lt;a href=&#34;http://docs.ansible.com/ansible/ec2_vpc_module.html&#34;&gt;ec2_vpc module&lt;/a&gt; to create two new VPCs and capture the output of these as variables.  We can then use pass the output from VPC creation into the &lt;a href=&#34;http://docs.ansible.com/ansible/ec2_vpc_peer_module.html&#34;&gt;ec2_vpc_peer module&lt;/a&gt; to configure peering.&lt;/p&gt;
&lt;p&gt;Once Ansible is installed you can clone example repository.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;git clone https://github.com/darrylcauldwell/aws-ansible.git
cd aws-ansible
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Inside the repository is an example playbook.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;local-vpc-peering.yml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The contents of which are shown here.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yml&#34; data-lang=&#34;yml&#34;&gt;---
- &lt;span style=&#34;color:#f92672&#34;&gt;hosts&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;localhost&amp;#34;&lt;/span&gt;
   &lt;span style=&#34;color:#f92672&#34;&gt;connection&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;local&amp;#34;&lt;/span&gt;

   &lt;span style=&#34;color:#f92672&#34;&gt;tasks&lt;/span&gt;:
   - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;First VPC&amp;#34;&lt;/span&gt;
   &lt;span style=&#34;color:#f92672&#34;&gt;ec2_vpc&lt;/span&gt;:
       &lt;span style=&#34;color:#f92672&#34;&gt;state&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;present&lt;/span&gt;
       &lt;span style=&#34;color:#f92672&#34;&gt;cidr_block&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;10.0.0.0&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;/16&lt;/span&gt;
       &lt;span style=&#34;color:#f92672&#34;&gt;resource_tags&lt;/span&gt;: { &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Name&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;First VPC&amp;#34;&lt;/span&gt; }
       &lt;span style=&#34;color:#f92672&#34;&gt;subnets&lt;/span&gt;:
       - &lt;span style=&#34;color:#f92672&#34;&gt;cidr&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;10.0.1.0&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;/24&lt;/span&gt;
           &lt;span style=&#34;color:#f92672&#34;&gt;az&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;eu-west-1a&lt;/span&gt;
           &lt;span style=&#34;color:#f92672&#34;&gt;resource_tags&lt;/span&gt;: {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Location&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;SiteA&amp;#34;&lt;/span&gt;}
       - &lt;span style=&#34;color:#f92672&#34;&gt;cidr&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;10.0.2.0&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;/24&lt;/span&gt;
           &lt;span style=&#34;color:#f92672&#34;&gt;az&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;eu-west-1b&lt;/span&gt;
           &lt;span style=&#34;color:#f92672&#34;&gt;resource_tags&lt;/span&gt;: {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Location&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;SiteB&amp;#34;&lt;/span&gt;}
       - &lt;span style=&#34;color:#f92672&#34;&gt;cidr&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;10.0.3.0&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;/24&lt;/span&gt;
           &lt;span style=&#34;color:#f92672&#34;&gt;az&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;eu-west-1c&lt;/span&gt;
           &lt;span style=&#34;color:#f92672&#34;&gt;resource_tags&lt;/span&gt;: {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Location&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;SiteC&amp;#34;&lt;/span&gt;}
       &lt;span style=&#34;color:#f92672&#34;&gt;region&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;eu-west-1&lt;/span&gt;
       &lt;span style=&#34;color:#f92672&#34;&gt;wait&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;yes&amp;#34;&lt;/span&gt; 
   &lt;span style=&#34;color:#f92672&#34;&gt;register&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;first_vpc&lt;/span&gt;

   - &lt;span style=&#34;color:#f92672&#34;&gt;debug&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;msg=&amp;#34;{{ first_vpc }}&amp;#34; &lt;/span&gt;

   - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Second VPC&amp;#34;&lt;/span&gt;
   &lt;span style=&#34;color:#f92672&#34;&gt;ec2_vpc&lt;/span&gt;:
       &lt;span style=&#34;color:#f92672&#34;&gt;state&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;present&lt;/span&gt;
       &lt;span style=&#34;color:#f92672&#34;&gt;cidr_block&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;10.1.0.0&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;/16&lt;/span&gt;
       &lt;span style=&#34;color:#f92672&#34;&gt;resource_tags&lt;/span&gt;: { &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Name&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Second VPC&amp;#34;&lt;/span&gt; }
       &lt;span style=&#34;color:#f92672&#34;&gt;subnets&lt;/span&gt;:
       - &lt;span style=&#34;color:#f92672&#34;&gt;cidr&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;10.1.1.0&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;/24&lt;/span&gt;
           &lt;span style=&#34;color:#f92672&#34;&gt;az&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;eu-west-1a&lt;/span&gt;
           &lt;span style=&#34;color:#f92672&#34;&gt;resource_tags&lt;/span&gt;: {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Location&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;SiteA&amp;#34;&lt;/span&gt;}
       - &lt;span style=&#34;color:#f92672&#34;&gt;cidr&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;10.1.2.0&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;/24&lt;/span&gt;
           &lt;span style=&#34;color:#f92672&#34;&gt;az&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;eu-west-1b&lt;/span&gt;
           &lt;span style=&#34;color:#f92672&#34;&gt;resource_tags&lt;/span&gt;: {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Location&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;SiteB&amp;#34;&lt;/span&gt;}
       - &lt;span style=&#34;color:#f92672&#34;&gt;cidr&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;10.1.3.0&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;/24&lt;/span&gt;
           &lt;span style=&#34;color:#f92672&#34;&gt;az&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;eu-west-1c&lt;/span&gt;
           &lt;span style=&#34;color:#f92672&#34;&gt;resource_tags&lt;/span&gt;: {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Location&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;SiteC&amp;#34;&lt;/span&gt;}
       &lt;span style=&#34;color:#f92672&#34;&gt;region&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;eu-west-1&lt;/span&gt;
       &lt;span style=&#34;color:#f92672&#34;&gt;wait&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;yes&amp;#34;&lt;/span&gt; 
   &lt;span style=&#34;color:#f92672&#34;&gt;register&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;second_vpc&lt;/span&gt;

   - &lt;span style=&#34;color:#f92672&#34;&gt;debug&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;msg=&amp;#34;{{ second_vpc }}&amp;#34; &lt;/span&gt;

   - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Create local VPC peering connection&amp;#34;&lt;/span&gt;
   &lt;span style=&#34;color:#f92672&#34;&gt;ec2_vpc_peer&lt;/span&gt;:
       &lt;span style=&#34;color:#f92672&#34;&gt;region&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;eu-west-1&lt;/span&gt;
       &lt;span style=&#34;color:#f92672&#34;&gt;vpc_id&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{{ first_vpc.vpc_id }}&amp;#34;&lt;/span&gt;
       &lt;span style=&#34;color:#f92672&#34;&gt;peer_vpc_id&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{{ second_vpc.vpc_id }}&amp;#34;&lt;/span&gt;
       &lt;span style=&#34;color:#f92672&#34;&gt;state&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;present&lt;/span&gt;
   &lt;span style=&#34;color:#f92672&#34;&gt;register&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;vpc_peer&lt;/span&gt;

   - &lt;span style=&#34;color:#f92672&#34;&gt;debug&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;msg=&amp;#34;{{ vpc_peer }}&amp;#34;&lt;/span&gt;

   - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Accept local VPC peering connection&amp;#34;&lt;/span&gt;
   &lt;span style=&#34;color:#f92672&#34;&gt;ec2_vpc_peer&lt;/span&gt;:
       &lt;span style=&#34;color:#f92672&#34;&gt;region&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;eu-west-1&lt;/span&gt;
       &lt;span style=&#34;color:#f92672&#34;&gt;peering_id&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{{ vpc_peer.peering_id }}&amp;#34;&lt;/span&gt;
       &lt;span style=&#34;color:#f92672&#34;&gt;state&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;accept&lt;/span&gt;
   &lt;span style=&#34;color:#f92672&#34;&gt;register&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;accept_peer&lt;/span&gt;

   - &lt;span style=&#34;color:#f92672&#34;&gt;debug&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;msg=&amp;#34;{{ accept_peer }}&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;I&amp;rsquo;ve added debugging of output, if you run this you will see the two VPCs get created and then the peering configured between them.&lt;/p&gt;
&lt;p&gt;## Cross Account VPC Peering Using Access Keys&lt;/p&gt;
&lt;p&gt;As well as confguring peering within a single account, we can also use Ansible across AWS accounts. The steps we use are very similar but we begin to use &lt;a href=&#34;http://boto.cloudhackers.com/en/latest/boto_config_tut.html&#34;&gt;boto configuration profiles&lt;/a&gt; once we have a configuration profile for each account in place we can then target each task in the play to a different account. As we are using boto we&amp;rsquo;ll authenticate using AWS Access Key and Secret rather than role based permissions applied to the EC2 instance, we cannot remove a role from a EC2 instance so terminate the old Ansible server and create a new one as above but without the IAM Role attached.&lt;/p&gt;
&lt;p&gt;Within each account your managing create an IAM User called AnsibleAdministratorAccess and attach the AdmistratorAccess policy, add the Access Key ID and Secret Access Key to the boto2 and boto3 configuration files. I create a profile for each account named the account number.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;sudo vi /etc/boto.cfg

&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;profile 843555617105&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
aws_access_key_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &amp;lt;your_access_key_here&amp;gt;
aws_secret_access_key &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &amp;lt;your_secret_key_here&amp;gt;

&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;profile 664710917345&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
aws_access_key_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &amp;lt;your_access_key_here&amp;gt;
aws_secret_access_key &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &amp;lt;your_secret_key_here&amp;gt;

mkdir ~/.aws/
cp /etc/boto.cfg ~/.aws/config
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once Ansible and boto are installed and configured you can clone example repository.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git clone https://github.com/darrylcauldwell/aws-ansible.git
cd aws-ansible
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Inside the repository is an example playbook.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cross-account-vpc-peering.yml 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;You&amp;rsquo;ll notice this playbook looks very similar to the one for local peering. The key differences are the addition of the profile parameter for the ec2_vpc and ec2_vpc_peer tasks, and the addition of account number hosting VPCs.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yml&#34; data-lang=&#34;yml&#34;&gt;---
- &lt;span style=&#34;color:#f92672&#34;&gt;hosts&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;localhost&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;connection&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;local&amp;#34;&lt;/span&gt;

    &lt;span style=&#34;color:#f92672&#34;&gt;tasks&lt;/span&gt;:
    - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;First VPC&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;ec2_vpc&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;state&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;present&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;cidr_block&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;10.0.0.0&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;/16&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;profile&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;843555617105&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;resource_tags&lt;/span&gt;: { &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Name&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;First VPC&amp;#34;&lt;/span&gt; }
        &lt;span style=&#34;color:#f92672&#34;&gt;subnets&lt;/span&gt;:
        - &lt;span style=&#34;color:#f92672&#34;&gt;cidr&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;10.0.1.0&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;/24&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;az&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;eu-west-1a&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;resource_tags&lt;/span&gt;: {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Location&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;SiteA&amp;#34;&lt;/span&gt;}
        - &lt;span style=&#34;color:#f92672&#34;&gt;cidr&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;10.0.2.0&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;/24&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;az&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;eu-west-1b&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;resource_tags&lt;/span&gt;: {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Location&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;SiteB&amp;#34;&lt;/span&gt;}
        - &lt;span style=&#34;color:#f92672&#34;&gt;cidr&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;10.0.3.0&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;/24&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;az&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;eu-west-1c&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;resource_tags&lt;/span&gt;: {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Location&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;SiteC&amp;#34;&lt;/span&gt;}
        &lt;span style=&#34;color:#f92672&#34;&gt;region&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;eu-west-1&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;wait&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;yes&amp;#34;&lt;/span&gt; 
    &lt;span style=&#34;color:#f92672&#34;&gt;register&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;first_vpc&lt;/span&gt;

    - &lt;span style=&#34;color:#f92672&#34;&gt;debug&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;msg=&amp;#34;{{ first_vpc }}&amp;#34; &lt;/span&gt;

    - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Second VPC&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;ec2_vpc&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;state&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;present&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;cidr_block&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;10.1.0.0&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;/16&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;profile&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;664710917345&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;resource_tags&lt;/span&gt;: { &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Name&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Second VPC&amp;#34;&lt;/span&gt; }
        &lt;span style=&#34;color:#f92672&#34;&gt;subnets&lt;/span&gt;:
        - &lt;span style=&#34;color:#f92672&#34;&gt;cidr&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;10.1.1.0&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;/24&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;az&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;eu-west-1a&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;resource_tags&lt;/span&gt;: {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Location&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;SiteA&amp;#34;&lt;/span&gt;}
        - &lt;span style=&#34;color:#f92672&#34;&gt;cidr&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;10.1.2.0&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;/24&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;az&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;eu-west-1b&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;resource_tags&lt;/span&gt;: {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Location&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;SiteB&amp;#34;&lt;/span&gt;}
        - &lt;span style=&#34;color:#f92672&#34;&gt;cidr&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;10.1.3.0&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;/24&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;az&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;eu-west-1c&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;resource_tags&lt;/span&gt;: {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Location&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;SiteC&amp;#34;&lt;/span&gt;}
        &lt;span style=&#34;color:#f92672&#34;&gt;region&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;eu-west-1&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;wait&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;yes&amp;#34;&lt;/span&gt; 
    &lt;span style=&#34;color:#f92672&#34;&gt;register&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;second_vpc&lt;/span&gt;

    - &lt;span style=&#34;color:#f92672&#34;&gt;debug&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;msg=&amp;#34;{{ second_vpc }}&amp;#34; &lt;/span&gt;

    - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Create local VPC peering connection&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;ec2_vpc_peer&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;profile&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;843555617105&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;region&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;eu-west-1&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;vpc_id&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{{ first_vpc.vpc_id }}&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;peer_vpc_id&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{{ second_vpc.vpc_id }}&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;peer_owner_id&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;664710917345&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;state&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;present&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;register&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;vpc_peer&lt;/span&gt;

    - &lt;span style=&#34;color:#f92672&#34;&gt;debug&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;msg=&amp;#34;{{ vpc_peer }}&amp;#34;&lt;/span&gt;

    - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Accept local VPC peering connection&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;ec2_vpc_peer&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;profile&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;664710917345&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;region&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;eu-west-1&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;peering_id&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{{ vpc_peer.peering_id }}&amp;#34;&lt;/span&gt; 
        &lt;span style=&#34;color:#f92672&#34;&gt;state&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;accept&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;register&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;accept_peer&lt;/span&gt;

    - &lt;span style=&#34;color:#f92672&#34;&gt;debug&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;msg=&amp;#34;{{ accept_peer }}&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;I&amp;rsquo;ve added debugging of output, if you run this&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;ansible-playbook aws-ansible/cross-account-vpc-peering.yml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You will see the two VPCs in different accounts and get created and then the peering configured between them.&lt;/p&gt;
&lt;h2 id=&#34;cross-account-vpc-peering-using-iam-assume-role-provider&#34;&gt;Cross Account VPC Peering Using IAM Assume Role Provider&lt;/h2&gt;
&lt;p&gt;It is Amazon best practise is to &lt;a href=&#34;http://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html#delegate-using-roles&#34;&gt;delegate access using roles instead of sharing credentials.&lt;/a&gt; You can define a role that specifies what permissions the IAM users in the other account are allowed, and from which AWS accounts the IAM users are allowed to assume the role. Up to now we&amp;rsquo;ve used IAM User and Access Keys to authenticate across multiple accounts, here we will look at configuring Ansible using AssumeRole.&lt;/p&gt;
&lt;p&gt;Unfortunatly ec2_vpc does not yet support boto3 and this is required to use AssumeRole, ec2_vpc_peer however does support this. What this means though is we need to configure boto2 config file with access key in both accounts.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;sudo vi /etc/boto.cfg

&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;profile 843555617105&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
aws_access_key_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &amp;lt;your_access_key_here&amp;gt;
aws_secret_access_key &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &amp;lt;your_secret_key_here&amp;gt;

&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;profile 664710917345&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
aws_access_key_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &amp;lt;your_access_key_here&amp;gt;
aws_secret_access_key &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &amp;lt;your_secret_key_here&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In order to configure boto3 to use AssumeRole we first, create an IAM User called AnsibleAdminUser in your first account. Then create an IAM Role your second account called &amp;lsquo;AnsibleAdministrator&amp;rsquo; for role type select &amp;lsquo;Role for Cross-Account Access \ Provide access between AWS accounts you own&amp;rsquo; then enter the Account ID of your first account and attach policy AdmistratorAccess. Once created view your new role in IAM and copy the Role ARN eg arn:aws:iam::664710917345:role/AnsibleAdministrator&lt;/p&gt;
&lt;p&gt;Configure boto3 credentials&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;mkdir ~/.aws
sudo vi ~/.aws/credentials 

&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;664710917345-AnsibleAdminUser&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
aws_access_key_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &amp;lt;your_access_key_here&amp;gt;
aws_secret_access_key &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &amp;lt;your_secret_key_here&amp;gt;

sudo vi ~/.aws/config

&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;profile 664710917345&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
aws_access_key_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &amp;lt;your_access_key_here&amp;gt;
aws_secret_access_key &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &amp;lt;your_secret_key_here&amp;gt;

&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;profile 843555617105&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; 
role_arn&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;arn:aws:iam::843555617105:role/AnsibleAdministrator
source_profile&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;664710917345-AnsibleAdminUser
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once the credentials files are completed we can clone the example git repo and run the playbook.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git clone https://github.com/darrylcauldwell/aws-ansible.git
ansible-playbook aws-ansible/cross-account-vpc-peering.yml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We should see the same behaviour where two VPCs are created and VPC Peering is established between them.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>How To Use AWS CloudFormation With Ansible</title>
      <link>https://darrylcauldwell.github.io/post/ansible-clouformation/</link>
      <pubDate>Wed, 09 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/ansible-clouformation/</guid>
      <description>
        
          &lt;p&gt;AWS CloudFormation gives developers and systems administrators an easy way to create and manage a collection of related AWS resources, provisioning and updating them in an orderly and predictable fashion. Ansible is a radically simple IT automation engine that automates cloud provisioning, configuration management, application deployment, intra-service orchestration, and many other IT needs. Ansible uses no agents and no additional custom security infrastructure, so it&amp;rsquo;s easy to deploy, it uses a very simple language which allows you to describe your automation jobs in a way that approaches plain English.&lt;/p&gt;
&lt;h2 id=&#34;install-ansible-for-aws-management&#34;&gt;Install Ansible For AWS Management&lt;/h2&gt;
&lt;p&gt;In order that Ansible can manage AWS services create an IAM Role named Ansible and assign it to the AdmistratorAccess policy, then create a RHEL7 EC2 instance with this IAM role attached. The Ansible AWS modules manages AWS via the API by use of the &lt;a href=&#34;http://boto.cloudhackers.com/&#34;&gt;Python boto library&lt;/a&gt; and locally installed AWSCLI. Once the RHEL instance is running connect and run the following commands to install Ansible and the boto and AWS CLI python library.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;sudo yum install wget -y
wget http://dl.fedoraproject.org/pub/epel/7/x86_64/e/epel-release-7-8.noarch.rpm
sudo rpm -ivh epel-release-7-8.noarch.rpm
sudo yum install ansible git python python-devel python-pip -y
sudo pip install boto awscli
sudo yum update -y
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;deploy-an-ec2-instance-using-ansible&#34;&gt;Deploy An EC2 Instance Using Ansible&lt;/h2&gt;
&lt;p&gt;Once installed we can test Ansible can communicate correctly with AWS by creating a security group and EC2 instance. I&amp;rsquo;ve prepared a short playbook for my AWS account, in order to use yourself modify the five variables at the top of the playbook.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;git clone https://github.com/darrylcauldwell/aws-ansible.git
ansible-playbook /home/ec2-user/aws-ansible/my-test-play.yml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;deploy-an-ec2-instance-using-cloudformation&#34;&gt;Deploy An EC2 Instance Using CloudFormation&lt;/h2&gt;
&lt;p&gt;Amazon provide various &lt;a href=&#34;http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cfn-sample-templates.html&#34;&gt;CloudFormation Sample Templates&lt;/a&gt;. In this example I&amp;rsquo;ll use the sample template EC2InstanceWithSecurityGroupSample: this creates an Amazon EC2 instance and a security group.&lt;/p&gt;
&lt;p&gt;I included the template file in the github repository with the example files in which we pulled in previous step. The sample template takes upto three parameters,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;KeyName : Name of an existing EC2 KeyPair to enable SSH access to the instance&lt;/li&gt;
&lt;li&gt;InstanceType (Optional) : The size of EC2 instance if not specified defaults to t2.small&lt;/li&gt;
&lt;li&gt;SSHLocation (Optional) : The range of IP addresses which is allowed to connect to SSH defaults to 0.0.0.0/0&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The example AWS provide requires a default region to be set on the AWS CLI, to do this use &lt;a href=&#34;http://docs.aws.amazon.com/cli/latest/userguide/cli-chap-getting-started.html&#34;&gt;AWS Configure&lt;/a&gt;. We can then ask CloudFormations to deploy the template and include the parameters we want.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;aws configure
aws cloudformation create-stack --stack-name startmyinstance --template-body file:///home/ec2-user/aws-ansible/EC2InstanceWithSecurityGroupSample.template --parameters  ParameterKey&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;KeyName,ParameterValue&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;MyEC2 ParameterKey&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;InstanceType,ParameterValue&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;t1.micro 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;deploy-an-ec2-instance-using-ansible--cloudformation&#34;&gt;Deploy An EC2 Instance Using Ansible &amp;amp; CloudFormation&lt;/h2&gt;
&lt;p&gt;Taking the scenrio one step further we&amp;rsquo;d like to drive the deployment of AWS infrastructure from Ansible therefore the parameters required by the CloudFormation templates we should use Ansible CloudFormation module and variables.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yml&#34; data-lang=&#34;yml&#34;&gt;---
- &lt;span style=&#34;color:#f92672&#34;&gt;hosts&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;localhost&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;connection&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;local&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;gather_facts&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;false&lt;/span&gt;

&lt;span style=&#34;color:#f92672&#34;&gt;vars&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;KeyName&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;MyEC2&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;InstanceType&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;t2.micro&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;SSHLocation&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;0.0.0.0/0&amp;#34;&lt;/span&gt;

&lt;span style=&#34;color:#f92672&#34;&gt;tasks&lt;/span&gt;:
    - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Run my CloudFormation stack&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;cloudformation&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;stack_name&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;MyEC2Stack&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;region&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;eu-west-1&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;state&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;present&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;template&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;EC2InstanceWithSecurityGroupSample.template&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;template_parameters&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;KeyName&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{{ KeyName }}&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;InstanceType&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{{ InstanceType }}&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;SSHLocation&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{{ SSHLocation }}&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;tags&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;tool&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;ansible&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;env&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;test&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;register&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my_ec2_stack&lt;/span&gt;

    - &lt;span style=&#34;color:#f92672&#34;&gt;debug&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;msg=&amp;#34;{{ my_ec2_stack.stack_resources}}&amp;#34;&lt;/span&gt;
    - &lt;span style=&#34;color:#f92672&#34;&gt;debug&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;msg=&amp;#34;{{ my_ec2_stack.stack_outputs}}&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;I included the example Ansible playbook above in the github repository with the example files in which we pulled in previous step.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;ansible-playbook /home/ec2-user/aws-ansible/my-other-test-play.yml

PLAY &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;localhost&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; ***************************************************************
TASK &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;Run my CloudFormation stack&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; *********************************************
changed: &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;localhost&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
TASK &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;debug&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; *******************************************************************
ok: &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;localhost&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;msg&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;last_updated_time&amp;#34;&lt;/span&gt;: null, 
            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;logical_resource_id&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;EC2Instance&amp;#34;&lt;/span&gt;, 
            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;physical_resource_id&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;i-040228bd8fcb5c81a&amp;#34;&lt;/span&gt;, 
            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;resource_type&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;AWS::EC2::Instance&amp;#34;&lt;/span&gt;, 
            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;status&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;CREATE_COMPLETE&amp;#34;&lt;/span&gt;, 
            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;status_reason&amp;#34;&lt;/span&gt;: null
        &lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;, 
        &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;last_updated_time&amp;#34;&lt;/span&gt;: null, 
            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;logical_resource_id&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;InstanceSecurityGroup&amp;#34;&lt;/span&gt;, 
            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;physical_resource_id&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;MyEC2Stack-InstanceSecurityGroup-3YAAZV42DEPF&amp;#34;&lt;/span&gt;, 
            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;resource_type&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;AWS::EC2::SecurityGroup&amp;#34;&lt;/span&gt;, 
            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;status&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;CREATE_COMPLETE&amp;#34;&lt;/span&gt;, 
            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;status_reason&amp;#34;&lt;/span&gt;: null
        &lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
TASK &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;debug&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; *******************************************************************
ok: &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;localhost&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;msg&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;AZ&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;eu-west-1a&amp;#34;&lt;/span&gt;, 
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;InstanceId&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;i-040228bd8fcb5c81a&amp;#34;&lt;/span&gt;, 
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;PublicDNS&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;ec2-54-171-78-90.eu-west-1.compute.amazonaws.com&amp;#34;&lt;/span&gt;, 
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;PublicIP&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;54.171.78.90&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
PLAY RECAP *********************************************************************
localhost                  : ok&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;    changed&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;    unreachable&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;    failed&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;   
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You will see that if we run this it creates the stack with parameters we defined as variables.  Notice at the end of the first task we register the output as an object. For the example we output this to the screen by using a debug task, and it includes the EC2 instance details. You could just as easily use this to continue configuration of the EC2 instance guest operating system.&lt;/p&gt;
&lt;p&gt;The Ansible playbook is idempotent so if you re-run the playbook whith state attribute as &amp;lsquo;present&amp;rsquo; it checks it is in place and makes no changes. If you would like to remove the CloudFormation Stack then you can change the state attribute to &amp;lsquo;absent&amp;rsquo; and when you re-run the playbook the CloudFormation Stack will be removed.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Docker Networking</title>
      <link>https://darrylcauldwell.github.io/post/docker-net/</link>
      <pubDate>Tue, 08 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/docker-net/</guid>
      <description>
        
          &lt;p&gt;Hear I describe Docker networking from the very basic through to extending it by pluggin in alternative drivers. In order to follow along with this post you will require Docker capability on your laptop to do this follow &lt;a href=&#34;https://docs.docker.com/engine/installation/&#34;&gt;these instructions&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Mostly will be using &lt;a href=&#34;https://www.alpinelinux.org/&#34;&gt;Alpine Linux&lt;/a&gt; as it is very small so downloads quickly and doesn&amp;rsquo;t consume many resources.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;docker pull alpine
docker images
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Output from images command should list all images you hold locally including Alpine Linux&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;REPOSITORY  TAG     IMAGE ID        CREATED         SIZE
alpine      latest  baa5d63471ea    2 weeks ago     4.803 MB
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Once we have the Alpine Linux image local we can then launch it,  if we do this with interactive and simulated TTY options we get presented with the Linux shell&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;docker run --interactive --tty alpine sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;From here we can view the docker containers view of the networking,  we see here it has allocated an rfc1918 address and that it can ping outbound.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;/ &lt;span style=&#34;color:#75715e&#34;&gt;# ip addr&lt;/span&gt;
1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu &lt;span style=&#34;color:#ae81ff&#34;&gt;65536&lt;/span&gt; qdisc noqueue state UNKNOWN qlen &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
    valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
    valid_lft forever preferred_lft forever
16: eth0@if17: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&amp;gt; mtu &lt;span style=&#34;color:#ae81ff&#34;&gt;1500&lt;/span&gt; qdisc noqueue state UP 
    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.2/16 scope global eth0
    valid_lft forever preferred_lft forever
    inet6 fe80::42:acff:fe11:2/64 scope link 
    valid_lft forever preferred_lft forever
/ &lt;span style=&#34;color:#75715e&#34;&gt;# ping 8.8.8.8&lt;/span&gt;
PING 8.8.8.8 &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;8.8.8.8&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;56&lt;/span&gt; data bytes
&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt; bytes from 8.8.8.8: seq&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; ttl&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;61&lt;/span&gt; time&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;43.770 ms
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To detach the tty without exiting the shell, use the escape sequence Ctrl+p + Ctrl+q more details &lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/attach/&#34;&gt;here&lt;/a&gt;.  Once exited you should still be able to see the container in the running state.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;docker ps -a

CONTAINER ID    IMAGE   COMMAND     CREATED             STATUS          PORTS   NAMES
5099910cc9d0    alpine  &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;sh&amp;#34;&lt;/span&gt;        &lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt; minutes ago       Up &lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt; minutes            elegant_torvalds
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If you need to get back to the running shell you can use either the container id or the name, these two commands are equivelant.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;docker attach 5099910cc9d0
docker attach elegant_torvalds
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;So now if we start a second instance of Apline Linux in container&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;docker run --interactive --tty alpine sh
docker ps -a

CONTAINER ID    IMAGE   COMMAND     CREATED             STATUS          PORTS   NAMES
e96c3e67410c    alpine  &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;sh&amp;#34;&lt;/span&gt;        &lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt; seconds ago       Up &lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt; seconds            suspicious_pare
5099910cc9d0    alpine  &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;sh&amp;#34;&lt;/span&gt;        &lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt; minutes ago       Up &lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt; minutes            elegant_torvalds
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We can attach and detach to each,  we notice that the second instance has been assigned next IP 172.17.0.3 and that it can ping the first instance 172.17.0.2.&lt;/p&gt;
&lt;p&gt;If we then detach the containers and view what docker networking shows, we see that Docker uses the concept of Drivers and that we are using the default bridge driver.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;docker network ls

NETWORK ID          NAME                DRIVER
64481f7454d1        bridge              bridge              
a8f3b81d9991        host                host                
6ccbf074e447        none                null         
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We can explore the properties of the bridge network a little more, and see the IP addresses it has issued to the containers.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;docker network inspect bridge

&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Name&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;bridge&amp;#34;&lt;/span&gt;,
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Id&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;64481f7454d138e43558359d1e41bb96564769bfcccc547b42b2a37b873c3a73&amp;#34;&lt;/span&gt;,
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Scope&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;local&amp;#34;&lt;/span&gt;,
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Driver&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;bridge&amp;#34;&lt;/span&gt;,
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;EnableIPv6&amp;#34;&lt;/span&gt;: false,
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;IPAM&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Driver&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;default&amp;#34;&lt;/span&gt;,
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Options&amp;#34;&lt;/span&gt;: null,
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Config&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
                &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Subnet&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;172.17.0.0/16&amp;#34;&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;,
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Internal&amp;#34;&lt;/span&gt;: false,
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Containers&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#f92672&#34;&gt;{}&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;,
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Options&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;com.docker.network.bridge.default_bridge&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;true&amp;#34;&lt;/span&gt;,
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;com.docker.network.bridge.enable_icc&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;true&amp;#34;&lt;/span&gt;,
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;com.docker.network.bridge.enable_ip_masquerade&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;true&amp;#34;&lt;/span&gt;,
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;com.docker.network.bridge.host_binding_ipv4&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;0.0.0.0&amp;#34;&lt;/span&gt;,
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;com.docker.network.bridge.name&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;docker0&amp;#34;&lt;/span&gt;,
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;com.docker.network.driver.mtu&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;1500&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;,
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Labels&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#f92672&#34;&gt;{}&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;So we can see that docker created a shared bridge, but what happens if you want to isolate containers on the same host well we can create a different bridge network we see it allocates the 172.18.0.0/16 CIDR.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;docker network create --driver bridge my-bridge-network
docker network inspect my-bridge-network

&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Name&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;my-bridge-network&amp;#34;&lt;/span&gt;,
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Id&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;5fec8c172a6c323a616c54938815b42d6baab04e816d7a5bb9113a0e914c52a4&amp;#34;&lt;/span&gt;,
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Scope&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;local&amp;#34;&lt;/span&gt;,
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Driver&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;bridge&amp;#34;&lt;/span&gt;,
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;EnableIPv6&amp;#34;&lt;/span&gt;: false,
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;IPAM&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Driver&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;default&amp;#34;&lt;/span&gt;,
            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Options&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#f92672&#34;&gt;{}&lt;/span&gt;,
            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Config&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;
                &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
                    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Subnet&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;172.18.0.0/16&amp;#34;&lt;/span&gt;,
                    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Gateway&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;172.18.0.1/16&amp;#34;&lt;/span&gt;
                &lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;,
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Internal&amp;#34;&lt;/span&gt;: false,
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Containers&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#f92672&#34;&gt;{}&lt;/span&gt;,
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Options&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#f92672&#34;&gt;{}&lt;/span&gt;,
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Labels&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#f92672&#34;&gt;{}&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;So if we create a new container now on this new network, we see it gets IP address on 172.18.0.0/16 and it cannot ping containers on 172.17.0.0/16.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;docker run --interactive --tty --net&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;my-bridge-network alpine sh
/ &lt;span style=&#34;color:#75715e&#34;&gt;# ipaddr&lt;/span&gt;
1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu &lt;span style=&#34;color:#ae81ff&#34;&gt;65536&lt;/span&gt; qdisc noqueue state UNKNOWN qlen &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
    valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
    valid_lft forever preferred_lft forever
25: eth0@if26: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&amp;gt; mtu &lt;span style=&#34;color:#ae81ff&#34;&gt;1500&lt;/span&gt; qdisc noqueue state UP 
    link/ether 02:42:ac:12:00:02 brd ff:ff:ff:ff:ff:ff
    inet 172.18.0.2/16 scope global eth0
    valid_lft forever preferred_lft forever
    inet6 fe80::42:acff:fe12:2/64 scope link 
    valid_lft forever preferred_lft forever
/ &lt;span style=&#34;color:#75715e&#34;&gt;# ping 172.17.0.3&lt;/span&gt;
PING 172.17.0.3 &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;172.17.0.3&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;56&lt;/span&gt; data bytes
^C
--- 172.17.0.3 ping statistics ---
&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt; packets transmitted, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; packets received, 100% packet loss
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We have focussed on the shipped bridge driver, however since &lt;a href=&#34;https://github.com/docker/libnetwork&#34;&gt;LibNetwork project&lt;/a&gt; got integrated into docker the driver became plugable. Some of the Docker networking ecosystems, include Weave, Nuage, Cisco, Microsoft, Calico, Midokura, and VMware.&lt;/p&gt;
&lt;p&gt;Upto now we have looked at networking between containers on the same host by bridging to the network interface card. You will probably want to extend the layer 2 networking capacibility so containers on different hosts can communicate. To do this we would use &lt;a href=&#34;https://docs.docker.com/swarm/networking/&#34;&gt;Docker Swarm&lt;/a&gt; which includes the multi-host networking feature and allows the creation of custom container networks which span multiple Docker hosts. By default it does this by use of the &amp;lsquo;overlay&amp;rsquo; network driver&lt;/p&gt;
&lt;p&gt;An interesting option to use as a Docker networking driver is &lt;a href=&#34;https://github.com/projectcalico/calico-containers&#34;&gt;Project Calico for Containers&lt;/a&gt; as the overlay networking expands across more and more hosts it can experience performance issues. Project Calico aims to over come this issue but allow container connectivity across hosts by having each container route directly at Layer 3 rather than Layer 2.  It does this by having a calico-node container installed and running on each host which manages the network routing etc.&lt;/p&gt;
&lt;p&gt;As in my previous post about &lt;a href=&#34;https://darrylcauldwell.github.io/install-vic/&#34;&gt;vSphere Integrated Containers&lt;/a&gt; its interesting to see VMware integrating with Docker and I&amp;rsquo;d expect it won&amp;rsquo;t be too long until we discover how NSX will plug into Docker Networking.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Migrate VMware VMs to AWS EC2 using Server Migration Services (SMS)</title>
      <link>https://darrylcauldwell.github.io/post/aws-sms/</link>
      <pubDate>Tue, 01 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/aws-sms/</guid>
      <description>
        
          &lt;p&gt;The &lt;a href=&#34;https://aws.amazon.com/server-migration-service/&#34;&gt;AWS Server Migration Service&lt;/a&gt; simplifies and streamlines the process of migrating existing virtualized applications to Amazon EC2. AWS SMS allows you to automate, schedule, and track incremental replications of live server volumes, making it easier for you to coordinate large-scale server migrations. Presently this only supports migrating from VMware with support for other hypervisors and physical servers is coming soon.&lt;/p&gt;
&lt;p&gt;Amazon provide a virtual appliance (OVA) which can be imported into your existing vCenter, once booted this is configured to connect to vCenter and your AWS account. Once configured this appliance is controlled by the AWS SMS service to take a snapshot of VMware virtual machines and facilitate the upload of the snapshot copy into an S3 bucket.  Once the VMware snapshot is uploaded into the S3 bucket the SMS service then updates the disk format and then prepare this as an AMI.&lt;/p&gt;
&lt;p&gt;The size of virtual machine images is such that the upload process might well take a long time, and during this time you might well want to keep the virtual machine running. The changes made during this time therefore will not be reflected in the initial AMI created. As such AWS SMS offers the option of running the replication job again, but rather than the job creating a full new virtual machine it takes an incremental snapshot.  Once the upload of this is completed the SMS service processes the initial upload with the incremental to form a new AMI.&lt;/p&gt;
&lt;h2 id=&#34;how-to-configure-server-migration-services-sms&#34;&gt;How To: Configure Server Migration Services (SMS)&lt;/h2&gt;
&lt;p&gt;The process is pretty straight forwards,  first task is to download the AWS Server Migration Connector from &lt;a href=&#34;https://s3.amazonaws.com/sms-connector/AWS-SMS-Connector.ova&#34;&gt;S3&lt;/a&gt;, then deploy the OVA.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/aws-sms-ova-deploy.jpeg&#34; alt=&#34;Deploy OVF Template&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/aws-sms-ova-deploy-final.jpeg&#34; alt=&#34;Deploy OVF Ready to complete&#34;&gt;&lt;/p&gt;
&lt;p&gt;The SMS Connector needst to connect to your AWS account and therefore we need to create a user with the &amp;ldquo;ServerMigrationConnector&amp;rdquo; role attached.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/aws-sms-account.jpeg&#34; alt=&#34;MigrationUser Role Mapping&#34;&gt;&lt;/p&gt;
&lt;p&gt;Once the SMS connector appliance is deployed connect to the web UI by opening the browser to https://dhcp-addr&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/aws-sms-cfg-wiz.jpeg&#34; alt=&#34;AWS Server Migration Service Splash&#34;&gt;&lt;/p&gt;
&lt;p&gt;Work through the wizard to configure all,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Step 1: License Agreement&lt;/li&gt;
&lt;li&gt;Step 2: Create a Password&lt;/li&gt;
&lt;li&gt;Step 3: Network Info&lt;/li&gt;
&lt;li&gt;Step 4: Log Uploads and Upgrades&lt;/li&gt;
&lt;li&gt;Step 5: Server Migration Service&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Once configuration is complete the connection to AWS and vCenter should show good in the connector configuration.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/aws-sms-cfg-complete.jpeg&#34; alt=&#34;AWS Server Migration Service Configuration Complete&#34;&gt;&lt;/p&gt;
&lt;p&gt;If we then connect to AWS we can see the connector.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/aws-sms-cfg-complete-console.jpeg&#34; alt=&#34;AWS Server Migration Service Complete Console&#34;&gt;&lt;/p&gt;
&lt;p&gt;In order to create the first replication job we need to import the list of vCenter VMs by using the &amp;lsquo;Import server catalog&amp;rsquo; function.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/aws-sms-import.jpeg&#34; alt=&#34;AWS Server Migration Service Import Server Catalog&#34;&gt;&lt;/p&gt;
&lt;p&gt;There is not a default role supplied which the SMS services can use to form AMI&amp;rsquo;s from the uploaded VMware snapshots. To do this download this file &lt;a href=&#34;https://darrylcauldwell.github.io/attachments/trust-policy.json&#34;&gt;trust-policy.json&lt;/a&gt; and this file &lt;a href=&#34;https://darrylcauldwell.github.io/attachments/role-policy.json&#34;&gt;role-policy.json&lt;/a&gt;. Then at a command prompt, go to the directory where you stored the two JSON files, and run the following commands to create the SMS service role:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;aws iam create-role --role-name sms --assume-role-policy-document file://trust-policy.json
aws iam put-role-policy --role-name sms --policy-name sms --policy-document file://role-policy.json
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;how-to-migrate-virtual-machine&#34;&gt;How To: Migrate Virtual Machine&lt;/h2&gt;
&lt;p&gt;Once the vCenter Server Inventory is imported to AWS SMS, and the role is created we can create our first replication job by using the SMS service wizard.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Step 1: Select the servers&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Select the virtual machine(s) you would like to migrate.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Step 2: Configure server-specific settings&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Select the license type for the guest operating system of the virtual server(s) being migrated.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Step 3: Configure replication job settings&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Schedule the replication job, assuming you used the two files about to create the SMS role for IAM service role leave as default &amp;lsquo;sms&amp;rsquo;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Step 4: Review&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Once the job schedules,  the first task the job performs is to create a VMware snapshot, it&amp;rsquo;s important to remember to have enough disk capacity to hold snapshots.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/aws-sms-seed-snapshot.jpeg&#34; alt=&#34;AWS Server Migration Service Seeding Snapshot&#34;&gt;&lt;/p&gt;
&lt;p&gt;The AWS console doesn&amp;rsquo;t update very well, so its best to view the progress via the AWS CLI. First list all of the replication jobs and from this you can find the JobID then to make it easier to read target the output to the specific JobID.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;aws sms get-replication-jobs  
aws sms get-replication-jobs --replication-job-id sms-job-2ca54045  
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;A replication job refers to the server being migrated,  as we mentioned earlier multiple replications can occur for example the initial seed and an incremental.  Therefore within a replication job there might be various replication runs.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;aws sms get-replication-runs --replication-job-id sms-job-2ca54045  
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In the following example we can see this has three runs in the runlist, the initial seed which has completed, an incrememental which has completed, it also has a pending job as I had left the default replication job values to schedule a daily incremental.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/aws-sms-repl-runs.jpeg&#34; alt=&#34;AWS Server Migration Service Replication Runs&#34;&gt;&lt;/p&gt;
&lt;p&gt;When a job is running you would see the state roll through the various stages&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Pending&lt;/li&gt;
&lt;li&gt;Active&lt;/li&gt;
&lt;li&gt;Complete&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;While the job state is in the Active state the statusMessage rolls through the various stages&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Uploading&lt;/li&gt;
&lt;li&gt;Converting&lt;/li&gt;
&lt;li&gt;Preparing&lt;/li&gt;
&lt;li&gt;Completed&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Each run forms a new AMI, each newly created AMIs can then be launched in ec2, so you can for example start from the initial seed replication, one containing all the incrementals or anywhere in between.&lt;/p&gt;
&lt;h2 id=&#34;offical-sms-documentation-links&#34;&gt;Offical SMS Documentation Links&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/server-migration-service/&#34;&gt;Marketing Page&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/blogs/aws/new-aws-server-migration-service/&#34;&gt;AWS Blog&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://docs.aws.amazon.com/ServerMigration/latest/userguide/server-migration.html&#34;&gt;Tech Documentation&lt;/a&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>AWS Certified Solutions Architect Professional - Study Link O&#39;Rama</title>
      <link>https://darrylcauldwell.github.io/post/aws-sa-study/</link>
      <pubDate>Wed, 19 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/aws-sa-study/</guid>
      <description>
        
          &lt;p&gt;While studying to become a &lt;a href=&#34;https://aws.amazon.com/certification/certified-solutions-architect-professional/&#34;&gt;AWS Certified Solutions Architect - Professional&lt;/a&gt; I have been passed and found lots of resources, in this post I am trying to store the links which are useful. I started my journey with the &lt;a href=&#34;https://d0.awsstatic.com/training-and-certification/docs-sa-pro/AWS_certified_solutions_architect_professional_blueprint.pdf&#34;&gt;AWS exam blueprint&lt;/a&gt;. This is I believe the perfect place to start to study as it describes when exactly is covered by the exam and the weighted value of each skill being measured. I&amp;rsquo;ve then categorised the many study links I have been passed under each knowledge domain.&lt;/p&gt;
&lt;p&gt;After each knowledge domain is covered I&amp;rsquo;ve placed links to the base knowledge covered in Associate level exams.  Finally there is a section of the blog posts from people who have taken the exam and there experience of the process.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PL_RVC-cMNyYTz8zlxq117O1bfji-knooI&#34;&gt;A series of video&amp;rsquo;s for AWS Solutions Architecture Professional training.&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;high-availability-and-business-continuity-15&#34;&gt;High Availability and Business Continuity (15%)&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://d0.awsstatic.com/whitepapers/Storage/Backup_and_Recovery_Approaches_Using_AWS.pdf&#34;&gt;Backup and Recovery Approaches Using AWS&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://d0.awsstatic.com/whitepapers/best-practices-for-backup-and-recovery-on-prem-to-aws.pdf&#34;&gt;Enterprise Backup and Recovery&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://d0.awsstatic.com/whitepapers/implementing-windows-file-server-disaster-recovery.pdf&#34;&gt;Using Amazon Web Services and DFS Replication for Disaster Recovery of File Servers&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://d0.awsstatic.com/whitepapers/Backup_Archive_and_Restore_Approaches_Using_AWS.pdf&#34;&gt;Backup and Recovery Approaches Using AWS&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://d0.awsstatic.com/whitepapers/aws-disaster-recovery.pdf&#34;&gt;Using AWS for Disaster Recovery&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://d0.awsstatic.com/whitepapers/aws-migrate-resources-to-new-region.pdf&#34;&gt;Migrating AWS Resources to a New Region&lt;/a&gt;
&lt;a href=&#34;http://docs.aws.amazon.com/opsworks/latest/userguide/workinginstances-autohealing.html&#34;&gt;Using OpsWorks Auto Healing&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/NoSwvJ18tMM&#34;&gt;How to Enable Disaster Recovery and Migrate to AWS (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/bXrGUlgbl-s&#34;&gt;Deploying a Disaster Recovery Site on AWS (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/5hCAwEQpWNc&#34;&gt;Rapid Recovery Solution for Disaster Recovery (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/xA97GUzLAls&#34;&gt;Multi-Region Application Using Amazon VPC (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/XU6KDBQiwEM&#34;&gt;Deploy High Availability &amp;amp; Disaster Recovery Architectures with AWS (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/zYI4Gx0D54U&#34;&gt;Introducing AWS Solutions for Backup and Archiving (Video)&lt;/a&gt;
&lt;a href=&#34;https://youtu.be/VmjDfz-MIZE&#34;&gt;AWS Storage Gateway: Secure, Cost-Effective Backup &amp;amp; Archive (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;http://www.zerto.com/disaster-recovery-for-vmware-hyper-v-and-aws-that-actually-works/&#34;&gt;Disaster Recovery for VMware, Hyper-V, and AWS&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;costing-6&#34;&gt;Costing (6%)&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://d0.awsstatic.com/whitepapers/aws_pricing_overview.pdf&#34;&gt;How AWS Pricing Works&lt;/a&gt;
&lt;a href=&#34;https://youtu.be/kId90Q7b6kY&#34;&gt;Cost Optimisation on AWS (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/i1Uq8_gt2p4&#34;&gt;Cost Optimization at Scale (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/R_0BQIeRNHw&#34;&gt;The Science of Saving with AWS Reserved Instances (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/SG1DsYgeGEk&#34;&gt;Running Lean Architectures: Optimizing for Cost Efficiency (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/LZwlkqERv2g&#34;&gt;Cloud-Native Cost Optimization (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/rnL9Raf5shM&#34;&gt;Strategies to Quantify TCO and Optimize Costs using AWS (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/lVOw1u_UaDE&#34;&gt;EC2 Dedicated Hosts: Save Money, Use Your Software Licenses (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://connect.awswebcasts.com/p2lkwv8o9rs/&#34;&gt;Save Up to 90% on your Amazon EC2 Bill with Spot Instances&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.cloudability.com/aws-101-reserved-instances/&#34;&gt;Reserved Instances 101&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;http://visit.cloudability.com/ReservedInstanceGuide&#34;&gt;Complete Guide to AWS Reserved Instances&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/fLex8Qgzvpk&#34;&gt;Advanced Strategies for AWS Cost Allocation with Tags and Linked Accounts (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;http://www.rightscale.com/webinars/lp/10-ways-optimize-public-private-cloud-costs-webinar&#34;&gt;10 Ways to Optimize Public and Private Cloud Costs&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://support.cloudability.com/hc/en-us/articles/205014127-Webinar-Mastering-the-fundamentals-of-AWS-cost-management&#34;&gt;Mastering the fundamentals of AWS cost management&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.cloudability.com/aws-enterprise-cost-management-webinar/&#34;&gt;Managing enterprise AWS costs at scale&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://support.cloudability.com/hc/en-us/articles/205034237-Webinar-Using-Cloudability-to-reduce-AWS-costs&#34;&gt;Using Cloudability to reduce AWS costs&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;deployment-management-10&#34;&gt;Deployment Management (10%)&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;http://d0.awsstatic.com/whitepapers/overview-of-deployment-options-on-aws.pdf&#34;&gt;Deployment Options on AWS&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://d0.awsstatic.com/whitepapers/managing-multi-tiered-web-applications-with-opsworks.pdf&#34;&gt;Managing Multi-Tiered Applications with AWS OpsWorks&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://d0.awsstatic.com/whitepapers/overview-of-deployment-options-on-aws.pdf&#34;&gt;Overview of Deployment Options on AWS&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://d0.awsstatic.com/whitepapers/managing-multi-tiered-web-applications-with-opsworks.pdf&#34;&gt;Managing Multi-Tiered Web Applications with OpsWorks&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://d0.awsstatic.com/whitepapers/managing-your-aws-infrastructure-at-scale.pdf&#34;&gt;Managing your AWS Infrastructure at Scale&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://d0.awsstatic.com/whitepapers/AWS_DevOps.pdf&#34;&gt;Introduction to DevOps on AWS&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/WL2xSMVXy5w&#34;&gt;Infrastructure as Code (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/1QCXABOIcuc&#34;&gt;Managing Your Infrastructure as Code (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/-0ELfN-kb7g&#34;&gt;Zero to Sixty: AWS CloudFormation (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/6R44BADNJA8&#34;&gt;CloudFormation Masterclass (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/Wk-tOPicq78&#34;&gt;Using AWS CloudFormation for Deployment and Management at Scale (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/fVMlxJJNmyA&#34;&gt;CloudFormation Best Practices (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/ZhGMaw67Yu0&#34;&gt;CloudFormation under the Hood (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/WNLIsqjkvu8&#34;&gt;Deploy, Manage, and Scale Your Apps with OpsWorks and Elastic Beanstalk (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/A4NSyUbAEkw&#34;&gt;CodeDeploy: Automating Your Software Deployments (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/5xlqk9bFkYM&#34;&gt;Introducing AWS OpsWorks (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/AQWl5jLtsTc&#34;&gt;Getting Started with AWS OpsWorks (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/WxSu015Zgak&#34;&gt;AWS OpsWorks Under the Hood (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/OJVLYPo2T4Y&#34;&gt;Going Zero to Sixty with AWS Elastic Beanstalk (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/nkj0GXgaRv8&#34;&gt;Scaling Your Web Applications with AWS Elastic Beanstalk (Video)&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;network-design-10&#34;&gt;Network Design (10%)&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://d0.awsstatic.com/whitepapers/aws-amazon-vpc-connectivity-options.pdf&#34;&gt;Amazon VPC Network Connectivity Options&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/5_bQ6Dgk6k8&#34;&gt;VPC Fundamentals and Connectivity Options (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/SMvom9QjkPk&#34;&gt;Deep Dive: AWS Direct Connect and VPNs (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/ykmqjgLdmL4&#34;&gt;From One to Many: Evolving VPC Design (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/3qln2u1Vr2E&#34;&gt;Another Day, Another Billion Packets (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/DVywbZdzW4c&#34;&gt;New Capabilities for Amazon Virtual Private Cloud (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/EqVpsnAen5I&#34;&gt;Build a Remote Access VPN Solution on AWS (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/f9y-T7mQVxs&#34;&gt;Amazon Route 53 Deep Dive: Delivering Resiliency, Minimizing Latency (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/XXUYbdbCb6Q&#34;&gt;Consolidating DNS Data in the Cloud with Amazon Route 53 (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/MKn_PQtRcl8&#34;&gt;Implementing Microsoft DirectAccess and NAT in the AWS Cloud (Video)&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;data-storage-15&#34;&gt;Data Storage (15%)&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=gUYa7RzrNhM&#34;&gt;Maximizing EC2 and EBS Performance (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;http://docs.aws.amazon.com/AmazonS3/latest/dev/UsingMFADelete.html&#34;&gt;S3 MFA Delete&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://d0.awsstatic.com/whitepapers/Big_Data_Analytics_Options_on_AWS.pdf&#34;&gt;Big Data Analytics Options on AWS&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://d0.awsstatic.com/whitepapers/AWS%20Storage%20Services%20Whitepaper-v9.pdf&#34;&gt;Cloud Storage Services Overview&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://d0.awsstatic.com/whitepapers/rdbms-in-the-cloud-sql-server-on-aws.pdf&#34;&gt;RDBMS in the Cloud: Deploying SQL Server on AWS&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/Z5vNK6U2HKA&#34;&gt;Understand AWS Storage Options (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/3HDQsW_r1DM&#34;&gt;State of the Union: AWS Storage Services (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/VC0k-noNwOU&#34;&gt;S3 Masterclass (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/OuyUbvtgfDk&#34;&gt;EBS Deep Dive (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/2wKgha8CZ_w&#34;&gt;Amazon EBS: Designing for Performance (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/OvoTPdm9cck&#34;&gt;Storage Management &amp;amp; Backup Using Amazon S3 &amp;amp; Amazon Glacier (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/PmPriuFEz1k&#34;&gt;How Electronic Arts, State of Texas, &amp;amp; H3 Biomedicine Use AWS (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://connect.awswebcasts.com/p1fr4f2iitu/&#34;&gt;Amazon S3 Deep Dive and Best Practices (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/1TvJCLl9NNg&#34;&gt;Amazon S3 Deep Dive and Best Practices (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/P0pKdy_Y0CM&#34;&gt;New Storage Class for Amazon S3: Standard-Infrequent Access (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/eKyS9rvbj40&#34;&gt;Intro to AWS: Database Services (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/eHg8LD5KNC0&#34;&gt;Amazon RDS for MySQL: Best Practices (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/AtASjS0hVDA&#34;&gt;Best Practices: SQL Server on Amazon RDS and EC2 (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/WnFYoiRqEHw&#34;&gt;A Technical Introduction to Amazon Elastic MapReduce (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/zc1_Rfb_txQ&#34;&gt;EMR Masterclass (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/4HseALaLllc&#34;&gt;EMR Deep Dive and Best Practices (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/lMRVg2f380Y&#34;&gt;EFS Update (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/tDqLwzQEOmM&#34;&gt;From Zero to NoSQL Hero: Amazon DynamoDB Tutorial (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/ggDIat_FZtA&#34;&gt;Amazon DynamoDB Deep Dive (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/VuKu23oZp9Q&#34;&gt;Deep Dive: Amazon DynamoDB (Video)&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;security-19&#34;&gt;Security (19%)&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://d0.awsstatic.com/whitepapers/DDoS_White_Paper_June2015.pdf&#34;&gt;AWS Best Practises for DDoS Resiliency&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://d0.awsstatic.com/whitepapers/aws-securing-data-at-rest-with-encryption.pdf&#34;&gt;Securing Data at Rest with Encryption&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;http://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html&#34;&gt;IAM Best Practise&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://aws.amazon.com/blogs/security/enabling-federation-to-aws-using-windows-active-directory-adfs-and-saml-2-0/&#34;&gt;SAML Federation with ADFS and AWS&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;http://aws.amazon.com/code/1288653099190193&#34;&gt;Identity Broker Sample For Active Directory&lt;/a&gt;
&lt;a href=&#34;https://web-identity-federation-playground.s3.amazonaws.com/index.html&#34;&gt;IAM Federation Playground&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://docs.aws.amazon.com/IAM/latest/UserGuide/tutorial_cross-account-with-roles.html&#34;&gt;Delegate Access Across AWS Accounts Using IAM Roles&lt;/a&gt;
&lt;a href=&#34;https://d0.awsstatic.com/whitepapers/aws-security-best-practices.pdf&#34;&gt;AWS Security Best Practices&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://aws.amazon.com/training/course-descriptions/security-fundamentals/&#34;&gt;Amazon Web Services Security Fundamentals&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://d0.awsstatic.com/whitepapers/Security/Intro_to_AWS_Security.pdf&#34;&gt;Introduction to AWS Security&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://d0.awsstatic.com/whitepapers/Security/AWS%20Security%20Whitepaper.pdf&#34;&gt;Overview of Security Processes&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://d0.awsstatic.com/whitepapers/compliance/AWS_Risk_and_Compliance_Whitepaper.pdf&#34;&gt;AWS Risk and Compliance&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://d0.awsstatic.com/whitepapers/DDoS_White_Paper_June2015.pdf&#34;&gt;AWS DDoS Whitepaper&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://d0.awsstatic.com/whitepapers/aws-whitepaper-single-sign-on-integrating-aws-open-ldap-and-shibboleth.pdf&#34;&gt;Single Sign-On: Integrating AWS, OpenLDAP, and Shibboleth&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://d0.awsstatic.com/whitepapers/AWS_Securing_Data_at_Rest_with_Encryption.pdf&#34;&gt;Securing Data at Rest with Encryption&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://d0.awsstatic.com/whitepapers/compliance/AWS_Security_at_Scale_Logging_in_AWS_Whitepaper.pdf&#34;&gt;Security at Scale: Logging in AWS&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers.html&#34;&gt;Identity Providers and Federation&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/yVWHNJel7Qs&#34;&gt;Understanding The AWS Security Model (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/suOObEz_2Fc&#34;&gt;Getting Started with AWS Identity and Access Management (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/_wiGpBQGCjU&#34;&gt;IAM Best Practices to Live By (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/Du478i9O_mc&#34;&gt;How to Become an IAM Policy Ninja in 60 Minutes or Less (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/0WI5sirOvco&#34;&gt;Mastering Access Control Policies (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/rXPyGDWKHIo&#34;&gt;Security Best Practices (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/zU1x5SfKEzs&#34;&gt;Advanced Security Best Practices Masterclass (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/DykPS2gvDeo&#34;&gt;Architecting for Greater Security on AWS (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/Ys0gG1koqJA&#34;&gt;Defending Against DDoS Attacks (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/NL3sDn92NuU&#34;&gt;Practical Steps to Hack-Proofing AWS (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/nqaL5zJqFuo&#34;&gt;Architecting for End-to-End Security in the Enterprise (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/ZaOR-ybLJF0&#34;&gt;Log, Monitor and Analyze your IT with Amazon CloudWatch (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/jX6pEWf344I&#34;&gt;Mobile Identity Management &amp;amp; Data Sync Using Amazon Cognito (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/KtMANvC7_n8&#34;&gt;Reliable Design and Deployment of Security and Compliance (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/On9NoUwj-Os&#34;&gt;Strategies for Protecting Data Using Encryption in AWS (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/bqIYI3mDsd4&#34;&gt;Encryption and Key Management in AWS (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/0kWpm1FyG_Q&#34;&gt;Secure Applications with AWS Key Management Service (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/pi4HTSrmzis&#34;&gt;Encryption Key Storage with AWS KMS at Okta (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/WUQNeMhkaco&#34;&gt;Intrusion Detection in the Cloud (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/nzSrRvADh6g&#34;&gt;Incident Response in the Cloud (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/8AODa_AazY4&#34;&gt;SSL with Amazon Web Services (Video)&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;scalability--elasticity-15&#34;&gt;Scalability &amp;amp; Elasticity (15%)&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/blogs/aws/auto-scale-dynamodb-with-dynamic-dynamodb/&#34;&gt;AutoScaling for DynamoDB&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;http://nineofclouds.blogspot.com.au/2013/01/vpc-migration-nats-bandwidth-bottleneck.html&#34;&gt;VPC Migration: NATs &amp;amp; Bandwidth Bottleneck&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://d0.awsstatic.com/whitepapers/managing-your-aws-infrastructure-at-scale.pdf&#34;&gt;Managing Your AWS Infrastructure at Scale&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://d0.awsstatic.com/whitepapers/performance-at-scale-with-amazon-elasticache.pdf&#34;&gt;Performance at Scale with Amazon ElastiCache&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/gUAuhdtHacI&#34;&gt;Using Amazon CloudFront For Your Websites &amp;amp; Apps (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/s9Xt1qzD6SA&#34;&gt;Best Practices for Content Delivery using Amazon CloudFront (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/eorGJL-LkJc&#34;&gt;Secure Content Delivery Using Amazon CloudFront (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/91TAx4fmcxk&#34;&gt;Elastic Load Balancing Deep Dive and Best Practices (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/vg5onp8TU6Q&#34;&gt;Scaling Up to Your First 10 Million Users (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/bSa_byGRGR4&#34;&gt;Scaling Infrastructure Operations with AWS (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/4trGuelatMI&#34;&gt;All You Need To Know About Auto Scaling (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/FxCF34txNfk&#34;&gt;Introduction to Amazon Kinesis (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/XFHtsUgH-L8&#34;&gt;Streaming Data Processing with Amazon Kinesis and AWS Lambda (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/JFfvD2cw2IE&#34;&gt;Building Real-time Streaming Applications with Amazon Kinesis (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/8u9wIC1xNt8&#34;&gt;Kinesis Deep Dive (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/4VfIINg9DYI&#34;&gt;ElastiCache: Deep Dive (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/zc1_Rfb_txQ&#34;&gt;EMR Masterclass (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/4HseALaLllc&#34;&gt;EMR Deep Dive and Best Practices (Video)&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;cloud-migration--hybrid-architecture-10&#34;&gt;Cloud Migration &amp;amp; Hybrid Architecture (10%)&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/ec2/vm-import/&#34;&gt;Existing vSphere, Hyper-V and Xen VM Import&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://aws.amazon.com/ec2/vcenter-portal/&#34;&gt;AWS Management Portal for vCenter&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://aws.amazon.com/ec2/vcenter-portal/&#34;&gt;vCenter Portal&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://d0.awsstatic.com/whitepapers/migration-best-practices-rdbms-to-dynamodb.pdf&#34;&gt;Best Practices for Migrating from RDBMS to Amazon DynamoDB&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://d0.awsstatic.com/whitepapers/the-path-to-the-cloud-dec2015.pdf&#34;&gt;A Practical Guide to Cloud Migration&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://d0.awsstatic.com/whitepapers/migration-best-practices-rdbms-to-dynamodb.pdf&#34;&gt;Migration Best Practices – RDBMS to DynamoDB&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://d0.awsstatic.com/whitepapers/strategies-for-migrating-oracle-database-to-aws.pdf&#34;&gt;Strategies for Migrating Oracle Database to AWS&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;http://aws.amazon.com/ec2/vcenter-portal/&#34;&gt;AWS Management Portal for vCenter&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/we4dcxIDKJo&#34;&gt;Enable &amp;amp; Secure Your Business Apps via the Hybrid Cloud on AWS (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/kgp8jjO6O6Y&#34;&gt;Preparing for Migration: A Roadmap to AWS (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/kn4bETDe5gk&#34;&gt;Migrating Fox’s Media Supply Chains to the Cloud with AWS (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/XKkYY_FCiQ4&#34;&gt;How Delaware North Migrated 90+ Apps in Four Months (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/pBIbsofLQ3w&#34;&gt;Acceleration of AWS Enterprise Adoption in GE (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;http://www.rightscale.com/webinars/lp/aws-vmware-architect-hybid-environments-webinar&#34;&gt;AWS and VMware: How to Architect Hybrid Environments&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;aws-core-knowledge&#34;&gt;AWS Core Knowledge&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;http://aws.amazon.com/architecture/&#34;&gt;AWS Architecture Center&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;http://d0.awsstatic.com/whitepapers/architecture/AWS_Well-Architected_Framework.pdf&#34;&gt;AWS Well‐Architected Framework&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://media.amazonwebservices.com/AWS_Cloud_Best_Practices.pdf&#34;&gt;Architecting for the Cloud: Best Practices&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;All re:invent 2016 Sessions are available on &lt;a href=&#34;https://www.youtube.com/playlist?list=PLhr1KZpdzukdGa7Gqu4bdql4KH7sL3mhf&#34;&gt;AWS YouTube Playlist&lt;/a&gt;. All slides used at re:Invent, Summit, DevDay are all available on &lt;a href=&#34;http://www.slideshare.net/AmazonWebServices&#34;&gt;AWS SlideShare&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The User \ Developer and FAQs Are Useful
&lt;a href=&#34;http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Introduction.html&#34;&gt;CloudFront Developer Guide&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://aws.amazon.com/cloudfront/faqs/&#34;&gt;CloudFront FAQs&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/Welcome.html&#34;&gt;CloudFormations User Guide&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://aws.amazon.com/cloudformation/faqs/&#34;&gt;CloudFormations FAQ&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://aws.amazon.com/cloudhsm/faqs/&#34;&gt;CloudHSM FAQ&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://aws.amazon.com/cloudwatch/faqs/&#34;&gt;CloudWatch FAQ&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://aws.amazon.com/config/faq/&#34;&gt;Config FAQ&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://aws.amazon.com/datapipeline/faqs/&#34;&gt;Data Pipeline FAQs&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;http://docs.aws.amazon.com/directconnect/latest/UserGuide/Welcome.html&#34;&gt;Direct Connect User Guide&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://aws.amazon.com/directconnect/faqs/&#34;&gt;Direct Connect FAQs&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Introduction.html&#34;&gt;DynamoDB Developer Guide&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://aws.amazon.com/dynamodb/faqs/&#34;&gt;DynamoDB FAQs&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AmazonEBS.html&#34;&gt;EBS User Guide&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://aws.amazon.com/ebs/faqs/&#34;&gt;EBS FAQ&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/concepts.html&#34;&gt;EC2 User Guide&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://aws.amazon.com/ec2/instance-types/&#34;&gt;EC2 Instance Types&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://aws.amazon.com/ec2/faqs/&#34;&gt;EC2 FAQ&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/jLVPqoV4YjU&#34;&gt;EC2 Masterclass (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/Welcome.html&#34;&gt;Elastic BeanStalk Developer Guide&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://aws.amazon.com/elasticache/faqs/&#34;&gt;ElasticCache FAQs&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://aws.amazon.com/elasticloadbalancing/faqs/&#34;&gt;Elastic LoadBalancer FAQ&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://youtu.be/WnFYoiRqEHw&#34;&gt;Elastic MapReduce : A Technical Introduction (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://aws.amazon.com/glacier/faqs/&#34;&gt;Glacier FAQs&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;http://docs.aws.amazon.com/IAM/latest/UserGuide/introduction.html&#34;&gt;IAM User Guide&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://aws.amazon.com/iam/faqs/&#34;&gt;IAM FAQ&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://aws.amazon.com/importexport/&#34;&gt;Import Export Snowball&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://aws.amazon.com/importexport/faqs/&#34;&gt;Import Export FAQs&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://www.youtube.com/watch?v=8u9wIC1xNt8&#34;&gt;Kinesis Deep Dive (Video)&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;http://docs.aws.amazon.com/streams/latest/dev/introduction.html&#34;&gt;Kenesis Developer Guide&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://aws.amazon.com/kinesis/streams/faqs/&#34;&gt;Kenesis FAQ&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://aws.amazon.com/kms/faqs/&#34;&gt;KMS FAQ&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://aws.amazon.com/opsworks/faqs/&#34;&gt;OpsWorks FAQ&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://aws.amazon.com/rds/faqs/&#34;&gt;RDS FAQ&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://aws.amazon.com/redshift/faqs/&#34;&gt;Redshift FAQs&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://aws.amazon.com/route53/faqs/&#34;&gt;Route 53 FAQ&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;http://docs.aws.amazon.com/sns/latest/dg/welcome.html&#34;&gt;SNS Developer Guide&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;http://aws.amazon.com/sns/faqs/&#34;&gt;SNS FAQ&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://aws.amazon.com/storagegateway/faqs/&#34;&gt;Storage Gateway FAQs&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://aws.amazon.com/s3/faqs/&#34;&gt;S3 FAQ&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Introduction.html&#34;&gt;VPC User Guide&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://aws.amazon.com/vpc/faqs&#34;&gt;VPC FAQ&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;certification-journey-blog-posts&#34;&gt;Certification Journey Blog Posts&lt;/h1&gt;
&lt;p&gt;As well as technical study its always good to hear the personal experience stories of people who have studied for and successfully passed.&lt;br&gt;
&lt;a href=&#34;http://ozaws.com/2015/09/17/aws-professional-solution-architect-certification-tips/&#34;&gt;Nick Triantafillou&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://cloudninjablog.wordpress.com/2015/07/22/aws-certified-solutions-architect-professional-certification-the-road-to-success/&#34;&gt;Jason Oliver&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://medium.com/@anything_cloud/how-to-pass-aws-certified-professional-solutions-architect-exam-5bbb44c04fda&#34;&gt;Frank van der Meer&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://medium.com/@anything_cloud/aws-certified-solutions-architect-professional-level-sample-exam-questions-and-answers-with-dd7df8984a8c#.gxz682t78&#34;&gt;Frank van der Meer - Sample Exam Questions&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;http://cantrill.io/certification/aws/2015/10/04/passing-the-aws-solutions-architect-professional-exam.html&#34;&gt;Adrian Cantrill&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://medium.com/@jcutting/preparing-for-the-aws-architect-professional-exam-cf54acc1fb2a#.5a5sk5clx&#34;&gt;Jeremiah Cutting&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://hydrasit.com/passed-aws-solutions-architect-professional-exam/&#34;&gt;Stephen Wilding&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;http://blog.henrik.org/2016/04/how-i-studied-for-aws-certified.html&#34;&gt;Henrik Johnson&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;https://blog.michaelwittig.info/aws-certified-solutions-architect-professional-level/&#34;&gt;Michael Wittig&lt;/a&gt;&lt;br&gt;
&lt;a href=&#34;http://www.mitchyb.com/2015/10/aws-certified-solutions-architect.html&#34;&gt;Mitch Beaumont&lt;/a&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>AWSome Day - AWS Roadshow - Leeds 2016</title>
      <link>https://darrylcauldwell.github.io/post/aws-awesome/</link>
      <pubDate>Thu, 15 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/aws-awesome/</guid>
      <description>
        
          &lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/aws-awsome-day-logo.jpeg&#34; alt=&#34;AWS Awesome Day Logo&#34;&gt;&lt;/p&gt;
&lt;p&gt;The &amp;lsquo;AWSome Day&amp;rsquo; is a roadshow for people new to Amazon Web Services Cloud. I am about to change roles to work with customer solutions
leveraging Amazon Web Services Cloud rather than VMware private cloud. I&amp;rsquo;ve just passed the entry level &amp;lsquo;AWS Business Professional&amp;rsquo; and
&amp;lsquo;AWS Technology Professional&amp;rsquo; partner accreditations. I am presently self studying towards the associate level &amp;lsquo;Certified Solutions Archiect&amp;rsquo;.
Certification self study is good but can be a little dry so the offer of having some &amp;lsquo;free&amp;rsquo; training and access to some expert solutions architects was
very welcome. Having been to various VMware roadshow type events they are also generally a great place to meet similar interested people in
the ecosystem.&lt;/p&gt;
&lt;p&gt;The day started with a session highlighting how and why customers are using AWS to develop, deploy and operate secure applications and IT services.
This session gave various real world customer use case examples and how they have used the AWS services to transform their business. The event then
broke into a two tracks one technical and the other business track. I followed the technical track. The technical had various sessions covering the AWS foundational
services, EC2, S3, EBS, Glacier, Kinesis, VPC, IAM, RDS and DynamoDB. Once the foundational services had been covered there more sessions covering
Elastic Beanstalk, Auto Scaling, Load Balancing, CloudWatch and Trusted Advisor. The sessions were delivered by two AWS technical trainers who
were supported by two AWS solutions architects to answer questions. The breadth of topics meant the sessions were not deep dives, however the Q&amp;amp;A
was lively and it teased out a lot of technical detail. The technical level of the sessions was close to the training materials I have been following
for ‘AWS Solutions Architecture – Associate’ certification although not a substitute to my self-study it was useful to take the information from a
real trainer and be able to ask questions.&lt;/p&gt;
&lt;p&gt;There were vendors sponsoring the day, Alert Logic, Xen, QA and Global Knowledge, I took chance to speak to them all during the time between sessions.
Alert Logic provide a managed security operations center type service, we had a great discussion about the different threat vectors used by attackers
of AWS solutions and some of the AWS services which provide analytics.  Xen are a UK solutions provider who offer Solutions Architect consultancy for
businesses moving to AWS, we had a great discussion on the challenges enterprise business face when moving to AWS.  QA &amp;amp; Global Knowledge are both
training providers who I spoke to about the AWS certification path, most of which I had already found from the AWS website but it was encouraging to
hear of the training options available.&lt;/p&gt;
&lt;p&gt;In summary the AWSome Day was valuable to me to support my study for upcoming exam but also start exploring the current actual business use cases to AWS
service mappings and have dialog with vendors in and around the AWS space. I had a great day at the AWSome Day 2016 and would recomend to anyone starting
or thinking about going on an AWS journey.&lt;/p&gt;
&lt;h2 id=&#34;links-to-the-days-slides&#34;&gt;Links to the days slides&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;http://www.slideshare.net/IanMassingham/aws-awsome-day-roadshow-intro&#34;&gt;Introduction &amp;amp; Closing AWSome Day Slides&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.slideshare.net/AmazonWebServices/awsome-day-leeds&#34;&gt;AWSome Day Technical Track Slides&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.slideshare.net/IanMassingham/tag/jan-16-awsomeday&#34;&gt;AWSome Day Business Track Slides&lt;/a&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Installing vSphere Integrated Containers In Five Minutes</title>
      <link>https://darrylcauldwell.github.io/post/vic/</link>
      <pubDate>Wed, 13 Jul 2016 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/vic/</guid>
      <description>
        
          &lt;p&gt;As it looks like vSphere Integrated Containers will feature a lot at the upcoming VMworld I took the chance to install this and find out more.&lt;/p&gt;
&lt;p&gt;The &lt;a href=&#34;https://github.com/vmware/vic/tree/master/doc/user_doc/vic_installation&#34;&gt;documentation available&lt;/a&gt; on isn&amp;rsquo;t extensive, but, contains all I needed to know and I think benefits from being to the point.&lt;/p&gt;
&lt;p&gt;The files needed to set this up are provided as a gzip file
&lt;a href=&#34;https://bintray.com/vmware/vic-repo/build#files&#34;&gt;hosted on bintray&lt;/a&gt;. Just checking the file dates you can see the development is iterating at a great pace with around six releases per day. I chose to download the latest package which contains installers to be run from different operating systems.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;Platform&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;Supported Versions&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Windows&lt;/td&gt;
&lt;td&gt;7, 10&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Mac OS X&lt;/td&gt;
&lt;td&gt;10.11 (TBC)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Linux&lt;/td&gt;
&lt;td&gt;Ubuntu 15.04, others TBD&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;My homelab is vCenter, single cluster of two ESX hosts, storage VSAN and networking NSX. Security is not important in my homelab and TLS adds complication so I chose not to add this. There are great syntaxt examples to follow in the documentation, but here are options I used.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;./vic-machine-darwin create --target 192.168.1.13 --user Administrator@vsphere.local --password VMware1! --compute-resource ElectricChair --image-datastore vsanDatastore --bridge-network DPortGroup --name vch
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/vic-install.jpg&#34; alt=&#34;vSphere Integrated Containers Install&#34;&gt;&lt;/p&gt;
&lt;p&gt;In order to use vSphere Integrated Containers you&amp;rsquo;ll need a Docker client, for Mac there is the choice of &lt;a href=&#34;https://www.docker.com/products/docker-toolbox&#34;&gt;Docker Toolbox&lt;/a&gt; or the newer &lt;a href=&#34;https://docs.docker.com/docker-for-mac/&#34;&gt;Beta Docker for Mac&lt;/a&gt;. I had the beta installed, and found I needed to remove this and replace with Docker Toolbox.&lt;/p&gt;
&lt;p&gt;The first thing to do is ensure that you can connect and that it looks healthy, to do this run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;docker -H ipaddress-vch:2375 info
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/vic-info.jpg&#34; alt=&#34;vSphere Integrated Containers Info&#34;&gt;&lt;/p&gt;
&lt;p&gt;Its always useful to look in the log files when your setting something up for the first time, however SSH is disabled on the VCH host so I enabled SSH for current session.  Logon via console using &lt;em&gt;root&lt;/em&gt; with password of &lt;em&gt;password&lt;/em&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;systemctl start sshd
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;There are five log files I found so far&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;/var/log/vic/docker-personality.log
/var/log/vic/imagec.log
/var/log/vic/init.log
/var/log/vic/port-layer.log
/var/log/vic/vicadmin.log
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;So now we&amp;rsquo;re running and can access logs the next thing to do is pull a container&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;docker -H paddress-vch:2375 pull vmwarecna/nginx
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/vic-nginx.jpg&#34; alt=&#34;vSphere Integrated Containers NGINX&#34;&gt;&lt;/p&gt;
&lt;p&gt;Once its local we can start it up,  we&amp;rsquo;ll start it in the background and put a port mapping of port 80 in place and then view it.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker -H ipaddress-vch:2375 run -d -p 80:80 vmwarecna/nginx
docker -H ipaddress-vch:2375 ps
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/vic-nginx-go.jpg&#34; alt=&#34;vSphere Integrated Containers NGINX Go&#34;&gt;&lt;/p&gt;
&lt;p&gt;We can then also see that a new VM has been created in vCenter with VM name matching the UID of the docker container.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/vic-nginx-vm.jpg&#34; alt=&#34;vSphere Integrated Containers NGINX VM&#34;&gt;&lt;/p&gt;
&lt;p&gt;We can then stop this and tidy up our test container&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;docker -H ipaddress-vch:2375 stop container-id
docker -H ipaddress-vch:2375 rm container-id
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;As its so easy to install and configure its probably worth while removing VCH and when you come to use it pull the latest to remove is as easy as installing.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;./vic-machine-darwin delete --target vcenter.darrylcauldwell.local --user Administrator@vsphere.local --password VMware1! --name vch --force
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/vic-bye.jpg&#34; alt=&#34;vSphere Integrated Containers Bye!&#34;&gt;&lt;/p&gt;
&lt;p&gt;There is a little bug just now and the image files don&amp;rsquo;t seem to get removed by uninstall process but these are easy enough to delete along with the VIC folder from the datatore.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m disappointed in myself for waiting so long to look at this, what was putting me off was the thought it might be complex but it proved to be very much straight forwards.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Safely Lockdown NSX Distributed Firewall (DFW) Ruleset</title>
      <link>https://darrylcauldwell.github.io/post/nsx-dfw-lockdown/</link>
      <pubDate>Tue, 05 Jul 2016 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/nsx-dfw-lockdown/</guid>
      <description>
        
          &lt;p&gt;A common dilemma when developing a solution with firewall is whether to change the Default rule to Deny at the start and develop the ruleset as part of development or leave the Default rule to Allow and secure it later. In modern agile teams its best to develop the ruleset as part of development ensuring the ruleset is tested with the product as introducing it later could well invalidate every bit of testing performed.&lt;/p&gt;
&lt;p&gt;If however you find yourself in the situation where a NSX firewall solution is deployed with the Default rule to Allow and your asked to implement a ruleset to cover the traffic and change default to Deny. This is one possible solution to capture the required configuration.&lt;/p&gt;
&lt;h2 id=&#34;enable-default-rule-logging&#34;&gt;Enable Default Rule Logging&lt;/h2&gt;
&lt;p&gt;In order we can capture the active traffic we can first enable Logging on the default rule.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/dFW-EnableLogging.jpg&#34; alt=&#34;NSX Enable Logging&#34;&gt;&lt;/p&gt;
&lt;p&gt;We can then operate the environment normally for a period of time which captures all business processes. This maybe a day, a week, a month or more.&lt;/p&gt;
&lt;h2 id=&#34;centralize-logging&#34;&gt;Centralize Logging&lt;/h2&gt;
&lt;p&gt;NSX data plane logging is written to the VMkernel.log files,  therefore if a logical firewall rule log is generated for a vNIC of a VM it is written to the ESX host log file which it was residing at that time.&lt;/p&gt;
&lt;p&gt;The distributed firewall configuration can apply to the whole vCenter and all objects within. You must therefore configure the remote syslog server for each host in each cluster that has firewall enabled. The remote syslog server is specified in the &lt;em&gt;Syslog.global.logHost&lt;/em&gt; attribute. My preference is to use vRealize Log Insight for centralized syslog.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/dFW-EnableRemoteLogging.jpg&#34; alt=&#34;NSX Remote Logging&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;identifying-traffic-hitting-default-allow&#34;&gt;Identifying Traffic Hitting Default Allow&lt;/h2&gt;
&lt;p&gt;When we browse the firewall log entries we find that in order to narrow our search to the correct rule we need to establish the &lt;em&gt;vmw_nsx_firewall_ruleid&lt;/em&gt; for the default layer 3 rule which we are logging. The &lt;em&gt;vmw_nsx_firewall_ruleid&lt;/em&gt; is not displayed via the NSX Firewall GUI but can be easily got from the NSX REST API by running the GET method on this URL&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;https://&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;nsx-mgr-ip&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;/api/4.0/firewall/globalroot-0/config?ruleType&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;LAYER3
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/dFW-DefaultRuleID.jpg&#34; alt=&#34;NSX Default Rule ID&#34;&gt;&lt;/p&gt;
&lt;p&gt;We see in this example the &lt;em&gt;rule id=&amp;ldquo;1001&amp;rdquo;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Once we have this we can create a vRealize Log Insight query to list all logs generated by this rule.  To make this query easier to view I remove all columns except timestamp and vmw_nsx_firewall.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/dFW-LI-Query.jpg&#34; alt=&#34;Query Firewall Events Log Insight &#34;&gt;&lt;/p&gt;
&lt;p&gt;From this data we can then identify what traffic would be blocked if we changed the default rule to Deny. We can work through this data, identify valid traffic flows. We can then put in explicit allow rules for the valid traffic. When we are happy no traffic is being logged by the Default Rule we can change it to Deny.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Migrate Wordpress to GitHub Pages</title>
      <link>https://darrylcauldwell.github.io/post/jekyll/</link>
      <pubDate>Wed, 29 Jun 2016 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/jekyll/</guid>
      <description>
        
          &lt;p&gt;There are the steps I used to migrate my blog from Wordpress to GitHub Pages,  first I will try and describe why I am doing this.&lt;/p&gt;
&lt;h2 id=&#34;migrate-to-learn&#34;&gt;Migrate To Learn&lt;/h2&gt;
&lt;p&gt;Learning new technical skills is straight forwards but while building any new skill building a muscle memory for command syntax is only achieved by taking as many opportunities to exercise the muscle as possible.&lt;/p&gt;
&lt;p&gt;I found at my old job I was more and more using distributed source control more and more to help my day to day work, since changing job this required much less. The goal at my employer is to use this in the near future so editing my personal blog is a good way to keep learning and building knowledge with github. By migrating my blog to GitHub Pages and Jekyll, publishing a blog post becomes committing changes and pushing them to GitHub.&lt;/p&gt;
&lt;p&gt;Albeit distributed source control is used much less in my new role writting infrastructure configuration code is still very much required. I&amp;rsquo;ve moved away from Sublime Text and been starting to use the excellent Visual Studio Code at work. I write much less code at home on Mac and struggle with the shortcut key differences. By maintaining my personal blog as a series of files which I use a code editor will help me with this.&lt;/p&gt;
&lt;p&gt;While working with Ansible I use YAML formatted files, using Jeykll and passing variables seems a great way to keep using and learning.&lt;/p&gt;
&lt;h2 id=&#34;migration-overview&#34;&gt;Migration Overview&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Install Jekyll&lt;/li&gt;
&lt;li&gt;Create new Jekyll project&lt;/li&gt;
&lt;li&gt;Create GitHub Pages site&lt;/li&gt;
&lt;li&gt;Export Wordpress posts as Jekyll&lt;/li&gt;
&lt;li&gt;Test posts on Jekyll (Local)&lt;/li&gt;
&lt;li&gt;Commit exported posts to GitHub Pages&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;install-jekyll&#34;&gt;Install Jekyll&lt;/h2&gt;
&lt;p&gt;The &lt;a href=&#34;https://jekyllrb.com/docs/installation&#34;&gt;Jekyll install&lt;/a&gt; requires Ruby and Ruby Gems be in place before starting.
These are included with OS X so we can just pen terminal and run the following to install.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;sudo gem install jekyll
sudo gem install jekyll-paginate
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;create-new-jekyll-project&#34;&gt;Create new Jekyll project&lt;/h2&gt;
&lt;p&gt;A Jekyll project is just a collection of files so first its worth creating a folder to house the project then running a Jekyll command
to create the framework files.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;mkdir Website
cd Website/
jekyll new darrylcauldwell.com
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;create-github-pages-site&#34;&gt;Create GitHub Pages site&lt;/h2&gt;
&lt;p&gt;Create a personal GitHub repository called &lt;em&gt;projectname&lt;/em&gt;.github.io,  for example &amp;lt;&lt;em&gt;&amp;gt;darrylcaudwell.github.io&amp;lt;&lt;/em&gt;&amp;gt;.&lt;/p&gt;
&lt;p&gt;Initialise your Jekyll website project folder as a local git repository, add all the files to the local repository, link the local
git repository to github.com, create first commit and then push this to master.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;git init
git add .
git remote add github git@github.com:darrylcauldwell/darrylcauldwell.github.io
git add README.md
git commit -m &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;first commit&amp;#34;&lt;/span&gt;
git remote add origin https://github.com/darrylcauldwell/darrylcauldwell.github.io.git
git push -u origin master
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;By performing this commit should trigger the creation of your SSL secured GitHub Pages website in my example the URL is.
&lt;a href=&#34;https://darrylcauldwell.github.io&#34;&gt;https://darrylcauldwell.github.io&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;export-wordpress-posts-as-jekyll&#34;&gt;Export Wordpress posts as Jekyll&lt;/h2&gt;
&lt;p&gt;So by this stage we have the website running with our chosen theme and we&amp;rsquo;re now ready to migrate across all old posts from wordpress.&lt;/p&gt;
&lt;p&gt;Within existing wordpress site install the &lt;a href=&#34;https://wordpress.org/plugins/wp2jekyll/&#34;&gt;&amp;lsquo;WordPress2Jekyll&amp;rsquo;&lt;/a&gt; plugin and use this to export the site as a zip file.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cd yourproject
jekyll build
git add .
git commit -m &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;imports old blog posts&amp;#34;&lt;/span&gt;
git push -u origin master
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;redirect-url&#34;&gt;Redirect URL&lt;/h2&gt;
&lt;p&gt;Once your happy that your website is fully funcional on the URL &lt;em&gt;yourproject&lt;/em&gt;.github.io you can then add a DNS alias to point your domain
name to the new site.  After a few days if your still happy you can then remove your account from previous hosting company.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>vRealize Orchestrator 7 (vRO) Install</title>
      <link>https://darrylcauldwell.github.io/post/vro-install/</link>
      <pubDate>Tue, 14 Jun 2016 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/vro-install/</guid>
      <description>
        
          &lt;p&gt;While attempting to setup vRealize Orchestrator 7 at home it soon became clear the documentation isn&amp;rsquo;t great after much flipping between documents and blog posts I got this installed and working. Here I are the steps I followed.&lt;/p&gt;
&lt;h2 id=&#34;deploy-vrealize-orchestrator&#34;&gt;Deploy vRealize Orchestrator&lt;/h2&gt;
&lt;p&gt;Deploy the OVA via web client and specify network details appropriate to your home lab,  ensure a DNS A and PTR record are created for the vRealize Orchestrator appliance.  The Orchestrator client relies on a Java Runtime so while OVA deploys its a good time to install this if its not already.&lt;/p&gt;
&lt;p&gt;Once deployed the various interfaces to vRO can be accessed from the main menu screen https://vro-fqdn:8281/vco/.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/vROstartPage.jpg&#34; alt=&#34;vRO Start Page&#34;&gt;&lt;/p&gt;
&lt;p&gt;From the menu select &amp;lsquo;Orchestrator Control Center&amp;rsquo; from the start menu and authenticate with the account named root with the password you specified during OVA deployment.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/vROcontrolCenter.jpg&#34; alt=&#34;vRO Control Center&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;configure-vcenter-connection&#34;&gt;Configure vCenter Connection&lt;/h2&gt;
&lt;p&gt;The first thing to do once vRealize Orchestrator is deployed is to import the vCenter SSL certitificate. Select the Control Center &amp;lsquo;Manage \ Certificates&amp;rsquo; menu item.  Within trusted certificates tab click &amp;lsquo;Import \ Import from URL&amp;rsquo;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/vROtrustVcenter.jpg&#34; alt=&#34;vRO Trust vCenter&#34;&gt;&lt;/p&gt;
&lt;p&gt;Within this wizard enter the FQDN of your vCenter and at next wizard screen
click Import.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/vROimportCert.jpg&#34; alt=&#34;vRO Import Certificate&#34;&gt;&lt;/p&gt;
&lt;p&gt;I use vCenter as an appliance with embedded Platform Services Controller, I&amp;rsquo;d prefer to manage vRealize Orchestrator using the same Single Sign On account.  To do this use the vRealize Orchestrator Control Center menu option &amp;lsquo;Manage \ Configure Authentication Provider&amp;rsquo;.&lt;/p&gt;
&lt;p&gt;Select &amp;lsquo;Authentication mode&amp;rsquo; to be vSphere,  enter FQDN of vCenter and click Connect.  Your then asked for a User name and password, this account is used to bind to Single Sign On so enter your logon details and click Register. Your then asked to enter an Admin group, start to type Administrator and click the Search button to the right and it should list all available groups from SSO with Administrator in the name.  Select &amp;lsquo;vsphere.local\Administrators&amp;rsquo; and click Save.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/vROauth.jpg&#34; alt=&#34;vRO Authentication Mode&#34;&gt;&lt;/p&gt;
&lt;p&gt;Once added the vRO service needs to be restarted there is a link presented once configuration is saved,  or this can be selected from &amp;lsquo;Mange \ Startup Options&amp;rsquo;.&lt;/p&gt;
&lt;p&gt;You should now be able to open the main menu and start the vRO Client, login with your SSO credentials and start having fun.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/vROclientStart.jpg&#34; alt=&#34;vRO Client Start&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;redirect-syslog-to-log-insight&#34;&gt;Redirect Syslog to Log Insight&lt;/h2&gt;
&lt;p&gt;I use vRealize Log Insight to to centralize all my lab log files. To set Log Insight as a remote syslog use &amp;lsquo;Control Center \ Log \ Logging Integration&amp;rsquo;.  Complete the details of Log Insight server.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/vROlogInsight.jpg&#34; alt=&#34;vRO Log Insight&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;configure-ntp&#34;&gt;Configure NTP&lt;/h2&gt;
&lt;p&gt;I sync time from Active Directory in my homelab,  this is done from the appliance configuration application located https://&lt;!-- raw HTML omitted --&gt;:5480. Within this go to the &amp;lsquo;Admin \ Time Settings&amp;rsquo; menu option and enter the NTP server IP address.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/vROconfigurator.jpg&#34; alt=&#34;vRO Configurator&#34;&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Deploying NSX-V With Ansible</title>
      <link>https://darrylcauldwell.github.io/post/nsx-install-ansible/</link>
      <pubDate>Wed, 08 Jun 2016 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/nsx-install-ansible/</guid>
      <description>
        
          &lt;p&gt;Here I will describe the steps taken to deploy NSX Manager using the &lt;a href=&#34;https://github.com/vmware/nsxansible&#34;&gt;Ansible NSX Module&lt;/a&gt;. The NSX Ansible module is written by VMware and is provided opensource on GitHub. To work properly this depends on the &lt;a href=&#34;https://github.com/vmware/nsxraml&#34;&gt;NSX RAML Specification&lt;/a&gt;, &lt;a href=&#34;https://github.com/vmware/nsxramlclient&#34;&gt;NSX RAML Python Client&lt;/a&gt;, &lt;a href=&#34;https://github.com/vmware/pyvmomi&#34;&gt;vSphere API Python Bindings&lt;/a&gt; and the &lt;a href=&#34;https://www.vmware.com/support/developer/ovf/&#34;&gt;OVF Tool&lt;/a&gt; all being installed on the Ansible server.&lt;/p&gt;
&lt;p&gt;The following assumes you have a working Ansible installation already, and a vSphere environmentto install NSX to. If you don&amp;rsquo;t yet have these you can see how I performed my &lt;a href=&#34;%7B%7Bsite.url%7D%7D/how-to-setup-an-ansible-test-lab-for-windows-managed-nodes-custom-windows-modules/&#34;&gt;Ansible Installation&lt;/a&gt; in this earlier blog post.&lt;/p&gt;
&lt;h2 id=&#34;nsx-raml-specification&#34;&gt;NSX RAML Specification&lt;/h2&gt;
&lt;p&gt;As the NSX REST API changes with each release the REST API Markup Language (RAML) specification for NSX is provided as a different branch of the GitHub repository.  In my environment I will be using NSX 6.2.2 so first I ensure the git client is installed to my Ansible server and then I use this to take a clone of the correct branch.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;yum install git-all
git clone -b 6.2.2 https://github.com/vmware/nsxraml.git /nsxraml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;nsx-raml-python-client&#34;&gt;NSX RAML Python Client&lt;/h2&gt;
&lt;p&gt;The NSX RAML python client is series of functions which can be used standalone or in our case called by the Ansible NSX module.  To install these we need to ensure the &amp;lsquo;Python Package Manger&amp;rsquo; and some other tools are installed and available on our Ansible server.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;yum install python-pip gcc libxslt-devel python-devel pyOpenSSL
pip install --upgrade pip
pip install lxml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once thes pre-requiste components are in place we can then install the NSX RAML python client. Similar to the RAML specification, the client functions are also dependant on version. The version which works with NSX RAML Specification 6.2.2 is Python client 1.0.4.  To install this version from Python package manager we use.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;pip install nsxramlclient&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;1.0.4
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If you have NSX Manager already deployed you can create a session to this using the python client.  First start python by running&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;python
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;then you can run the commands similar to this to create a session.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; nsxramlclient.client &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; NsxClient
nsxraml_file &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/nsxraml/nsxvapi.raml&amp;#39;&lt;/span&gt;
nsxmanager &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;nsx.darrylcauldwell.local&amp;#39;&lt;/span&gt;
nsx_username &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;admin&amp;#39;&lt;/span&gt;
nsx_password &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;VMware!&amp;#39;&lt;/span&gt;
client_session &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; NsxClient(nsxraml_file, nsxmanager, nsx_username, nsx_password, debug&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;you can then see the session by running the following command in python session&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;client_session
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-install-ansible-RAMLclient.jpg&#34; alt=&#34;NSX RAML Client&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;vmware-vsphere-api-python-bindings&#34;&gt;VMware vSphere API Python Bindings&lt;/h2&gt;
&lt;p&gt;As well as the NSX Python client the Ansible NSX Module also depends on the VMware vSphere API Python Bindings (pyVmomi. pyVmomi is the Python SDK for the VMware vSphere API that allows you to manage ESX, ESXi, and vCenter. This is similarly installed with the python package manager using command like.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;pip install pyvmomi
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;ovf-tool&#34;&gt;OVF Tool&lt;/h2&gt;
&lt;p&gt;The final thing to be installed for the NSX Module to operate correctly is the VMware OVF Tool. The OVF tool for Linux version 4.1.0 is &lt;a href=&#34;https://my.vmware.com/group/vmware/details?downloadGroup=OVFTOOL410&amp;amp;productId=491#&#34;&gt;available here&lt;/a&gt;, please note a VMware login is required to get this.&lt;/p&gt;
&lt;p&gt;Once downloaded to the Ansbile server, we need to ensure it has execute attribute and then execute it to start the install, the commands to do this for the current version 4.1.0 are.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;chmod +x VMware-ovftool-4.1.0-2459827-lin.x86_64.bundle
./VMware-ovftool-4.1.0-2459827-lin.x86_64.bundle
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-install-ansible-ovftool.jpg&#34; alt=&#34;OVFTool&#34;&gt;&lt;/p&gt;
&lt;p&gt;Once the install is running you have to agree to EULA, to get to the end of the text, hold down the Space bar. When prompted &lt;em&gt;Do you agree?&lt;/em&gt; type yes.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-install-ansible-ovftool2.jpg&#34; alt=&#34;OVFTool&#34;&gt;&lt;/p&gt;
&lt;p&gt;Once OVF Tool is installed we can use SCP to copy the NSX OVA, VMware-NSX-Manager-6.2.2-3604087.ova, to Ansible server I placed this in folder named /OVAs.&lt;/p&gt;
&lt;h2 id=&#34;ansible-nsx-module&#34;&gt;Ansible NSX Module&lt;/h2&gt;
&lt;p&gt;We already have Git installed for dowlnloading the NSX RAML Specification so we can use this to clone the NSX Ansible repository.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;git clone https://github.com/vmware/nsxansible.git /nsxansible
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;deploy-nsx-manager&#34;&gt;Deploy NSX Manager&lt;/h2&gt;
&lt;p&gt;The NSX Module comes supplied with some example playbooks for performing common tasks, we’ll first take a copy of the example to deploy NSX Manager&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cp /nsxansible/test_deploynsxova.yml /nsxansible/darryl_deploynsxova.yml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We can then edit the contents to match the variables we plan to deploy in environment. While most of playbook contents are environmental specific varibles its worth noting that we run this module against the Ansible server itself as this is where the OVA and ovftool are located so hosts: value will always be localhost.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-install-ansible-NSXmgr.jpg&#34; alt=&#34;Deploy NSX Manager&#34;&gt;&lt;/p&gt;
&lt;p&gt;Once we have our environmental specific entries set we can execute the playbook with Ansible.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;ansible-playbook darryl_deploynsxova.yml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-install-ansible-playbook.jpg&#34; alt=&#34;Deploy NSX Manager Playbook&#34;&gt;&lt;/p&gt;
&lt;p&gt;We see this deploys ‘NSX Manager’ and configures the setting specified in the playbook.&lt;/p&gt;
&lt;h2 id=&#34;deploy-nsx-manager-and-register-with-vcenter-and-sso&#34;&gt;Deploy NSX Manager and register with vCenter and SSO&lt;/h2&gt;
&lt;p&gt;As with any Ansible playbook we can put common variables in a central location and call these from playbooks. An example is provided called answerfile-deployLab.yml. Variable names are overlapped between parts of the NSX Modules, in order that they are unique in the central answer file the names vary but its very easy to match these.&lt;/p&gt;
&lt;p&gt;An example of my playbook to deploy NSX Manager and then register this with vCenter and SSO.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-install-ansible-mgr-cfg.jpg&#34; alt=&#34;Deploy and Configure NSX Manager Playbook&#34;&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Ansibile NSX Configuration - Infrastructure As Code</title>
      <link>https://darrylcauldwell.github.io/post/nsx-ansible-iac/</link>
      <pubDate>Tue, 07 Jun 2016 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/nsx-ansible-iac/</guid>
      <description>
        
          &lt;p&gt;With the rise of DevOps culture and the ethos of automate all the things. Using test driven development techniques to apply application configuration declaratively has become widespread. The ever closer working relations of developers and infrastructure operations staff to become an application centric delivery and management unit has lead to many benefits.  One of the benefits is the shared empathy for each others pain points and understanding of how each approaches tackling these. It is clear that managing configuration as code has many benefits for consistent repeated delivery of applications.&lt;/p&gt;
&lt;p&gt;Tools which are commonly used for deploying applications with declarative configuration include Puppet, Chef and Ansible. The processes for distributed source control are also mature and with Git, Bitbucket and Apache Subversion there is a DVCS for most use-cases. As we work as one delivery team sharing tools and repositories is natural as with this we can look to deploy our infrastructure and application configuration with a single tool and avoid issues with interoperability and hand off.&lt;/p&gt;
&lt;p&gt;VMware NSX offers many things to many people with this rich feature set comes complexity in configuration.  At VMworld Europe 2015 I was introduced to Yves Fauser and attended his session &lt;a href=&#34;https://vmworld2015.lanyonevents.com/connect/sessionDetail.ww?SESSION_ID=4972&amp;amp;tclass=popup&#34;&gt;‘NET4972 – Incorporating VMware NSX in your DevOps Toolchain – Network Programmability with Python and Ansible‘.&lt;/a&gt;  He had created an [NSX RAML specification]((&lt;a href=&#34;http://github.com/vmware/nsxraml),&#34;&gt;http://github.com/vmware/nsxraml),&lt;/a&gt; a &lt;a href=&#34;http://github.com/vmware/nsxramlclient.&#34;&gt;Python NSX RAML client&lt;/a&gt; he then brings these altogether into a usable form by way of an &lt;a href=&#34;https://github.com/vmware/nsxansible&#34;&gt;NSX Ansible module.&lt;/a&gt;  The &lt;a href=&#34;https://github.com/vmware/nsxansible&#34;&gt;Ansible module&lt;/a&gt; offers examples which give the ability to NSX Manager, configure NSX to vCenter integration, configure VXLAN, deploy NSX Controllers and then deploy some logical switches.&lt;/p&gt;
&lt;p&gt;I explorered this capability in [this follow up post.]({{ site.url }}/deploy-nsx-from-ansible)&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Configuring NSX Edge to DLR OSPF</title>
      <link>https://darrylcauldwell.github.io/post/nsx-edge-ospf/</link>
      <pubDate>Mon, 23 May 2016 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/nsx-edge-ospf/</guid>
      <description>
        
          &lt;p&gt;As part of study for VCIX-NV I’ve given myself task of exploring in my new home lab all parts of NSX which I&amp;rsquo;m still not fully comfortable.  One of these things is OSPF,  to investigate this I came up with a test scenario and then worked through the steps to achieve a solution to meet the scenario design.&lt;/p&gt;
&lt;h2 id=&#34;scenario-design&#34;&gt;Scenario Design&lt;/h2&gt;
&lt;p&gt;We will replicate a typical development environment secured with an Edge Gateway.  Within the environment the developers will have ability to add and remove logical switches to the DLR and the automatic updating of the Edge Gateway routing table.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-edge-ospf-test.jpg&#34; alt=&#34;NSX Edge OSPF Test&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;deploy-edge-transit-logical-switch-and-distributed-logical-router&#34;&gt;Deploy Edge, Transit Logical Switch and Distributed Logical Router&lt;/h2&gt;
&lt;p&gt;The lab has VXLAN capability during my NSX core home lab configuration, so has hosts prepared, VNI pool and deployed Controller.&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;ll first deploy the Transit logical switch.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-edge-ospf-ls.jpg&#34; alt=&#34;NSX Edge Logical Switch&#34;&gt;&lt;/p&gt;
&lt;p&gt;Create Edge Gateway with an Uplink interface on the OOB network  (192.168.1.43) and on the Transit network (192.168.2.1) .&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-edge-ospf-edge-deploy.jpg&#34; alt=&#34;NSX Edge Deploy&#34;&gt;&lt;/p&gt;
&lt;p&gt;Create DLR initially with a single uplink on Transit network (192.168.2.254) , do not configure a default gateway.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-edge-ospf-dlr.jpg&#34; alt=&#34;NSX Edge DLR&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;configure-ospf-area&#34;&gt;Configure OSPF Area&lt;/h2&gt;
&lt;p&gt;An OSPF area is a logical collection of OSPF networks, routers, and links that have the same area identification. The simulated development environment we are using RFC1918 address space in order that the IP address schema can overlap as such our OSPF routing will be internal so we will create an OSPF area which is type Stub.&lt;/p&gt;
&lt;p&gt;On Edge Gateway Enable Dynamic Routing Configuration on the Transit interface.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-edge-ospf-dynamic.jpg&#34; alt=&#34;NSX Edge OSPF Dynamic&#34;&gt;&lt;/p&gt;
&lt;p&gt;Then we need to enable OSPF&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-edge-ospf-enable.jpg&#34; alt=&#34;NSX Edge OSPF Enable&#34;&gt;&lt;/p&gt;
&lt;p&gt;We require a stub OSPF area, and usefully Area ID 51 is configured already so we&amp;rsquo;ll use this.  We just need to associate this with the Transit interface in order it can communicate with DLR.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-edge-ospf-mapping.jpg&#34; alt=&#34;NSX Edge OSPF Mapping&#34;&gt;&lt;/p&gt;
&lt;p&gt;Repeat the steps used for configuring OSPF on the Edge on the DLR, when enabling OSPF enter the forwarding address to match the Transit network IP interface and the protocol address to be another available IP address on the Transit network.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-edge-ospf-ProFwd.jpg&#34; alt=&#34;NSX Edge OSPF Protocol Forward&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;route-distribution&#34;&gt;Route Distribution&lt;/h2&gt;
&lt;p&gt;The default Route Redistribution configuration for DLR is to distribute information about networks it is connected to.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-edge-ospf-RouteDistribute.jpg&#34; alt=&#34;OSPF Route Redistribution&#34;&gt;&lt;/p&gt;
&lt;p&gt;If we now check the Edge Gateway routing table we can see all routing is of type C (directly connected) or S (static entry for default gateway).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-edge-ospf-RouteTable.jpg&#34; alt=&#34;OSPF Route Table&#34;&gt;&lt;/p&gt;
&lt;p&gt;If I now simulate a developer creating a new Logical Switch for network 192.168.3.0/24 which is attached to DLR as internal interface 192.168.3.1.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-edge-ospf-test1DLR.jpg&#34; alt=&#34;OSPF Test 1 DLR&#34;&gt;&lt;/p&gt;
&lt;p&gt;We can then check the Edge Gateway routing table again.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-edge-ospf-test1DLR.jpg&#34; alt=&#34;OSPF Test 1 Edge&#34;&gt;&lt;/p&gt;
&lt;p&gt;We see a new route added type O (ospf derived) N2 (OSPF NSSA external type 2).  Which directs this traffic to the DLR interface on Transit network.&lt;/p&gt;
&lt;p&gt;If we then simulate the developer adding the test2 and test3 networks. We see the other routes populated.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-edge-ospf-test2-3.jpg&#34; alt=&#34;OSPF Test 2-3&#34;&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>NSX Backup and Restore</title>
      <link>https://darrylcauldwell.github.io/post/nsx-backup-restore/</link>
      <pubDate>Fri, 20 May 2016 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/nsx-backup-restore/</guid>
      <description>
        
          &lt;p&gt;As part of study for VCIX-NV I&amp;rsquo;ve given myself task of exploring in my new home lab all parts of NSX which I don&amp;rsquo;t use at work. One of these things is NSX Backup and Restore,  its not that we don&amp;rsquo;t use these function but that its relatively high impacting if it goes wrong.  To investigate this I came up with a list of networking configuration to test backup and restore of and the steps to I followed to perform each backup and restore type.&lt;/p&gt;
&lt;h2 id=&#34;scenario-1---distributed-firewall&#34;&gt;Scenario 1 - Distributed Firewall&lt;/h2&gt;
&lt;p&gt;To backup and restore distributed firewall rules is relatively straight forwards to do.  I&amp;rsquo;m starting with no rules created.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-backup-BlankRuleset.jpg&#34; alt=&#34;NSX Firewall Blank Ruleset&#34;&gt;&lt;/p&gt;
&lt;p&gt;Then create a new section.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-backup-BandR.jpg&#34; alt=&#34;NSX Firewall New Section&#34;&gt;&lt;/p&gt;
&lt;p&gt;Add some rules for example any to WEB on HTTP Service and WEB to DB on SQL Service.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-backup-testRules.jpg&#34; alt=&#34;NSX Firewall New Rules&#34;&gt;&lt;/p&gt;
&lt;p&gt;Click Export and save these as a file.&lt;/p&gt;
&lt;p&gt;Delete the WEB to DB rule.&lt;/p&gt;
&lt;p&gt;To perform a restore we do this from the Saved Configuration tab,  we see that there are only auto saved backups.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-backup-Restore1.jpg&#34; alt=&#34;NSX Firewall Auto-Saved&#34;&gt;&lt;/p&gt;
&lt;p&gt;In order to restore from the file backup we need to import this into the Saved Configurations.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-backup-Restore2.jpg&#34; alt=&#34;NSX Firewall Import Saved&#34;&gt;&lt;/p&gt;
&lt;p&gt;Now we can change back to the Configuration tab and use &amp;lsquo;Load Saved Configuration&amp;rsquo; option to restore the exported file based backup.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-backup-Restore3.jpg&#34; alt=&#34;NSX Firewall Restore&#34;&gt;&lt;/p&gt;
&lt;p&gt;The deleted rule then gets added back.&lt;/p&gt;
&lt;h2 id=&#34;scenario-2---nsx-manager&#34;&gt;Scenario 2 - NSX Manager&lt;/h2&gt;
&lt;p&gt;To backup and restore NSX Manager it depends on having access to a FTP or SFTP to store the configuration in.&lt;/p&gt;
&lt;p&gt;Previously I&amp;rsquo;d created a CentOS7 virtual machine template,  I deployed one of these and then followed this procedure to configure FTP.&lt;/p&gt;
&lt;p&gt;Configure the FTP server settings in NSX.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-backup-nsxBackup.jpg&#34; alt=&#34;NSX Manager Configuration Backup&#34;&gt;&lt;/p&gt;
&lt;p&gt;Once backup location is configured click Backup to create a backup.&lt;/p&gt;
&lt;p&gt;Check the FTP server and it should have a folder called nsx created and within a file prefixed with nsx followed by the date and time stamp.&lt;/p&gt;
&lt;p&gt;Make a change to NSX configuration,  for example assign the NSX Manager the primary role.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-backup-PrimaryRole.jpg&#34; alt=&#34;NSX Manager Assign Primary Role&#34;&gt;&lt;/p&gt;
&lt;p&gt;Check role is applied.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-backup-Primary.jpg&#34; alt=&#34;NSX Manager Is Primary&#34;&gt;&lt;/p&gt;
&lt;p&gt;If we now restore the configuration from the NSX Backup we should see the NSX Manager revert to running the Standalone role.&lt;/p&gt;
&lt;p&gt;Select the backup created prior to making the configuration change and click Restore.  The NSX Manager will restore and then restart the Management Services so will take a minute or two. We can then check the role is reverted to Standalone.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-backup-Standalone.jpg&#34; alt=&#34;NSX Manager Is Standalone&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;scenario-3---vsphere-distributed-switch&#34;&gt;Scenario 3 - vSphere Distributed Switch&lt;/h2&gt;
&lt;p&gt;I have in lab a vSphere Distributed Switch configured with some Distributed Portgroups and Logical Switches created on.  Otherwise you might need to create some configuration.&lt;/p&gt;
&lt;p&gt;Use the context menu of the vDistributed Switch to Export the configuration to a file.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-backup-Export-vDS.jpg&#34; alt=&#34;Export VDS&#34;&gt;&lt;/p&gt;
&lt;p&gt;This creates a compressed zip file,  most files within this are not readable except for an xml file which appears to be a manifest of the zip file.&lt;/p&gt;
&lt;p&gt;To test that the configuration is restored add an additional distributed portgroup named TestRestore1.&lt;/p&gt;
&lt;p&gt;Use the context menu of the vDistributed Switch to Restore the configuration from the file.  Interesting we find that the Portgroup created post backup is not removed.&lt;/p&gt;
&lt;p&gt;If we export the configuration again to include the new TestRestore1 Portgroup. Then delete the TestRestore1 Portgroup. Then Restore the configuration we find the TestRestore1 Portgroup is added back.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-backup-TestRestore.jpg&#34; alt=&#34;Restored VDS&#34;&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>NSX-V Load Balancer As A Service LBaaS</title>
      <link>https://darrylcauldwell.github.io/post/nsx-lbaas/</link>
      <pubDate>Fri, 20 May 2016 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/nsx-lbaas/</guid>
      <description>
        
          &lt;p&gt;As part of study for VCIX-NV I&amp;rsquo;ve given myself task of exploring in my homelab all parts of NSX which I don&amp;rsquo;t use
at work. One of these things is NSX Load Balancer as a Service (LBaaS), to investigate this I came up with a test
scenario and then worked through the steps to achieve a solution to meet the design.&lt;/p&gt;
&lt;h2 id=&#34;load-balancer-scenariodesign&#34;&gt;Load Balancer Scenario Design&lt;/h2&gt;
&lt;p&gt;I started by reading the &lt;a href=&#34;http://pubs.vmware.com/NSX-62/index.jsp#com.vmware.nsx.admin.doc/GUID-412635AE-1F2C-4CEC-979F-CC5B5D866F53.html&#34;&gt;NSX Administration Guide&lt;/a&gt; section covering load balancer configuration.&lt;/p&gt;
&lt;p&gt;Here is what I plan to achieve my client and browser will sit on the 192.168.1.0/24 out of band network.  I&amp;rsquo;ll create a new WEB VLAN 1000 to host 192.168.2.0/24 network,  the Edge Gateway will serve this network with DHCP and DHCP will issue gateway IP to be its own address,  two web server VMs will be assigned to this network.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-lbaas-onearm.jpg&#34; alt=&#34;One Armed Load Balancer&#34;&gt;&lt;/p&gt;
&lt;p&gt;A destination network address translation (DNAT) rule will be configured to pass this OOB network IP address to the load balancerd address on the WEB network. The load balancer will round robin traffic between the two web servers. Port 80 will be monitored on web servers and when apache is stopped on one server all traffic should direct to the active server. The Edge firewall will be configured to block all traffic except for HTTP to the web servers.&lt;/p&gt;
&lt;h2 id=&#34;configure-underlay&#34;&gt;Configure Underlay&lt;/h2&gt;
&lt;p&gt;Create VLAN 1000 on physical switch and ensure this is allowed in the trunk presented to the virtual distributed switch ports.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-lbaas-VLAN1000-Assignment.jpg&#34; alt=&#34;VLAN 1000 Assignment&#34;&gt;&lt;/p&gt;
&lt;p&gt;Create a distributed portgroup for VLAN1000 and OOB.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-lbaas-vDS-OOB-and-WEB.jpg&#34; alt=&#34;Distributed Portgroup&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;deploy-edge-gateway&#34;&gt;Deploy Edge Gateway&lt;/h2&gt;
&lt;p&gt;Create a Compact NSX Edge Gateway with an &lt;em&gt;Uplink&lt;/em&gt; interface on the OOB with IP address 192.168.1.40 and &lt;em&gt;Internal&lt;/em&gt; interface on the WEB - VLAN1000 with IP address 192.168.2.254 .  Specify 192.168.1.254 as default gateway on the OOB interface. Ensure firewall is set to accept as default policy.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-lbaas-EdgeSummary.jpg&#34; alt=&#34;Edge Deployment Summary&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;create-dnat-rule&#34;&gt;Create DNAT Rule&lt;/h2&gt;
&lt;p&gt;As 192.168.2.0/24 is not a network my home router is aware of I must create a Destination NAT rule on 192.168.1.0/24 network to map to the 192.168.2.0/24 address.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-lbaas-DNAT.jpg&#34; alt=&#34;Destination NAT&#34;&gt;&lt;/p&gt;
&lt;p&gt;Ensure this is created by connecting SSH session to the Edge and viewing the NAT configuration by running&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;show nat
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-lbaas-NAT-CLI.jpg&#34; alt=&#34;Destination NAT&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;configure-web-server-dhcp&#34;&gt;Configure Web Server DHCP&lt;/h2&gt;
&lt;p&gt;Enable DHCP and create a DHCP scope 192.168.2.10-192.168.2.50.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-lbaas-DHCP.jpg&#34; alt=&#34;DHCP&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;create-web-servers&#34;&gt;Create Web Servers&lt;/h2&gt;
&lt;p&gt;I&amp;rsquo;ll look to create two test web servers each will host a single web page with its actual IP address on.  When I connect to load balanced IP the page contents returned will flip between the two servers.&lt;/p&gt;
&lt;p&gt;I created a &lt;a href=&#34;https://darrylcauldwell.github.io/post/vsphere-vm-templates&#34;&gt;CentOS 7 VM template&lt;/a&gt; previously in lab and so for this test scenario I provisioned two new VMs from this named web1 and web2.  I left both as DHCP and setup the web server using following commands.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;yum install httpd -y
service httpd start
ifconfig | grep &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;inet&amp;#34;&lt;/span&gt; &amp;amp;gt; /var/www/html/test.html
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;configure-load-balancer&#34;&gt;Configure Load Balancer&lt;/h2&gt;
&lt;p&gt;Enable the load balance function on the Edge.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-lbaas-LoadBalancer-Enable.jpg&#34; alt=&#34;DHCP&#34;&gt;&lt;/p&gt;
&lt;p&gt;Create a load balancer application profile called Web and mark is for HTTP traffic.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-lbaas-LoadBalancer-AppProfile.jpg&#34; alt=&#34;Load Balancer AppProfile&#34;&gt;&lt;/p&gt;
&lt;p&gt;Add web1 and web2 virtual machines to a load balancer pool with monitor port 80.  If adding as VM object as per screenshot then you might have IPv6 issue see section below for solution,  alternatively enter IP address.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-lbaas-LoadBalancer-PoolMembers.jpg&#34; alt=&#34;Load Balancer Pool Membership&#34;&gt;&lt;/p&gt;
&lt;p&gt;Create a load balancer virtual server to link all the parts into a VIP.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-lbaas-WebLB.jpg&#34; alt=&#34;Load Balancer Virtual Server&#34;&gt;&lt;/p&gt;
&lt;p&gt;Once this is created you will be able to browse to http://192.168.1.40/test.html on the OOB network this will return a web page displaying IP address.  Refreshing the page will display a similar page but with alternate VM IP address.&lt;/p&gt;
&lt;h2 id=&#34;nsx-loadbalancer-ipv6-issue&#34;&gt;NSX LoadBalancer IPv6 Issue&lt;/h2&gt;
&lt;p&gt;I found when I configured this initially by selecting VM objects in the Virtual Server the loadbalancer tried to configure all IP addresses including the IPv6 addresses which are present by default in Centos7.  This caused a error in LoadBalancer and wouldn&amp;rsquo;t allow me to proceed.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-lbaas-LoadBalance-IPv6.jpg&#34; alt=&#34;Load Balancer Virtual Server&#34;&gt;&lt;/p&gt;
&lt;p&gt;I disabled IPv6 on both CentOS7 VMs by adding the following to /etc/sysctl.conf:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;net.ipv6.conf.all.disable_ipv6 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
net.ipv6.conf.default.disable_ipv6 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Then run the following to commit the changes.  When VMs had only IPv4 addresses the process works without error.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;sysctl -p
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;secure-solution&#34;&gt;Secure Solution&lt;/h2&gt;
&lt;p&gt;Up to now we have had the Edge firewall default rule set to allow,  one of the first tasks we would want to do once web load balancing is working is to secure the solution.&lt;/p&gt;
&lt;p&gt;To do this we create a new rule explicitly allowing HTTP traffic to the IP address it will enter the Edge on,  and once in place change default rule to Deny.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-lbaas-LB-Firewall.jpg&#34; alt=&#34;Load Balancer Firewall&#34;&gt;&lt;/p&gt;
&lt;p&gt;Once in place test you still have access to the web page.&lt;/p&gt;
&lt;h2 id=&#34;load-balance-monitoring&#34;&gt;Load Balance Monitoring&lt;/h2&gt;
&lt;p&gt;When creating the Loadbalance configuration we specified to monitor port 80 was available in order to include the server in the balanced set. Before proceeding here ensure that when you connect to 192.168.1.40 and refresh load balancing is working correctly and returning IP addresses alternately.&lt;/p&gt;
&lt;p&gt;We then stop the apache service on one of the VMs using:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;service httpd stop
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-lbaas-apache-stop.jpg&#34; alt=&#34;Apache Stop&#34;&gt;&lt;/p&gt;
&lt;p&gt;If we now go back to browser and refresh a few times it will direct all traffic to one server IP address.  If we restart apache using&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;service httpd start
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;and refresh the browser we find load balancing is returned and refreshes alternate the IP addresses.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>NSX Activity Monitoring</title>
      <link>https://darrylcauldwell.github.io/post/nsx-activity/</link>
      <pubDate>Thu, 19 May 2016 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/nsx-activity/</guid>
      <description>
        
          &lt;p&gt;As part of study for VCIX-NV I&amp;rsquo;ve given myself task of exploring all parts of NSX which I don&amp;rsquo;t use at work. One of these things is NSX Activity Monitoring,  to investigate this I came up with a test scenario and then worked through the steps to achieve a solution to meet the scenario design.&lt;/p&gt;
&lt;h2 id=&#34;scenario-design&#34;&gt;Scenario Design&lt;/h2&gt;
&lt;p&gt;Gather traffic data between Activity Monitored virtual machines.&lt;/p&gt;
&lt;h2 id=&#34;virtual-machine-configuration&#34;&gt;Virtual Machine Configuration&lt;/h2&gt;
&lt;p&gt;I created a Windows 2012 R2 virtual machine template previously,  deploy two of these to a network with DHCP enabled for example in my lab the OOB network.&lt;/p&gt;
&lt;p&gt;The Windows template I created has the VMware Tools typical installation performed. To use the NSX Activity Monitoring the Network File Introspection Driver (vnetflt.sys) is required.  To add this we need to re-run the VMware tools installer,  select modify and then add NSX Network File Introspection Driver.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-activity-WindowsDriver.jpg&#34; alt=&#34;Install Windows Driver&#34;&gt;&lt;/p&gt;
&lt;p&gt;Add IIS role to one of the hosts.&lt;/p&gt;
&lt;p&gt;Add server to Active Directory domain and reboot.&lt;/p&gt;
&lt;p&gt;In vSphere web client select each virtual machine in turn and enable NSX Activity Monitoring.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-activity-EnableMonitoring.jpg&#34; alt=&#34;Enable Monitoring&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;deployactivity-monitor-appliances&#34;&gt;Deploy Activity Monitor Appliances&lt;/h2&gt;
&lt;p&gt;From the Networking and Security menu, select Installation. Navigate to the Service Deployments tab and glick green add button.&lt;/p&gt;
&lt;p&gt;In order to gather activity data virtual appliances are required to be deployed.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-activity-DeployActivityServices.jpg&#34; alt=&#34;Deploy Virtual Appliances&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;register-a-windows-domain-with-nsx-manager&#34;&gt;Register a Windows Domain with NSX Manager&lt;/h2&gt;
&lt;p&gt;In vSphere web client click Networking and Security and then click NSX Managers. Click an NSX Manager in the Name column and then click the Manage tab. Click the Domain tab and then click the Add domain (Add domain) icon.&lt;/p&gt;
&lt;p&gt;Complete the domain details as per your Active Directory.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-activity-Add-Domain.jpg&#34; alt=&#34;Add Domain&#34;&gt;&lt;/p&gt;
&lt;p&gt;Wait for synchronization status to show SUCCESS.&lt;/p&gt;
&lt;h2 id=&#34;generate-activity&#34;&gt;Generate Activity&lt;/h2&gt;
&lt;p&gt;Connect to test virtual machine which &lt;!-- raw HTML omitted --&gt;does not&lt;!-- raw HTML omitted --&gt; have IIS installed and open browser to virtual machine with IIS installed.&lt;/p&gt;
&lt;p&gt;Test data is being gathered by Activity Monitor.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-activity-ActivityMonitorActivity.jpg&#34; alt=&#34;Activity Monitor Activity&#34;&gt;&lt;/p&gt;
&lt;p&gt;Another easy test is to copy a file between the two virtual machines.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-activity-ActivityMonitorSMB-CIFS.jpg&#34; alt=&#34;Activity Monitor Activity&#34;&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Create VMware Virtual Machine Templates</title>
      <link>https://darrylcauldwell.github.io/post/vsphere-vm-templates/</link>
      <pubDate>Tue, 17 May 2016 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/vsphere-vm-templates/</guid>
      <description>
        
          &lt;p&gt;When creating virtual machine templates I&amp;rsquo;d like to do this consistently as such I&amp;rsquo;ll try and keep this post up to date with the settings I am including.&lt;/p&gt;
&lt;h2 id=&#34;centos-7&#34;&gt;CentOS 7&lt;/h2&gt;
&lt;p&gt;New custom VM named CentOS7, hardware version 11, guest operating system Linux version &amp;lsquo;CentOS 4/5/6/7 (64-bit)&amp;rsquo;. We&amp;rsquo;d like a small template which we expand if required, so single virtual socket with single core, 2GB virtual memory, one VMXNET3 NIC, default LSI Logic Parallel SCSI controller with a thin 16GB hard disk and mount CentOS7 ISO as CD-ROM.&lt;/p&gt;
&lt;p&gt;Power on VM and open console, ensure you change NIC to connected and enter password otherwise leave all as default and install. Now I install common tools to use within lab, so once installed reboot and logon still using remote console.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;yum install open-vm-tools net-tools epel-release gcc git
yum update
cp -f /etc/sysconfig/network-scripts/ifcfg-eth0 /tmp/eth0
sed &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/^HWADDR/d&amp;#34;&lt;/span&gt; /tmp/eth0 &amp;amp;gt; /etc/sysconfig/network-scripts/ifcfg-eth0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Shutdown the virtual machine and convert to template using vCenter.&lt;/p&gt;
&lt;h2 id=&#34;windows-2012-r2&#34;&gt;Windows 2012 R2&lt;/h2&gt;
&lt;p&gt;New custom VM named Win2012R2, hardware version 11, guest operating system Windows version &amp;lsquo;Microsoft Windows Server 2012 (64-bit)&amp;rsquo;. We&amp;rsquo;d like a small template which we expand if required, so single virtual socket with single core, 4GB virtual memory, one VMXNET3 NIC, default LSI Logic SAS SCSI controller with a thin 40GB hard disk and mount Windows 2012 R2 ISO as CD-ROM.&lt;/p&gt;
&lt;p&gt;Power on VM and open console, select Datacenter Edition with GUI and enter password otherwise leave all as default and install. Once installed rebooted logon and perform Typical VMware tools install.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Apply MSDN License Key and Active Windows&lt;/li&gt;
&lt;li&gt;Disable IE Enhanced Security&lt;/li&gt;
&lt;li&gt;Use Windows Update to apply all current patches, repeat until all dependant patches are installed.&lt;/li&gt;
&lt;li&gt;Copy \Sources\SxS folder from CD-ROM to C:\&lt;/li&gt;
&lt;li&gt;As some Updates will update .net we should force the Assemblies to get updated&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;%&lt;/span&gt;windir%\Microsoft.NET\Framework\v4.0.30319\ngen.exe update /force
&lt;span style=&#34;color:#66d9ef&#34;&gt;%&lt;/span&gt;windir%\Microsoft.NET\Framework64\v4.0.30319\ngen.exe update /force&amp;lt;/code&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Shutdown the virtual machine and convert to template using vCenter.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>vCloud Director REST API</title>
      <link>https://darrylcauldwell.github.io/post/vcd-rest/</link>
      <pubDate>Sat, 16 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/vcd-rest/</guid>
      <description>
        
          &lt;p&gt;If you find the vCloud Director GUI a little annoying a nice way to get the information you need is via the REST API. Using the REST API you can gather information (GET), update information (PUT) and call operational methods like (POST).&lt;/p&gt;
&lt;p&gt;There are many ways you would call the REST API,  if you want to control this programmatically you would be aiming to orchestrate a series of curl commands to issue your GET, PUT and POST commands with the parameters you want to achieve the task you need.&lt;/p&gt;
&lt;p&gt;In order to build the syntax for your curl commands there are browser plugins which allow you to work out what you need to do manually.  If you use Chrome the best I’ve found is &lt;a href=&#34;https://chrome.google.com/webstore/detail/postman-rest-client/fdmmgilgnpjigdojojpjoooidkmcomcm&#34;&gt;PostMAN&lt;/a&gt;,  the only thing which annoys me about this is it doesn’t seem to have an option to save your custom header info, so I tend to use Firefox and the &lt;a href=&#34;https://addons.mozilla.org/en-US/firefox/addon/restclient/W0Sqc4ZY642oFbg&amp;amp;bvm=bv.83829542,d.d2s&#34;&gt;RESTClient plugin&lt;/a&gt; and with that you can save favorites and add and remove these as needed quickly and easily.&lt;/p&gt;
&lt;p&gt;I’ll explain remaining of this assuming you are using Firefox RESTclient.&lt;/p&gt;
&lt;p&gt;Within RESTclient click Authentication and choose Basic Authentication then complete form
Username:    user@organization
Password:    password&lt;/p&gt;
&lt;p&gt;Select Remember Me if you want to save this for future use.&lt;/p&gt;
&lt;p&gt;Within RESTclient click Headers choose Custom Header&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;Name:        Accept
Value:       application/*+xml;version&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;5.5
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Click “Save To Favorites“.&lt;/p&gt;
&lt;p&gt;Note where reads 5.5 could read 1.5 or 5.1 if your connecting to earlier versions of vCD.&lt;/p&gt;
&lt;p&gt;Change Method To POST and enter URL https://{vcloud ip}/api/sessions&lt;/p&gt;
&lt;p&gt;Your completed form should look a little like this.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/vcd-sessions.png&#34; alt=&#34;vCloud Director Sessions&#34;&gt;&lt;/p&gt;
&lt;p&gt;This should return a 200 OK and forms your a session token with VCD,  at this point your now authorized to perform any action via REST as your account allows via the GUI.&lt;/p&gt;
&lt;p&gt;To test this you might want to list all vApps,  to do this you would ensure method is set to GET and enter a URL to:
https://{vcloud ip}/api/vApps/query&lt;/p&gt;
&lt;p&gt;For a full list of GET, PUT and POST API calls VMware documents them
&lt;a href=&#34;http://pubs.vmware.com/vcd-55/topic/com.vmware.vcloud.api.reference.doc_55/doc/index.html&#34;&gt;here.&lt;/a&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>DevOps != Products</title>
      <link>https://darrylcauldwell.github.io/post/devops/</link>
      <pubDate>Tue, 06 Oct 2015 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/devops/</guid>
      <description>
        
          &lt;p&gt;The last 10 to 20 years in the enterprise has been defined by increasing capital spending on fixed assets (CapEx) while reducing the cost of staffing and operations (OpEx).  Gartner report the growth of spend on enterprise application software (EAS) is continuing to grow and in 2015 will grow at &lt;a href=&#34;http://www.gartner.com/newsroom/id/3119717&#34;&gt;7.5% to $149.9 Billion&lt;/a&gt;.  According to the &lt;a href=&#34;https://hbr.org/2011/09/why-your-it-project-may-be-riskier-than-you-think/ar/1&#34;&gt;Harvard Business Review&lt;/a&gt; one in six IT projects had an average cost overrun of 200% and a schedule overrun of 70%.&lt;/p&gt;
&lt;p&gt;Some companies who provide solutions to enterprise businesses have continued to use the same delivery model they have used for years,  of investing in products (increase CapEx) and reducing people count and replacing high skilled workers with fewer, low cost, lower skilled workers (reducing OpEx). The current levels of under staffing in IT teams lead to constant firefighting that leaves no energy, time or motivation to conduct fire prevention. A common reason heard for buying product to meet a requirement is that the IT staff don&amp;rsquo;t have the time or skills, but they rarely consider where the skills are created ? Who gave those people the time, scope and resources to develop those skills? Training an upskilling builds employee loyalty, new skills of existing employee allows them to quickly realise business benefit, bringing in new hires with skills which are out of context take longer to realize business benefits.&lt;/p&gt;
&lt;p&gt;Other companies have realized the legacy model is broken and have made pivot to lower CapEx spend by the use of open source products hosted on IaaS in the cloud. The effective use of open source products ran to host production services within the cloud increases complexity and as the products are open source and self supported increases the requirement for a highly skilled and highly motivated workforce. The companies who are choosing to invest in people rather than hardware and products to deliver the requirements of business are excelling in the industry as they have improved service agility. Service agility means they can pivot quickly to quickly deliver new features to there customer,  they can scale out on demand to give the required density at the right time and also give great visibility. The success of these cloud native companies shows that over-investment in people NOT over-investment in products produces real increases in productivity.  The other factor about these companies to note is that with a small workforce of highly skilled engineers everyone is required to cover each other, the developers needed to understand the operational requirements and the operations an intimate knowledge of the requirements of the application.  This close relationship and shared empathy between developer and operator is in essence to me what the DevOps culture is.&lt;/p&gt;
&lt;p&gt;Choosing people over products is not limited to the cloud native application space,  cloud providers make huge investment in hardware and software and the scale at which they work to deliver effectively means they need to draw every ounce of productivity out of there hardware investment.  To do this requires again very highly skilled, highly motivated employeers,  examples of success in this area have been Facebook and there founding of the &lt;a href=&#34;http://www.opencompute.org/about/&#34;&gt;Open Compute Project&lt;/a&gt;, the &lt;a href=&#34;http://research.google.com/pubs/pub43438.html&#34;&gt;Google borg project&lt;/a&gt;,  &lt;a href=&#34;https://aws.amazon.com/about-aws/global-infrastructure/&#34;&gt;AWS&lt;/a&gt; and Azure.&lt;/p&gt;
&lt;p&gt;The growth of the enterprise application software (EAS) and the purchase promise of the EAS product vendors to reduce the cost of ownership through faster performance, better features, better software and usability and see that the enterprise fails to deliver large projects. Then consider the success of cloud native companies and DevOps culture,  it leads us to the conclusion that enterprise IT needs to change fundamentally in how they make decisions.&lt;/p&gt;
&lt;p&gt;We can summaries &amp;lsquo;DevOps = People&amp;rsquo; and therefore &amp;lsquo;DevOps != Products&amp;rsquo;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Project Bonneville - vSphere Integrated Containers</title>
      <link>https://darrylcauldwell.github.io/post/vic-bonneville/</link>
      <pubDate>Tue, 06 Oct 2015 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/vic-bonneville/</guid>
      <description>
        
          &lt;p&gt;Working for a company which develops software for business I&amp;rsquo;ve been keen on following the story of containers unfold. The explosion of containers and microservices in the software development space has been a revolution in the way applications can be architected and deployed. This has put a great deal of power in the hands of the developer but with great power comes great responsibility for operational management.&lt;/p&gt;
&lt;p&gt;Working in the operational side the key words to my working life are Availability, Reliability, Maintainability, Supportability and Security. The operational model to effectively run containers in production requires a paradigm shift where the approach and underlying assumptions are revisited. Working in a company promoting DevOps culture and values we in the operational side are beginning to gain greater empathy to the challenges a developer faces and how they believe containers will help. Gaining a technical understanding of Docker has therefore become a priority so I can ensure the infrastructure I design and engineer can help the developer deliver not only velocity but help them to deliver Availability, Reliability, Maintainability, Supportability and Security.&lt;/p&gt;
&lt;p&gt;During &lt;a href=&#34;https://darrylcauldwell.github.io/post/fargo&#34;&gt;VMworld 2014 project Fargo (VMfork)&lt;/a&gt; was described which has become the Instant Clone feature of vSphere 6. At the time I didn&amp;rsquo;t take too much notice as this was signed to virtual desktop space.  During April this year VMware released project Photon which is essentially a minimal Linux container host,  at the time this was confusing to me as RedHat Atomic, Ubuntu Snappy and CoreOS seemed to have all bases covered in this space. That is until two months later when Ben Corrie of VMware announced project Bonneville to the world.&lt;/p&gt;
&lt;p&gt;The fundamental to this solution is a 1:1 model between container host and containers rather than one host with many containers. Project Bonneville is a Docker daemon that has custom drivers for networks and execution that is compatible with the Docker Client APIs, and that means a vSphere VM is treated exactly like a Docker container. With this it redefined a Docker container as a x86 hardware virtualised VM, (not tied to host running the Linux kernel), a Bonneville VM can theoretically run containers of any kernel version of any operating system and can do it fast and efficiently.&lt;/p&gt;
&lt;p&gt;‘Instant Clone’ also known as VMfork or Project Fargo, gives the ability to clone and deploy virtual machines, as much as 10x faster than what is currently possible before. It does this by using rapid in-memory cloning of running virtual machines and copy-on-write to quickly deploy clones of a parent virtual machine. Using this clone method of the container host ensures the only changed blocks and memory pages are those used by container itself this.&lt;/p&gt;
&lt;p&gt;A fantastic architecture flow of how Bonneville might work is described in this diagram as posted by George Hicken @hickeng.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/vic-bonneville.png&#34; alt=&#34;vSphere Integrated Containers&#34;&gt;&lt;/p&gt;
&lt;p&gt;The benefits this technology appears to offer appear fantastic and I am really looking forwards to attending Ben Corrie&amp;rsquo;s session &amp;lsquo;INF5229 — Docker and Fargo: Exploding the Linux Container Host&amp;rsquo; to solidify my understanding and learn more about how we can begin exploiting this to help our developers deliver Availability, Reliability, Maintainability, Supportability and Security alongside the awesome features they write.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>VMware Projects Fargo (VMFork) &amp; Meteor</title>
      <link>https://darrylcauldwell.github.io/post/fargo/</link>
      <pubDate>Tue, 06 Oct 2015 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/fargo/</guid>
      <description>
        
          &lt;p&gt;There was announced during VMworld a technology preview for Project Fargo (formerly VMFork) it is likely this will be launched with vSphere6. The aim of Fargo is to provides a fast, scalable differential clone of a running VM.  I see this as very similar to Redirect-on-Write (RoW) methodology used by NetApp snapshots where at the point of snap the existing blocks are frozen and any writes (creations/changes/deletions) are redirected to new blocks. However with Fargo rather than than a snapshot we are creating a Copy-on-Write(CoW) the difference being that with CoW the original data that is being written to is copied into a new file that is set aside for the snapshot before original data is overwritten. So before a write is allowed to a block, copy-on-write moves the original data block to the snapshot storage.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/fargo-cow.gif&#34; alt=&#34;Copy On Write&#34;&gt;&lt;/p&gt;
&lt;p&gt;The key benefits of the use of this method is that its near instantaneous and can be done from a running VM,  so a new VM spawned would typically take less than 1 second and be in the same running state. As well as this as only changed blocks are written the solution will take up dramatically less disk space.&lt;/p&gt;
&lt;p&gt;While there are many potential use cased for Fargo it was presented with virtual desktop in mind where providing an instant clone of running non-persistent desktop would avoid the boot storms to the storage subsystem.&lt;/p&gt;
&lt;p&gt;So now you have quick provisioning of operating system you then need to deliver the right user applications to it quickly and this is I assume to be done by &lt;a href=&#34;http://blogs.vmware.com/euc/2014/08/cloudvolumes.html&#34;&gt;CloudVolumes&lt;/a&gt; where applications are abstracted and layered onto the users operating system.  The combination of these two tools appears to be known as Project Meteor.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>NSX Distributed Firewall Under The Covers</title>
      <link>https://darrylcauldwell.github.io/post/nsx-dfw/</link>
      <pubDate>Tue, 21 Jul 2015 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/nsx-dfw/</guid>
      <description>
        
          &lt;p&gt;An NSX distributed firewall (dFW) runs as an ESXi host as a kernel module added as a VMware Installation Bundle (VIB). The dFW rules operate on Layer 2 through Layer 4; although this can be extended through Layer 7 by integrating with a 3-Party vendor.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;L2 rules are based on MAC address L2 protocols like ARP, RARP and LLDP etc.&lt;/li&gt;
&lt;li&gt;L3 and 4 rules are based on IP source/destination and L4 uses a TCP or UDP ports.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/dFW_TCP_OSI.png&#34; alt=&#34;TCP OSI&#34;&gt;&lt;/p&gt;
&lt;p&gt;The NSX dFW enforces a state full firewall service for VMs using the vNIC as the enforcement point. Every packet that leaves the VM (before VTEP encapsulation) or enters the VM (After VTEP de-encapsulation) can be inspected with a firewall policy.&lt;/p&gt;
&lt;p&gt;The ruleset is created and managed via NSX Manager either API or UI. The ESXi host has two dFW specific modules vShield Statefull Firewall and VMware Internetworking Service Insertion Platform (vSIP). vShield Statefull Firewall performs the following roles.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Interact with NSX Manager to retrieve DFW policy rules.&lt;/li&gt;
&lt;li&gt;Gather DFW statistics information and send them to the NSX Manager.&lt;/li&gt;
&lt;li&gt;Send audit logs information to the NSX Manager.&lt;/li&gt;
&lt;li&gt;Receive configuration from NSX manager to create (or delete) DLR Control VM, create (or delete) ESG.&lt;/li&gt;
&lt;li&gt;Part of the host preparation process SSL related tasks from NSX manager&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;VMware Internetworking Service Insertion Platform is the distributed firewall kernel space module core component. The vSIP receives firewall rules via vShield State-full Firewall and downloads them down to each VMware-sfw. When VM connect to Logical switch there are security services each packet transverse which are implemented as IOChains processed at the Kernel level.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/dFW_Slots.png&#34; alt=&#34;TCP OSI&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Slot 0: Distributed Virtual Filter (DVFilter): It monitors the incoming and outgoing traffic on the protected virtual NIC and performs stateless filtering.&lt;/li&gt;
&lt;li&gt;Slot 1: Switch Security module (SW-sec): Learns VMs IP and MAC address. sw-sec is critical component capture DHCP Ack and ARP broadcast message and forward this info as unicast to NSX Controller to perform the ARP suppression feature. This is also the layer where NSX IP spoof guard is implemented.&lt;/li&gt;
&lt;li&gt;Slot 2: NSX Distributed Firewall (VMware-sfw): This is the place where DFW firewall rules are stored and enforced; VMware-sfw contains rules table and connections table received via vShield State-full Firewall&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The effect of the processing of these packets is that packet leaving the VM which doesn’t match firewall rules get removed before arriving at the vSphere Switch.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>What is Virtustream xStream Cloud</title>
      <link>https://darrylcauldwell.github.io/post/virtustream/</link>
      <pubDate>Tue, 21 Jul 2015 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/virtustream/</guid>
      <description>
        
          &lt;p&gt;If you are an IT consumer with Enterprise workload it is a risk moving this workload to the cloud,  how can you guarantee your potential future cloud provider is delivering you the service you require and once there how can you measure how well they are achieving delivering that service.&lt;/p&gt;
&lt;h2 id=&#34;what-is-a-micro-vm-uvm&#34;&gt;What Is A Micro VM (uVM)&lt;/h2&gt;
&lt;p&gt;A Micro VM (uVM) is a measure mechanism used to define the resource consumption of a collection of running virtual machine,  it does not matter if the the virtual machine could be running on vSphere or KVM,  and it does not mater what operating systems the virtual machine is running be it Windows \ Linux.&lt;/p&gt;
&lt;p&gt;The virtual machine resource usage is measured in the Micro VM unit,  the standard unit size used here is&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1 CPU Unit = 200MHz&lt;/li&gt;
&lt;li&gt;1 RAM Unit = 768MB&lt;/li&gt;
&lt;li&gt;1 IO Unit (Storage or Network) = 40 IO&lt;/li&gt;
&lt;li&gt;1 Bandwidth Unit = 2 Mb/s&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you take a collection of servers running differing workloads which combine to provide an application service you can use a consistent measurement metric across these to measure the resources required to deliver that service. So whether it is a a single app and single database server,  or it maybe a hundred different servers running a hundred different pieces of different software, the running capacity it consumes can be given as a consistent metric.&lt;/p&gt;
&lt;h2 id=&#34;what-is-virtustream-xstream&#34;&gt;What Is Virtustream xStream&lt;/h2&gt;
&lt;p&gt;Virtustream is a IaaS cloud provider as well they have produce software called xStream which they use to monitor and measure there own IaaS cloud,  but they also offer this product to measure and monitor other clouds (private, public or hybrid).&lt;/p&gt;
&lt;p&gt;With a consistent independent metric of a uVM established you can create boundaries around normal usage range and factor in peak workload to form logical application resource groups, these resource groups can then be measured against service level agreements to ensure the cloud provider is delivering the resources.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Configuring Network Core Dump With PowerCLI</title>
      <link>https://darrylcauldwell.github.io/post/core-dump/</link>
      <pubDate>Wed, 17 Jun 2015 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/core-dump/</guid>
      <description>
        
          &lt;p&gt;The VMware vSphere Network Dump Collector service enables a host to transmit diagnostic information via the network to a remote netdump service, which stores it on disk. Network-based coredump collection can be configured in addition to or instead of disk-based coredump collection. This may be useful in stateless environments with no local disk usable for a diagnostic partition.&lt;/p&gt;
&lt;p&gt;vSphere ESXi Dump Collector service pre-packaged with the vSphere vCenter Server Virtual Appliance, and if vCenter on Windows vSphere ESXi Dump Collector typically is installed on same server.&lt;/p&gt;
&lt;p&gt;It is a little bit of a pain to configure this on every server, so I wrote this little script to get all hosts and then configure each ESXi host registered with vCenter to point its core dumps to the vCenter.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;Add-PSSnapin VMware.VimAutomation.Core
$vcenter = &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;
Connect-VIServer $vcenter
&lt;span style=&#34;color:#66d9ef&#34;&gt;foreach&lt;/span&gt;($vmhost &lt;span style=&#34;color:#66d9ef&#34;&gt;in&lt;/span&gt; Get-VMHost){
$esxcli = Get-EsxCli -VMHost $vmhost.Name
$esxcli.system.coredump.network.set($null,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;vmk0&amp;#34;&lt;/span&gt;,$vcenter,6500)
$esxcli.system.coredump.network.set(1)
$esxcli.system.coredump.network.get()
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
        
      </description>
    </item>
    
    <item>
      <title>Docker On Photon On vCloud Air</title>
      <link>https://darrylcauldwell.github.io/post/docker-photon/</link>
      <pubDate>Thu, 04 Jun 2015 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/docker-photon/</guid>
      <description>
        
          &lt;p&gt;There has been a lot of industry noise around Docker and VMware project Photon so these have been on the agenda to explore as well.  I generally perform my little research projects running nested ESXi on VMware Fusion on my laptop, but VMware are &lt;a href=&#34;http://vcloud.vmware.com/uk/service-offering/virtual-private-cloud-ondemand&#34;&gt;offering £300 of free service credits&lt;/a&gt; for trialing vCloud Air OnDemand.  Here is my how to guide of the steps I used.&lt;/p&gt;
&lt;h2 id=&#34;vcloud-air-networking&#34;&gt;vCloud Air Networking&lt;/h2&gt;
&lt;p&gt;This post assumes your starting with a clean vCloud Air account,  obviously you may already have vCloud Air networking setup,  if so there is no need for this section as long as the Photon and test nexted ESXi VM sit on a common broadcast network this should be fine.&lt;/p&gt;
&lt;p&gt;First task would be to setup a &amp;lsquo;Virtual Private Cloud OnDemand&amp;rsquo; this you create in a location close to you for me thats Slough, UK,  this will create virtual datacenter with &amp;lsquo;default-routed-network&amp;rsquo; (192.168.109.1/24).&lt;/p&gt;
&lt;h2 id=&#34;create-photon-vapp&#34;&gt;Create Photon vApp&lt;/h2&gt;
&lt;p&gt;Surprisingly there is no Photon vApp Template available in the vCloud Air public catalog,  they do however provide the photon-1.0TP1.iso.  So first task is to navigate to vCloud Director, Catalog view and create  new personal Catalog called &amp;lsquo;Photon&amp;rsquo; then navigate to the Public Catalog \ Media tab and copy the Photon ISO to your new personal Catalog.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;While in vCloud Director navigate to My Cloud and &amp;lsquo;Build New vApp&amp;rsquo;&lt;/li&gt;
&lt;li&gt;Within the new vApp add a VM called &amp;lsquo;photon&amp;rsquo;&lt;/li&gt;
&lt;li&gt;Change its OS to &amp;lsquo;Other 3.x Linux (64-bit)&amp;rsquo;&lt;/li&gt;
&lt;li&gt;Increase memory to 2vCPU, 2GB vRAM and vHDD to 40GB&lt;/li&gt;
&lt;li&gt;Change network to &amp;lsquo;default-routed-network&amp;rsquo;, &amp;lsquo;Static - Manual&amp;rsquo; &amp;lsquo;192.168.109.100&amp;rsquo;&lt;/li&gt;
&lt;li&gt;Ensure &amp;lsquo;Organization VDC network&amp;rsquo; is selected and NOT &amp;lsquo;vApp network&amp;rsquo;&lt;/li&gt;
&lt;li&gt;Attach the Photon ISO as CDROM and power on.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;base-photon-configuration&#34;&gt;Base Photon Configuration&lt;/h2&gt;
&lt;p&gt;Open remote console to the Photon VM and it should be at boot menu.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/docker-photon.jpg&#34; alt=&#34;Photon OS&#34;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;From boot menu select Install&lt;/li&gt;
&lt;li&gt;Accept EULA,  and defaults through disk partitioning&lt;/li&gt;
&lt;li&gt;At installation type select &amp;lsquo;3. Photon Full OS (All).&lt;/li&gt;
&lt;li&gt;Give hostname &amp;lsquo;photon.local&amp;rsquo; and give a root password (NextGEN1!)&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;configure-ssh-inbound&#34;&gt;Configure SSH Inbound&lt;/h1&gt;
&lt;p&gt;So next you might not want to use the vCloud Air console to access Photon,  you will probably want to use a SSH client and connect directly.  So to do that we would need to create a &amp;lsquo;Network Address Translation&amp;rsquo; NAT rule to link the vCloud Air externally published IP address with the internal IP address.  There are two types of NAT rule, SNAT and DNAT,  we will be looking to configure DNAT as the traffic is traveling from the Internet (the source) to a virtual machine inside vCloud Air (the destination).&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Once booted,  connect to console and logon with root and password.&lt;/li&gt;
&lt;li&gt;Use &lt;a href=&#34;http://www.virten.net/2015/04/basic-commands-for-vmware-photon-and-docker/&#34;&gt;this post&lt;/a&gt; to enable SSH and set static IP address to 192.168.109.100/24 with gateway of 192.168.109.1.&lt;/li&gt;
&lt;li&gt;If we navigate to vCloud Director view &amp;lsquo;Administration&amp;rsquo; tab,  select vDC in the left pane and choose &amp;lsquo;Edge Gateway&amp;rsquo; in the right pane.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/docker-photon-vCD_Gateway.jpg&#34; alt=&#34;vCloud Director Gateway&#34;&gt;&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;Select &amp;lsquo;gateway&amp;rsquo; and select the Action for &amp;lsquo;External IP Allocations&amp;rsquo;,  note down the external IP address.&lt;/li&gt;
&lt;li&gt;Ensure &amp;lsquo;gateway&amp;rsquo; still selected and select the Action for &amp;lsquo;Edge Gateway Services&amp;rsquo;,  change to the NAT tab,  and click &amp;lsquo;Add DNAT&amp;rsquo;,  change applied to to your network add the External IP address as you noted just before,  select port 22 (SSH) for Outgoing and Translated ports,  and give the Photon IP address as the Internal IP.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/docker-photon-Air_NAT.jpg&#34; alt=&#34;vCloud Director NAT&#34;&gt;&lt;/p&gt;
&lt;ol start=&#34;6&#34;&gt;
&lt;li&gt;Ensure &amp;lsquo;gateway&amp;rsquo; still selected and select the Action for &amp;lsquo;Edge Gateway Services&amp;rsquo;,  change to the firewall tab and add ingress firewall rule called SSH-In from external to specific IP 192.168.109.100 port 22.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/docker-photon-Air_FW.jpg&#34; alt=&#34;vCloud Director Firewall&#34;&gt;&lt;/p&gt;
&lt;ol start=&#34;7&#34;&gt;
&lt;li&gt;If all has gone to plan you should now be able to connect from a remote SSH client.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/docker-photon-Remote_SSH.jpg&#34; alt=&#34;SSH Remote Shell&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;enable-vcloud-air-vm-internet-access&#34;&gt;Enable vCloud Air VM Internet Access&lt;/h2&gt;
&lt;p&gt;To enable our vCloud Air VMs to access the internet we need to configure a NAT rule to handle the private to public address and also a firewall rule to allow the traffic.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Add a source NAT rule,  for Original Source enter 192.168.109.0/24 and for Translated Source select your public IP address.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/docker-photon-SNAT.png&#34; alt=&#34;Source NAT&#34;&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Add a firewall rule to allow all traffic outbound,  give it name Any-Out,  Source as &amp;lsquo;Internal&amp;rsquo; and destination &amp;lsquo;External&amp;rsquo;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/docker-photon-FW_Out.png&#34; alt=&#34;Outbound Firewall&#34;&gt;&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Your Photon VM should now be able to talk to the Internet&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/docker-photon-nslookup.png&#34; alt=&#34;Outbound Connectivity Test&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;docker&#34;&gt;Docker&lt;/h2&gt;
&lt;p&gt;Docker itself is included in the Photon image so with Internet connectivity you can pull things from public repositories and away you go.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Log Insight for VMware Integrated OpenStack</title>
      <link>https://darrylcauldwell.github.io/post/vrli-openstack/</link>
      <pubDate>Thu, 23 Apr 2015 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/vrli-openstack/</guid>
      <description>
        
          &lt;p&gt;vRealize Log Insight is not a product I have had much to do with up to now,  but that changed a few days ago when I was asked to perform an evaluation of how Log Insight might help with the management and administration of VMware Integrated OpenStack environment.&lt;/p&gt;
&lt;p&gt;So lets start what is vRealize Log Insight, in essence it is a tool for aggregating the viewing of all the log files from all aspects of your infrastructure. It delivers real-time log management, with machine learning-based Intelligent Grouping, and high performance search. While it is a VMware product it is fully extensible and can receive log files from any product,  the product vendor then writes a Log Insight content pack to give the intelligence to identify good and problem states.&lt;/p&gt;
&lt;p&gt;The environment I was given already had Log Insight 2.0A deployed, some of the content packs I was exploring for VMware Integrated OpenStack required the latest Log Insight 2.5.  Here I detail the &amp;lsquo;how to&amp;rsquo; steps I followed for upgrading Log Insight and then adding the content packs.&lt;/p&gt;
&lt;h2 id=&#34;log-insight-20a-to-25-upgrade&#34;&gt;Log Insight 2.0A to 2.5 Upgrade&lt;/h2&gt;
&lt;p&gt;The OpenStack content pack only supports Log Insight 2.5,  so to install this my first task is to upgrade Log Insight
itself,  this is is surprisingly easy.  Simply obtain a copy of the vRealize Log Insight upgrade bundle .pak file from &lt;a href=&#34;https://my.vmware.com/web/vmware/downloads&#34;&gt;VMware Downloads&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Connect to Log Insight as admin,  once connected select &amp;lsquo;Administration&amp;rsquo; from the menu icon in very top right corner, upload PAK file,  click Upgrade.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/vrli-openstack-LogInsightUpgrade.jpg&#34; alt=&#34;Log Insight Upgrade&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;installing-openstack-log-insight-content-pack&#34;&gt;Installing OpenStack Log Insight Content Pack&lt;/h2&gt;
&lt;p&gt;There are two methods for installing content packs,  the first is via the Log Insight itself,  it has a market place feature which connects to the internet to get the list of available Content Packs you then click install and the tool does the rest.  While my test environment had internet access I could have used this,  but as most production workload is isolated from internet instead I opted for the offline method. The OpenStack content pack is downloadable from &lt;a href=&#34;https://solutionexchange.vmware.com/store/products/openstack-content-pack&#34;&gt;Solutions Exchange&lt;/a&gt;. It comes as a small zip file,  within the zip is a vlcp file,  extract this.&lt;/p&gt;
&lt;p&gt;Connect to Log Insight as admin,  once connected select &amp;lsquo;Content Packs&amp;rsquo; from menu icon in very top right corner,  select &amp;lsquo;Import Content Pack&amp;rsquo;,  you get the option now to install as a content pack (available to all) or into my content (available only to user importing).  Click Browse and find the extracted OpenStack vlcp file and click Import.&lt;/p&gt;
&lt;p&gt;I was surprised to find that the content pack did not require configuring with keystone location or credentials, I assume it picks these up from something VIO adds to vCenter, but it just worked which is great.&lt;/p&gt;
&lt;h2 id=&#34;installing-nsx-log-insight-content-pack&#34;&gt;Installing NSX Log Insight Content Pack&lt;/h2&gt;
&lt;p&gt;VMware Integrated Openstack uses NSX-MH,  so I installed NSX content pack,  it didn&amp;rsquo;t appear to get any data,  I was surprised to find when looking a little closer and speaking to our TAM that the current version of the content pack (v1.0) is NSX-V only.&lt;/p&gt;
&lt;h2 id=&#34;installing-arista-eos-switch-log-insight-content-pack&#34;&gt;Installing Arista-EOS Switch Log Insight Content Pack&lt;/h2&gt;
&lt;p&gt;Our VMware Integrated Openstack uses Arista EOS switches,  these integrate with NSX,  and Arista provide Content Pack, I used the same method as above to add the content pack to Log Insight.&lt;/p&gt;
&lt;p&gt;The Arista EOS switches don&amp;rsquo;t support Log Insight by default but they are extensible and Arista provide a Log Insight agent by way of an rpm file,  this is copied and installed to all of the switch&amp;rsquo;s and the loginsight.yaml file is then updated with the IP address of Log Insight server and the level of logging to perform.&lt;/p&gt;
&lt;h2 id=&#34;exploring-log-insight&#34;&gt;Exploring Log Insight&lt;/h2&gt;
&lt;p&gt;Having the power to look across every log file in the estate from a single pane of glass is hard to quantify until you start to work through an issue. The thing VMware have succeeded in doing with this product is keeping the view as clean and uncluttered as possible but still giving all and more of the required functionality.  All content packs provide a default dashboard view constructed to highlight the areas of there product which they believe would be of interest. Navigation in the dashboard view between content packs is via a menu at the top of the left pane,  once selected the left pane gives all of the sub dashboards you can see here OpenStack provides eleven dashboards one for each project.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/vrli-openstack-LI_OS.png&#34; alt=&#34;Log Insight OpenStack&#34;&gt;&lt;/p&gt;
&lt;p&gt;You can use these dashboards to get a general idea about health,  but also you&amp;rsquo;ll have occurrences where users report an issue and you need to investigate.  Maybe a incident ticket got logged and it took a day or so to come through to you,  the dashboards show default last five minutes,  these can be set to show last hour,  last six hours or last twenty four hours,  but the most useful might be a custom time window.  The custom time window could be used to pick the day the issue occurred and it would update the dashboard to show what was going on in the log files at that time.  Here you might see a spike in events and want to drill in to the detail,  so you can just click on the spike and change to interactive view and it will display all the log entries for all components being managed which relating to that spike.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/vrli-openstack-LI_IV.jpg&#34; alt=&#34;Log Insight Interactive View&#34;&gt;&lt;/p&gt;
&lt;p&gt;Once in the interactive view you have several options in the bottom pane to adjust the view,  the default view is &amp;lsquo;Events&amp;rsquo; as name suggests this lists all event entries.  If you change to &amp;lsquo;Field Table&amp;rsquo; this gives a little more structure to the view by separating out each part into a column.  The &amp;lsquo;Event Types&amp;rsquo; view collapses the Events by Type so if you have like 100 errors,  this view might show that there are only 3x types of error and that 70 are of type 1, 20 type 2 and 10 of type 3.  The &amp;lsquo;Event Trends&amp;rsquo; is as a progression from &amp;lsquo;Events by Type&amp;rsquo; and shows the collapsed view but shows which are trending into decline and which are trending up in occurrence.&lt;/p&gt;
&lt;h2 id=&#34;real-life-usage&#34;&gt;Real Life Usage&lt;/h2&gt;
&lt;p&gt;Its hard to quantify how useful Log Insight can be until you have to work through a proper issue.  Luckily (well maybe not lucky to get a fault) while looking at Log Insight a fault manifested itself to users in OpenStack Horizon that they could not deploy new VM instances.  I opened the Log Insight OpenStack content pack and without any awareness of the components of openstack could see nova had been reporting issues at the time the issues reported. The error messages were very generic and not leading to pointing to the fault so I went to the vSphere content pack and found messages which correlated to the time in nova which showed a ESXi host was having issues with clomd and suggested it needed restarting. CLOMD (Cluster Level Object Manager Daemon) plays a key role in the operation of a VSAN cluster so I checked VSAN dashboard in the content pack and could see other issues.  I then connected to the ESX host restarted clomd and the issue went away,  all this took about 5 minutes.  When I took a step back to think about this,  I had queries the log files of about 20-30 servers and was able to stay focused on the issue and the pattern of the fault rather than on logging on to the servers and finding the log files.  Bear in mind I&amp;rsquo;m not Log Insight expert this was my first day using it and its ease of use coupled with its power makes it a truly wonderful tool for the administrator.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>OpenStack Windows Image</title>
      <link>https://darrylcauldwell.github.io/post/openstack-glance-win/</link>
      <pubDate>Thu, 23 Apr 2015 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/openstack-glance-win/</guid>
      <description>
        
          &lt;p&gt;While looking at OpenStack as the control plane for vSphere it appears there isn&amp;rsquo;t too much detail and I found it tricky to create my first OpenStack image.  Here are the steps I followed.&lt;/p&gt;
&lt;h2 id=&#34;create-vsphere-donor-windows-virtual-machine&#34;&gt;Create vSphere Donor Windows Virtual Machine&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Use vSphere web client wizard to create new hardware v10 virtual machine in vSphere with Thin vHDD&lt;/li&gt;
&lt;li&gt;Attach Windows DVD ISO&lt;/li&gt;
&lt;li&gt;Install Windows to virtual machine&lt;/li&gt;
&lt;li&gt;Disconnect DVD ISO&lt;/li&gt;
&lt;li&gt;Install VMware Tools&lt;/li&gt;
&lt;li&gt;Complete VMware Tools Reboot&lt;/li&gt;
&lt;li&gt;Power Down VM&lt;/li&gt;
&lt;li&gt;Export VM as OVF&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;create-openstack-image&#34;&gt;Create OpenStack Image&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Open OpenStack Console&lt;/li&gt;
&lt;li&gt;Change to your Project in left pane&lt;/li&gt;
&lt;li&gt;Select Manage Compute, Images and Snapshots&lt;/li&gt;
&lt;li&gt;Click Create Image&lt;/li&gt;
&lt;li&gt;Complete form using this as an example,  for Image File,  open the OVF file and select the VMDK you exported earlier&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openstack-glance-win-Image-Create.png&#34; alt=&#34;Openstack Image&#34;&gt;&lt;/p&gt;
&lt;ol start=&#34;6&#34;&gt;
&lt;li&gt;Click Create Image&lt;/li&gt;
&lt;li&gt;Wait while file uploads, it takes a while, you&amp;rsquo;ll be returned to console when it completes&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Note: this updates the file to folder glance_openstack on the datastore glance is configured to use. Once created you can cross ref the file UID with the OpenStack Console.&lt;/p&gt;
&lt;h2 id=&#34;test-openstack-image-works-as-instance&#34;&gt;Test OpenStack Image Works As Instance&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Open OpenStack Console&lt;/li&gt;
&lt;li&gt;Change to your Project in left pane&lt;/li&gt;
&lt;li&gt;Select Manage Compute Instances&lt;/li&gt;
&lt;li&gt;Click Launch Instance in right pane&lt;/li&gt;
&lt;li&gt;Complete Details Form&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openstack-glance-win-InstanceLaunch.png&#34; alt=&#34;Openstack Instance Launch&#34;&gt;&lt;/p&gt;
&lt;ol start=&#34;6&#34;&gt;
&lt;li&gt;Ensure correct Security Group selected on Access and Security Tab&lt;/li&gt;
&lt;li&gt;Ensure correct Network is selected on Networking tab&lt;/li&gt;
&lt;li&gt;Click Launch&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;vsan-abnormality&#34;&gt;VSAN Abnormality&lt;/h2&gt;
&lt;p&gt;If your Image is to go to a VSAN datastore and your using OpenStack Havana the above method will fail, this is because VSAN introduces a new disk type [streamOptimized] (&lt;a href=&#34;http://specs.openstack.org/openstack/nova-specs/specs/kilo/approved/vmware-vsan-support.html&#34;&gt;http://specs.openstack.org/openstack/nova-specs/specs/kilo/approved/vmware-vsan-support.html&lt;/a&gt;) which the UI is not aware of (this is fixed in Icehouse and later).&lt;/p&gt;
&lt;p&gt;In order to import these images you would need to use the OpenStack command line interface.  First open WebUI then  &amp;ldquo;Project -&amp;gt; Manage Compute -&amp;gt; Access &amp;amp; Security&amp;rdquo; and click Download OpenStack RC File.&lt;/p&gt;
&lt;p&gt;SCP the RC file to your Linux jump box /var/tmp and then use&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;source /var/tmp/&amp;lt;filename&amp;gt;.rc
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Enter password when prompted.&lt;/p&gt;
&lt;p&gt;Once you have authenticated,  run script like (substituting name and filename as required.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;glance --insecure --os-endpoint-type internalURL image-create &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;--name Windows2008R2-VM10 &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;--property vmware_disktype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;streamOptimized &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;--property vmware_adaptertype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;lsiLogic &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;--container-format&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;bare --disk-format&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;vmdk &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;--is-public&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;--file&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;/var/tmp/Windows2008R2-VM10-disk1.vmdk&amp;lt;/code&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You should get output like&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openstack-glance-win-streamOptimized2.png&#34; alt=&#34;Stream Optimized&#34;&gt;&lt;/p&gt;
&lt;p&gt;If you have uploaded an image already and found that its not streamOptimized you can change the attribute.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;glance image-update &amp;lt;image_name or uuid&amp;gt; --property vmware_disktype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;streamOptimized
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
        
      </description>
    </item>
    
    <item>
      <title>Intel NUC Cluster Hardware</title>
      <link>https://darrylcauldwell.github.io/post/homelab-nuc/</link>
      <pubDate>Thu, 16 Apr 2015 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/homelab-nuc/</guid>
      <description>
        
          &lt;p&gt;I have worked most of my professional life with systems built with Intel x86, x64. Often there is little hardware available in the work environment to learn and try out new things.&lt;/p&gt;
&lt;p&gt;I enjoy learning by doing and to begin to better understand the technology looked to build a cluster of Intel NUCs. My goals of cluster include understanding more about:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;VMware vSphere, NSX and vSAN&lt;/li&gt;
&lt;li&gt;Kubernetes, OpenShift and Tanzu&lt;/li&gt;
&lt;li&gt;Configuring infrastructure with Python, Ansible and Terraform&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;compute&#34;&gt;Compute&lt;/h1&gt;
&lt;p&gt;The NUC6i5SYH was latest model when I purchased. My purchasing decision was primarily lead by power as these draw 60watt at peak load. I also wanted to try vSAN which drove need for at least two disk bays and the NUC has an M.2 and a 2.5&amp;quot; Drive bay.&lt;/p&gt;
&lt;h1 id=&#34;storage&#34;&gt;Storage&lt;/h1&gt;
&lt;p&gt;To form vSAN required the two internal disks be fully available which drove the addition of USB Flash Drive. The NUCs sit on and around desk so its very easy for them to get knocked the SanDisk Cruzer Fit formfactor keeps the chance of damage to a minimum.&lt;/p&gt;
&lt;p&gt;I was working to a budget but wanted good performance. When cluster operating with vSAN all writes go via a cache disk and then get destaged to capacity tier. For the vSAN cache tier I chose the 128GB Samsung SM951 NVMe M.2 as it is rated for ~2,150MiB/sec read and 1550MB/s MiB/sec write. For the vSAN capacity tier I chose the 1TB Samsung 850 EVO SATA3 as it is rated for ~500MiB/sec read and write. The lab does not need a lot of capacity so only two of the three NUCs are populated with disks and contribute to vSAN the third contributes only compute capacity to the cluster.&lt;/p&gt;
&lt;p&gt;As well as internal storage I have a Synology DiskStation DS213j a  &amp;ldquo;budget-friendly&amp;rdquo; 2-bay NAS server. It isn&amp;rsquo;t the fastest but offers iSCSI and/or NFS with 100MiB/sec read and 70MiB/sec write.&lt;/p&gt;
&lt;h1 id=&#34;network&#34;&gt;Network&lt;/h1&gt;
&lt;p&gt;One of usecases I wanted to explore with this hardware was Software Defined Networking. To this end I wanted network switch to support configuring multiple VLANs. To connect three NUCs each with two 1GbE NICs would consume six ports, to uplink to wider home network and the Synolofy DiskStation drove my choice to the eight 1GbE port Cisco SG200-08.&lt;/p&gt;
&lt;p&gt;To simulate redundant networking scenarios at the ESXi side I wanted to add a second NIC albeit connecting to same switch. To allow for USB NIC on NUCs VMware released a unsupported driver by way of a Fling. This was a little prescritive and this lead me to the StarTech USB 3.0 to Gigabit Ethernet NICs.&lt;/p&gt;
&lt;p&gt;My home office is in a cabin in the garden while it has power cabling it has no network cabling. To give a cabled network connection I use TP-Link AV500/AV600s. As these are very specific to my scenario I&amp;rsquo;ve not included them in the BOM.&lt;/p&gt;
&lt;p&gt;# Bill Of Materials&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;3x Intel NUC 6th Gen NUC6i5SYH (3x £358=) £1,074&lt;/li&gt;
&lt;li&gt;3x Crucial 32GB Kit (2x16GB) DDR4 (3x £86=) £258&lt;/li&gt;
&lt;li&gt;2x Samsung SM951 NVMe 128GB M.2 (2x £43=) £86&lt;/li&gt;
&lt;li&gt;2x Samsung 850 EVO 1TB SATA3 (2x £248=) £496&lt;/li&gt;
&lt;li&gt;3x SanDisk Cruzer Fit 16GB USB Flash Drive (3x £5=) £15&lt;/li&gt;
&lt;li&gt;3x StarTech USB 3.0 to Gigabit Ethernet (3x £17=) £51&lt;/li&gt;
&lt;li&gt;1x Cisco SG200-08 8-port Gigabit £73&lt;/li&gt;
&lt;li&gt;7x 0.5m Cat6 Cables £7&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Total cluster parts cost ~£2060&lt;/p&gt;
&lt;p&gt;Note: Prices at time of purchase in 2014/2015&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Post To Slack From Powershell</title>
      <link>https://darrylcauldwell.github.io/post/slack-powershell/</link>
      <pubDate>Thu, 09 Apr 2015 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/slack-powershell/</guid>
      <description>
        
          &lt;p&gt;Working in a technical team distributed across multiple time zones makes it difficult to collaborate and keep everyone on the same page. I’ve used various communications tools to try and help with this and today the team I am working with started to look at Slack.  Slack seems ideal for our needs as it provides easily searchable discussion forums and has apps available for Mac, Windows, iOS and Android, it has a free usage model with limitations which won’t effect our working and if we grow we can extend to a paid license.&lt;/p&gt;
&lt;p&gt;The other really neat thing is that all its features are fully exposed by its API and it integrates via webhooks with many other applications including GitHub, GoogleDrive and Jira. As we added integrations and started to look at the API documentation as a trial I explored posting messages using the REST api from Powershell. It turned out to be really easy to do,  here are my notes on how you can.&lt;/p&gt;
&lt;h2 id=&#34;how-to&#34;&gt;How To&lt;/h2&gt;
&lt;p&gt;While logged into slack use the following URL &lt;a href=&#34;https://api.slack.com/web#authentication&#34;&gt;https://api.slack.com/web#authentication&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This should take you to screen to issue a OAuth2 token.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/slack-powershell-token.png&#34; alt=&#34;Slack OAuth2 Token&#34;&gt;&lt;/p&gt;
&lt;p&gt;Click Create token and copy the text string for the token. We then need to format the message and call postMessage method with Powershell.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$postSlackMessage = @{token=&amp;quot;&amp;lt;your-token&amp;gt;&amp;quot;;channel=&amp;quot;#general&amp;quot;;txt=&amp;quot;Hello from PowerShell!&amp;quot;;username=&amp;quot;via API&amp;quot;}
Invoke-RestMethod -Uri https://slack.com/api/chat.postMessage -Body $postSlackMessage
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This should return a message like&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;ok   channel   ts                message
--   -------   --                -------
True C04BHJ94Z 1428592795.000059 @&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;text&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;Hello from PowerShe...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You can do everything you want via the API not just post messages,  check out the &lt;a href=&#34;https://api.slack.com/&#34;&gt;API documentation&lt;/a&gt; for the other methods.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Ansible For Windows Managed Nodes</title>
      <link>https://darrylcauldwell.github.io/post/ansible-windows/</link>
      <pubDate>Tue, 27 Jan 2015 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/ansible-windows/</guid>
      <description>
        
          &lt;p&gt;On starting to look at learning using Ansible to manage Windows hosts, first step was to setup a test lab.&lt;/p&gt;
&lt;p&gt;Setup an Ubuntu 14.04 or CentOS 7 and a Windows 2008 R2 virtual machines.&lt;/p&gt;
&lt;h2 id=&#34;install-ansible-ubuntu&#34;&gt;Install Ansible (Ubuntu)&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;apt-get install software-properties-common
apt-add-repository ppa:ansible/ansible
apt-get update
apt-get install ansible
sudo pip install http://github.com/diyan/pywinrm/archive/master.zip#egg&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;pywinrm
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;install-ansible-centos-7-minimal&#34;&gt;Install Ansible (CentOS 7 Minimal)&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;yum update
yum install net-tools
yum install epel-release
yum install ansible
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;configure-winrm-on-windows-2008-r2-guest&#34;&gt;Configure WinRM On Windows 2008 R2 Guest&lt;/h2&gt;
&lt;p&gt;The configuration of Windows managed guests WinRM is automated and available in
&lt;a href=&#34;https://github.com/ansible/ansible/blob/devel/examples/scripts/ConfigureRemotingForAnsible.ps1&#34;&gt;this&lt;/a&gt; powershell script.&lt;/p&gt;
&lt;h2 id=&#34;create-a-working-space-test-your-connectivity&#34;&gt;Create A Working Space Test Your Connectivity&lt;/h2&gt;
&lt;p&gt;Ansible is file based,  so here I create a folder underneath my home directory to store my lab configuration&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;mkdir -p ~/ansible_test/group_vars
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We then create a file for holding hosts in lab and begin editing it&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;vi ~/ansible_test/host
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Add the contents of this in the following format,  adding extra lines with extra IPs as needed&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yml&#34; data-lang=&#34;yml&#34;&gt;[&lt;span style=&#34;color:#ae81ff&#34;&gt;windows]&lt;/span&gt;
&lt;span style=&#34;color:#ae81ff&#34;&gt;&amp;lt;windows server ip address&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We then create a file for holding WinRM connectivity hosts in lab and begin editing it&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;vi /home/&amp;lt;user&amp;gt;/ansible_test/group_vars/windows.yml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Add the contents of this in the following format,  adding extra lines with username and password as needed&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# it is suggested that these be encrypted with ansible-vault:&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# ansible-vault edit group_vars/windows.yml&lt;/span&gt;
ansible_ssh_user: &amp;lt;admin user&amp;gt;
ansible_ssh_pass: &amp;lt;admin user password&amp;gt;
ansible_ssh_port: &lt;span style=&#34;color:#ae81ff&#34;&gt;5986&lt;/span&gt;
ansible_connection: winrm
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once we have these two files setup,  we can look to test connectivity&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cd /home/dcauldwell/ansible_test
ansible windows -i host -m win_ping
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Debugging is not enabled by default,  you might want to append -vvvvv to enable this if you have issue on first connect.&lt;/p&gt;
&lt;p&gt;If you still have issues you can test connectivity using cURL&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;curl -vk -d &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt; -u &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;user:pass&amp;#34;&lt;/span&gt; https://&amp;lt;windows server ip address&amp;gt;:5986/wsman&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;When you havethe win_ping module working,  you can look at running the other modules shipped with the core product a full list can be found here.  Maybe you might gather the Ansible facts using.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;ansible &amp;lt;windows server ip address&amp;gt; -m setup
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;create-a-custom-powershell-module&#34;&gt;Create A Custom Powershell Module&lt;/h2&gt;
&lt;p&gt;On looking at the core modules you might think your a bit limited but its easy to wrapper your existing Powershell logic as an Ansible module.&lt;/p&gt;
&lt;p&gt;I decided to keep all my custom modules in the lab in there own folder and change the module path.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;mkdir -p ~/ansible_test/group_vars/library
export ANSIBLE_LIBRARY&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;~/ansible_test/library/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;An Ansible Powershell module is made up of two files,  one is the ps1 with the script contents and one is py which has description and examples.  The main difference appears to be to get the Powershell console output back to Ansible you need to form as object and convert that object to JSON.  It also appears not required but good practice to set an object to be returned with a changed flag to true or false unsure but believe this logic might be used at runtime to decide whether to call the handler.&lt;/p&gt;
&lt;p&gt;An easy way to create a new module,  is to copy an existing one and rename it this way you get the supporting text and structure.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cp /usr/share/pyshared/ansible/modules/core/windows/win_ping* ~/ansible_test/library/
mv ~/ansible_test/library/win_ping.ps1 ~/ansible_test/library/&amp;lt;new module name&amp;gt;.ps1
mv ~/ansible_test/library/win_ping.py ~/ansible_test/library/&amp;lt;new module name&amp;gt;.py
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;A simple example use case might be if you wanted to call the Get-Host cmdlet to gather Powershell version your ps1 might read.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#!powershell&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# WANT_JSON&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# POWERSHELL_COMMON&lt;/span&gt;
$data = Get-Host | Select Version
$result = New-Object psobject @{
get_host_version = $data
changed = $false
};
Exit-Json $result;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Using the same example your py might read&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;DOCUMENTATION &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&amp;#39;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;---
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;module: get_host
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;version_added: &amp;#34;0.1&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;short_description: Call Get-Host cmdlet.
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;description:
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;- Call Get-Host cmdlet
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
EXAMPLES &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&amp;#39;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;# Test connectivity to a windows host
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;ansible winserver -m get_host
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;# Example from an Ansible Playbook
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;- action: get_host
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once we have these two module files,  we can look to test the new module&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cd /home/dcauldwell/ansible_test
ansible windows -i host -m get_host
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If its working you should get returned the output from Get-Host command&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;dcauldwell@ansible-server:~/ansible_test$ ansible windows -i host -m get_host
192.128.0.60 | success &amp;gt;&amp;gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;changed&amp;#34;&lt;/span&gt;: false,
&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;get_host_version&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Version&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Build&amp;#34;&lt;/span&gt;: -1,
&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Major&amp;#34;&lt;/span&gt;: 4,
&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;MajorRevision&amp;#34;&lt;/span&gt;: -1,
&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Minor&amp;#34;&lt;/span&gt;: 0,
&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;MinorRevision&amp;#34;&lt;/span&gt;: -1,
&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Revision&amp;#34;&lt;/span&gt;: -1
&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;With this technique you should be able to form some simple modules.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Is the future of sysadmin to be an SRE?</title>
      <link>https://darrylcauldwell.github.io/post/devops-sre/</link>
      <pubDate>Thu, 22 Jan 2015 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/devops-sre/</guid>
      <description>
        
          &lt;p&gt;I recently came across the role SRE, I didn&amp;rsquo;t know what this was so researched it a little and found that it refers to Site Reliability Engineers after reading around the subject here is my considered opinion.&lt;/p&gt;
&lt;p&gt;The classic sysadmin role could be defined in generic terms as &amp;ldquo;IT operations staff responsible for designing, building, and maintaining an organization&amp;rsquo;s computer infrastructure&amp;rdquo;. The world of IT is continually growing and changing, we&amp;rsquo;re presently going through technological changes and a move to virutalization and containization of server services, a sysadmin now only needs to manage the hosting platform and can manage by policy applied around the server instance and use light touch operational administration of the each server instance.  As well as this businesses are also changing and attempting to embrace lean methodologies to gain the efficiencies they promise, starting in software engineering using Agile process and now moving to encompass operational management by breaking down the silos between development and operations. A healthy DevOps culture is shown by having working relationships which allows each classical team to see how their work influences and affects the other, and by combining knowledge and effort, produces a more robust, reliable, agile product as a result.&lt;/p&gt;
&lt;p&gt;But what of the next stages when server administration is so light tough and infrastructure is delivered by coded workflow, well then you only need hire people who write code. It is within businesses evolved to this point where the term Site Reliability Engineers (SREs) comes in. These are engineers who know enough about programming languages, data structures and algorithms, and performance to properly review the working of an application to properly instrument, measure and alert on its running. Alongside these application skills they have knowledge of operational management to ensure the software continues to have these capabilities through its operational life which might include resilience of failures component, server and site (cloud provider), scalability to accommodate varying workload levels, and security patch management.&lt;/p&gt;
&lt;p&gt;Over the years I&amp;rsquo;ve spoken to a lot of system administrators have come into their roles as an evolution as well maybe through help desk, various layers of support, or even just running computer systems at home and transitioning those skills into servers at work. It is pretty clear in my mind that the same evolutionary path won&amp;rsquo;t work for the transition into SRE, as the move towards the SRE role requires software engineering skills to understand the application itself these skills are classical and learned in a structured way. I have learned a lot about programmatic structure through working with Powershell however the discipline of a computer scientist or software engineer are still quite distant, programming at any level however is a good starting point to work from, and the more you look at programming and languages the more you understand of a developers view point.&lt;/p&gt;
&lt;p&gt;Today many businesses are on a journey of evolution and right now only a handful are at the point in the journey were SREs are needed.  However right now every infrastructure would benefit from having its systems administrator having better programming skills, as such I will be looking to further advancing and formalizing my programming skills.  Bearing in mind the future I believe all sys admins should do the same!&lt;/p&gt;
&lt;p&gt;Interesting article about the job from a &lt;a href=&#34;%22http://googleforstudents.blogspot.co.uk/2012/06/site-reliability-engineers-worlds-most.html&#34;&gt;Google Site Reliability Engineer&lt;/a&gt;.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>NetApp Cloud OnTap For AWS</title>
      <link>https://darrylcauldwell.github.io/post/aws-ontap/</link>
      <pubDate>Fri, 12 Dec 2014 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/aws-ontap/</guid>
      <description>
        
          &lt;p&gt;NetApp has often been a pioneer of bleeding edge concepts in storage. When designing data ONTAP and the WAFL file system they were the first to look at creating a virtual control plane for data. They also pioneered fully non disruptive upgrades when the introduced clustered data ONTAP.  They then introduced ONTAP Edge for providing the really cool features of data ONTAP for non NetApp SANs. Recently the pioneering spirit has been continuing with the launch of Cloud ONTAP for AWS which takes the clustered data ONTAP features to overlay Amazon EC2 storage.&lt;/p&gt;
&lt;p&gt;There are hundreds of business use cases which spring to mind when you begin to consider what this offers, however the total killer feature for this is using snap mirror to extend your data between private cloud and public cloud.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/aws-ontap.jpg&#34; alt=&#34;NetApp Cloud OnTap for AWS&#34;&gt;&lt;/p&gt;
&lt;p&gt;Using the public cloud makes great sense for standing up solutions quickly and without the up front capital expenditure and instead the operational usage charging. As your new product grows and becomes more popular it maybe your operational charges out weight the cost savings and you then want to bring it to private cloud.&lt;/p&gt;
&lt;p&gt;Most applications have great agility for the application, simply stand up a new OS in other cloud provider and install application.  However application data agility is, until now, much harder to manage.&lt;/p&gt;
&lt;p&gt;In this example you would simply build your private cloud and new application tier and use snap mirror to bring your data to your datacenter and keep it in sync with the application still running.  When all sync&amp;rsquo;d you would cutover by breaking the mirror all could be seam less to your customers.&lt;/p&gt;
&lt;p&gt;I expect as well that while currently this is only for EC2 storage, if it was to also interface into S3 and glacier you could also move your data tiering&lt;/p&gt;
&lt;p&gt;While I love NetApp I&amp;rsquo;m not a storage admin,  and while the ONTAP simulator is useful at $1.50 per hour if I ever wanted to exercise my skills I could just spin up a clustered ONTAP AMI and away I would go then release it to save the recurring charge.&lt;/p&gt;
&lt;p&gt;While there is more detailed info on the &lt;a href=&#34;http://www.netapp.com/us/system/pdf-reader.aspx?cc=us&amp;amp;m=ds-3618.pdf&amp;amp;pdfUri=tcm:10-127470&#34;&gt;NetApp website&lt;/a&gt;, a superb way to see this in action is to sign up for free and look at &lt;a href=&#34;https://poc.netapp.com/cloud/testdrive/&#34;&gt;test drive&lt;/a&gt;where you get to spin up a AMI on NetApp&amp;rsquo;s AWS account and look around.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>VMware Virtual Volumes Deep Dive</title>
      <link>https://darrylcauldwell.github.io/post/vvols/</link>
      <pubDate>Fri, 24 Oct 2014 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/vvols/</guid>
      <description>
        
          &lt;h2 id=&#34;how-vvols-will-help&#34;&gt;How vVols Will Help&lt;/h2&gt;
&lt;p&gt;The constraints and issues which VVOLs address include, LUNs introduce constrains such as the quantity of LUNs we can present,  having lots of LUNs each with unused space is in efficient as such we currently shared VMs on data stores and this  gives a lack of granular control for passing storage attribute on a per-VM basis.&lt;/p&gt;
&lt;p&gt;Virtual Volumes addresses these challenges by rather than using the construct of LUNs on the storage array which is then formatted with VMFS filesystem.  Instead we would create on the storage array a Storage Container, the capabilities of the  Storage Container are exposed via the VMware Aware Storage API (VASA) provider and the data path is exposed via a Protocol Endpoint (PE). While the PE exposes the data path traffic is not funneled through it it provides a pointer, the ESXi to array IO is direct. The removal of the LUN construct and replacement the storage container removes the constraints of using LUNs.&lt;/p&gt;
&lt;p&gt;The capabilities of the VMware Aware Storage API (VASA) provider needs to be extended for VVOLs so will increment to version 2. The storage array vendor will provide this extended VASA provider, the current deployment of VASA providers is most typically on a management server, as this is now more critical, it is likely vendors will move its hosting to the array, by way of firmware update. By moving the VASA provider to the array will give the solution the inherent resilience built in to the array.&lt;/p&gt;
&lt;p&gt;The Virtual Volume is analogous to the file object which makes up a virtual machine. The other key thing which VVOLs gives us is that by directly exposing the storage we get more full access to offload work to the storage array.  For example snapshots traditionally are managed snapshots within vSphere but now these are performed directly as storage array operations as Un-(vSphere)managed snapshots which allows this to be done as efficiently as possible. As well as snapshotting all SCSI operations, ATS, XCOPY, UNMAP, TRIM etc are also performed natively. One thing to note is that snapshotting of a running virtual machine while being much fantastically improved is not instantaneous for a running virtual machine as the memory bitmap is still required to be written.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://www.wooditwork.com/wp-content/uploads/2014/08/image_thumb18.png&#34; alt=&#34;Virtual Volumes&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;vvols-deep-dive&#34;&gt;VVOLs Deep Dive&lt;/h2&gt;
&lt;p&gt;The Protocol Endpoint (PE) is compatible with all SAN and NAS protocols and each can support any one of the protocols at a given time. The PE is still a SCSI device and as such is managed by the Pluggable Storage Architecture (PSA) which applies the multi-path policies, the PSA is modified slightly to be aware of the PE construct. There can be multiple PEs defined an SCSI PE is picked up during a rescan. While you may at first thing that VVOLs is purely for block storage it is also a construct which can be used with NFS, a NFS PE is maintained as an IP address or file path, ESX identifies and maintains all discovered PEs within a database. Each Virtual volumes has a UID, the data paths are established through a VASA bind request, the bind request is processed by VASA and the mapping of UID and paths can be many to many and all bindings are stored within the database.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://datacenterdude.com/wp-content/uploads/2012/10/vmware-vvol-1.png&#34; alt=&#34;Protocol Endpoint&#34;&gt;&lt;/p&gt;
&lt;p&gt;The storage container holds the capabilities of the storage, capabilities would be things like performance tier (Diamond, Gold, Silver, Bronze), backup, snapshots, whether it is de-duplicated. We can therefore use storage containers as logical partitions to apply  storage needs and requirements. There would be a minimum of one storage container per array and maximum would depend on vendor. There is no direct mapping between storage container and PE, a PE can manage multiple storage containers and multiple PEs can manage a single storage container. These storage container capabilities are then advertised for use by ESX through the VMware Aware Storage API (VASA) provider. Surprisingly at first we still need to form Storage Containers into datastores within vSphere. This requirement is to allow all the traditional features of vSphere HA, SDRS etc, which need to interact with the datastore construct.&lt;/p&gt;
&lt;p&gt;A virtual volume is per virtual machine but within it is broken up by capability requirement into five sub-types,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Config-VVOL&lt;/li&gt;
&lt;li&gt;Data-VVOL&lt;/li&gt;
&lt;li&gt;Mem-VVOL&lt;/li&gt;
&lt;li&gt;Swap-VVOL&lt;/li&gt;
&lt;li&gt;Other-VVOL&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;With this granularity we can now place each VVOL sub-type onto a Storage Container with the best match for its capability requirement.&lt;/p&gt;
&lt;p&gt;To consume VVOLs effectively and on a per object (per virtual machine) basis we need to move towards Storage Policy Based Management (SPBM) so we can consume the storage capabilities presented with VVOLs by VMware Aware Storage API (VASA) provider.&lt;/p&gt;
&lt;p&gt;In this current release mentioned as 2015 SRM is not supported, although it was mentioned that that is on radar for 2016. The use of RDMs is also not supported within VVOLs, you can however present these as normal outside of the VVOL container.&lt;/p&gt;
&lt;h2 id=&#34;try-vvols-at-home&#34;&gt;Try VVOLs At Home&lt;/h2&gt;
&lt;p&gt;Up until recently you couldn&amp;rsquo;t realistically configure a VVOLs solution unless you had a spare array running beta firmware which supported VASA2. That is until NetApp shipped &lt;a href=&#34;http://mysupport.netapp.com/NOW/download/tools/simulator/ontap/8.X/&#34;&gt;OnTap simulator 8.2.1&lt;/a&gt;, the NetApp Simulator is run as a nested VM under Fusion, Workstaion or ESX and provides the interface for vSphere 6 to connect to.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>NetApp FAS IOPS Theoretical Maximum &amp; Workload Aggregate Load Balancing</title>
      <link>https://darrylcauldwell.github.io/post/netapp-iops/</link>
      <pubDate>Tue, 26 Aug 2014 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/netapp-iops/</guid>
      <description>
        
          &lt;p&gt;To achieve good performance for a virtualized workload your Storage Area Network (SAN) should deliver high IOps with a predictable low latency. If you are using a good flash system where IOps (Input/Output Operations Per Second) effectively become an unlimited resource then latency will probably be your limiting factor.&lt;/p&gt;
&lt;p&gt;The NetApp FAS family of storage systems offer a series of arrays at various price points and specifications. NetApp also offer the option of adding Performance Acceleration Module (PAM) to improve the performance of random read intensive workloads by way of a tunable cache to reduce latency. the model you have will shape the latency capability for example the &lt;a href=&#34;https://www.spec.org/sfs2008/results/res2009q1/sfs2008-20081215-00111.html&#34;&gt;FAS3140 with PAM and FC disk gives a latency at 40,000 IOPs of 4.4ms&lt;/a&gt; where the &lt;a href=&#34;https://www.spec.org/sfs2008/results/res2009q3/sfs2008-20090727-00126.html&#34;&gt;FAS3160 with PAM and FC disk gives a latency at 40,000 IOPs of 1.7ms.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;You can add varying amounts of disk shelves and disks to the various FAS models. The amount of disk and specification of disk and aggregate design will effect the theoretical maximum amount of IOps. Duncan Epping wrote &lt;a href=&#34;http://www.yellow-bricks.com/2009/12/23/iops/&#34;&gt;this piece&lt;/a&gt; on the calculation of IOps and if we use this in an example. We have 90 disk per storage controller and we form 3 aggregates each with 30 SAN 15K disks. Within the aggregate we follow &lt;a href=&#34;https://communities.netapp.com/message/2676%20&#34;&gt;NetApp best practice&lt;/a&gt; to form two RAID groups of no more than 16x disks and so form 2x RAID-DP RAID groups within each aggregate which consumes 2×2 disks for parity.  We know from using vscsiStats that today our VMs generate approximatley 60% read and 40% write traffic,  so our formula would read for each aggregate ((26*175)&lt;em&gt;0.6)+((26&lt;/em&gt;85)&lt;em&gt;0.4) = 3614 IOps per aggregate.  If we then add a PAM card the cache would potentially absorb some of IOps going as disk reads, this is very worload dependant but if we look on &lt;a href=&#34;https://communities.netapp.com/servlet/JiveServlet/download/3053-2273/TechONTAP_PAM.ppt&#34;&gt;page 9 of this NetApp powerpoint&lt;/a&gt; we can see the 256GB PAM absorbing 2000 of the 5847 disk reads,  around 30% which would effect our formula to (((26&lt;/em&gt;175)*0.6)&lt;em&gt;1.3)+((26&lt;/em&gt;85)*0.4) and give 4433 IOps per aggregate.&lt;/p&gt;
&lt;p&gt;It is important to understand the relationship between IOps and the disks as we can see in our example each storage controller has 3x islands of IOps.  As such workload can become hot in one aggregate and cool in others,  to ensure your driving your system the most efficient way you should monitor the average IOps in each aggregate and can look to balance these.  You can use either svMotion to move VM workload between datastores in different aggregates or data motion to move volumes between aggregates.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Scrum Team Demystified</title>
      <link>https://darrylcauldwell.github.io/post/devops-scrum/</link>
      <pubDate>Tue, 26 Aug 2014 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/devops-scrum/</guid>
      <description>
        
          &lt;p&gt;While I worked with Agile as a software tester when the concept first came out in 2002 shortly afterwards I joined a new company in a new role in Infrastructure, IT operations if you will. My recollection of Agile is that it was not a process at all; rather, it’s a set of principles summarized by the Agile Manifesto.&lt;/p&gt;
&lt;p&gt;This seems like a lifetime ago,  but its finally made a comeback to my work life as I now work in team looking to foster a DevOps culture in our workplace.  A DevOps culture is an extension of Agile culture which rather than focusing purely on application life-cycle management it looks to now encompass server life-cycle management too. It aims to achieve this by breaking down organizational barriers to become a single cohesive team delivering a application service rather than discreet silo team structure.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/devops-scrum.png&#34; alt=&#34;DevOps&#34;&gt;&lt;/p&gt;
&lt;p&gt;While Agile and DevOps are cultural changes and not methodologies in themselves there are methodologies which embody the principles such as Scrum, again there is no formal definition of a Scrum but industry members have formed frameworks such as &lt;a href=&#34;http://www.mountaingoatsoftware.com/agile/scrum&#34;&gt;Mike Cohen&lt;/a&gt;. A scrum team is a strong informal collaboration of engineers and developers, within the loose role construct of a Scrum team.The team ideally are co-located, in same building, or at least same timezone so they can work closely and all be aware of each others work. The other ideal is that business or product owner while not sitting within the Scrum team is very close to them, and the team is given wide discretion to develop and innovate in order to reflect their informal understanding of the customer&amp;rsquo;s real desire which is validated.&lt;/p&gt;
&lt;p&gt;In support of this new way of working you can also use tools which support these frameworks.  One such tool is from Atlassian which includes Jira which is a tracker for team planning, it is used to capture and organize issues, assign work, and follow team activity. Atlassian provide an Agile plugin for Jira to give the schema extensions to give the console the concept of Sprint, Theme, Epic and Stories as a way to organize the issues and work, it also enables all of these things to be measured for velocity with regards to team performance.  At the side of Jira sits Atlassian Confluence essentially a Wiki for the creation of the evolving design documentation.&lt;/p&gt;
&lt;p&gt;I mentioned above Sprint, Theme, Epic and Stories.  My loose definition of these terms stems from Mike Cohn&amp;rsquo;s &lt;a href=&#34;http://www.mountaingoatsoftware.com/agile&#34;&gt;Agile template&lt;/a&gt;. Where Scrum story is a user requirement definition,  a Scrum epic is a large user story, there is no threshold at where a story becomes a Epic it is just a big story,  potentially an Epic is a large story waiting to be more clearly defined and broken down into stories. A Scrum theme is a collection of Stories and \ or Epics. A Scrum sprint is a collection of Epics and \ or Stories which we hope to do within a set time frame. So we might have 100 stories pending,  and if our Sprint window is one week we might say this week we have these people engaged and can therefore complete these 10 stories. In practical terms for a sprint, we therefore draw a loose line in the sand that a Story should be achievable within a Sprint and an Epic a story which spans Sprints. Within Atlassian Jira story dependencies can be formed,  so if a Story hits an issue or hits a block the impact of this can be seen further up the dependency tree.&lt;/p&gt;
&lt;p&gt;As well as managing the tasks and workload with Jira another key part is harnessing automation to give predictable and repeatable delivery of your application service.With the cloud comes the decoupling of operating systems from physical servers, storage and networking,  and with containers the further decoupling of application from operating systems. With self service software defined data center and OpenStack cloud management platform cloud style infrastructure deployments is becoming more accessible to the traditional private data centers too.  With so many configuration items required to deliver a application service within software defined infrastructure as well as the application itself.  It can be useful to harness desired state tooling such as &lt;a href=&#34;https://www.chef.io/chef/&#34;&gt;Chef&lt;/a&gt; and &lt;a href=&#34;http://puppetlabs.com/&#34;&gt;Puppet&lt;/a&gt;, and leveraging distributed version control systems like &lt;a href=&#34;https://github.com/&#34;&gt;GitHub&lt;/a&gt;, to manage, deploy and enforce your configuration.&lt;/p&gt;
&lt;p&gt;A neat video on Jira, Agile, Scrum and Kanban&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=NrHpXvDXVrw&#34;&gt;https://www.youtube.com/watch?v=NrHpXvDXVrw&lt;/a&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Optimal TCP Window Size For Long Distance WAN Link</title>
      <link>https://darrylcauldwell.github.io/post/tcp-optimal/</link>
      <pubDate>Thu, 24 Jul 2014 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/tcp-optimal/</guid>
      <description>
        
          &lt;p&gt;If you have a requirement to copy large amounts of data along way around the world you may find that despite your link being 60Mb/s if its 5,000 miles away you only can transfer files at much less like 10Mb/s. The cause of this is generally the TCP Window Size is optimized by OS and FTP clients by default to work on networks with less distance and less network round trip latency.&lt;/p&gt;
&lt;p&gt;When using TCP to transfer data the two most important factors are the TCP window size and the round trip latency.  If you know the TCP window size and the round trip latency you can calculate the maximum possible throughput of a data transfer between two hosts, regardless of how much bandwidth you have.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;TCP-Window-Size-in-bits / Latency-in-seconds = Bits-per-second-throughput
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The standard Windows TCP window is 64KB&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;64KB = 65536 Bytes = 524288 bits
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;To calculate the round trip delay time can be done in many ways, the easiest is to use ping.exe as this records RTD in ms.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;images/tcp-rtd.gif&#34; alt=&#34;Round Trip Delay&#34;&gt;&lt;/p&gt;
&lt;p&gt;In the above the average latency is 38ms.  So using formula we can calculate the theoretical maximum.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;524288 / 0.038 = 13797053 bp/s = 13.8 Mbp/s
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;So you might want to know what you can do to make it faster? As with any equation the answer is adjust part so either increase the TCP window size and/or reduce latency. In many ways the latency is not something we can control easily but we can easily adjust the TCP window size.  If we know the latency and we know the size of pipe we have we should be able to calculate the best TCP window size.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(Link speed * Latency / 8) = TCP Window size Bytes
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;So if we have a 60Mb/s link across a route 5,042 miles incurring latency of 173ms.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(60000000*0.173)/8 = 1297500
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The downside to increasing the TCP window size on your server is that these larger packets increase the buffer size, this buffer sits in memory. Also if larger packets are lost, then more data is lost and therefore more needs retransmitting.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Setup Hanlon</title>
      <link>https://darrylcauldwell.github.io/post/hanlon/</link>
      <pubDate>Fri, 04 Apr 2014 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/hanlon/</guid>
      <description>
        
          &lt;p&gt;Since the company I work for CSC got a new CEO then CTO its changed direction and the latest change has been to &lt;a href=&#34;http://www.vdatacloud.com/blogs/2014/05/22/finding-value-in-opensource/&#34;&gt;participate with the Open Source community&lt;/a&gt;.  With this news shortly followed an updated version of a tool our new CTO &lt;a href=&#34;https://twitter.com/DanHushon&#34;&gt;Dan Hushon&lt;/a&gt; worked on at EMC with &lt;a href=&#34;https://twitter.com/lynxbat&#34;&gt;Nicholas Weaver&lt;/a&gt; it was formerly called &lt;a href=&#34;https://github.com/puppetlabs/Razor%22&#34;&gt;Razor&lt;/a&gt; and the new fork is &lt;a href=&#34;https://github.com/csc/Hanlon&#34;&gt;Hanlon&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I chose CentOS 6.5 64bit to host Hanlon and configured this as a VM with two vNICs one normal internet facing and one on a new private vSwitch with no uplinks,  the private is where DHCP\PXE\TFTP will be setup on and where the ESXi VMs will hopefully get built.  All these sit on an nested ESXi 5.0 configured with 12GB of vRAM and access to 1TB of NFS disk running inside VMware Fusion 6 on a Mac.&lt;/p&gt;
&lt;p&gt;I don&amp;rsquo;t work with Linux so some of my commands might be sub optimal, I&amp;rsquo;ll try and record all I use here for reference, and if you see anything I&amp;rsquo;m doing badly please do say.&lt;/p&gt;
&lt;p&gt;First task to the new VM is to start VMware tools installer which mounts the correct ISO,  then install the tools via putty session (or via console).&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;yum -y install perl
mkdir /mnt/cdrom
mount /dev/cdrom /mnt/cdrom
cp /mnt/cdrom/VMwareTools-*.tar.gz /tmp
tar -zxf /tmp/VMwareTools-*.tar.gz -C /tmp
cd /tmp/vmware-tools-distrib/
./vmware-install.pl --default
rm -f /tmp/VMwareTools-*.tar.gz
rm -rf /tmp/vmware-tools-distrib

&lt;span style=&#34;color:#75715e&#34;&gt;# I then changed from DHCP to static IP addressing,  to note shown here are only the lines I changed or added the rest I left as they populated by OS&lt;/span&gt;

vi /etc/sysconfig/network-scripts/ifcfg-eth0
BOOTPROTO&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;none
NETWORK&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&amp;amp;lt;Internet Facing Network Address&amp;amp;gt;
NETMASK&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&amp;amp;lt;Internet Facing Subnet Mask&amp;amp;gt;
IPADDR&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&amp;amp;lt;Internet Facing IP Address&amp;amp;gt;
vi /etc/sysconfig/network-scripts/ifcfg-eth1
BOOTPROTO&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;none
NETWORK&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&amp;amp;lt;Private Network Address&amp;amp;gt;
NETMASK&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&amp;amp;lt;Private Subnet Mask&amp;amp;gt;
IPADDR&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&amp;amp;lt;Private IP Address&amp;amp;gt;

&lt;span style=&#34;color:#75715e&#34;&gt;# My next port of call was to add a DHCP server to the VM, I chose ISC as that was recommended for Razor and appeared simple and well [documented](http://prefetch.net/articles/iscdhcpd.html).&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;## Install DHCP&lt;/span&gt;
yum install dhcp

&lt;span style=&#34;color:#75715e&#34;&gt;## Change DHCP that to listen on eth1&lt;/span&gt;
vi /etc/sysconfig/dhcpd

DHCPDARGS&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;eth1

&lt;span style=&#34;color:#75715e&#34;&gt;## Create a new config file&lt;/span&gt;
vi /etc/dhcp/dhcpd.conf

&lt;span style=&#34;color:#75715e&#34;&gt;## Populate with following (altering with your ID address ranges)&lt;/span&gt;
subnet 172.25.1.0 netmask 255.255.255.0 &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
range 172.25.1.20 172.25.1.50;
option tftp-server-name &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;172.25.1.10&amp;#34;&lt;/span&gt;;
&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; exists user-class and option user-class &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;iPXE&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
filename &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;hanlon.ipxe&amp;#34;&lt;/span&gt;;
&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
filename &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;undionly.kpxe&amp;#34;&lt;/span&gt;;
&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
next-server 172.25.1.10;
&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;## Start DHCP using&lt;/span&gt;
/etc/init.d/dhcpd start
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Test ISC DHCP and option by creating a VM with no OS,  and with only a NIC on the
private network and it should now pickup a PXE address.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/hanlon-PXE-Boot.gif&#34; alt=&#34;Hanlon PXE Boot&#34;&gt;&lt;/p&gt;
&lt;p&gt;It will fail as there is no PXE or TFTP server setup yet on the Hanlon server. So next step is to add a PXE and TFTP server,  so first task is to install it.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;yum -y install tftp-server tftp

&lt;span style=&#34;color:#75715e&#34;&gt;## Enable TFTP&lt;/span&gt;
sed -i &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;s/disable\t\t\t= yes/disable\t\t\t= no/g&amp;#39;&lt;/span&gt; /etc/xinetd.d/tftp
service xinetd restart

&lt;span style=&#34;color:#75715e&#34;&gt;## Install Java&lt;/span&gt;
yum -y install java-1.7.0-openjdk

&lt;span style=&#34;color:#75715e&#34;&gt;## Create MongoDB Repo config file&lt;/span&gt;
vi /etc/yum.repos.d/mongodb.repo

&lt;span style=&#34;color:#75715e&#34;&gt;## Then populate new file with&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;mongodb&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;MongoDB Repository
baseurl&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;http://downloads-distro.mongodb.org/repo/redhat/os/x86_64/
gpgcheck&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
enabled&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;## Install MongoDB from repo&lt;/span&gt;
yum -y install mongodb-org

&lt;span style=&#34;color:#75715e&#34;&gt;## Install Torquebox Ruby Application Platform&lt;/span&gt;
curl -L -O http://torquebox.org/release/org/torquebox/torquebox-dist/3.0.1/torquebox-dist-3.0.1-bin.zip
yum -y install unzip
unzip torquebox-dist-3.0.1-bin.zip -d $HOME
echo &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;export TORQUEBOX_HOME=$HOME/torquebox-3.0.1&amp;#39;&lt;/span&gt; &amp;amp;gt;&amp;amp;gt; ~/.bashrc
echo &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;export JBOSS_HOME=$TORQUEBOX_HOME/jboss&amp;#39;&lt;/span&gt; &amp;amp;gt;&amp;amp;gt; ~/.bashrc
echo &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;export JRUBY_HOME=$TORQUEBOX_HOME/jruby&amp;#39;&lt;/span&gt; &amp;amp;gt;&amp;amp;gt; ~/.bashrc
echo &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;export PATH=$JRUBY_HOME/bin:$PATH&amp;#39;&lt;/span&gt; &amp;amp;gt;&amp;amp;gt; ~/.bashrc
exec $SHELL -l

&lt;span style=&#34;color:#75715e&#34;&gt;## Download Hanlon&lt;/span&gt;
mkdir /opt/hanlon
cd /opt/hanlon
yum -y install git
git clone https://github.com/csc/Hanlon.git

&lt;span style=&#34;color:#75715e&#34;&gt;## Install Requisite Ruby Gems for Hanlon&lt;/span&gt;
cd /opt/hanlon/Hanlon
bundle install
gem update --system

&lt;span style=&#34;color:#75715e&#34;&gt;## Just need now to finalise the configuration of the Hanlon Microkernel, configure TFTP and  iPXE.&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;## Install GCC&lt;/span&gt;
yum -y install gcc gcc-c++

&lt;span style=&#34;color:#75715e&#34;&gt;## Download iPXE &amp;amp; Make Files&lt;/span&gt;
git clone https://github.com/ipxe/ipxe.git
curl -O https://gist.githubusercontent.com/jcpowermac/7cc13ce51816ce5222f4/raw/4384911a921a732e0b85d28ff3485fe18c092ffd/image_comboot.patch
yum -y install patch genisoimage
patch -p0 &amp;lt; image_comboot.patch
cd ipxe/src
make

&lt;span style=&#34;color:#75715e&#34;&gt;## Move new iPXE files to correct place for TFTP&lt;/span&gt;
cd bin
cp undionly.kpxe /var/lib/tftpboot/undionly.kpxe
cp ipxe.pxe /var/lib/tftpboot/ipxe.kpxe
cp ipxe.iso /var/lib/tftpboot/ipxe.iso

&lt;span style=&#34;color:#75715e&#34;&gt;## Get Syslinux files and move to correct place&lt;/span&gt;
curl -O https://www.kernel.org/pub/linux/utils/boot/syslinux/syslinux-6.02.tar.gz
tar -zxvf syslinux-6.02.tar.gz --strip-components &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt; -C /var/lib/tftpboot syslinux-6.02/bios/core/pxelinux.0
tar -zxvf syslinux-6.02.tar.gz --strip-components &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt; -C /var/lib/tftpboot syslinux-6.02/bios/com32/menu/menu.c32

&lt;span style=&#34;color:#75715e&#34;&gt;## Create Hanlon.pxe&lt;/span&gt;
yum -y install wget
wget https://github.com/csc/Hanlon-Microkernel/releases/download/v1.0/hnl_mk_prod-image.1.0.iso&amp;lt;
/opt/hanlon/Hanlon/cli/hanlon image add -t mk -p hnl_mk_prod-image.1.0.iso
/opt/hanlon/Hanlon/cli/hanlon config ipxe &amp;gt; /var/lib/tftpboot/hanlon.ipxe

&lt;span style=&#34;color:#75715e&#34;&gt;## Configure TFTBoot&lt;/span&gt;
mkdir /var/lib/tftpboot/pxelinux.cfg
cat &amp;gt; /var/lib/tftpboot/pxelinux.cfg/default &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;lt;&amp;lt;EOF
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;default menu.c32
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;prompt 0
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;menu title Hanlon Boot Menu
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;timeout 50
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;f1 help.txt
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;f2 version.txt
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;label hanlon-boot
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;menu label Automatic hanlon Node Boot
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;kernel ipxe.lkrn
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;append initrd=hanlon.ipxe
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;label boot-else
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;menu label Bypass hanlon
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;localboot 1
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;EOF&lt;/span&gt;&amp;gt;&amp;gt;

&lt;span style=&#34;color:#75715e&#34;&gt;## Bind TFTP to eth1&lt;/span&gt;
vi /etc/xinetd.d/tftp
add bind &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &amp;lt;ipaddress&amp;gt; of eth1
chkconfig dhcpd on
service xinetd restart

&lt;span style=&#34;color:#75715e&#34;&gt;## Test TFTP is working&lt;/span&gt;
tftp localhost4
get hanlon.ipxe
quit

&lt;span style=&#34;color:#75715e&#34;&gt;## If TFTP Times Out Try Disable Firewall&lt;/span&gt;
service iptables stop
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;At this point you should be able to create a test VM bound to same Host Only network and it should pick up a DHCP address then connect to TFTP server and download and boot an image.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>HP C7000 Interconnect Bay Mapping</title>
      <link>https://darrylcauldwell.github.io/post/hpe-c7000-interconnects/</link>
      <pubDate>Thu, 27 Mar 2014 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/hpe-c7000-interconnects/</guid>
      <description>
        
          &lt;p&gt;Here I address the most common query people have when using HP C7000 chassis, namely how do the bay
mappings work.&lt;/p&gt;
&lt;h2 id=&#34;half-height-blades&#34;&gt;Half Height Blades&lt;/h2&gt;
&lt;p&gt;HP supply blades which occupy single or double slots,  the single height blades map in the following way.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Device&lt;/th&gt;
&lt;th&gt;Interconnect Bay Mapping&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;OnBoard NIC1&lt;/td&gt;
&lt;td&gt;Bay 1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;OnBoard NIC2&lt;/td&gt;
&lt;td&gt;Bay 2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Mezz1 HBA1&lt;/td&gt;
&lt;td&gt;Bay 3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Mezz1 HBA2&lt;/td&gt;
&lt;td&gt;Bay 4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Mezz2 NIC1&lt;/td&gt;
&lt;td&gt;Bay 5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Mezz2 NIC2&lt;/td&gt;
&lt;td&gt;Bay 6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Mezz2 NIC3&lt;/td&gt;
&lt;td&gt;Bay 7&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Mezz2 NIC4&lt;/td&gt;
&lt;td&gt;Bay 8&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/hpe-c7000-mapping-half.png&#34; alt=&#34;Half Height Blade Mappings&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;full-height-blades&#34;&gt;Full Height Blades&lt;/h2&gt;
&lt;p&gt;For dual height blade server such as BL680c the mappings work the same way although each server has two mappings to each for example slot one maps to ports one and nine in each interconnect bay as opposed to just bay port one if in slot one and port nine if in slot nine.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/hpe-c7000-mapping-full.gif&#34; alt=&#34;Full Height Blade Mappings&#34;&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Windows Server 2012 - SAN Performance</title>
      <link>https://darrylcauldwell.github.io/post/win2012-san-perf/</link>
      <pubDate>Mon, 03 Mar 2014 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/win2012-san-perf/</guid>
      <description>
        
          &lt;p&gt;In a newly deployed Windows Server 2012 HyperV environment with around sixty nodes, running a couple of hundred Windows Server 2012 virtual machines running various applications.  We found the EMC VMX storage which underpinned this became massively busy with Write IO at around 3am,  the Write IO was mostly coming from TRIM and Unmap commands,  the amount has a dramatic impact and leads to lots of 153 errors on the server estate,  after one to two hours the Write IO subsided. I wrote a script to audit the estate to identify if there was any pattern to the errors. We found the errors correlated to the 3am Window also.&lt;/p&gt;
&lt;p&gt;EMC initially said the cause of this was the way the VNX was interpreting ODX command and they asked if we disable ODX on all HyperV servers. I used a PowerShell command to extract out all servers in AD with a ServiceConnection point of HyperV,  then looked to audit ODX on these and then disable.&lt;/p&gt;
&lt;p&gt;Since disabling the problem persisted second thoughts were that there was some tasks scheduled within the applications running on the VMs which was triggering this event,  after speaking to the product groups they said nothing was scheduled at this time. We continued our search within the HyperV communities and found &lt;a href=&#34;http://larsjoergensen.net/windows/windows-server/windows-server-2012/server-2012-automatic-maintenance-killed-san&#34;&gt;this article&lt;/a&gt; which suggested some scheduled tasks are now enabled by default within Windows Server 2012.  On looking there appear two&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;\Microsoft\Windows\TaskScheduler\Regular Maintenance
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;which has a Trigger Daily At 03:00 (if 2012 R2 this would be 2am as the default time changed) and&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;\Microsoft\Windows\TaskScheduler\Maintenance Configurator
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;which has a Trigger Daily At 01:00.&lt;/p&gt;
&lt;p&gt;The Action for these tasks is “Custom Handler”, Microsoft publish no details on what these tasks do. We logged a call with Microsoft and they also did not know what these, but they did say that tasks with a “Custom Handler” are umbrella’s for other tasks.&lt;/p&gt;
&lt;p&gt;As Regular Maintenance appeared to be the most likely due to execution time, I viewed its Last Run Time.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/win2012-san-perf-tshed.png&#34; alt=&#34;Task Scheduler&#34;&gt;&lt;/p&gt;
&lt;p&gt;I then manually worked through each Windows task in Task Scheduler and took note of which Tasks had Last Run Time which matched that of “Regular Maintenance”.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;\Microsoft\Windows\.NET Framework\.Net Framework NGEN v4.0.30319
\Microsoft\Windows\.NET Framework.Net Framework NGEN v4.0.30319 64
\Microsoft\Windows\Application Experience\AitAgent
\Microsoft\Windows\Application Experience\ProgramDataUpdater
\Microsoft\Windows\ApplicationData\CleanupTermporaryState
\Microsoft\Windows\Chkdsk\ProactiveScan
\Microsoft\Windows\Customer Experience Improvement Program\KernelCeipTask
\Microsoft\Windows\Customer Experience Improvement Program\UsbCeip
\Microsoft\Windows\Defrag\ScheduledDefrag
\Microsoft\Windows\Device Setup\Metadata Refresh
\Microsoft\Windows\PI\Sqm-Tasks
\Microsoft\Windows\Registry\RegIdleBackup
\Microsoft\Windows\Servicing\StartComponentCleanup
\Microsoft\Windows\Shell\CreateObjectTask
\Microsoft\Windows\Time Synchronization\SynchronizeTime
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Of these tasks,  we identified &lt;em&gt;ScheduleDefrag&lt;/em&gt; and &lt;em&gt;Chkdsk&lt;/em&gt; as potentially moving a lot of data around and freeing up blocks which would trigger Windows to isssue TRIM \ Unmap commands for the SAN to \recover the space within the Thin LUN.&lt;/p&gt;
&lt;p&gt;While looking at Trim \ Unmap on 2012 I  found that you can disable Trim \ Unmap commands being issued by setting the &lt;a href=&#34;http://technet.microsoft.com/en-us/library/cc785435.aspx&#34;&gt;DisableDeleteNotify&lt;/a&gt; file system attribute.&lt;/p&gt;
&lt;p&gt;As there are around 350 virtual servers per site, it was not practical to audit, enable and disable each of the four configuration items, &lt;em&gt;ODX&lt;/em&gt;, &lt;em&gt;Trim on delete&lt;/em&gt;, &lt;em&gt;ScheduledDefrag&lt;/em&gt; and &lt;em&gt;ChkDskProactiveScan&lt;/em&gt; so I wrote a modular PowerShell script to get current state,  enable and disable each against a list of servers,  this script can be &lt;a href=&#34;https://github.com/darrylcauldwell/WindowsTrimAndUnmap&#34;&gt;found here.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Our storage vendor provided this excellent detail &lt;a href=&#34;https://emc--c.na5.visual.force.com/apex/KB_BreakFix_1?id=kA1700000000tup&#34;&gt;EMC KB182688&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I would like to take functionality of thin provisioning so we have left enabled TrimOnDelete, but I could not see why you would want to Defrag a volume sitting on a Thin SAN LUN so we have disabled the ScheduledDefrag task. By disabling the task prevents Regular Maintenance running this at the 3am Window.*&lt;/p&gt;
&lt;p&gt;For the medium to longer term we are looking to prove the performance differential between 2012 R0 to R2 and if beneficial look to migrate to that.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Configuring Puppet</title>
      <link>https://darrylcauldwell.github.io/post/puppet/</link>
      <pubDate>Mon, 23 Sep 2013 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/puppet/</guid>
      <description>
        
          &lt;p&gt;I&amp;rsquo;m a traditional wintel vmware engineer working in the UK in a team focusing on platform configuration automation for virtual and physical Windows hosted solutions. This video of how &lt;a href=&#34;http://www.youtube.com/watch?v=UUgoiwEFe1A&#34;&gt;Puppet can be used to manage Amazon EC2&lt;/a&gt;. Shortly after watching this VMware Hybrid Cloud Services launched and on watching Nicholas Weavers video from PuppetConf 2013](&lt;a href=&#34;http://www.youtube.com/watch?v=tp_1N3RSyUY)&#34;&gt;http://www.youtube.com/watch?v=tp_1N3RSyUY)&lt;/a&gt;. From this point on I decided that I needed to look into Puppet and how it could help me,  on initial looking it became clear that Puppet is traditionally *nix but does function on Windows so I thought I&amp;rsquo;d start here.&lt;/p&gt;
&lt;h2 id=&#34;environmental-summary&#34;&gt;Environmental Summary&lt;/h2&gt;
&lt;p&gt;VMWare Workstation - 8.0.6 build-1035888&lt;br&gt;
Puppet Learning VM (1.5GB vRAM 1x vCPU 4.5GB HDD), &lt;a href=&#34;http://info.puppetlabs.com/download-learning-puppet-VM.html&#34;&gt;Download Here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;puppet-learning-vm---configuration&#34;&gt;Puppet Learning VM - Configuration&lt;/h2&gt;
&lt;p&gt;Once the Puppet Enterprise Learning VM is deployed from the OVF.  Its pretty intuitive setup I only changed to a bridged network connection for vNIC and installed VMware tools.&lt;/p&gt;
&lt;p&gt;VMware tools install command syntax used&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;yum -y install perl
mkdir /mnt/cdrom
mount /dev/cdrom /mnt/cdrom
cp /mnt/cdrom/VMwareTools-*.tar.gz /tmp
umount /mnt/cdrom
tar -zxf /tmp/VMwareTools-*.tar.gz -C /tmp
cd /
./tmp/vmware-tools-distrib/vmware-install.pl --default
rm -f /tmp/VMwareTools-*.tar.gz
rm -rf /tmp/vmware-tools-distrib
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
        
      </description>
    </item>
    
  </channel>
</rss>
