<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>automation on </title>
    <link>https://darrylcauldwell.github.io/categories/automation/</link>
    <description>Recent content in automation on </description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Wed, 12 Aug 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://darrylcauldwell.github.io/categories/automation/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Programaticly configuring VMware Storage Profile API with Python</title>
      <link>https://darrylcauldwell.github.io/post/python_spbm/</link>
      <pubDate>Wed, 12 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/python_spbm/</guid>
      <description>
        
          &lt;p&gt;I was looking to programaticly configuring VMware Storage Profile recently. My scripting language of choice is Python, VMware maintain &lt;a href=&#34;https://github.com/vmware/pyvmomi&#34;&gt;pyVmomi&lt;/a&gt; is which is the Python SDK for the VMware vSphere API. pyVmomi can be used to form binding and configure the &lt;a href=&#34;https://code.vmware.com/apis/968/vsphere&#34;&gt;vSphere Web Services API&lt;/a&gt; and the &lt;a href=&#34;https://code.vmware.com/apis/971&#34;&gt;VMware Storage Policy API&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The Storage Policy API is exposed as a Web service, running on VMware vCenter server systems.  When I approached the requirement it wasn&amp;rsquo;t clear to me how to connect to the Storage Policy API Web service. I read the &lt;a href=&#34;https://code.vmware.com/docs/11900/vmware-storage-policy-sdk-programming-guide&#34;&gt;VMware Storage Policy SDK Programming Guide&lt;/a&gt; section on forming connection which describes using the session cookie from a vCenter Server session to establish the Storage Policy session.&lt;/p&gt;
&lt;p&gt;pyVim is a client-side Python API which wraps pvVmomi these are made available as a package.  These are published to PyPI repository and as such can be installed easily with pip.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install --upgrade pyvmomi
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It we look at pyVmomi in GitHub we can see that &lt;a href=&#34;https://github.com/vmware/pyvmomi/blob/master/pyVim/connect.py&#34;&gt;pyVim.connect&lt;/a&gt; defines a function SmartConnect which can be used to form connection to the vSphere Web Services API.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#!/usr/bin/env python3
# Connect to a VMOMI ServiceInstance.

import ssl argparse atexit getpass
from pyVim.connect import SmartConnect

def get_args():
    parser = argparse.ArgumentParser(
        description=&#39;Arguments for talking to vCenter&#39;)

    parser.add_argument(&#39;-s&#39;, &#39;--host&#39;,
                        required=True,
                        action=&#39;store&#39;,
                        help=&#39;vCenter Server FQDN or IP address&#39;)

    parser.add_argument(&#39;-o&#39;, &#39;--port&#39;,
                        type=int,
                        default=443,
                        action=&#39;store&#39;,
                        help=&#39;vCenter Server TCP port&#39;)

    parser.add_argument(&#39;-u&#39;, &#39;--user&#39;,
                        required=True,
                        action=&#39;store&#39;,
                        help=&#39;Username to login to vCenter Server&#39;)

    parser.add_argument(&#39;-p&#39;, &#39;--password&#39;,
                        required=False,
                        action=&#39;store&#39;,
                        help=&#39;Password to login to vCenter Server&#39;)

    args = parser.parse_args()

    if not args.password:
        args.password = getpass.getpass(prompt=&#39;Enter password:&#39;)

    return args

def main():
    args = get_args()

    &amp;quot;&amp;quot;&amp;quot; connect to vcenter service instance &amp;quot;&amp;quot;&amp;quot;

    context = None
    if hasattr(ssl, &amp;quot;_create_unverified_context&amp;quot;):
        context = ssl._create_unverified_context()

    serviceInstance = SmartConnect(
                    host=args.host,
                    user=args.user,
                    pwd=args.password,
                    port=args.port,
                    sslContext=context)

    atexit.register(Disconnect, serviceInstance)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;To connect to the VMware Storage Policy API we need to get the session cookie. The &lt;a href=&#34;https://github.com/vmware/pyvmomi/blob/master/pyVmomi/VmomiSupport.py&#34;&gt;VmomiSupport&lt;/a&gt; provides us helper functions to do things like gather the context which includes session cookie details. With this we can form a stub session to the Storage Policy API.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    &amp;quot;&amp;quot;&amp;quot; connect to pbm service instance &amp;quot;&amp;quot;&amp;quot;

    VmomiSupport.GetRequestContext()[&amp;quot;vcSessionCookie&amp;quot;] = \
    serviceInstance._stub.cookie.split(&#39;&amp;quot;&#39;)[1]
    hostname = serviceInstance._stub.host.split(&amp;quot;:&amp;quot;)[0]
    pbmStub = SoapStubAdapter(
        host=hostname,
        version=&amp;quot;pbm.version.version1&amp;quot;,
        path=&amp;quot;/pbm/sdk&amp;quot;,
        poolSize=0,
        sslContext=ssl._create_unverified_context())
    pbmServiceInstance = pbm.ServiceInstance(&amp;quot;ServiceInstance&amp;quot;, pbmStub)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;With this connection in place we can make our request, in this example pull back all of the Storage Profiles.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
    &amp;quot;&amp;quot;&amp;quot; get profiles &amp;quot;&amp;quot;&amp;quot;

    profileManager = pbmServiceInstance.RetrieveContent().profileManager
    profiles = profileManager.PbmQueryProfile(resourceType=pbm.profile.ResourceType(resourceType=&amp;quot;STORAGE&amp;quot;))
    print(profiles)

if __name__ == &#39;__main__&#39;:
    main()
&lt;/code&gt;&lt;/pre&gt;
        
      </description>
    </item>
    
    <item>
      <title>Orchestrating configuration of vROps via REST API with Postman</title>
      <link>https://darrylcauldwell.github.io/post/vrops_rest/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/vrops_rest/</guid>
      <description>
        
          &lt;p&gt;vRealize Operations Manager (vROps) exposes some of its configuration via RESTful API. With this we can look to programatically control its configuration. My workflow is to use a REST client to explore API and validate payload formatting before moving to script the steps. My REST client of choice is &lt;a href=&#34;https://www.postman.com/&#34;&gt;Postman&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Performing any REST configuration in vRealize Operations Manager requires at least two steps:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Authenticate&lt;/li&gt;
&lt;li&gt;Perform action, like configure a new vCenter adapter&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To faciliate running a sequence of actions I start by creating a POSTMAN collection. Requests stored within the collection can be played in sequence. Using the example of configuring a new vCenter adapter we might create a collection called &amp;lsquo;vROps - New vCenter Adapter&amp;rsquo;.&lt;/p&gt;
&lt;p&gt;In case we have multiple environments and want to export our collection and reuse we  want to store environmental specifics as variables. To faciliate this we can create a POSTMAN envrionment. For example we might create a environment called &amp;lsquo;Homelab&amp;rsquo; which has variable vrops-fqdn and both initial and current value of vrops01.example.local&lt;/p&gt;
&lt;p&gt;vRealize Operations Manager REST API documentation describes how we can &lt;a href=&#34;https://docs.vmware.com/en/vRealize-Operations-Manager/8.1/com.vmware.vcom.api.doc/GUID-C3F0A911-A587-40F7-9998-13D4880A0C2B.html&#34;&gt;aquire an authentication token&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Create new reques in Postman with name &amp;lsquo;Aquire token&amp;rsquo;, set the request method to POST and set URL to use environment variable like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{% raw %}
https://{{vrops-fqdn}}/suite-api/api/auth/token/acquire
{% endraw %}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The documentation shows that two headers are required to be supplied so we must configure our request to pass these:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Content-Type: application/json
Accept: application/json
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The documentation also describes that we need to POST the vROps logon credentials as the body. Within Postman change body type to raw and paste below substrituing credentials appropriate to your environment.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{
  &amp;quot;username&amp;quot;: &amp;quot;vRealize-username&amp;quot;,
  &amp;quot;password&amp;quot;: &amp;quot;vRealize-password&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Successul processing of credential by the REST method returns a JSON body containing the token parameter. We want to capture this to use in the next step in our process. We can do this in Postman by running a script after the request is made which extracts the token value and sets this an environment variable. Change to the Test tab and add the following script.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;var jsonData = JSON.parse(responseBody);
postman.setEnvironmentVariable(&amp;quot;bearerToken&amp;quot;, jsonData.token);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We can now look at the next step in our example is to add a vCenter adapter which is documented &lt;a href=&#34;https://docs.vmware.com/en/vRealize-Operations-Manager/8.1/com.vmware.vcom.api.doc/GUID-18D17D09-628F-4974-AFE4-E94446E3462D.html&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Create new reques in Postman with name &amp;lsquo;Aquire token&amp;rsquo;, set the request method to POST and set URL to use environment variable like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{% raw %}
https://{{vrops-fqdn}}/suite-api/api/adapters
{% endraw %}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We require to apply three headers to this request, the ones to describe payload is in JSON format and an authentication header which passes the token value environment variable from previous step.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{% raw %}
Content-Type: application/json
Accept: application/json
Authentication: vRealizeOpsToken {{bearerToken}}
{% endraw %}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The documentation supplies an example body to post with some optional parameters. Similar to aquire step we place this in request body tab and ensure raw format is selected (ensuring you set envioronmentally values).&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{
  &amp;quot;name&amp;quot; : &amp;quot;New VC Adapter Instance&amp;quot;,
  &amp;quot;collectorId&amp;quot; : &amp;quot;1&amp;quot;,
  &amp;quot;adapterKindKey&amp;quot; : &amp;quot;VMWARE&amp;quot;,
  &amp;quot;resourceIdentifiers&amp;quot; : [ 
    {
      &amp;quot;name&amp;quot; : &amp;quot;VCURL&amp;quot;,
      &amp;quot;value&amp;quot; : &amp;quot;https://vcenter.example.local&amp;quot;
    } 
  ],
  &amp;quot;credential&amp;quot; : {
    &amp;quot;id&amp;quot; : null,
    &amp;quot;name&amp;quot; : &amp;quot;VC-Credential-1&amp;quot;,
    &amp;quot;adapterKindKey&amp;quot; : &amp;quot;VMWARE&amp;quot;,
    &amp;quot;credentialKindKey&amp;quot; : &amp;quot;PRINCIPALCREDENTIAL&amp;quot;,
    &amp;quot;fields&amp;quot; : [ 
      {
        &amp;quot;name&amp;quot; : &amp;quot;USER&amp;quot;,
        &amp;quot;value&amp;quot; : &amp;quot;administrator@vsphere.local&amp;quot;
      }, 
      {
        &amp;quot;name&amp;quot; : &amp;quot;PASSWORD&amp;quot;,
        &amp;quot;value&amp;quot; : &amp;quot;VC-dummy-passwd&amp;quot;
      } 
    ],
  },
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It is not essential but it is useful for troubleshooting of our request to output the token environment variable value to log prior to attempting to make the request. To do this we can use the &amp;lsquo;Pre-request script&amp;rsquo; tab and add the follwoing script.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;console.log(pm.environment.get(&amp;quot;bearerToken&amp;quot;));
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We can now run the collection which will open &amp;lsquo;Postman runner&amp;rsquo; which will make the two requests. The summary detail is output to &amp;lsquo;Postman running&amp;rsquo; and you can get more detailed output in &amp;lsquo;Postman console&amp;rsquo; view.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Cloudbased-init For vSphere</title>
      <link>https://darrylcauldwell.github.io/post/cloudbased-init/</link>
      <pubDate>Thu, 26 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/cloudbased-init/</guid>
      <description>
        
          &lt;p&gt;vRealize Automation Cloud and 8.x allows you to deploy and configure cloud agnostic virtual machines. To achieve agnostic in-guest OS customization capability across for on-premises vSphere, AWS, GCP and Azure endpoints &lt;a href=&#34;https://cloud-init.io/&#34;&gt;cloud-init&lt;/a&gt; is used for Linux guests and &lt;a href=&#34;https://cloudbase.it/cloudbase-init/&#34;&gt;cloudbase-init&lt;/a&gt; is used for Windows guests.&lt;/p&gt;
&lt;h2 id=&#34;inital-attempt-all-defaults&#34;&gt;Inital Attempt All Defaults&lt;/h2&gt;
&lt;p&gt;In vSphere I created a Windows 2019 VM with defaults except for mapping ISO as CD/ROM. I then ran through installer to install Standard edition with Desktop experience, installed VMware Tools, disabled firewall and enabled Remote Desktop. I installed Cloudbased- init 0.9.12.dev76 and optional Carbon PowerShell module to default location. For configuration options I left the default Admin user be created into Administrators group, in addition I selected option to ‘Run Cloudbased-Init service as LocalSystem’. I chose options to &amp;lsquo;Run Sysprep to create a generalized image&amp;rsquo; and &amp;lsquo;Shutdown when Sysprep terminates&amp;rsquo;. When complete I change virtual machine to be a virtual machine template.&lt;/p&gt;
&lt;p&gt;I connect to vRealize Automation Cloud &amp;gt; Infrastructure &amp;gt; Cloud Accounts &amp;gt; {my account} and run &amp;lsquo;Sync Images&amp;rsquo;.  Once image sync is completed vRealize Automation Cloud &amp;gt; Infrastructure &amp;gt; Image Mappings and create &amp;lsquo;New Image Mapping&amp;rsquo;. Create a Blueprint with single Cloud Agnostic Machine linked to the image mapping.&lt;/p&gt;
&lt;p&gt;When I provision a vRA Cloud blueprint to deploy a VM&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;formatVersion: 1
inputs: {}
resources:
Cloud_Machine_1:
    type: Cloud.Machine
    properties:
    image: dc-win2019
    flavor: small
    cloudConfig: |
        #cloud-config
        hostname: i-got-a-new-name
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The VM powers on and cloud-data gets passed by vRealize Automation Cloud as an OVF which is mounted as CDROM with CDROM contents ovf-env.xml in its root.&lt;/p&gt;
&lt;p&gt;Cloud-init runs on startup but appears to fail to do what it is asked, Cloudbase-init.log contains error.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;2019-09-26 16:00:15.041 4360 ERROR cloudbaseinit.metadata.services.base [-] HTTPConnectionPool(host=&#39;169.254.169.254&#39;, port=80): Max retries exceeded with url: /openstack/latest/meta_data.json
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;adding-ovf-metadata-service&#34;&gt;Adding OVF Metadata Service&lt;/h2&gt;
&lt;p&gt;Looking at the error suggested to me that Cloudbase-Init was not finding the OVF and file. I read through some of the Cloudbase-Init documentation and found that metadata service configuration was specified in,&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;C:\Program Files\Cloudbase Solutions\Cloudbase-Init\conf\cloudbase-init-unattend.conf
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Checking the default configuration file does not include the &lt;a href=&#34;https://cloudbase-init.readthedocs.io/en/latest/services.html&#34;&gt;OvfService metadata service&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;metadata_services=cloudbaseinit.metadata.services.configdrive.ConfigDriveService,cloudbaseinit.metadata.services.httpservice.HttpService,cloudbaseinit.metadata.services.ec2service.EC2Service,cloudbaseinit.metadata.services.maasservice.MaaSHttpService
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If I follow similar steps to before to creeate templat but during install of Cloudbase-init but DO NOT chose wizard options &amp;lsquo;Sysprep and Shutdown&amp;rsquo;.  Instead I update the metadata_services entry in the cloudbase-init-unattend.conf file include OvfService like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;metadata_services=cloudbaseinit.metadata.services.ovfservice.OvfService
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Other Cloudbase-Init &lt;a href=&#34;https://cloudbase-init.readthedocs.io/en/latest/plugins.html#plugins&#34;&gt;plugins&lt;/a&gt; which require reading metadata, such that which sets the hostname, pickup their configuration from this config file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;C:\Program Files\Cloudbase Solutions\Cloudbase-Init\conf\cloudbase-init.conf
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The default installation of cloudbase-init.conf does not have a metadata_services entry at all. To allow the plugins be capable of reading metadata from OVF source add the following line to the file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;metadata_services=cloudbaseinit.metadata.services.ovfservice.OvfService
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;When both files have been updated execute sysprep passing the same parameters as the Cloudbase-Init installer wizard would:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd “C:\Program Files\Cloudbase Solutions\Cloudbase-Init\conf\”
C:\Windows\System32\Sysprep\Sysprep.exe /quiet /generalize /oobe /shutdown /unattend:unattend.xml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Performing a deployment of thee vRealize Automation Cloud blueprint example from earlier now deploys a VM with its hostname updated.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Understanding VMware Guest OS Customization</title>
      <link>https://darrylcauldwell.github.io/post/guest-customization/</link>
      <pubDate>Wed, 11 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/guest-customization/</guid>
      <description>
        
          &lt;p&gt;I recently began looking more closely at cloud-init for customizing VMware guest VMs. This caused me some heachaches! I took various notes while troubleshooting and researching around this.&lt;/p&gt;
&lt;h2 id=&#34;why-guest-os-customization-is-needed&#34;&gt;Why Guest OS Customization Is Needed&lt;/h2&gt;
&lt;p&gt;When you clone a virtual machine or deploy a virtual machine from a template it clones the virtual hard disk and all guest operating system settings. In many deployment scenarios if virtual machines with identical settings are deployed conflicts can occur, such as duplicate computer names. Typically for this deployment scenario during deployment guest operating system customization is required to be performed to give them uniqueness.&lt;/p&gt;
&lt;h2 id=&#34;vm-guest-os-customization-approach&#34;&gt;VM Guest OS Customization Approach&lt;/h2&gt;
&lt;p&gt;VMware has long provided the facility to perform guest operating system customization through a combination of vCenter Server and VMware Tools. This gives the option to choose to launch the Guest Customization wizard during the cloning or deployment process,  or can create standard customization specifications and apply these during the cloning or deployment process.&lt;/p&gt;
&lt;p&gt;When the virtual machine template is Linux the VMware guest operating system customization is performed using a combination of cloud-init and a collection of perl scripts packaged with open-vm-tools.&lt;/p&gt;
&lt;h2 id=&#34;logfiles-and-log-configuration&#34;&gt;Logfiles and Log Configuration&lt;/h2&gt;
&lt;p&gt;Guest OS can be complex and things can go wrong during guest OS customization. When they do its useful to understand where to look for clues as to cause.&lt;/p&gt;
&lt;p&gt;If there were any problems with the extraction and deployment of the customization package onto the guest operating system these are written to:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;/var/log/vmware-imc/toolsDeployPkg.log
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;VMware guest operating system customization steps performed using the perl scripts output to default location of /var/log/messages. There are many other things in this log file so can use grep to view only the customization steps:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;grep &amp;quot;customize-guest&amp;quot; /var/log/messages 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;There are many options for configuring cloud-init logging. These can be configured these within your template virtual machine. The configuration settings are stored in:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;/etc/cloud/cloud.cfg.d/05_logging.cfg
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Within this configuration file we can identify that by default cloud-init directs the main handler output to a file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;/var/log/cloud-init.log
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We can also see that by default the stdout and stderr of the specific we tell it to perform is written to:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;/var/log/cloud-init-output.log
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;customization-guest-customatization-configuration&#34;&gt;Customization Guest Customatization Configuration&lt;/h2&gt;
&lt;p&gt;There are many options which cloud-init can be configured with. These can be configured these within your template virtual machine. The configuration settings are stored in:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;/etc/cloud/cloud.cfg
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;One of the options which can be configured is whether VMware tools perl scripts are ran. How to enable or disable this is documented in this article:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;https://kb.vmware.com/s/article/59557
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It is useful to note here that there is currently a known issue when cloud-init calls the open-vm-tools perl scripts for &amp;lsquo;Ubuntu 18.04&amp;rsquo;. The boot sequence and bring up order can cause the perl scripts to fail. A high level cause and workaround are described here:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;https://kb.vmware.com/s/article/56409 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;A more detailed description of the bug including some very interesting detail about how cloud-init and open-vm-tools perl scripts are called is described here:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;https://bugs.launchpad.net/ubuntu/+source/open-vm-tools/+bug/1793715
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;cloud-init-user-data&#34;&gt;Cloud-Init User-Data&lt;/h2&gt;
&lt;p&gt;One of the more useful enhancements of using cloud-init is the ability to instruct the guest operating system to run things such as custom scripts during boot.&lt;/p&gt;
&lt;p&gt;User-Data content supports the following types of content &amp;lsquo;gzip compressed&amp;rsquo; or &amp;lsquo;mime multi-part archive&amp;rsquo;. With a mime multi-part file, the user can specify more than one type of data within the content.  For full details on the User-Data content format see here:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;https://cloudinit.readthedocs.io/en/latest/topics/format.html
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The two most common data types I use at the moment are Cloud Config Data or simple shell scripts. To differentiate sections when using a &amp;lsquo;mime multi-part archive&amp;rsquo; begin each section with data type for example  &lt;code&gt;#!&lt;/code&gt; for shell script or &lt;code&gt;#cloud-config&lt;/code&gt; for cloud config data.&lt;/p&gt;
&lt;p&gt;Cloud-init can be fussy about syntax of the file contents once created you can validate the syntaxt using a command like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cloud-init devel schema --config-file /tmp/user-data
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;vcenter-deploy-ova-import&#34;&gt;vCenter Deploy OVA Import&lt;/h2&gt;
&lt;p&gt;Some operating systems packages which include cloud-init expose options to confiure during deployment.  For example Ubuntu which can be found here:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;https://cloud-images.ubuntu.com/releases/18.04/release/ubuntu-18.04-server-cloudimg-amd64.ova
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The Ubunutu image includes property &amp;lsquo;Encoded user-data&amp;rsquo; this has property description &lt;em&gt;&amp;ldquo;In order to fit into a xml attribute, this value is base64 encoded . It will be decoded, and then processed normally as user-data&amp;rdquo;&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;I like to keep a file copy of the un-encoded and encoded user-data. To do this I use text editior to create a file with the required cloud-init user-data contents.  I then use &lt;a href=&#34;https://linux.die.net/man/1/base64&#34;&gt;base64&lt;/a&gt; to output contents into a file appended with .b64.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;base64 --input /tmp/user-data --output /tmp/user-data.b64
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If encoded user-data is passed during deployment of OVA file in this way this will run when the VM boots.&lt;/p&gt;
&lt;h2 id=&#34;cloud-assembly&#34;&gt;Cloud Assembly&lt;/h2&gt;
&lt;p&gt;Other VMware products such as Cloud Assembly can utilize open-vm-tools and cloud-init to perform guest customization.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;https://docs.vmware.com/en/VMware-Cloud-Assembly/services/Using-and-Managing/GUID-70EA052D-FABF-4CE5-875D-9B52FED08AA3.html
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;https://blogs.vmware.com/management/2018/11/customizing-cloud-assembly-deployments-with-cloud-init.html
&lt;/code&gt;&lt;/pre&gt;
        
      </description>
    </item>
    
    <item>
      <title>Cloud Assembly VM Guest Management With Ansible</title>
      <link>https://darrylcauldwell.github.io/post/ansible-cloud-assembly/</link>
      <pubDate>Thu, 01 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/ansible-cloud-assembly/</guid>
      <description>
        
          &lt;p&gt;VMware &lt;a href=&#34;https://cloud.vmware.com/cloud-automation-services&#34;&gt;Cloud Automation Services&lt;/a&gt; is a product suite comprising three products, &lt;a href=&#34;https://cloud.vmware.com/cloud-assembly&#34;&gt;Cloud Assembly&lt;/a&gt;, &lt;a href=&#34;https://cloud.vmware.com/service-broker&#34;&gt;Service Broker&lt;/a&gt; and &lt;a href=&#34;https://cloud.vmware.com/code-stream&#34;&gt;Code Stream&lt;/a&gt;. Cloud Assembly provides a blueprinting engine and manages connectivity to multiple cloud endpoints. Service Broker provides a unified catalog for publishing blueprints with role-based policies. Code Stream provides a release pipeline with analytics.&lt;/p&gt;
&lt;p&gt;The Cloud Assembly blueprinting engine can be used to consistently deliver VMs and applications.  To deliver VM guest configuration Cloud Assembly natively uses &lt;a href=&#34;https://cloudinit.readthedocs.io/en/latest/&#34;&gt;cloud-init&lt;/a&gt;. This native VM guest configuration capability can be extended with desired state management tools &lt;a href=&#34;https://puppet.com/&#34;&gt;Puppet&lt;/a&gt; and &lt;a href=&#34;https://www.ansible.com/&#34;&gt;Ansible&lt;/a&gt;. A major difference between the Puppet and Ansible is that Puppet requires an in-guest agent where Ansible operates agentless.&lt;/p&gt;
&lt;h2 id=&#34;ansible&#34;&gt;Ansible&lt;/h2&gt;
&lt;p&gt;In this blog post I am going to focus on Cloud Assembly integration with Ansible.  The Ansible engine is &lt;a href=&#34;https://github.com/ansible/ansible&#34;&gt;fully open source&lt;/a&gt;, but OSS RedHat also offers a &lt;a href=&#34;https://www.ansible.com/products/engine&#34;&gt;license model and support package&lt;/a&gt; for Ansible engine. In addition to the Ansible engine RedHat provides support for &lt;a href=&#34;https://www.ansible.com/products/tower&#34;&gt;Ansible Tower&lt;/a&gt; which offers many enterprise grade features. A useful comparison can be found in the blog &lt;a href=&#34;https://www.ansible.com/blog/red-hat-ansible-automation-engine-vs-tower&#34;&gt;Red Hat Ansible Automation: Engine, Tower or Both&lt;/a&gt;. Cloud Assembly supports integration directly with Ansible engine and does not depend on Ansible Tower.&lt;/p&gt;
&lt;p&gt;The Ansible control node connects to managed nodes and pushing out small programs, called &amp;ldquo;Ansible modules&amp;rdquo; to them. These programs are written to be resource models of the desired state of the system. Ansible then executes these modules (over SSH by default), and removes them when finished.&lt;/p&gt;
&lt;h2 id=&#34;ansible-headless-deployment-model&#34;&gt;Ansible Headless Deployment Model&lt;/h2&gt;
&lt;p&gt;Ansible does not require a single controlling machine. Any Linux machine can run Ansible. A headless deployment model is where each machine runs as both the Ansible control node role and the Ansible controlled node. The absence of a central management server requirement can greatly increase availability, simplify disaster-recovery planning and enhance security (no single point of control).&lt;/p&gt;
&lt;p&gt;When we use this deployment model each server has Ansible installed and has inventory file with a single entry named localhost. We create a Cloud Assembly blueprint which includes cloud-init configuration to pull an Ansible playbook from a repository and execute it locally. Here the Ansible playbook is specific to the server role on which it will be ran.&lt;/p&gt;
&lt;p&gt;An example of how to deploy an application using this deployment architecture using Cloud Assembly is described &lt;a href=&#34;https://github.com/darrylcauldwell/titoAnsibleHeadless&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;central-ansible-control-node&#34;&gt;Central Ansible Control Node&lt;/h2&gt;
&lt;p&gt;While running Ansible without a central control node can be useful for some deployment scenarios, others are better suited to having a central Ansible controller node controlling multiple clients.&lt;/p&gt;
&lt;p&gt;Typical factors which would drive a deployment architecture with a central control node would be the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Windows guests as Ansible control node can only runs on Linux&lt;/li&gt;
&lt;li&gt;Large deployments that require centralized control for day two operations&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;When we use this deployment model we deploy a central Ansible control node and on this we create SSH authorization private public key pair. We then configure this to be integrated with Cloud Assembly.&lt;/p&gt;
&lt;p&gt;We create a Cloud Assembly blueprint which includes on each VM resource cloud-init configuration to create a local account named ansible which has a SSH public key of key pair on the Ansible control node. The Cloud Assembly blueprint then has Ansible resource added with details of the Ansible control node, the private key to use to connect and which playbook to execute. Within the blueprint the Ansible resouece has a relationship formed with the appropriate VM resources. When the blueprint is deployed the VM resources get added dynamically to the Ansible server inventory file and the playbook executed. In this model the Ansible playbook can be application rather than server role specific.&lt;/p&gt;
&lt;p&gt;An example of how to deploy an application with this deployment architecture using Cloud Assembly is described &lt;a href=&#34;https://github.com/darrylcauldwell/titoAnsible&#34;&gt;here&lt;/a&gt;.  This also includes a simplified example of how Ansible server can be used for day two operations for servers of a specific type.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Controlling NSX-T with Terraform</title>
      <link>https://darrylcauldwell.github.io/post/nsx-terraform/</link>
      <pubDate>Mon, 07 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/nsx-terraform/</guid>
      <description>
        
          &lt;p&gt;Hashicorp Terraform is a tool which enables you to safely and predictably create, change, and improve infrastructure by defining its configuration as code.&lt;/p&gt;
&lt;p&gt;VMware NSX-T is a product which enables software defined network infrastructure.&lt;/p&gt;
&lt;p&gt;The Terraform NSX-T provider allows us to deliver and maintain NSX-T configuration as code.&lt;/p&gt;
&lt;p&gt;This is a walkthrough of how in a very few commands you can begin to control NSX-T configuration using NSX-T.&lt;/p&gt;
&lt;p&gt;If starting from scratch &lt;a href=&#34;https://learn.hashicorp.com/terraform/getting-started/install.html&#34;&gt;install a simple terraform server&lt;/a&gt;,  on CentOS / RHEL you would use these commands.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;yum update -y
yum install wget net-tools unzip -y
cd /tmp
wget https://releases.hashicorp.com/terraform/0.11.11/terraform_0.11.11_linux_amd64.zip
mkdir /terraform
unzip terraform_0.11.11_linux_amd64.zip -d /terraform
cd /terraform
./terraform --version
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once we have this installed we can configure the  NSX-T Manager connection details as variables in a reusable variables file.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cat &amp;gt; /terraform/variables.tf &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;lt;&amp;lt; &amp;#39;__EOF__&amp;#39;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;variable &amp;#34;nsx_manager&amp;#34; {}
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;variable &amp;#34;nsx_username&amp;#34; {}
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;variable &amp;#34;nsx_password&amp;#34; {}
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;__EOF__&lt;/span&gt;

cat &amp;gt; /terraform/terraform.tfvars &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;lt;&amp;lt; &amp;#39;__EOF__&amp;#39;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;nsx_manager = &amp;#34;192.168.1.15&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;nsx_username = &amp;#34;admin&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;nsx_password = &amp;#34;VMware1!&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;__EOF__&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We can then create a very basic Terraform configuration file which uses these variables and then performs a simple action like creating a NSX IP Set.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cat &amp;gt; /terraform/nsx.tf &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;lt;&amp;lt; &amp;#39;__EOF__&amp;#39;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;provider &amp;#34;nsxt&amp;#34; {
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  host                  = &amp;#34;${var.nsx_manager}&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  username              = &amp;#34;${var.nsx_username}&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  password              = &amp;#34;${var.nsx_password}&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  allow_unverified_ssl  = true
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  max_retries           = 10
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  retry_min_delay       = 500
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  retry_max_delay       = 5000
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  retry_on_status_codes = [429]
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;}
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;resource &amp;#34;nsxt_ip_set&amp;#34; &amp;#34;ip_set1&amp;#34; {
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  description  = &amp;#34;IP Set provisioned by Terraform&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  display_name = &amp;#34;IP Set&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  tag {
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    scope = &amp;#34;color&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    tag   = &amp;#34;blue&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  }
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  ip_addresses = [&amp;#34;1.1.1.1&amp;#34;, &amp;#34;2.2.2.2&amp;#34;]
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;}
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;__EOF__&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;With this in place we can initialize Terraform and get it to pull down the NSX-T provider.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;./terraform init
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If all has gone well Terraform should initialize successfully.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;We can now look at the changes our Terraform configuration file will make to NSX.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;./terraform plan
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We should see the single resource defined in the Terraform configuration file.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;Now we have verified it does what we hope we can then look to apply the change.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;./terraform apply
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Not as this is changing configuration we get asked to confirm action.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;Once ran successfully we can then check in NSX GUI and confirm the IP Set is created.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;If we would like to launch and destroy application specific NSX network infrastructure when we deploy our application. We would do this with a CI/CD pipeline tool like Jenkins will walk through this. If starting from scratch &lt;a href=&#34;https://wiki.jenkins.io/display/JENKINS/Installing+Jenkins+on+Red+Hat+distributions&#34;&gt;install a simple jenkins server&lt;/a&gt;, on CentOS / RHEL you would use these commands.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;yum update -y
yum install wget net-tools unzip -y
wget -O /etc/yum.repos.d/jenkins.repo http://pkg.jenkins-ci.org/redhat-stable/jenkins.repo
rpm --import https://jenkins-ci.org/redhat/jenkins-ci.org.key
yum install jenkins java -y
service jenkins start
chkconfig jenkins on
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once installed and running we would normally load the &lt;a href=&#34;https://wiki.jenkins.io/display/JENKINS/Terraform+Plugin&#34;&gt;Terraform plugin&lt;/a&gt;,  however this does not presently work as Terraform prompts for confirmation.  There is a &lt;a href=&#34;https://github.com/jenkinsci/terraform-plugin/pull/4/commits/47d6d3da54dd2cc437c1efb5df89cdccdb0f3eb0&#34;&gt;pending pull request to fix this&lt;/a&gt; until this gets merged we need a workaround.&lt;/p&gt;
&lt;p&gt;To workaround this issue we can still control Terraform with Jenkins by calling a shell script from within Jenkins job.  To do this we will create a folder and give Jenkins user account permissions by running following.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;mkdir /terraform
sudo usermod -a -G root jenkins
chmod -R g+w /terraform
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We can then create a Jenkins job with Build contents which creates a Terraform file and applies this.  A simple example would be.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cd /terraform

cat &amp;gt; /terraform/nsx.tf &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;lt;&amp;lt; &amp;#39;__EOF__&amp;#39;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;provider &amp;#34;nsxt&amp;#34; {
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  host                  = &amp;#34;192.168.1.15&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  username              = &amp;#34;admin&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  password              = &amp;#34;VMware1!&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  allow_unverified_ssl  = true
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  max_retries           = 10
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  retry_min_delay       = 500
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  retry_max_delay       = 5000
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  retry_on_status_codes = [429]
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;}
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;resource &amp;#34;nsxt_ip_set&amp;#34; &amp;#34;ip_set1&amp;#34; {
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  description  = &amp;#34;IP Set provisioned by Terraform&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  display_name = &amp;#34;IP Set&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  tag {
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    scope = &amp;#34;color&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    tag   = &amp;#34;blue&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  }
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  ip_addresses = [&amp;#34;1.1.1.1&amp;#34;, &amp;#34;2.2.2.2&amp;#34;]
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;}
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;__EOF__&lt;/span&gt;

./terraform init

./terraform apply -auto-approve

rm -f nsx.tf
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This is an overly simple example and more likely we would pull a config file from distributed source control such as github.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>NSX-T for OpenShift</title>
      <link>https://darrylcauldwell.github.io/post/nsx-openshift/</link>
      <pubDate>Sat, 28 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/nsx-openshift/</guid>
      <description>
        
          &lt;p&gt;While looking at the various documentation sets I found it difficult to understand the NSX-T and OpenShift integration. A lot was masked by configuration performed by Ansible scripts. Here I try and record my understanding of the technology and then work through getting this running in a capacity constrained lab environment.&lt;/p&gt;
&lt;h2 id=&#34;nsx-t&#34;&gt;NSX T&lt;/h2&gt;
&lt;p&gt;NSX-T (NSX Transformers) can provide network virtualization for multi-hypervisor environments, including both vSphere and KVM. It is also designed to address emerging application frameworks and architectures that have heterogeneous endpoints and technology stacks such as OpenStack, Red Hat OpenShift, Pivotal Cloud Foundry, Kubernetes, and Docker. NSX-V (NSX for vSphere) Manager integrates into vCenter and leverages a vSphere dvSwitch to form an overlay. NSX-T Manager can be used with vSphere it does not integrate with vCenter or dvSwitch, instead NSX is managed via its API, and its overlay is formed by each member having Open vSwitch (OVS) installed.&lt;/p&gt;
&lt;h2 id=&#34;red-hat-openshift&#34;&gt;Red Hat OpenShift&lt;/h2&gt;
&lt;p&gt;OpenShift helps you to develop, deploy, and manage container-based applications. It provides you with a self-service platform to create, modify, and deploy applications on demand, thus enabling faster development and release life cycles. OpenShift is built around a core of application containers powered by Docker, with orchestration and management provided by Kubernetes.&lt;/p&gt;
&lt;h2 id=&#34;container-networking-framework-background&#34;&gt;Container Networking Framework Background&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/docker/libnetwork/blob/master/docs/design.md&#34;&gt;Libnetwork&lt;/a&gt; is the canonical implementation Container Network Model (CNM) which formalizes the steps required to provide networking for containers while providing an abstraction that can be used to support multiple network drivers. Libnetwork provides an interface between the Docker daemon and network drivers. Container Network Model (CNM) is designed to support the Docker runtime engine only.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/containernetworking/cni&#34;&gt;Container Network Interface&lt;/a&gt; (CNI), consists of a specification and libraries for writing plugins to configure network interfaces in Linux containers, along with a number of supported plugins. Container Network Interface (CNI) supports integration with any container runtime.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift-cni.jpeg&#34; alt=&#34;Container Network Interface (CNI) Integration&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;vmware-nsx-and-kubernetes-integration&#34;&gt;VMware NSX and Kubernetes Integration&lt;/h2&gt;
&lt;p&gt;VMware provide an &lt;a href=&#34;https://my.vmware.com/group/vmware/details?downloadGroup=NSX-T-PKS-221&amp;amp;productId=673&#34;&gt;NSX Container Plugin package&lt;/a&gt; which contains the required modules to integrate NSX-T with Kubernetes.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;NSX Container Plugin (NCP) - is a container image which watches the Kubernetes API for changes to Kubernetes Objects (namespaces, network policies, services etc.). It calls the NSX API to creates network constructs based on object addition and changes.&lt;/li&gt;
&lt;li&gt;NSX DaemonSet
&lt;ul&gt;
&lt;li&gt;NSX Node Agent - is a container image which manages the container network interface&lt;/li&gt;
&lt;li&gt;NSX Kube-Proxy - is a container image which replaces the native distributed east-west load balancer in Kubernetes with the NSX load-balancer based on Open vSwitch (OVS).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;NSX Container Network Interface (CNI) - is an executable which allow the integration of NSX into Kubernetes.&lt;/li&gt;
&lt;li&gt;Open vSwitch&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift-ncp.jpeg&#34; alt=&#34;NSX and Kubernetes Integration&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;nsx-for-openshift&#34;&gt;NSX For OpenShift&lt;/h2&gt;
&lt;p&gt;NSX implements a discreet network topology per Kubernetes namespace. NSX maps logical network elements like logical switches and distributed logical router to Kubernetes namespaces. Each of those network topologies can be directly routed, or privately addressed and behind NAT.&lt;/p&gt;
&lt;h2 id=&#34;nsx-for-openshift-homelab&#34;&gt;NSX For OpenShift Homelab&lt;/h2&gt;
&lt;p&gt;For the rest of this blog post I am aiming to create a NSX OpenShift integration. I aiming for two namespaces, each with a logical router and three subnets. The namespaces will use private address ranges and the tier-0 router will provide SNAT connectivity to the routed network.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift-nsx-topology.jpeg&#34; alt=&#34;NSX Topology&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;starting-point-homelab-configuration&#34;&gt;Starting point homelab configuration&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;1GbE Switch (Layer 2 only)
&lt;ul&gt;
&lt;li&gt;VLAN 0 - CIDR 192.168.1.0/24&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;vSphere vCenter Appliance 6.7&lt;/li&gt;
&lt;li&gt;3x vSphere ESXi 6.7 Update 1 hosts (Intel NUC - 3x 1.8GHz CPU &amp;amp; 32GB RAM)
&lt;ul&gt;
&lt;li&gt;Onboard NIC is connected to a vSphere Standard Switch&lt;/li&gt;
&lt;li&gt;USB3 NIC is unused and will be used for NSX&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;VSAN&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The following resources are required&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Small NSX-T Manager is a VM sized 8GB vRAM, 2x vCPU and 140GB vHDD&lt;/li&gt;
&lt;li&gt;Small NSX Controller is a VM sized 8GB vRAM, 2x vCPU and 120GB vHDD&lt;/li&gt;
&lt;li&gt;Small NSX Edge is a VM sized 4GB vRAM, 2x vCPU and 120GB vHDD&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;nsx-management-plane&#34;&gt;NSX Management Plane&lt;/h2&gt;
&lt;p&gt;Deploy a small NSX unifed appliance specifying the nsx-manager role. Once deployed link this to vCenter, to do this add vCenter in &amp;lsquo;Fabric / Compute Manager&amp;rsquo;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift-nsx-compute-manager.jpeg&#34; alt=&#34;NSX-T Management Plane&#34;&gt;&lt;/p&gt;
&lt;p&gt;With the manager in place we now need to create the management plane, to do this we need to install the management plane agent (MPA) on each host so they are added as usable Fabric Nodes.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift-nsx-nodes.jpeg&#34; alt=&#34;NSX-T Fabric Nodes&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;tunnel-endpoint-ip-pool&#34;&gt;Tunnel Endpoint IP Pool&lt;/h2&gt;
&lt;p&gt;We create an IP pool one for the Transort Nodes to communicate for my scenario the three ESXi hosts and an edge will all participate so I create an IP Pool with four addresses. Navigate to Inventory &amp;gt; Groups &amp;gt; IP Pools and click add.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift-nsx-ip-pool.png&#34; alt=&#34;NSX-T IP Pool&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;nsx-control-plane&#34;&gt;NSX Control Plane&lt;/h2&gt;
&lt;p&gt;In order to create an overlay network we need an NSX Controller to manage the hosts. NSX Controllers serve as the central control point got all hosts, logical switches, and logical routers.&lt;/p&gt;
&lt;p&gt;While NSX Manager can deploy and configure NSX Controllers the size cannot be selected. As lab is resource constrained I only want a small NSX Controller, the &amp;lsquo;NSX Controller for VMware ESXi&amp;rsquo; is a separate OVA download where size can be selected.&lt;/p&gt;
&lt;p&gt;Once the controller appliance is deployed we need to facilitate communications between it and nsx manager.  To do this open an SSH session with admin user to NSX Manager and run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;get certificate api thumbprint
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Open an SSH session to NSX Controller with admin user and run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;join management-plane &amp;lt;NSX-Manager&amp;gt; username admin thumbprint &amp;lt;NSX-Managers-thumbprint&amp;gt;

set control-cluster security-model shared-secret

initialize control-cluster
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift-nsx-mgr-ctrl-thumb.jpeg&#34; alt=&#34;NSX-T Controller&#34;&gt;&lt;/p&gt;
&lt;p&gt;This should then be viewable in NSX Manager&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift-nsx-control-cluster.jpeg&#34; alt=&#34;NSX-T Controller Cluster&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;overlay-transport-zone&#34;&gt;Overlay Transport Zone&lt;/h2&gt;
&lt;p&gt;All the virtual network objects will need to communicate across an overlay network. To faciliate this the three esxi hosts and edges need to be part of an Overlay Transport Zone.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift-nsx-transport.jpeg&#34; alt=&#34;NSX-T Transport Zone&#34;&gt;&lt;/p&gt;
&lt;p&gt;Once we have a Transport Zone we can add our NSX fabric nodes as transport nodes. Navigate menu to Select Fabric &amp;gt; Transport Nodes and click Add.  A wizard will open on the general tab select first Node (host), give appropriate name for that host and select the openshift transport zone.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift-nsx-transport-node.jpeg&#34; alt=&#34;NSX-T Transport Node&#34;&gt;&lt;/p&gt;
&lt;p&gt;Change to N-VDS tab, create N-VDS for openshift, select default NIOC, select default hostswitch Uplink profile, select transport IP Pool and enter Physical NIC identifier for Uplink-1.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift-nsx-host-vds.jpeg&#34; alt=&#34;NSX-T Transport Zone N-VDS&#34;&gt;&lt;/p&gt;
&lt;p&gt;In order that the NSX Container Plugin can find the correct NSX objects all of the NSX objects created require a tag applying. For this lab build I am using tag dc-openshift. Navigate within NSX Manager to Fabric &amp;gt; Transport Zones, select overlay network then Actions &amp;gt; Manage Tags and apply tag.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Scope = ncp/cluster and Tag = dc-openshift
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift-ncp-tags.jpeg&#34; alt=&#34;NSX-T Openshift Tags&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;vlan-transport-zone&#34;&gt;VLAN Transport Zone&lt;/h2&gt;
&lt;p&gt;As well as connecting to the overlay network the Edges running Tier-0 routing functions also needs to be able to connect to the physical network. This connectivity is achieved by using a Transport Zone of type VLAN.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift-nsx-vlan-transport.png&#34; alt=&#34;NSX-T VLAN Transport Zone&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;nsx-edge&#34;&gt;NSX Edge&lt;/h2&gt;
&lt;p&gt;We need some way for the logical container overlay network to communicate with the physical network. AN NSX Edge can host services which provide this connectivity.&lt;/p&gt;
&lt;p&gt;The NSX Edge has 4 network adapters, the first is used by the management network, the other 3 interfaces (fp-eth0, fp-eth1 and fp-eth2) can then be used for connecting to overlay networks or for routing. Within my lab I have a single flat physical network so all NSX Edge interfaces connect to the same Port Group.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;GUI Reference&lt;/th&gt;
&lt;th&gt;VM vNIC&lt;/th&gt;
&lt;th&gt;NIC&lt;/th&gt;
&lt;th&gt;Lab Function&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Managewment&lt;/td&gt;
&lt;td&gt;Network adapter 1&lt;/td&gt;
&lt;td&gt;eth0&lt;/td&gt;
&lt;td&gt;Management&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Datapath #1&lt;/td&gt;
&lt;td&gt;Network adapter 2&lt;/td&gt;
&lt;td&gt;fp-eth0&lt;/td&gt;
&lt;td&gt;Overlay&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Datapath #2&lt;/td&gt;
&lt;td&gt;Network adapter 3&lt;/td&gt;
&lt;td&gt;fp-eth1&lt;/td&gt;
&lt;td&gt;Uplink&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Datapath #3&lt;/td&gt;
&lt;td&gt;Network adapter 4&lt;/td&gt;
&lt;td&gt;fp-eth2&lt;/td&gt;
&lt;td&gt;Unused&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift-nsx-edge.jpeg&#34; alt=&#34;NSX-T Add Edge&#34;&gt;&lt;/p&gt;
&lt;p&gt;The NSX Edge needs to participate in the Overlay Transport Zone so we need to first configure this as Transport Node.  This is very similar process to how we setup ESXi hosts as Transport Nodes except on N-VDS tab we add to both overlay and vlan transport zones,  we use the edge-vm Uplink profile and for Virtual NIC select appropriate NIC as per table above.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift-nsx-edge-nvds.png&#34; alt=&#34;NSX-T Edge N-VDS&#34;&gt;&lt;/p&gt;
&lt;p&gt;In order we can deploy Tier-0 router the Edge needs to be a member of an Edge Cluster.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift-nsx-edge-cluster.jpeg&#34; alt=&#34;NSX-T Add Edge Cluster&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;tier-0-router&#34;&gt;Tier-0 Router&lt;/h2&gt;
&lt;p&gt;Once the Edge Cluster is created we can create the tier-0 router.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift-nsx-tier0.jpeg&#34; alt=&#34;NSX-T Add Edge Tier-0 Router&#34;&gt;&lt;/p&gt;
&lt;p&gt;In my lab I have 192.168.1.0 /24 and will be using the 172.16.0.0 /16 address space for NSX. I would like to use network address translation (NAT) and allocate a separate SNAT IP on the 192.168.1.0 network for each OpenShift namespace on the 172.16.0.0 network.  To achieve this I need to configure a redistribution criteria of type Tier-0 NAT.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift-nsx-tier0-route-redist.jpeg&#34; alt=&#34;NSX-T Add Edge Tier-0 Route Redist&#34;&gt;&lt;/p&gt;
&lt;p&gt;The next step requires an NSX Logical Switch so we create that.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift-nsx-logical-switch.jpeg&#34; alt=&#34;NSX-T Add Logical Switch&#34;&gt;&lt;/p&gt;
&lt;p&gt;We can now configure the Router Port,  selecting the Transport Node and Logical Switch.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift-nsx-tier0-route-port.jpeg&#34; alt=&#34;NSX-T Add Tier-0 Router Port&#34;&gt;&lt;/p&gt;
&lt;p&gt;This will be used by OpenShift to once created navigate to Actions &amp;gt; Manage Tags and apply tag.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Scope = ncp/cluster and Tag = dc-openshift
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift-ncp-tags.jpeg&#34; alt=&#34;NSX-T Add NCP Tags&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;ip-block-kubernetes-pods&#34;&gt;IP Block Kubernetes Pods&lt;/h2&gt;
&lt;p&gt;In order to create the topology we are aiming for we need to create an IP Blocks for each of our two namespaces.  Within each IP Block we need to create the three subnets. In the end you should end up with something which looks like this, and all IP Block needs to have the ncp/cluster tag.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift-nsx-ddi-blocks.jpeg&#34; alt=&#34;NSX-T Add NCP Tags&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;ip-pool-snat&#34;&gt;IP Pool SNAT&lt;/h2&gt;
&lt;p&gt;We create an IP pool for the tier-0 router to issue SNAT and provide external (floating) IPs to OpenShift.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift-nsx-snat-pool.jpeg&#34; alt=&#34;NSX-T SNAT Pool&#34;&gt;&lt;/p&gt;
&lt;p&gt;Once created add the following two tags,&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Scope = ncp/cluster and Tag = dc-openshift
Scope = ncp/external and Tag = true
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;red-hat-openshift-origin&#34;&gt;Red Hat OpenShift Origin&lt;/h2&gt;
&lt;p&gt;OpenShift Origin is a computer software product from Red Hat for container-based software deployment and management. It is a supported distribution of Kubernetes using Docker containers and DevOps tools for accelerated application development.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openshift.jpeg&#34; alt=&#34;Openshift Stack&#34;&gt;&lt;/p&gt;
&lt;p&gt;OpenShift Origin is the upstream community project used in &lt;a href=&#34;https://www.openshift.com/products/online/&#34;&gt;OpenShift Online&lt;/a&gt;, &lt;a href=&#34;https://www.openshift.com/products/dedicated/&#34;&gt;OpenShift Dedicated&lt;/a&gt;, and &lt;a href=&#34;https://www.openshift.com/products/container-platform/&#34;&gt;OpenShift Container Platform (formerly known as OpenShift Enterprise)&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;VMware provides &lt;a href=&#34;https://github.com/vmware/nsx-integration-for-openshift&#34;&gt;Red Hat Ansible playbooks for installing NSX-T for OpenShift Container Platform&lt;/a&gt;. However, OpenShift Container Platform is a licensed product and this deploys a scaled-out deployment. Neither of these lend itself to a home lab deployment, my goal for the rest of this blog post is to detail the steps I follow for a cutdown installation.&lt;/p&gt;
&lt;h2 id=&#34;create-openshift-origin-base-vm&#34;&gt;Create OpenShift Origin Base VM&lt;/h2&gt;
&lt;p&gt;The OpenShift Container Platform is Red Hat Enterprise Linux based, I don&amp;rsquo;t have a Red Hat Enterprise Linux subscription license. As such I created a CentOS 7 (64-bit) virtual machine, as the library versions are the same, so binaries that work on one will work on the other.&lt;/p&gt;
&lt;p&gt;Each OpenShift node needs to be managed and also provide connectivity to NSX, it is possible to perform these two functions on same vNIC however, I give my VM two vNICs one for management on VLAN backed dvPortgroup and one for NSX on VXLAN backed dvPortgroup. I used the CentOS minimal installation ISO set static IP address on management vNIC, and create DNS A &amp;amp; PTR records for this.&lt;/p&gt;
&lt;p&gt;Once built I run following commands to install Docker, some other basic tools and apply latest patches.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cat &amp;gt; /etc/yum.repos.d/docker.repo &amp;lt;&amp;lt; &#39;__EOF__&#39;
[docker]
name=Docker Repository
baseurl=https://yum.dockerproject.org/repo/main/centos/7/
enabled=1
gpgcheck=1
gpgkey=https://yum.dockerproject.org/gpg
__EOF__
yum install -y https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm
yum install -y git open-vm-tools wget docker-engine net-tools python-pip
pip install docker-py
systemctl enable docker.service
yum update -y
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;default-kubernetes-service-addresses&#34;&gt;Default Kubernetes Service Addresses&lt;/h2&gt;
&lt;p&gt;OpenShift leverages the Kubernetes concept of a pod, which is one or more containers deployed together on one host, and the smallest compute unit that can be defined, deployed, and managed. A Kubernetes service address serves as an internal load balancer. It identifies a set of replicated pods in order to proxy the connections it receives to them. Services are assigned an IP address and port pair that, when accessed, proxy to an appropriate backing pod. These service addresses are assigned and managed by OpenShift. By default they are assigned out of the 172.30.0.0/16 network.&lt;/p&gt;
&lt;p&gt;To setup our environment we can configure the Docker daemon with an insecure registry parameter of 172.30.0.0/16.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;systemctl start docker
touch /etc/docker/daemon.json
cat &amp;gt; /etc/docker/daemon.json &amp;lt;&amp;lt; &#39;__EOF__&#39;
{
&amp;quot;insecure-registries&amp;quot;: [
    &amp;quot;172.30.0.0/16&amp;quot;
    ]
}
__EOF__
systemctl daemon-reload
systemctl restart docker
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;add-openshift-client&#34;&gt;Add OpenShift Client&lt;/h1&gt;
&lt;p&gt;The OpenShift client is used to manage the OpenShift installation and configuration it is supplied as a package. Download this, unpack and add to runtime path.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd /tmp
wget https://github.com/openshift/origin/releases/download/v3.10.0-rc.0/openshift-origin-client-tools-v3.10.0-rc.0-c20e215-linux-64bit.tar.gz
tar -xvf /tmp/openshift-origin-client-tools-v3.10.0-rc.0-c20e215-linux-64bit.tar.gz -C /bin
mv /bin/openshift* /home/openshift
echo &#39;PATH=$PATH:/home/openshift&#39; &amp;gt; /etc/profile.d/oc-path.sh
chmod +x /etc/profile.d/oc-path.sh
. /etc/profile
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;start-openshift-origin-as-all-in-one-cluster&#34;&gt;Start OpenShift Origin as all-in-one Cluster&lt;/h2&gt;
&lt;p&gt;For next steps we need a basic OpenShift stack. Rather than build something custom we can simply start a local OpenShift all-in-one cluster with a configured registry, router, image streams, and default templates, by running the following command (where openshift.darrylcauldwell.com is the FQDN which points to IP address of management interface of your VM),&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;oc cluster up --public-hostname=openshift.darrylcauldwell.com
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We should also be able to logon and see all of the OpenShift services listed&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;oc login -u system:admin
oc get services --all-namespaces
&lt;/code&gt;&lt;/pre&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;NAMESPACE&lt;/th&gt;
&lt;th&gt;NAME&lt;/th&gt;
&lt;th&gt;TYPE&lt;/th&gt;
&lt;th&gt;CLUSTER-IP&lt;/th&gt;
&lt;th&gt;EXTERNAL-IP&lt;/th&gt;
&lt;th&gt;PORT(S)&lt;/th&gt;
&lt;th&gt;AGE&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;default&lt;/td&gt;
&lt;td&gt;docker-registry&lt;/td&gt;
&lt;td&gt;ClusterIP&lt;/td&gt;
&lt;td&gt;172.30.1.1&lt;/td&gt;
&lt;td&gt;none&lt;/td&gt;
&lt;td&gt;5000/TCP&lt;/td&gt;
&lt;td&gt;9m&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;default&lt;/td&gt;
&lt;td&gt;kubernetes&lt;/td&gt;
&lt;td&gt;ClusterIP&lt;/td&gt;
&lt;td&gt;172.30.0.1&lt;/td&gt;
&lt;td&gt;none&lt;/td&gt;
&lt;td&gt;443/TCP,53/UDP,53/TCP&lt;/td&gt;
&lt;td&gt;10m&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;default&lt;/td&gt;
&lt;td&gt;router&lt;/td&gt;
&lt;td&gt;ClusterIP&lt;/td&gt;
&lt;td&gt;172.30.88.3&lt;/td&gt;
&lt;td&gt;none&lt;/td&gt;
&lt;td&gt;80/TCP,443/TCP,1936/TCP&lt;/td&gt;
&lt;td&gt;9m&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;kube-dns&lt;/td&gt;
&lt;td&gt;kube-dns&lt;/td&gt;
&lt;td&gt;ClusterIP&lt;/td&gt;
&lt;td&gt;172.30.0.2&lt;/td&gt;
&lt;td&gt;none&lt;/td&gt;
&lt;td&gt;53/UDP,53/TCP&lt;/td&gt;
&lt;td&gt;10m&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;openshift-apiserver&lt;/td&gt;
&lt;td&gt;api&lt;/td&gt;
&lt;td&gt;ClusterIP&lt;/td&gt;
&lt;td&gt;172.30.85.121&lt;/td&gt;
&lt;td&gt;none&lt;/td&gt;
&lt;td&gt;443/TCP&lt;/td&gt;
&lt;td&gt;10m&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;openshift-web-console&lt;/td&gt;
&lt;td&gt;webconsole&lt;/td&gt;
&lt;td&gt;ClusterIP&lt;/td&gt;
&lt;td&gt;172.30.83.178&lt;/td&gt;
&lt;td&gt;none&lt;/td&gt;
&lt;td&gt;443/TCP&lt;/td&gt;
&lt;td&gt;9m&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;We should also be able to see all of the OpenShift pods listed&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;oc get pod --all-namespaces
&lt;/code&gt;&lt;/pre&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;NAMESPACE&lt;/th&gt;
&lt;th&gt;NAME&lt;/th&gt;
&lt;th&gt;READY&lt;/th&gt;
&lt;th&gt;STATUS&lt;/th&gt;
&lt;th&gt;RESTARTS&lt;/th&gt;
&lt;th&gt;AGE&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;default&lt;/td&gt;
&lt;td&gt;docker-registry-1-4l59n&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;10m&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;default&lt;/td&gt;
&lt;td&gt;persistent-volume-setup-grm9s&lt;/td&gt;
&lt;td&gt;0/1&lt;/td&gt;
&lt;td&gt;Completed&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;10m&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;default&lt;/td&gt;
&lt;td&gt;router-1-5xtqg&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;10m&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;kube-dns&lt;/td&gt;
&lt;td&gt;kube-dns-bj5cq&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;11m&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;kube-proxy&lt;/td&gt;
&lt;td&gt;kube-proxy-9l8ql&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;11m&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;kube-system&lt;/td&gt;
&lt;td&gt;kube-controller-manager-localhost&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;10m&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;kube-system&lt;/td&gt;
&lt;td&gt;kube-scheduler-localhost&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;10m&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;kube-system&lt;/td&gt;
&lt;td&gt;master-api-localhost&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;10m&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;kube-system&lt;/td&gt;
&lt;td&gt;master-etcd-localhost&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;11m&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;openshift-apiserver&lt;/td&gt;
&lt;td&gt;openshift-apiserver-ptk5j&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;11m&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;openshift-controller-manager&lt;/td&gt;
&lt;td&gt;openshift-controller-manager-vg7gm&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;10m&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;openshift-core-operators&lt;/td&gt;
&lt;td&gt;openshift-web-console-operator-78ddf7cbb7-r8dhd&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;10m&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;openshift-web-console&lt;/td&gt;
&lt;td&gt;webconsole-847bc4ccc4-hgsv4&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;10m&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Once running we can open browser to OpenShift Origin&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;https://openshift.darrylcauldwell.com:8443/console/catalog
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Default credentials username &amp;lsquo;system&amp;rsquo; password &amp;lsquo;admin&amp;rsquo;&lt;/p&gt;
&lt;h2 id=&#34;nsx-t-open-vswitch&#34;&gt;NSX-T Open vSwitch&lt;/h2&gt;
&lt;p&gt;The NSX-T Container Plug-in (NCP) relies on Open vSwitch (OVS) providing a bridge to the NSX Logical Switch. VMware provide an Open vSwitch (OVS)  in the &lt;a href=&#34;https://my.vmware.com/web/vmware/details?downloadGroup=NSX-T-PKS-220&amp;amp;productId=673&#34;&gt;NSX Container Plugin 2.2.0&lt;/a&gt;, package.  Download expand and copy to OpenShift VM /tmp folder. Once uploaded install the following packages.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;yum install -y /tmp/nsx-container-2.2.0.8740202/OpenvSwitch/rhel74_x86_64/kmod-openvswitch-2.9.1.8614397.rhel74-1.el7.x86_64.rpm
yum install -y /tmp/nsx-container-2.2.0.8740202/OpenvSwitch/rhel74_x86_64/openvswitch-2.9.1.8614397.rhel74-1.x86_64.rpm
yum install -y /tmp/nsx-container-2.2.0.8740202/OpenvSwitch/rhel74_x86_64/openvswitch-kmod-2.9.1.8614397.rhel74-1.el7.x86_64.rpm
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Once installed start the Open vSwitch&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;service openvswitch start
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Once the Open vSwitch is running we can create a bridge network interface, and then connect this to the VM network interface located on the NSX-T Logical Switch. You can do this by running the following command (where eno33559296 is the devicename of NIC on NSX Logical Switch),&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ovs-vsctl add-br br-int
ovs-vsctl add-port br-int eno33559296 -- set Interface eno33559296 ofport_request=1
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;These connections are created with link state DOWN in order to use them we need to set link status is up for both,&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ip link set br-int up
ip link set eno33559296 up
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Update the network configuration file to ensure that the network interface is up after a reboot.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vi /etc/sysconfig/network-scripts/ifcfg-eno33559296
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Ensure has a line reading,&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ONBOOT=yes
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;nsx-t-container-network-interface-cni&#34;&gt;NSX-T Container Network Interface (CNI)&lt;/h2&gt;
&lt;p&gt;The NSX-T Container Plug-in (NCP) provides integration between NSX-T and container orchestrators such as Kubernetes. The installation files are in same package as the NSX Open vSwitch (OVS). Install using command.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;yum install -y /tmp/nsx-container-2.2.0.8740202/Kubernetes/rhel_x86_64/nsx-cni-2.2.0.8740202-1.x86_64.rpm
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;nsx-t-container-plug-in-ncp-replicationcontroller-rc&#34;&gt;NSX-T Container Plug-in (NCP) ReplicationController (RC)&lt;/h2&gt;
&lt;p&gt;There are a few accounts used for rights assignments, the project, users and roles are defined in NCP RBAC file. To create the users within the project run,&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;oc login -u system:admin
oc create -f /tmp/nsx-container-2.2.0.8740202/nsx-ncp-rbac.yml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The RBAC creates two service account users, the tokens for these are required by NCP in folder /etc/nsx-ujo. This gets mounted as config-volume and these tokens used for authentication.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;oc project nsx-system
mkdir -p /etc/nsx-ujo
SVC_TOKEN_NAME=&amp;quot;$(oc get serviceaccount ncp-svc-account -o yaml | grep -A1 secrets | tail -n1 | awk {&#39;print $3&#39;})&amp;quot;
oc get secret $SVC_TOKEN_NAME -o yaml | grep &#39;token:&#39; | awk {&#39;print $2&#39;} | base64 -d &amp;gt; /etc/nsx-ujo/ncp_token
NODE_TOKEN_NAME=&amp;quot;$(oc get serviceaccount nsx-node-agent-svc-account -o yaml | grep -A1 secrets | tail -n1 | awk {&#39;print $3&#39;})&amp;quot;
oc get secret $NOD_TOKEN_NAME -o yaml | grep &#39;token:&#39; | awk {&#39;print $2&#39;} | base64 -d &amp;gt; /etc/nsx-ujo/node_agent_token
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The pods which NSX-T Container Plug-in (NCP) ReplicationController (RC) run in need to use the host networking so we need to allow then this right by loading the NCP Security Context Constraints for NCP and NSX Node Agent.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;oc apply -f /tmp/nsx-container-2.2.0.8740202/Kubernetes/rhel_x86_64/ncp-os-scc.yml
oc adm policy add-scc-to-user ncp-scc -z ncp-svc-account
oc adm policy add-scc-to-user ncp-scc -z nsx-node-agent-svc-account
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Edit the ReplicationController (RC) YML file,&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vi /tmp/nsx-container-2.2.0.8740202/Kubernetes/ncp-rc.yml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Ensure the following lines are configured thus,&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;serviceAccountName: ncp-svc-account
apiserver_host_port = 8443
apiserver_host_ip = 192.168.1.20
nsx_api_managers = 192.168.1.15
insecure = True
nsx_api_user = admin
nsx_api_password = VMware1!
cluster = dc-openshift
adaptor = openshift
enable_snat = True
tier0_router = 0d772616-4c44-47ae-ac9e-06f3c0222211
overlay_tz = 5eeefd4c-bd7d-4871-9eba-d7ed02394dec
container_ip_blocks = 562c85de-8675-4bb2-b211-3f95a6342e0e, f225d518-2fe3-4f8d-a476-a4697bff3ea6
external_ip_pools = d5095d53-c7f8-4fcd-9fad-3032afd080a4
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The NSX-T Container Plug-in (NCP) is a docker image which we import into the local registry.  The image is referenced by later script by different tag name so we add an additional tag.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker load -i /tmp/nsx-container-2.2.0.8740202/Kubernetes/nsx-ncp-rhel-2.2.0.8740202.tar
docker image tag registry.local/2.2.0.8740202/nsx-ncp-rhel nsx-ncp
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Then we can create NSX ReplicationController&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;oc project nsx-system
oc create -f /tmp/nsx-container-2.2.0.8740202/Kubernetes/ncp-rc.yml
oc describe rc/nsx-ncp
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We should now see the container running within pod namespace nsx-system.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;oc get pod --all-namespaces
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If all has gone well we can now connect to the NCP container and use the &lt;a href=&#34;https://docs.vmware.com/en/VMware-NSX-T/2.2/com.vmware.nsxt.ncp_openshift.doc/GUID-12F44CD5-0518-41C3-BB14-5507224A5D60.html&#34;&gt;nsxcli&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;oc exec -it nsx-ncp-6k5t2 nsxcli
get ncp-nsx status
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;nsx-t-container-plug-in-ncp-node-agent-daemonset-ds&#34;&gt;NSX-T Container Plug-in (NCP) Node Agent DaemonSet (DS)&lt;/h2&gt;
&lt;p&gt;Edit the nsx-node-agent-ds.yml file,&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vi /tmp/nsx-container-2.2.0.8740202/Kubernetes/rhel_x86_64/nsx-node-agent-ds.yml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Ensure the following is set,&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;serviceAccountName: nsx-node-agent-svc-account
cluster = dc-openshift
apiserver_host_port = 8443
apiserver_host_ip = 192.168.1.20
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Once updated create the Node Agent Daemonset (DS),&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;oc login -u system:admin
oc apply -f /tmp/nsx-container-2.2.0.8740202/Kubernetes/rhel_x86_64/nsx-node-agent-ds.yml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Check the Node Agent Daemonset is there,&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;oc describe daemonset.apps/nsx-node-agent
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We should also be able to see all of the OpenShift pods listed including our two NSX ones.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;oc get pod --all-namespaces
&lt;/code&gt;&lt;/pre&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;NAMESPACE&lt;/th&gt;
&lt;th&gt;NAME&lt;/th&gt;
&lt;th&gt;READY&lt;/th&gt;
&lt;th&gt;STATUS&lt;/th&gt;
&lt;th&gt;RESTARTS&lt;/th&gt;
&lt;th&gt;AGE&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;default&lt;/td&gt;
&lt;td&gt;docker-registry-1-4l59n&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1h&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;default&lt;/td&gt;
&lt;td&gt;persistent-volume-setup-grm9s&lt;/td&gt;
&lt;td&gt;0/1&lt;/td&gt;
&lt;td&gt;Completed&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1h&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;default&lt;/td&gt;
&lt;td&gt;router-1-5xtqg&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1h&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;kube-dns&lt;/td&gt;
&lt;td&gt;kube-dns-bj5cq&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1h&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;kube-proxy&lt;/td&gt;
&lt;td&gt;kube-proxy-9l8ql&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1h&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;kube-system&lt;/td&gt;
&lt;td&gt;kube-controller-manager-localhost&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1h&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;kube-system&lt;/td&gt;
&lt;td&gt;kube-scheduler-localhost&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1h&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;kube-system&lt;/td&gt;
&lt;td&gt;master-api-localhost&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;1h&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;kube-system&lt;/td&gt;
&lt;td&gt;master-etcd-localhost&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1h&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;nsx-system&lt;/td&gt;
&lt;td&gt;nsx-ncp-9m2jl&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;10m&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;nsx-system&lt;/td&gt;
&lt;td&gt;nsx-node-agent-jlt5t&lt;/td&gt;
&lt;td&gt;2/2&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;4m&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;openshift-apiserver&lt;/td&gt;
&lt;td&gt;openshift-apiserver-ptk5j&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1h&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;openshift-controller-manager&lt;/td&gt;
&lt;td&gt;openshift-controller-manager-vg7gm&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1h&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;openshift-core-operators&lt;/td&gt;
&lt;td&gt;openshift-web-console-operator-78ddf7cbb7-r8dhd&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1h&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;openshift-web-console&lt;/td&gt;
&lt;td&gt;webconsole-847bc4ccc4-hgsv4&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;td&gt;Running&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1h&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;testing&#34;&gt;Testing&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;oc create namespace my-first
oc logs nsx-ncp-9m2jl | grep ERROR
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;nsx_ujo.k8s.ns_watcher Failed to create NSX topology for project my-first: Unexpected error from backend manager ([&amp;lsquo;192.168.1.15&amp;rsquo;]) for Allocate subnet from IP block&lt;/p&gt;
&lt;p&gt;more commands for working OpenShift here&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://static.rainfocus.com/vmware/vmworldus17/sess/148924638739800152Do/finalpresentationPDF/NET1522BU_FORMATTED_FINAL_1507910147966001nlDx.pdf&#34;&gt;https://static.rainfocus.com/vmware/vmworldus17/sess/148924638739800152Do/finalpresentationPDF/NET1522BU_FORMATTED_FINAL_1507910147966001nlDx.pdf&lt;/a&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Calling the NSX REST API with vRO and Navigating The XML Response</title>
      <link>https://darrylcauldwell.github.io/post/vro-nsx-rest/</link>
      <pubDate>Wed, 20 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/vro-nsx-rest/</guid>
      <description>
        
          &lt;p&gt;While the NSX for vSphere plugin for vRealize Orchestrator is useful, occasionally there are limitations. For example when creating an NSX Edge Services Gateway we use this method.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;NSXEdgeTrinityBasicController.createEdgeV4
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That method returns void,  so next you need to make a second method call using filter by name to get the object and obtain object ID which is typically the input to other methods.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;NSXEdgeTrinityBasicController.getAllEdgeSummariesV4
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;When creating NSX Distributed Logical Router it is the same method to create. However the second method to get the object fails as it cannot handle the additional property LogicalRouterScope which DLRs have, so throws an error.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;java.lang.NoSuchMethodException:com.vmware.vshield.edge.dto.trinity.LogicalRouterScope.&amp;lt;init&amp;gt;()
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;After trying various other NSX plugin methods all have same issue so I changed approach. NSX offers all its capabilities via &lt;a href=&#34;https://docs.vmware.com/en/VMware-NSX-for-vSphere/6.4/nsx_64_api.pdf&#34;&gt;REST API&lt;/a&gt;. vRealize Orchestrator comes with a HTTP-REST plugin, so in theory we can add NSX Managers as HTTP-REST endpoint and call everything direct.&lt;/p&gt;
&lt;p&gt;If you have multiple REST HTTP hosts added you would want to bring back a list of these.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;restHosts = RESTHostManager.getHosts();
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This returns an array of UUIDs of each REST host, we can use these UUIDs to get the REST host objects. We could normally loop to find the specific &lt;a href=&#34;http://www.vroapi.com/Class/REST/2.2.2/RESTHost&#34;&gt;RESThost&lt;/a&gt; object we are looking for, but for ease here we would use the first item from array.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;host = RESTHostManager.getHost(restHosts[0]);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;So we have the target &lt;a href=&#34;http://www.vroapi.com/Class/REST/2.2.2/RESTHost&#34;&gt;RESThost&lt;/a&gt; object look at forming the request using the &lt;a href=&#34;http://www.vroapi.com/Method/REST/2.2.2/RESTHost/createRequest&#34;&gt;createRequest&lt;/a&gt; method.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;request = host.createRequest(&#39;GET&#39;,&#39;/api/4.0/edges&#39;,&#39;&#39;);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Once we have our request formed we can look to make the call using the &lt;a href=&#34;http://www.vroapi.com/Method/REST/2.2.2/RESTHost/executeRequestWithCredentials&#34;&gt;executeRequestWithCredentials&lt;/a&gt; method. Here I store username and password as Secure String variables.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;responseStr = request.executeWithCredentials(username,password);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This returns a &lt;a href=&#34;http://www.vroapi.com/Class/REST/2.2.2/RESTResponse&#34;&gt;RESTResponse&lt;/a&gt; object, this has attribute contentAsString to navigate this XML we first convert this string to a &lt;a href=&#34;https://www.w3schools.com/XML/dom_document.asp&#34;&gt;XML DOM Document Object&lt;/a&gt;. vRealize Orchestrator comes with a &lt;a href=&#34;http://www.vroapi.com/Plugin/XML/7.0.1&#34;&gt;XML plugin&lt;/a&gt; we can use the &lt;a href=&#34;http://www.vroapi.com/Method/XML/7.0.1/XMLManager/fromString&#34;&gt;XMLManager.fromString&lt;/a&gt; method to perform this converstion.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;responseXml = XMLManager.fromString(responseStr.contentAsString);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If we look inside of the XML which is returned from /api/4.0/edges we can see each the hierachy that each NSX Edge is a XML Node called edgeSummary and within that Node are child nodes for all of its attributes.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;pagedEdgeList&amp;gt;
    &amp;lt;edgePage&amp;gt;
        &amp;lt;edgeSummary&amp;gt;
            &amp;lt;objectId&amp;gt;
            &amp;lt;objectTypeName&amp;gt;
            &amp;lt;vsmUuid&amp;gt;
            &amp;lt;nodeId&amp;gt;
            &amp;lt;Revision&amp;gt;
            &amp;lt;type&amp;gt;
            &amp;lt;name&amp;gt;
            ...
        &amp;lt;edgeSummary&amp;gt;
            &amp;lt;objectId&amp;gt;
            &amp;lt;objectTypeName&amp;gt;
            &amp;lt;vsmUuid&amp;gt;
            &amp;lt;nodeId&amp;gt;
            &amp;lt;Revision&amp;gt;
            &amp;lt;type&amp;gt;
            &amp;lt;name&amp;gt;
            ...
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;So we need to bring back all the edgeSummary Nodes and create a &lt;a href=&#34;http://www.vroapi.com/Class/XML/7.0.1/XMLNodeList&#34;&gt;XMLNodeList&lt;/a&gt; object containing all of out Edges.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;edgeNodeList = responseXml.getElementsByTagName(&amp;quot;edgeSummary&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Once we have this we can loop around the children of this and find the correct Edge entry and then get the objectId. We know the child order is always the same so we can choose data from positon in list and output the text content of Node.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;for (var i = 0 ; i &amp;lt; edgeNodeList.length ; i++) {
    var node = edgeNodeList.item(i) ;
    edgeChildNodeList = node.getChildNodes();
    if (edgeChildNodeList.item(6).textContent == edgeName) {
        var objectId = edgeChildNodeList.item(0).textContent ;
        System.log(&amp;quot;Edge named &amp;quot; + edgeName + &amp;quot; has objectId &amp;quot; + objectId) ;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;With this technique we should be able to get around any vRealize Orchestrator NSX Plugin limitation. This would also be useful for calling other RESTful APIs in absence of a specific vRealize Orchestrator plugin.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>vRealize Orchestrator NSX Plug-in Troubleshooting</title>
      <link>https://darrylcauldwell.github.io/post/vro-nsx-logging/</link>
      <pubDate>Tue, 06 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/vro-nsx-logging/</guid>
      <description>
        
          &lt;p&gt;The NSX-V Plug-in for vRealize Orchestrator offers some great functionally, however creating custom workflows caused me some headaches.&lt;/p&gt;
&lt;p&gt;When building some custom workflows using the vRO API explorer there are inconsistencies, I&amp;rsquo;ve learned to not rely on the vRO API explorer for NSX plug-in documentation and instead use &lt;a href=&#34;http://www.vroapi.com/Plugin/NSX/1.2.0&#34;&gt;www.vroapi.com&lt;/a&gt; which is more complete.&lt;/p&gt;
&lt;p&gt;Problems manifest themselves as failures to execute methods, but very little detail is returned with the error message. Within vRealize Orchestrator is a JavaScript runtime environment therefore we can install a plug-in such as &lt;a href=&#34;https://labs.vmware.com/flings/vco-cli&#34;&gt;vCO-CLI&lt;/a&gt; to get an exploratory programming interface and try the commands directly to see the return values. While this was useful it didn&amp;rsquo;t help with all issues.&lt;/p&gt;
&lt;p&gt;The NSX plug-in talks to NSX Manager via the REST API, so another avenue to follow is that you can enable HttpClient logging which captures the REST calls made by the Plug-in in real-time. After some searching &lt;a href=&#34;https://www.vcoteam.info/articles/learn-vco/199-how-to-handle-vcenter-orchestrator-logs.html&#34;&gt;I found vRealize Orchestrator&lt;/a&gt; uses &lt;a href=&#34;https://logging.apache.org/log4j/2.x/&#34;&gt;Apache log4j&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We can edit the log4j configuration file&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;/etc/vco/app-server/log4j.xml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Within this configuration file we find section for the HttpClient org.apache.http&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;category&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;additivity=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;true&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;name=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;org.apache.http&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;priority&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;value=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;INFO&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/&amp;gt;&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;/category&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We can enable HttpClient debugging by amending this to have value of DEBUG.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;category&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;additivity=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;true&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;name=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;org.apache.http&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;priority&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;value=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;DEBUG&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/&amp;gt;&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;/category&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once the vRealize Orchestrator server services are restarted the logging level will change and events will be written to the following log file.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;/var/log/vco/app-server/integration-server.log
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Using a combination of these methods has enabled resolution of all issues experienced up to now. To note putting a vRealize Orchestrator server into debug mode will slow down the vRealize Orchetrator server considerably. It is recommended to use DEBUG mode temporarily.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Controlling vSphere &amp; NSX-V With Python</title>
      <link>https://darrylcauldwell.github.io/post/nsx-python/</link>
      <pubDate>Mon, 15 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/nsx-python/</guid>
      <description>
        
          &lt;p&gt;My former colleagues had made me aware of pyVmomi an open source library which VMware provide and mostly maintain for managing vSphere, so its here I shall start. Since then NSX for vSphere has also an open source library NSX RAML Client provided by VMware so I&amp;rsquo;ll then move to that.&lt;/p&gt;
&lt;p&gt;I am performing this learning exercise in my home lab  using is vSphere 6.5, vSAN 6.5, NSX6.3, with Python 2.7.10, although this should work the same with other versions.&lt;/p&gt;
&lt;p&gt;Install pyVmomi and open vCenter connection and then initiate an interactive python environment&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;git clone https://github.com/vmware/pyvmomi.git
sudo pip install -r ~/pyvmomi/requirements.txt
python
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Import the pyVim, pyVmomi &amp;amp; SSL libraries we are using,&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; ssl
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; pyVim &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; connect
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; pyVmomi &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; vim, vmodl
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Open connection to vCenter then gather contents as an object&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;vcenter &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; connect&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;SmartConnect(
    host&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;192.168.1.13&amp;#39;&lt;/span&gt;,
    user&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;administrator@vsphere.local&amp;#39;&lt;/span&gt;,
    pwd&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;VMware1!&amp;#39;&lt;/span&gt;,
    port&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;443&lt;/span&gt;,
    sslContext&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;ssl&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;_create_unverified_context()
)
content &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; vcenter&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;RetrieveContent()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;basic-get-of-information&#34;&gt;Basic get of information&lt;/h1&gt;
&lt;p&gt;Once we have vCenter Object Model as content object we can output any part of this data&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;content.about.fullName
&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;VMware vCenter Server 6.5.0 build-5178943&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We can also explore the Object Model which is well descrived here in the &lt;a href=&#34;http://pubs.vmware.com/vsphere-65/topic/com.vmware.wssdk.apiref.doc/right-pane.html&#34;&gt;vSphere SDK API Docs&lt;/a&gt; and when we know what we want to look for we can search and display anything we like, for example the list of virtual machines.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;objView &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; content&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;viewManager&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;CreateContainerView(content&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;rootFolder,[vim&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;VirtualMachine],True)
vmList &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; objView&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;view
objView&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Destroy()
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt;  vm &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; vmList:
    vm&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;config&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;name
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;basic-put-of-configuration-information&#34;&gt;Basic put of configuration information&lt;/h1&gt;
&lt;p&gt;As well as getting information from the Object Model we can just as easily apply configuration to items within (assuming the account we connect with has sufficient rights),  for example if we gather the list of hosts and set a advanced option on all of them.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;objView &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; content&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;viewManager&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;CreateContainerView(content&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;rootFolder,[vim&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;HostSystem],True)
hostList &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; objView&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;view
objView&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Destroy()
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; host &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; hostList:
    optionManager &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; host&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;configManager&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;advancedOption
    option &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; vim&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;option&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;OptionValue(key&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;VSAN.ClomRepairDelay&amp;#39;&lt;/span&gt;, value&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;long(&lt;span style=&#34;color:#ae81ff&#34;&gt;120&lt;/span&gt;))
    optionManager&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;UpdateOptions(changedValue&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[option])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;nsx-for-vsphere&#34;&gt;NSX for vSphere&lt;/h1&gt;
&lt;p&gt;So we have the pyVmomi library for vSphere, in addition to this VMware have provided open source library for &lt;a href=&#34;https://github.com/vmware/nsxramlclient&#34;&gt;NSX for vSphere&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;ll first make sure the packages are installed along with the additional packages for managing NSX.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;sudo pip install nsxramlclient pyvim pyvmomi lxml requests
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The NSX for vSphere REST API changes with each version, so in order to use the nsxramlclient library we will need a RAML file specific to version of NSX-V we are connecting to. The RAML file also produces nice &lt;a href=&#34;https://htmlpreview.github.io/?https://github.com/vmware/nsxraml/blob/6.3/html-version/nsxvapi.html&#34;&gt;dynamic documentation of the NSX APIs&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;git clone https://github.com/vmware/nsxraml
cd nsxraml
git checkout 6.3
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;So now we can try and connect and get some information about anything described in the API document, like NSX Controllers.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; nsxramlclient.client &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; NsxClient
nsx_manager &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;192.168.1.18&amp;#34;&lt;/span&gt;
nsx_username &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;admin&amp;#34;&lt;/span&gt;
nsx_password &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;VMware1!VMware1!&amp;#34;&lt;/span&gt;
nsxraml_file &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;nsxvapi.raml&amp;#39;&lt;/span&gt;
nsx_manager_session &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; NsxClient(nsxraml_file, nsx_manager, nsx_username, nsx_password)
nsx_controllers &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nsx_manager_session&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;nsxControllers&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;read&amp;#39;&lt;/span&gt;)
nsx_controllers
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;When it comes to putting and posting information getting the formatting right can be a challenge. To this end with the library it is possible to create a template python dictionary using extract_resource_body_example.  Once we have this we can display the output structure but more usefully we can also substitute values into the template.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;new_ls &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nsx_manager_session&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;extract_resource_body_example(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;logicalSwitches&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;create&amp;#39;&lt;/span&gt;)
nsx_manager_session&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;view_body_dict(new_ls)
new_ls[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;virtualWireCreateSpec&amp;#39;&lt;/span&gt;][&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;name&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;TestLogicalSwitch1&amp;#39;&lt;/span&gt;
new_ls[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;virtualWireCreateSpec&amp;#39;&lt;/span&gt;][&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;description&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;TestLogicalSwitch1&amp;#39;&lt;/span&gt;
new_ls[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;virtualWireCreateSpec&amp;#39;&lt;/span&gt;][&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;tenantId&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Tenant1&amp;#39;&lt;/span&gt;
new_ls[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;virtualWireCreateSpec&amp;#39;&lt;/span&gt;][&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;controlPlaneMode&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;UNICAST_MODE&amp;#39;&lt;/span&gt;
nsx_manager_session&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;view_body_dict(new_ls)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once we have out body template correctly describing what we want we can post this and if all goes to plan create a new Logical Switch. In this example I am passing in the scopeId (transport zone) manually to keep it a simple example.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;new_ls_response &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nsx_manager_session&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;create(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;logicalSwitches&amp;#39;&lt;/span&gt;, uri_parameters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;{&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;scopeId&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;vdnscope-1&amp;#39;&lt;/span&gt;}, request_body_dict&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;new_ls)
nsx_manager_session&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;view_response(new_ls_response)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;summary&#34;&gt;Summary&lt;/h1&gt;
&lt;p&gt;It looks like with our new found friend the VMware Python libraries we can easily create and deploy a VMware configuration &amp;lsquo;infrastructure as code&amp;rsquo;.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>DynamoDB Python Test Environment with Cloud Formations</title>
      <link>https://darrylcauldwell.github.io/post/dynamodb-python/</link>
      <pubDate>Fri, 31 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/dynamodb-python/</guid>
      <description>
        
          &lt;p&gt;The goal of this post is to walk through the creation of a AWS test environment which I use to explore the Python SDK interactions with DyanmoDB. For learning I use the free tier and so used to create the environment as needed manually. After doing this once I decided to encapsulate the configuration in a Cloud Formations template and then deploy the stack when I needed it.&lt;/p&gt;
&lt;h1 id=&#34;environment-configuration&#34;&gt;Environment Configuration&lt;/h1&gt;
&lt;p&gt;The resources I require the Cloud Formation template to create&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DynamoDB Table&lt;/li&gt;
&lt;li&gt;Identify Access Management Policy Documents with rights to Put items into DDB and Scan items in DDB&lt;/li&gt;
&lt;li&gt;Identify Access Management Role linked to the policy document&lt;/li&gt;
&lt;li&gt;EC2 Security Group allowing SSH inbound from any IP address&lt;/li&gt;
&lt;li&gt;EC2 Instance with the IAM Role and EC2 Security Group attached, which on boot performs a yum update and installs the AWS Python SDK&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The Cloud Formation template I created to meet this requirement is &lt;a href=&#34;https://s3-eu-west-1.amazonaws.com/cfpythdynamo/PythonDynamoDict.json&#34;&gt;here on s3&lt;/a&gt;,  so we can first get this.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl https://s3-eu-west-1.amazonaws.com/cfpythdynamo/PythonDynamoDict.json -o PythonDynamoDict.json
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;To note in order to use this CF template it requires an EC2 access key,  if you pull down the json then search and replace &amp;ldquo;MyEC2&amp;rdquo; with the name of your EC2 access key before creating a stack. Assuming your laptop has AWS credentials configured to allow you rights to deploy Cloud Formation templates and create IAM.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;aws cloudformation deploy --template-file PythonDynamoDict.json --stack-name &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;PythonDDB&amp;#34;&lt;/span&gt; --capabilities &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;CAPABILITY_IAM&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This should take less than five minutes and output&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;Waiting &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; changeset to be created..
Waiting &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; stack create/update to complete
Successfully created/updated stack - PythonDDB
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;connect-python-session-to-ddb&#34;&gt;Connect Python session to DDB&lt;/h1&gt;
&lt;p&gt;Open an SSD session to the EC2 instance, once session is open,  open a interactive python session&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;python
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Then within the python session we can connect to and do stuff with DDB, I&amp;rsquo;ve included some simple transactions.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Import the boto3 and json library&lt;/span&gt;

&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; boto3&lt;span style=&#34;color:#f92672&#34;&gt;,&lt;/span&gt; json

&lt;span style=&#34;color:#75715e&#34;&gt;# Create an object to DynamoDB created by Cloud Formations in Ireland&lt;/span&gt;

dynamodb &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; boto3&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resource(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dynamodb&amp;#39;&lt;/span&gt;, region_name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;eu-west-1&amp;#39;&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# Create an object to the DDB Table created by Cloud Formations&lt;/span&gt;

table &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; dynamodb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Table(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;myTestDB&amp;#39;&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# Clear any previously created values from items object&lt;/span&gt;

items &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
item_dict &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; dict()

&lt;span style=&#34;color:#75715e&#34;&gt;# Define a helper class to convert a DynamoDB item to JSON&lt;/span&gt;

&lt;span style=&#34;color:#66d9ef&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;DecimalEncoder&lt;/span&gt;(json&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;JSONEncoder):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;default&lt;/span&gt;(self, o):
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; isinstance(o, decimal&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Decimal):
            &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; o &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:
                &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; float(o)
            &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
                &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; int(o)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; super(DecimalEncoder, self)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;default(o)

&lt;span style=&#34;color:#75715e&#34;&gt;# Create some DDB Table items&lt;/span&gt;

table&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;put_item(
   Item&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;{
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;ForeName&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Bobby&amp;#39;&lt;/span&gt;,
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;FamilyName&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Johnson&amp;#39;&lt;/span&gt;,
    },
)
table&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;put_item(
    Item&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;{
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;ForeName&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Sam&amp;#39;&lt;/span&gt;,
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;FamilyName&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Smith&amp;#39;&lt;/span&gt;,
    }
)

&lt;span style=&#34;color:#75715e&#34;&gt;# Perform a table scan to return all items&lt;/span&gt;

response &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; table&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;scan()
items &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; response[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Items&amp;#39;&lt;/span&gt;]

&lt;span style=&#34;color:#75715e&#34;&gt;# Cycle through item decobe the json and store the decoded item in a python dictionary named item_dict&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# here also updating formatting so only the values are stored.&lt;/span&gt;

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; item &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; items:
    decoded_item &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (json&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dumps(item, cls&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;DecimalEncoder))
    item_part_format &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; decoded_item&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;replace(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#34;FamilyName&amp;#34;: &amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;)
    item_str_formatted &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; item_part_format&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;replace(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;, &amp;#34;ForeName&amp;#34;: &amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;:&amp;#39;&lt;/span&gt;)
    item_dict&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;update(json&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loads(item_str_formatted))

&lt;span style=&#34;color:#75715e&#34;&gt;# If we print the dictionary we get the two key pairs&lt;/span&gt;

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; item_dict
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
        
      </description>
    </item>
    
    <item>
      <title>Simple REST API For DynamoDB Using Lambda</title>
      <link>https://darrylcauldwell.github.io/post/lambda-dynamodb/</link>
      <pubDate>Thu, 29 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/lambda-dynamodb/</guid>
      <description>
        
          &lt;p&gt;My goal here is to setup a simple RESTful API which accepts GET and POST methods to trigger a Lambda Function to read and put information into DynamoDB.&lt;/p&gt;
&lt;p&gt;First we&amp;rsquo;ll create a test DynamoDB table and put some items into it,&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;aws dynamodb create-table --table-name &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;MyTable&amp;#39;&lt;/span&gt; --attribute-definitions &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;[{&amp;#34;AttributeName&amp;#34;: &amp;#34;Name&amp;#34;, &amp;#34;AttributeType&amp;#34;: &amp;#34;S&amp;#34;}]&amp;#39;&lt;/span&gt; --key-schema &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;[{&amp;#34;AttributeName&amp;#34;: &amp;#34;Name&amp;#34;, &amp;#34;KeyType&amp;#34;: &amp;#34;HASH&amp;#34;}]&amp;#39;&lt;/span&gt; --provisioned-throughput &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{&amp;#34;ReadCapacityUnits&amp;#34;: &amp;#39;&lt;/span&gt;5&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;, &amp;#34;WriteCapacityUnits&amp;#34;: &amp;#39;&lt;/span&gt;5&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;}&amp;#39;&lt;/span&gt;

aws dynamodb put-item --table-name &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;MyTable&amp;#39;&lt;/span&gt; --item &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{&amp;#34;Name&amp;#34;: {&amp;#34;S&amp;#34;: &amp;#34;David&amp;#34;},&amp;#34;Age&amp;#34;: {&amp;#34;S&amp;#34;: &amp;#34;42&amp;#34;}}&amp;#39;&lt;/span&gt;

aws dynamodb put-item --table-name &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;MyTable&amp;#39;&lt;/span&gt; --item &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{&amp;#34;Name&amp;#34;: {&amp;#34;S&amp;#34;: &amp;#34;Brian&amp;#34;},&amp;#34;Age&amp;#34;: {&amp;#34;S&amp;#34;: &amp;#34;22&amp;#34;}}&amp;#39;&lt;/span&gt;

aws dynamodb put-item --table-name &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;MyTable&amp;#39;&lt;/span&gt; --item &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{&amp;#34;Name&amp;#34;: {&amp;#34;S&amp;#34;: &amp;#34;Sean&amp;#34;},&amp;#34;Age&amp;#34;: {&amp;#34;S&amp;#34;: &amp;#34;35&amp;#34;}}&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Then if we select Lambda in AWS console, and create a new function, then at &amp;lsquo;Select blueprint&amp;rsquo; select the blueprint named &amp;lsquo;Blank Function&amp;rsquo;. At next page click dashed box to configure a API Gateway trigger and change it to have Open security. Specify the name as &amp;lsquo;myTestLambda&amp;rsquo;, the runtime as &amp;lsquo;Python 2.7&amp;rsquo;, the Role as &amp;lsquo;Create new role from template(s), the role name as &amp;lsquo;myTestLambdaRole&amp;rsquo;, the Policy template as &amp;lsquo;Simple Microservice permissions&amp;rsquo; and the handler as &amp;lsquo;lambda_function.handler&amp;rsquo;.&lt;/p&gt;
&lt;p&gt;Paste the following as Lambda code&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; __future__ &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; print_function
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; boto3
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; json
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Loading function&amp;#39;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;handler&lt;/span&gt;(event, context):
    operation &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; event[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;operation&amp;#39;&lt;/span&gt;]
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;tableName&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; event:
        dynamo &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; boto3&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resource(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dynamodb&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Table(event[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;tableName&amp;#39;&lt;/span&gt;])
    operations &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;create&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x: dynamo&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;put_item(&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;x),
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;read&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x: dynamo&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_item(&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;x),
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;update&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x: dynamo&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;update_item(&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;x),
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;delete&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x: dynamo&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;delete_item(&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;x),
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;list&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x: dynamo&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;scan(&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;x),
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;echo&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x: x,
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;ping&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pong&amp;#39;&lt;/span&gt;
    }
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; operation &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; operations:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; operations[operation](event&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;payload&amp;#39;&lt;/span&gt;))
    &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;raise&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ValueError&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Unrecognized operation &amp;#34;{}&amp;#34;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(operation))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We can then test that we can pull back a specific database item for example the Brian record, select &amp;lsquo;Action \ Configure test event&amp;rsquo; and paste in the following.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;{
    &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;operation&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;read&amp;#34;&lt;/span&gt;,
    &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;tableName&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;MyTable&amp;#34;&lt;/span&gt;,
    &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;payload&amp;#34;&lt;/span&gt;: { &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;Key&amp;#34;&lt;/span&gt;: {&lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;Name&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Brian&amp;#34;&lt;/span&gt;}}
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;By clicking Test we can do an internal test of the function and pull back the DynamoDB item.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;{
&lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;Item&amp;#34;&lt;/span&gt;: {
    &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;Age&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;22&amp;#34;&lt;/span&gt;,
    &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;Name&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Brian&amp;#34;&lt;/span&gt;
}
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To do a table scan rather than targetted get,&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;{
    &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;operation&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;list&amp;#34;&lt;/span&gt;,
    &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;tableName&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;MyTable&amp;#34;&lt;/span&gt;,
    &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;payload&amp;#34;&lt;/span&gt;: { &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;TableName&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;MyTable&amp;#34;&lt;/span&gt;}
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The query can be adjusted to perform any operation on the database.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Patching Windows EC2 Instances</title>
      <link>https://darrylcauldwell.github.io/post/ec2-win-patching/</link>
      <pubDate>Wed, 28 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/ec2-win-patching/</guid>
      <description>
        
          &lt;p&gt;Amazon EC2 Systems Manager is a collection of capabilities that helps you automate management tasks such as collecting system inventory, applying operating system (OS) patches, automating the creation of Amazon Machine Images (AMIs), and configuring operating systems (OSs) and applications at scale.&lt;/p&gt;
&lt;p&gt;Amazon EC2 Systems Manager relies on the Amazon Simple Systems Management Service (SSM) agent being installed on the guests. The SSM agent is pre-installed on Windows Server 2016 instances or Windows Server 2003-2012 R2 instances created from AMI&amp;rsquo;s published after November 2016, if you created your own or used earlier AMI you&amp;rsquo;ll need to install. The SSM agent can be installed on other instances by following this &lt;a href=&#34;http://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/sysman-install-ssm-win.html&#34;&gt;install guide&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Patch Management is always an operational pain point so its welcome that AWS offers a solution. You create groups of computers to patch by applying a tag &amp;lsquo;Patch Group&amp;rsquo; and specifying a group name as the value. You create a group of patches by forming a patch baseline containing and excluding the patches you require. You then specify a maintenance window and specify task like patch this group of servers to this patch baseline.&lt;/p&gt;
&lt;h2 id=&#34;how-to&#34;&gt;How To&lt;/h2&gt;
&lt;p&gt;The guest agent requires permissions to connect to EC2 Systems Manager, we give these rights by create an EC2 Service role with the policy document &amp;lsquo;AmazonEC2RoleforSSM&amp;rsquo; attached. We then provision the EC2 instance to be patched with this role attached. If you have instance already deployed you can add the policy document to a role which is added already,  or clone the instance to a new AMI attach role and power on.&lt;/p&gt;
&lt;p&gt;Here I create a new role named &amp;lsquo;EC2-Systems-Manager-Role&amp;rsquo; with the policy document &amp;lsquo;AmazonEC2RoleforSSM&amp;rsquo; attached, attached it to a new test Windows 2016 EC2 instance.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;aws iam create-role --role-name EC2-Systems-Manager-Role --assume-role-policy-document &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{&amp;#34;Version&amp;#34;:&amp;#34;2012-10-17&amp;#34;,&amp;#34;Statement&amp;#34;:[{&amp;#34;Effect&amp;#34;:&amp;#34;Allow&amp;#34;,&amp;#34;Principal&amp;#34;:{&amp;#34;Service&amp;#34;:[&amp;#34;ssm.amazonaws.com&amp;#34;]},&amp;#34;Action&amp;#34;:[&amp;#34;sts:AssumeRole&amp;#34;]}]}&amp;#39;&lt;/span&gt;

aws iam create-instance-profile --instance-profile-name EC2-Systems-Manager-Profile

aws iam add-role-to-instance-profile --instance-profile-name EC2-Systems-Manager-Profile --role-name EC2-Systems-Manager-Role

aws ec2 create-security-group --group-name systemsManagerTest --description &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;EC2 Systems Manager Test Security Group&amp;#34;&lt;/span&gt;

aws ec2 run-instances --image-id ami-771b4504 --count &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; --instance-type t2.micro --key-name MyEC2 --security-groups systemsManagerTest --iam-instance-profile Name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;EC2-Systems-Manager-Profile
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The &amp;lsquo;Systems Manager Service&amp;rsquo; requires a Patch Group tag adding to the EC2 instances to patch,  so here we add a tag to the instance we just created.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;aws ec2 create-tags --resources &amp;lt;ec2-instance-id&amp;gt; --tags Key&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Patch Group&amp;#39;&lt;/span&gt;,Value&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Test-Patch&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The &amp;lsquo;Systems Manager Service - Maintenance Window&amp;rsquo; task requires rights on the EC2 instances to apply patches and also to task to the &amp;lsquo;Systems Manager Service&amp;rsquo;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;aws iam create-user --user-name ssmPatchUser
aws iam create-policy --policy-name ssmPassRole --policy-document &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{&amp;#34;Version&amp;#34;: &amp;#34;2012-10-17&amp;#34;,&amp;#34;Statement&amp;#34;: [{&amp;#34;Effect&amp;#34;: &amp;#34;Allow&amp;#34;,&amp;#34;Action&amp;#34;: [&amp;#34;iam:PassRole&amp;#34;],&amp;#34;Resource&amp;#34;: &amp;#34;*&amp;#34;}]}&amp;#39;&lt;/span&gt;
aws iam attach-user-policy --policy-arn arn:aws:iam::&amp;lt;your-acc-number&amp;gt;:policy/ssmPassRole  --user-name ssmPatchUser
aws iam attach-user-policy --policy-arn arn:aws:iam::aws:policy/AmazonSSMFullAccess --user-name ssmPatchUser
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We can then setup a patch baseline, this baseline auto approves all Critical, Important and Moderate patches of all classifications to be deployed seven days after they released.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;aws ssm create-patch-baseline --name &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;testBaseline&amp;#34;&lt;/span&gt; --approval-rules &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;PatchRules=[{PatchFilterGroup={PatchFilters=[{Key=MSRC_SEVERITY,Values=[Critical,Important,Moderate]},{Key=CLASSIFICATION,Values=[SecurityUpdates,Updates,UpdateRollups,CriticalUpdates]}]},ApproveAfterDays=7}]&amp;#34;&lt;/span&gt; --description &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;myBaseline&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We then take the baseline ID output and link the patch baseline with the patch group.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;aws ssm register-patch-baseline-for-patch-group --baseline-id &amp;lt;baseline-id&amp;gt; --patch-group &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Test-Patch&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once the baseline and patch groups are created and linked,  we create a SSM Maintenance Window with a task to deploy.  Here we create a schedule which starts every week day 6pm to midnight and stops scheduling tasks at 11pm. To format the cron expression is a little complex but its documented &lt;a href=&#34;https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/sysman-maintenance-cron.html?icmpid=docs_ec2_console&#34;&gt;here&lt;/a&gt; in my example we have a window at 6pm for six hours Monday through Friday.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;aws ssm create-maintenance-window --name myFirstMaintenanceWindow --schedule &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;cron(0 00 18 ? * MON-FRI)&amp;#34;&lt;/span&gt; --duration &lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt; --cutoff &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; --allow-unassociated-targets
aws ssm register-target-with-maintenance-window --window-id &amp;lt;maint-window-id&amp;gt; --targets &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Key=tag:Patch Group,Values=Test-Patch&amp;#34;&lt;/span&gt; --owner-information &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Test server&amp;#34;&lt;/span&gt; --resource-type &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;INSTANCE&amp;#34;&lt;/span&gt; 
aws ssm register-task-with-maintenance-window --window-id &amp;lt;your-maintenance-window-id&amp;gt; --targets &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Key=WindowTargetIds,Values=&amp;lt;your-target-group-id&amp;gt;&amp;#34;&lt;/span&gt; --task-arn &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;AWS-ApplyPatchBaseline&amp;#34;&lt;/span&gt; --service-role-arn &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;arn:aws:iam::&amp;lt;your-acc-id&amp;gt;:policy/ssmPassRole&amp;#34;&lt;/span&gt; --task-type &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;RUN_COMMAND&amp;#34;&lt;/span&gt; --max-concurrency &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; --max-errors &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; --priority &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; --task-parameters &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{\&amp;#34;Operation\&amp;#34;:{\&amp;#34;Values\&amp;#34;:[\&amp;#34;Install\&amp;#34;]}}&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Another useful little tool for making operating EC2 instances that little bit easier.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>DynamoDB With Powershell</title>
      <link>https://darrylcauldwell.github.io/post/dynamodb-powershell/</link>
      <pubDate>Tue, 20 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/dynamodb-powershell/</guid>
      <description>
        
          &lt;p&gt;AWS dynamoDB is a really useful key-value store which is really easy to consume from scripts. However while the AWS Powershell module contains functions for &amp;lsquo;Managing Tables&amp;rsquo; it does not contain functions for &amp;lsquo;Reading Data&amp;rsquo; or &amp;lsquo;Modifying Data&amp;rsquo;.  I had found Julian Biddle had written a &lt;a href=&#34;https://anoriginalidea.wordpress.com/2015/01/20/using-amazon-aws-dynamodb-from-powershell/&#34;&gt;blog post&lt;/a&gt; about how this might be done by making direct calls to AWS AmazonDynamoDBClient SDK for .net. While this was a useful starting point I had to read around this alot to get it to work how I needed, this post is an explaination of my understanding.&lt;/p&gt;
&lt;p&gt;The script this blog post documents is stored &lt;a href=&#34;https://github.com/darrylcauldwell/dynamoDB-powershell/blob/master/dynamoDB.ps1&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The first thing to do is setup your Powershell session with credentials which have permissions to Read and Write AWS dynamoDB. Here we create a profile and then set this as the default profile to be used.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;Import-Module AWSPowershell
Set-AWSCredentials -AccessKey &amp;lt;my-access-key&amp;gt; -SecretKey &amp;lt;my-access-key-secret&amp;gt; -StoreAs DynamoDB
Initialize-AWSDefaults -ProfileName DynamoDB -Region eu-west-1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We can then use the AWS cmdlets to create a test dynamoDB table.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;$exampleSchema = New-DDBTableSchema | Add-DDBKeySchema -KeyName &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Name&amp;#34;&lt;/span&gt; -KeyDataType &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;S&amp;#34;&lt;/span&gt;
$exampleTable = New-DDBTable &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;myExample&amp;#34;&lt;/span&gt; -Schema $exampleSchema -ReadCapacity 5 -WriteCapacity 5
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Then within our script we add the AmazonDynamoDB .net framework class.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;Add-Type -Path (${env&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;:&lt;/span&gt;ProgramFiles(x86)}+&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;\AWS SDK for .NET\bin\Net45\AWSSDK.DynamoDBv2.dll&amp;#34;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We then create a session to dynamoDB, in this example script we are running from within a Powershell session which already has permissions to DynamoDB. As such we need to specify which region our tables are in so we form a RegionEndpoint object for Ireland and pass this to form a session to that region.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;$regionName = &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;eu-west-1&amp;#39;&lt;/span&gt;
$regionEndpoint=&lt;span style=&#34;color:#66d9ef&#34;&gt;[Amazon.RegionEndPoint]&lt;/span&gt;::GetBySystemName($regionName)
$dbClient = New-Object Amazon.DynamoDBv2.AmazonDynamoDBClient($regionEndpoint)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If we wanted to authenticate within script we would form a credential object and pass that to the command to create the session for example.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;$dbClient = New-Object Amazon.DynamoDBv2.AmazonDynamoDBClient($creds, $regionEndpoint).
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;As we would typically make various put operations to DynamoDB we create a reuable function which takes parameters. In this example we have a function creating a single Item with two key-value pairs.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; putDDBItem{
    &lt;span style=&#34;color:#66d9ef&#34;&gt;param&lt;/span&gt; (
        &lt;span style=&#34;color:#66d9ef&#34;&gt;[string]&lt;/span&gt;$tableName,
        &lt;span style=&#34;color:#66d9ef&#34;&gt;[string]&lt;/span&gt;$key,
        &lt;span style=&#34;color:#66d9ef&#34;&gt;[string]&lt;/span&gt;$val,
        &lt;span style=&#34;color:#66d9ef&#34;&gt;[string]&lt;/span&gt;$key1,
        &lt;span style=&#34;color:#66d9ef&#34;&gt;[string]&lt;/span&gt;$val1
        )
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We create an object for the PutItemRequest operation, we then assign our tableName parameter as the string value for the TableName property.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;$req = New-Object Amazon.DynamoDBv2.Model.PutItemRequest
$req.TableName = $tableName
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We also need to populate the Item property, this is a dictionary which requires both a string value for the key name and an AttributeValue object. Here we add two key-value pairs to the item object request.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;$req.Item = New-Object &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;system.collections.generic.dictionary[string,Amazon.DynamoDBv2.Model.AttributeValue]&amp;#39;&lt;/span&gt;
$valObj = New-Object Amazon.DynamoDBv2.Model.AttributeValue
$valObj.S = $val
$req.Item.Add($key, $valObj)
$val1Obj = New-Object Amazon.DynamoDBv2.Model.AttributeValue
$val1Obj.S = $val1
$req.Item.Add($key1, $val1Obj)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once our object item request is formed we run this against the PutItem method of our dynamoDB database connection&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;$dbClient.PutItem($req)
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;As we would typically make various read operations to DynamoDB we create a reuable function which takes parameters.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; getDDBItem{
    &lt;span style=&#34;color:#66d9ef&#34;&gt;param&lt;/span&gt; (
            &lt;span style=&#34;color:#66d9ef&#34;&gt;[string]&lt;/span&gt;$tableName,
            &lt;span style=&#34;color:#66d9ef&#34;&gt;[string]&lt;/span&gt;$key,
            &lt;span style=&#34;color:#66d9ef&#34;&gt;[string]&lt;/span&gt;$keyAttrStr
            )

&lt;span style=&#34;color:#75715e&#34;&gt;## We create an object for the GetItemRequest operation, we then assign our tableName parameter as the string value for the TableName property. &lt;/span&gt;

$req = New-Object Amazon.DynamoDBv2.Model.GetItemRequest
$req.TableName = $tableName

&lt;span style=&#34;color:#75715e&#34;&gt;## We also need to populate the Key property, this is a dictionary which requires both a string value for the key name and an AttributeValue object for the value matching the Item we want to extract. The full command syntax can be found [here](http://docs.aws.amazon.com/sdkfornet/v3/apidocs/items/DynamoDBv2/TDynamoDBv2GetItemRequest.html).&lt;/span&gt;

$req.Key = New-Object &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;system.collections.generic.dictionary[string,Amazon.DynamoDBv2.Model.AttributeValue]&amp;#39;&lt;/span&gt;
$keyAttrObj = New-Object Amazon.DynamoDBv2.Model.AttributeValue
$keyAttrObj.S = $keyAttrStr
$req.Key.Add($key, $keyAttrObj.S)

&lt;span style=&#34;color:#75715e&#34;&gt;## Once we have our request object populated we then run the GetItem method and pass it the object we have formed. Here I adjust the scope of the object to script so this can be used within the script outside of the function.&lt;/span&gt;

$script:resp = $dbClient.GetItem($req)
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If we now call the set function and ask it to create an item,&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;putDDBItem -tableName &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;myExample&amp;#39;&lt;/span&gt; -key &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Name&amp;#39;&lt;/span&gt; -val &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Bob&amp;#39;&lt;/span&gt; -key1 &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Age&amp;#39;&lt;/span&gt; -val1 &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;21&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We can repeat this to populate a little more data into the table.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;putDDBItem -tableName &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;myExample&amp;#39;&lt;/span&gt; -key &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Name&amp;#39;&lt;/span&gt; -val &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Bert&amp;#39;&lt;/span&gt; -key1 &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Age&amp;#39;&lt;/span&gt; -val1 &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;22&amp;#39;&lt;/span&gt;
putDDBItem -tableName &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;myExample&amp;#39;&lt;/span&gt; -key &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Name&amp;#39;&lt;/span&gt; -val &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Sid&amp;#39;&lt;/span&gt; -key1 &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Age&amp;#39;&lt;/span&gt; -val1 &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;23&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Oncew we have some data in we can then call the query function to pull back the the Item where Name matches Bob.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;getDDBItem -tableName &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;myExample&amp;#39;&lt;/span&gt; -key &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Name&amp;#39;&lt;/span&gt; -keyAttrStr &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Bob&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The item is returned as an object, we can then display the contents of any key value pair such as Hugh&amp;rsquo;s age,  note the key value pair are also objects so we view the .S string attribute.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;$script:resp.Item.&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Age&amp;#39;&lt;/span&gt;.S
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;As for this example I scoped the object to script it will not be cleaned so we reset this to $null once we have consumed it.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;$script:resp = $null
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
        
      </description>
    </item>
    
    <item>
      <title>Setup VPC Peering With Ansible</title>
      <link>https://darrylcauldwell.github.io/post/vpc-ansible/</link>
      <pubDate>Mon, 14 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/vpc-ansible/</guid>
      <description>
        
          &lt;p&gt;In this post I look at setting up &lt;a href=&#34;http://docs.aws.amazon.com/AmazonVPC/latest/PeeringGuide/vpc-peering-overview.html&#34;&gt;AWS VPC peering&lt;/a&gt; using Ansible. To do this we will start simple and add complexity to our configuration, we will start with peering within a single account and then move to script across accounts.&lt;/p&gt;
&lt;h2 id=&#34;local-peering&#34;&gt;Local Peering&lt;/h2&gt;
&lt;p&gt;I&amp;rsquo;ll start by configuring two VPCs within the same account a single account, and configure peering between them. The Ansible host will sit within the same account which we create the new VPCs and peering. In order that Ansible can manage the AWS VPC services create an IAM Role named Ansible and assign it to the AdmistratorAccess policy. Once the IAM role is created we can then create a RHEL7 EC2 instance with this IAM role attached.&lt;/p&gt;
&lt;p&gt;The Ansible AWS modules manages AWS via the API by use of the &lt;a href=&#34;http://boto.cloudhackers.com/&#34;&gt;Python boto library&lt;/a&gt;, presently the boto project is migrating from v2 to v3, the Ansible VPC module relies on both versions.  In order for boto to function correctly we also need locally installed AWSCLI. Once the RHEL instance is running connect and run the following commands to install Ansible and the boto and AWS CLI python library.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;sudo yum install wget -y
wget http://dl.fedoraproject.org/pub/epel/7/x86_64/e/epel-release-7-8.noarch.rpm
sudo rpm -ivh epel-release-7-8.noarch.rpm
sudo yum install ansible git python python-devel python-pip -y
sudo pip install boto boto3 awscli
sudo yum update -y
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;What we&amp;rsquo;ll do is use the &lt;a href=&#34;http://docs.ansible.com/ansible/ec2_vpc_module.html&#34;&gt;ec2_vpc module&lt;/a&gt; to create two new VPCs and capture the output of these as variables.  We can then use pass the output from VPC creation into the &lt;a href=&#34;http://docs.ansible.com/ansible/ec2_vpc_peer_module.html&#34;&gt;ec2_vpc_peer module&lt;/a&gt; to configure peering.&lt;/p&gt;
&lt;p&gt;Once Ansible is installed you can clone example repository.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;git clone https://github.com/darrylcauldwell/aws-ansible.git
cd aws-ansible
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Inside the repository is an example playbook.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;local-vpc-peering.yml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The contents of which are shown here.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yml&#34; data-lang=&#34;yml&#34;&gt;---
- &lt;span style=&#34;color:#f92672&#34;&gt;hosts&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;localhost&amp;#34;&lt;/span&gt;
   &lt;span style=&#34;color:#f92672&#34;&gt;connection&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;local&amp;#34;&lt;/span&gt;

   &lt;span style=&#34;color:#f92672&#34;&gt;tasks&lt;/span&gt;:
   - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;First VPC&amp;#34;&lt;/span&gt;
   &lt;span style=&#34;color:#f92672&#34;&gt;ec2_vpc&lt;/span&gt;:
       &lt;span style=&#34;color:#f92672&#34;&gt;state&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;present&lt;/span&gt;
       &lt;span style=&#34;color:#f92672&#34;&gt;cidr_block&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;10.0.0.0&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;/16&lt;/span&gt;
       &lt;span style=&#34;color:#f92672&#34;&gt;resource_tags&lt;/span&gt;: { &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Name&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;First VPC&amp;#34;&lt;/span&gt; }
       &lt;span style=&#34;color:#f92672&#34;&gt;subnets&lt;/span&gt;:
       - &lt;span style=&#34;color:#f92672&#34;&gt;cidr&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;10.0.1.0&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;/24&lt;/span&gt;
           &lt;span style=&#34;color:#f92672&#34;&gt;az&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;eu-west-1a&lt;/span&gt;
           &lt;span style=&#34;color:#f92672&#34;&gt;resource_tags&lt;/span&gt;: {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Location&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;SiteA&amp;#34;&lt;/span&gt;}
       - &lt;span style=&#34;color:#f92672&#34;&gt;cidr&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;10.0.2.0&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;/24&lt;/span&gt;
           &lt;span style=&#34;color:#f92672&#34;&gt;az&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;eu-west-1b&lt;/span&gt;
           &lt;span style=&#34;color:#f92672&#34;&gt;resource_tags&lt;/span&gt;: {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Location&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;SiteB&amp;#34;&lt;/span&gt;}
       - &lt;span style=&#34;color:#f92672&#34;&gt;cidr&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;10.0.3.0&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;/24&lt;/span&gt;
           &lt;span style=&#34;color:#f92672&#34;&gt;az&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;eu-west-1c&lt;/span&gt;
           &lt;span style=&#34;color:#f92672&#34;&gt;resource_tags&lt;/span&gt;: {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Location&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;SiteC&amp;#34;&lt;/span&gt;}
       &lt;span style=&#34;color:#f92672&#34;&gt;region&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;eu-west-1&lt;/span&gt;
       &lt;span style=&#34;color:#f92672&#34;&gt;wait&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;yes&amp;#34;&lt;/span&gt; 
   &lt;span style=&#34;color:#f92672&#34;&gt;register&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;first_vpc&lt;/span&gt;

   - &lt;span style=&#34;color:#f92672&#34;&gt;debug&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;msg=&amp;#34;{{ first_vpc }}&amp;#34; &lt;/span&gt;

   - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Second VPC&amp;#34;&lt;/span&gt;
   &lt;span style=&#34;color:#f92672&#34;&gt;ec2_vpc&lt;/span&gt;:
       &lt;span style=&#34;color:#f92672&#34;&gt;state&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;present&lt;/span&gt;
       &lt;span style=&#34;color:#f92672&#34;&gt;cidr_block&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;10.1.0.0&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;/16&lt;/span&gt;
       &lt;span style=&#34;color:#f92672&#34;&gt;resource_tags&lt;/span&gt;: { &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Name&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Second VPC&amp;#34;&lt;/span&gt; }
       &lt;span style=&#34;color:#f92672&#34;&gt;subnets&lt;/span&gt;:
       - &lt;span style=&#34;color:#f92672&#34;&gt;cidr&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;10.1.1.0&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;/24&lt;/span&gt;
           &lt;span style=&#34;color:#f92672&#34;&gt;az&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;eu-west-1a&lt;/span&gt;
           &lt;span style=&#34;color:#f92672&#34;&gt;resource_tags&lt;/span&gt;: {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Location&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;SiteA&amp;#34;&lt;/span&gt;}
       - &lt;span style=&#34;color:#f92672&#34;&gt;cidr&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;10.1.2.0&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;/24&lt;/span&gt;
           &lt;span style=&#34;color:#f92672&#34;&gt;az&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;eu-west-1b&lt;/span&gt;
           &lt;span style=&#34;color:#f92672&#34;&gt;resource_tags&lt;/span&gt;: {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Location&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;SiteB&amp;#34;&lt;/span&gt;}
       - &lt;span style=&#34;color:#f92672&#34;&gt;cidr&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;10.1.3.0&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;/24&lt;/span&gt;
           &lt;span style=&#34;color:#f92672&#34;&gt;az&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;eu-west-1c&lt;/span&gt;
           &lt;span style=&#34;color:#f92672&#34;&gt;resource_tags&lt;/span&gt;: {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Location&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;SiteC&amp;#34;&lt;/span&gt;}
       &lt;span style=&#34;color:#f92672&#34;&gt;region&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;eu-west-1&lt;/span&gt;
       &lt;span style=&#34;color:#f92672&#34;&gt;wait&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;yes&amp;#34;&lt;/span&gt; 
   &lt;span style=&#34;color:#f92672&#34;&gt;register&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;second_vpc&lt;/span&gt;

   - &lt;span style=&#34;color:#f92672&#34;&gt;debug&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;msg=&amp;#34;{{ second_vpc }}&amp;#34; &lt;/span&gt;

   - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Create local VPC peering connection&amp;#34;&lt;/span&gt;
   &lt;span style=&#34;color:#f92672&#34;&gt;ec2_vpc_peer&lt;/span&gt;:
       &lt;span style=&#34;color:#f92672&#34;&gt;region&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;eu-west-1&lt;/span&gt;
       &lt;span style=&#34;color:#f92672&#34;&gt;vpc_id&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{{ first_vpc.vpc_id }}&amp;#34;&lt;/span&gt;
       &lt;span style=&#34;color:#f92672&#34;&gt;peer_vpc_id&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{{ second_vpc.vpc_id }}&amp;#34;&lt;/span&gt;
       &lt;span style=&#34;color:#f92672&#34;&gt;state&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;present&lt;/span&gt;
   &lt;span style=&#34;color:#f92672&#34;&gt;register&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;vpc_peer&lt;/span&gt;

   - &lt;span style=&#34;color:#f92672&#34;&gt;debug&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;msg=&amp;#34;{{ vpc_peer }}&amp;#34;&lt;/span&gt;

   - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Accept local VPC peering connection&amp;#34;&lt;/span&gt;
   &lt;span style=&#34;color:#f92672&#34;&gt;ec2_vpc_peer&lt;/span&gt;:
       &lt;span style=&#34;color:#f92672&#34;&gt;region&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;eu-west-1&lt;/span&gt;
       &lt;span style=&#34;color:#f92672&#34;&gt;peering_id&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{{ vpc_peer.peering_id }}&amp;#34;&lt;/span&gt;
       &lt;span style=&#34;color:#f92672&#34;&gt;state&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;accept&lt;/span&gt;
   &lt;span style=&#34;color:#f92672&#34;&gt;register&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;accept_peer&lt;/span&gt;

   - &lt;span style=&#34;color:#f92672&#34;&gt;debug&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;msg=&amp;#34;{{ accept_peer }}&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;I&amp;rsquo;ve added debugging of output, if you run this you will see the two VPCs get created and then the peering configured between them.&lt;/p&gt;
&lt;p&gt;## Cross Account VPC Peering Using Access Keys&lt;/p&gt;
&lt;p&gt;As well as confguring peering within a single account, we can also use Ansible across AWS accounts. The steps we use are very similar but we begin to use &lt;a href=&#34;http://boto.cloudhackers.com/en/latest/boto_config_tut.html&#34;&gt;boto configuration profiles&lt;/a&gt; once we have a configuration profile for each account in place we can then target each task in the play to a different account. As we are using boto we&amp;rsquo;ll authenticate using AWS Access Key and Secret rather than role based permissions applied to the EC2 instance, we cannot remove a role from a EC2 instance so terminate the old Ansible server and create a new one as above but without the IAM Role attached.&lt;/p&gt;
&lt;p&gt;Within each account your managing create an IAM User called AnsibleAdministratorAccess and attach the AdmistratorAccess policy, add the Access Key ID and Secret Access Key to the boto2 and boto3 configuration files. I create a profile for each account named the account number.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;sudo vi /etc/boto.cfg

&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;profile 843555617105&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
aws_access_key_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &amp;lt;your_access_key_here&amp;gt;
aws_secret_access_key &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &amp;lt;your_secret_key_here&amp;gt;

&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;profile 664710917345&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
aws_access_key_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &amp;lt;your_access_key_here&amp;gt;
aws_secret_access_key &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &amp;lt;your_secret_key_here&amp;gt;

mkdir ~/.aws/
cp /etc/boto.cfg ~/.aws/config
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once Ansible and boto are installed and configured you can clone example repository.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git clone https://github.com/darrylcauldwell/aws-ansible.git
cd aws-ansible
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Inside the repository is an example playbook.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cross-account-vpc-peering.yml 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;You&amp;rsquo;ll notice this playbook looks very similar to the one for local peering. The key differences are the addition of the profile parameter for the ec2_vpc and ec2_vpc_peer tasks, and the addition of account number hosting VPCs.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yml&#34; data-lang=&#34;yml&#34;&gt;---
- &lt;span style=&#34;color:#f92672&#34;&gt;hosts&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;localhost&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;connection&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;local&amp;#34;&lt;/span&gt;

    &lt;span style=&#34;color:#f92672&#34;&gt;tasks&lt;/span&gt;:
    - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;First VPC&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;ec2_vpc&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;state&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;present&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;cidr_block&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;10.0.0.0&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;/16&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;profile&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;843555617105&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;resource_tags&lt;/span&gt;: { &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Name&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;First VPC&amp;#34;&lt;/span&gt; }
        &lt;span style=&#34;color:#f92672&#34;&gt;subnets&lt;/span&gt;:
        - &lt;span style=&#34;color:#f92672&#34;&gt;cidr&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;10.0.1.0&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;/24&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;az&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;eu-west-1a&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;resource_tags&lt;/span&gt;: {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Location&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;SiteA&amp;#34;&lt;/span&gt;}
        - &lt;span style=&#34;color:#f92672&#34;&gt;cidr&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;10.0.2.0&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;/24&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;az&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;eu-west-1b&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;resource_tags&lt;/span&gt;: {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Location&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;SiteB&amp;#34;&lt;/span&gt;}
        - &lt;span style=&#34;color:#f92672&#34;&gt;cidr&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;10.0.3.0&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;/24&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;az&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;eu-west-1c&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;resource_tags&lt;/span&gt;: {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Location&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;SiteC&amp;#34;&lt;/span&gt;}
        &lt;span style=&#34;color:#f92672&#34;&gt;region&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;eu-west-1&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;wait&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;yes&amp;#34;&lt;/span&gt; 
    &lt;span style=&#34;color:#f92672&#34;&gt;register&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;first_vpc&lt;/span&gt;

    - &lt;span style=&#34;color:#f92672&#34;&gt;debug&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;msg=&amp;#34;{{ first_vpc }}&amp;#34; &lt;/span&gt;

    - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Second VPC&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;ec2_vpc&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;state&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;present&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;cidr_block&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;10.1.0.0&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;/16&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;profile&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;664710917345&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;resource_tags&lt;/span&gt;: { &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Name&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Second VPC&amp;#34;&lt;/span&gt; }
        &lt;span style=&#34;color:#f92672&#34;&gt;subnets&lt;/span&gt;:
        - &lt;span style=&#34;color:#f92672&#34;&gt;cidr&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;10.1.1.0&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;/24&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;az&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;eu-west-1a&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;resource_tags&lt;/span&gt;: {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Location&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;SiteA&amp;#34;&lt;/span&gt;}
        - &lt;span style=&#34;color:#f92672&#34;&gt;cidr&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;10.1.2.0&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;/24&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;az&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;eu-west-1b&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;resource_tags&lt;/span&gt;: {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Location&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;SiteB&amp;#34;&lt;/span&gt;}
        - &lt;span style=&#34;color:#f92672&#34;&gt;cidr&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;10.1.3.0&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;/24&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;az&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;eu-west-1c&lt;/span&gt;
            &lt;span style=&#34;color:#f92672&#34;&gt;resource_tags&lt;/span&gt;: {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Location&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;SiteC&amp;#34;&lt;/span&gt;}
        &lt;span style=&#34;color:#f92672&#34;&gt;region&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;eu-west-1&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;wait&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;yes&amp;#34;&lt;/span&gt; 
    &lt;span style=&#34;color:#f92672&#34;&gt;register&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;second_vpc&lt;/span&gt;

    - &lt;span style=&#34;color:#f92672&#34;&gt;debug&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;msg=&amp;#34;{{ second_vpc }}&amp;#34; &lt;/span&gt;

    - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Create local VPC peering connection&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;ec2_vpc_peer&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;profile&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;843555617105&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;region&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;eu-west-1&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;vpc_id&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{{ first_vpc.vpc_id }}&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;peer_vpc_id&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{{ second_vpc.vpc_id }}&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;peer_owner_id&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;664710917345&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;state&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;present&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;register&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;vpc_peer&lt;/span&gt;

    - &lt;span style=&#34;color:#f92672&#34;&gt;debug&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;msg=&amp;#34;{{ vpc_peer }}&amp;#34;&lt;/span&gt;

    - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Accept local VPC peering connection&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;ec2_vpc_peer&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;profile&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;664710917345&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;region&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;eu-west-1&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;peering_id&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{{ vpc_peer.peering_id }}&amp;#34;&lt;/span&gt; 
        &lt;span style=&#34;color:#f92672&#34;&gt;state&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;accept&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;register&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;accept_peer&lt;/span&gt;

    - &lt;span style=&#34;color:#f92672&#34;&gt;debug&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;msg=&amp;#34;{{ accept_peer }}&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;I&amp;rsquo;ve added debugging of output, if you run this&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;ansible-playbook aws-ansible/cross-account-vpc-peering.yml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You will see the two VPCs in different accounts and get created and then the peering configured between them.&lt;/p&gt;
&lt;h2 id=&#34;cross-account-vpc-peering-using-iam-assume-role-provider&#34;&gt;Cross Account VPC Peering Using IAM Assume Role Provider&lt;/h2&gt;
&lt;p&gt;It is Amazon best practise is to &lt;a href=&#34;http://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html#delegate-using-roles&#34;&gt;delegate access using roles instead of sharing credentials.&lt;/a&gt; You can define a role that specifies what permissions the IAM users in the other account are allowed, and from which AWS accounts the IAM users are allowed to assume the role. Up to now we&amp;rsquo;ve used IAM User and Access Keys to authenticate across multiple accounts, here we will look at configuring Ansible using AssumeRole.&lt;/p&gt;
&lt;p&gt;Unfortunatly ec2_vpc does not yet support boto3 and this is required to use AssumeRole, ec2_vpc_peer however does support this. What this means though is we need to configure boto2 config file with access key in both accounts.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;sudo vi /etc/boto.cfg

&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;profile 843555617105&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
aws_access_key_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &amp;lt;your_access_key_here&amp;gt;
aws_secret_access_key &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &amp;lt;your_secret_key_here&amp;gt;

&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;profile 664710917345&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
aws_access_key_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &amp;lt;your_access_key_here&amp;gt;
aws_secret_access_key &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &amp;lt;your_secret_key_here&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In order to configure boto3 to use AssumeRole we first, create an IAM User called AnsibleAdminUser in your first account. Then create an IAM Role your second account called &amp;lsquo;AnsibleAdministrator&amp;rsquo; for role type select &amp;lsquo;Role for Cross-Account Access \ Provide access between AWS accounts you own&amp;rsquo; then enter the Account ID of your first account and attach policy AdmistratorAccess. Once created view your new role in IAM and copy the Role ARN eg arn:aws:iam::664710917345:role/AnsibleAdministrator&lt;/p&gt;
&lt;p&gt;Configure boto3 credentials&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;mkdir ~/.aws
sudo vi ~/.aws/credentials 

&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;664710917345-AnsibleAdminUser&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
aws_access_key_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &amp;lt;your_access_key_here&amp;gt;
aws_secret_access_key &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &amp;lt;your_secret_key_here&amp;gt;

sudo vi ~/.aws/config

&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;profile 664710917345&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
aws_access_key_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &amp;lt;your_access_key_here&amp;gt;
aws_secret_access_key &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &amp;lt;your_secret_key_here&amp;gt;

&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;profile 843555617105&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; 
role_arn&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;arn:aws:iam::843555617105:role/AnsibleAdministrator
source_profile&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;664710917345-AnsibleAdminUser
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once the credentials files are completed we can clone the example git repo and run the playbook.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git clone https://github.com/darrylcauldwell/aws-ansible.git
ansible-playbook aws-ansible/cross-account-vpc-peering.yml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We should see the same behaviour where two VPCs are created and VPC Peering is established between them.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>How To Use AWS CloudFormation With Ansible</title>
      <link>https://darrylcauldwell.github.io/post/ansible-clouformation/</link>
      <pubDate>Wed, 09 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/ansible-clouformation/</guid>
      <description>
        
          &lt;p&gt;AWS CloudFormation gives developers and systems administrators an easy way to create and manage a collection of related AWS resources, provisioning and updating them in an orderly and predictable fashion. Ansible is a radically simple IT automation engine that automates cloud provisioning, configuration management, application deployment, intra-service orchestration, and many other IT needs. Ansible uses no agents and no additional custom security infrastructure, so it&amp;rsquo;s easy to deploy, it uses a very simple language which allows you to describe your automation jobs in a way that approaches plain English.&lt;/p&gt;
&lt;h2 id=&#34;install-ansible-for-aws-management&#34;&gt;Install Ansible For AWS Management&lt;/h2&gt;
&lt;p&gt;In order that Ansible can manage AWS services create an IAM Role named Ansible and assign it to the AdmistratorAccess policy, then create a RHEL7 EC2 instance with this IAM role attached. The Ansible AWS modules manages AWS via the API by use of the &lt;a href=&#34;http://boto.cloudhackers.com/&#34;&gt;Python boto library&lt;/a&gt; and locally installed AWSCLI. Once the RHEL instance is running connect and run the following commands to install Ansible and the boto and AWS CLI python library.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;sudo yum install wget -y
wget http://dl.fedoraproject.org/pub/epel/7/x86_64/e/epel-release-7-8.noarch.rpm
sudo rpm -ivh epel-release-7-8.noarch.rpm
sudo yum install ansible git python python-devel python-pip -y
sudo pip install boto awscli
sudo yum update -y
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;deploy-an-ec2-instance-using-ansible&#34;&gt;Deploy An EC2 Instance Using Ansible&lt;/h2&gt;
&lt;p&gt;Once installed we can test Ansible can communicate correctly with AWS by creating a security group and EC2 instance. I&amp;rsquo;ve prepared a short playbook for my AWS account, in order to use yourself modify the five variables at the top of the playbook.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;git clone https://github.com/darrylcauldwell/aws-ansible.git
ansible-playbook /home/ec2-user/aws-ansible/my-test-play.yml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;deploy-an-ec2-instance-using-cloudformation&#34;&gt;Deploy An EC2 Instance Using CloudFormation&lt;/h2&gt;
&lt;p&gt;Amazon provide various &lt;a href=&#34;http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cfn-sample-templates.html&#34;&gt;CloudFormation Sample Templates&lt;/a&gt;. In this example I&amp;rsquo;ll use the sample template EC2InstanceWithSecurityGroupSample: this creates an Amazon EC2 instance and a security group.&lt;/p&gt;
&lt;p&gt;I included the template file in the github repository with the example files in which we pulled in previous step. The sample template takes upto three parameters,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;KeyName : Name of an existing EC2 KeyPair to enable SSH access to the instance&lt;/li&gt;
&lt;li&gt;InstanceType (Optional) : The size of EC2 instance if not specified defaults to t2.small&lt;/li&gt;
&lt;li&gt;SSHLocation (Optional) : The range of IP addresses which is allowed to connect to SSH defaults to 0.0.0.0/0&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The example AWS provide requires a default region to be set on the AWS CLI, to do this use &lt;a href=&#34;http://docs.aws.amazon.com/cli/latest/userguide/cli-chap-getting-started.html&#34;&gt;AWS Configure&lt;/a&gt;. We can then ask CloudFormations to deploy the template and include the parameters we want.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;aws configure
aws cloudformation create-stack --stack-name startmyinstance --template-body file:///home/ec2-user/aws-ansible/EC2InstanceWithSecurityGroupSample.template --parameters  ParameterKey&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;KeyName,ParameterValue&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;MyEC2 ParameterKey&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;InstanceType,ParameterValue&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;t1.micro 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;deploy-an-ec2-instance-using-ansible--cloudformation&#34;&gt;Deploy An EC2 Instance Using Ansible &amp;amp; CloudFormation&lt;/h2&gt;
&lt;p&gt;Taking the scenrio one step further we&amp;rsquo;d like to drive the deployment of AWS infrastructure from Ansible therefore the parameters required by the CloudFormation templates we should use Ansible CloudFormation module and variables.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yml&#34; data-lang=&#34;yml&#34;&gt;---
- &lt;span style=&#34;color:#f92672&#34;&gt;hosts&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;localhost&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;connection&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;local&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;gather_facts&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;false&lt;/span&gt;

&lt;span style=&#34;color:#f92672&#34;&gt;vars&lt;/span&gt;:
    &lt;span style=&#34;color:#f92672&#34;&gt;KeyName&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;MyEC2&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;InstanceType&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;t2.micro&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;SSHLocation&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;0.0.0.0/0&amp;#34;&lt;/span&gt;

&lt;span style=&#34;color:#f92672&#34;&gt;tasks&lt;/span&gt;:
    - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Run my CloudFormation stack&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;cloudformation&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;stack_name&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;MyEC2Stack&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;region&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;eu-west-1&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;state&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;present&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;template&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;EC2InstanceWithSecurityGroupSample.template&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;template_parameters&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;KeyName&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{{ KeyName }}&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;InstanceType&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{{ InstanceType }}&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;SSHLocation&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{{ SSHLocation }}&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;tags&lt;/span&gt;:
        &lt;span style=&#34;color:#f92672&#34;&gt;tool&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;ansible&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;env&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;test&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;register&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;my_ec2_stack&lt;/span&gt;

    - &lt;span style=&#34;color:#f92672&#34;&gt;debug&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;msg=&amp;#34;{{ my_ec2_stack.stack_resources}}&amp;#34;&lt;/span&gt;
    - &lt;span style=&#34;color:#f92672&#34;&gt;debug&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;msg=&amp;#34;{{ my_ec2_stack.stack_outputs}}&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;I included the example Ansible playbook above in the github repository with the example files in which we pulled in previous step.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;ansible-playbook /home/ec2-user/aws-ansible/my-other-test-play.yml

PLAY &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;localhost&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; ***************************************************************
TASK &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;Run my CloudFormation stack&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; *********************************************
changed: &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;localhost&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
TASK &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;debug&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; *******************************************************************
ok: &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;localhost&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;msg&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;last_updated_time&amp;#34;&lt;/span&gt;: null, 
            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;logical_resource_id&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;EC2Instance&amp;#34;&lt;/span&gt;, 
            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;physical_resource_id&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;i-040228bd8fcb5c81a&amp;#34;&lt;/span&gt;, 
            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;resource_type&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;AWS::EC2::Instance&amp;#34;&lt;/span&gt;, 
            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;status&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;CREATE_COMPLETE&amp;#34;&lt;/span&gt;, 
            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;status_reason&amp;#34;&lt;/span&gt;: null
        &lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;, 
        &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;last_updated_time&amp;#34;&lt;/span&gt;: null, 
            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;logical_resource_id&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;InstanceSecurityGroup&amp;#34;&lt;/span&gt;, 
            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;physical_resource_id&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;MyEC2Stack-InstanceSecurityGroup-3YAAZV42DEPF&amp;#34;&lt;/span&gt;, 
            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;resource_type&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;AWS::EC2::SecurityGroup&amp;#34;&lt;/span&gt;, 
            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;status&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;CREATE_COMPLETE&amp;#34;&lt;/span&gt;, 
            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;status_reason&amp;#34;&lt;/span&gt;: null
        &lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
TASK &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;debug&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; *******************************************************************
ok: &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;localhost&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;msg&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;AZ&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;eu-west-1a&amp;#34;&lt;/span&gt;, 
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;InstanceId&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;i-040228bd8fcb5c81a&amp;#34;&lt;/span&gt;, 
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;PublicDNS&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;ec2-54-171-78-90.eu-west-1.compute.amazonaws.com&amp;#34;&lt;/span&gt;, 
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;PublicIP&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;54.171.78.90&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
PLAY RECAP *********************************************************************
localhost                  : ok&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;    changed&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;    unreachable&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;    failed&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;   
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You will see that if we run this it creates the stack with parameters we defined as variables.  Notice at the end of the first task we register the output as an object. For the example we output this to the screen by using a debug task, and it includes the EC2 instance details. You could just as easily use this to continue configuration of the EC2 instance guest operating system.&lt;/p&gt;
&lt;p&gt;The Ansible playbook is idempotent so if you re-run the playbook whith state attribute as &amp;lsquo;present&amp;rsquo; it checks it is in place and makes no changes. If you would like to remove the CloudFormation Stack then you can change the state attribute to &amp;lsquo;absent&amp;rsquo; and when you re-run the playbook the CloudFormation Stack will be removed.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Migrate VMware VMs to AWS EC2 using Server Migration Services (SMS)</title>
      <link>https://darrylcauldwell.github.io/post/aws-sms/</link>
      <pubDate>Tue, 01 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/aws-sms/</guid>
      <description>
        
          &lt;p&gt;The &lt;a href=&#34;https://aws.amazon.com/server-migration-service/&#34;&gt;AWS Server Migration Service&lt;/a&gt; simplifies and streamlines the process of migrating existing virtualized applications to Amazon EC2. AWS SMS allows you to automate, schedule, and track incremental replications of live server volumes, making it easier for you to coordinate large-scale server migrations. Presently this only supports migrating from VMware with support for other hypervisors and physical servers is coming soon.&lt;/p&gt;
&lt;p&gt;Amazon provide a virtual appliance (OVA) which can be imported into your existing vCenter, once booted this is configured to connect to vCenter and your AWS account. Once configured this appliance is controlled by the AWS SMS service to take a snapshot of VMware virtual machines and facilitate the upload of the snapshot copy into an S3 bucket.  Once the VMware snapshot is uploaded into the S3 bucket the SMS service then updates the disk format and then prepare this as an AMI.&lt;/p&gt;
&lt;p&gt;The size of virtual machine images is such that the upload process might well take a long time, and during this time you might well want to keep the virtual machine running. The changes made during this time therefore will not be reflected in the initial AMI created. As such AWS SMS offers the option of running the replication job again, but rather than the job creating a full new virtual machine it takes an incremental snapshot.  Once the upload of this is completed the SMS service processes the initial upload with the incremental to form a new AMI.&lt;/p&gt;
&lt;h2 id=&#34;how-to-configure-server-migration-services-sms&#34;&gt;How To: Configure Server Migration Services (SMS)&lt;/h2&gt;
&lt;p&gt;The process is pretty straight forwards,  first task is to download the AWS Server Migration Connector from &lt;a href=&#34;https://s3.amazonaws.com/sms-connector/AWS-SMS-Connector.ova&#34;&gt;S3&lt;/a&gt;, then deploy the OVA.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/aws-sms-ova-deploy.jpeg&#34; alt=&#34;Deploy OVF Template&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/aws-sms-ova-deploy-final.jpeg&#34; alt=&#34;Deploy OVF Ready to complete&#34;&gt;&lt;/p&gt;
&lt;p&gt;The SMS Connector needst to connect to your AWS account and therefore we need to create a user with the &amp;ldquo;ServerMigrationConnector&amp;rdquo; role attached.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/aws-sms-account.jpeg&#34; alt=&#34;MigrationUser Role Mapping&#34;&gt;&lt;/p&gt;
&lt;p&gt;Once the SMS connector appliance is deployed connect to the web UI by opening the browser to https://dhcp-addr&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/aws-sms-cfg-wiz.jpeg&#34; alt=&#34;AWS Server Migration Service Splash&#34;&gt;&lt;/p&gt;
&lt;p&gt;Work through the wizard to configure all,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Step 1: License Agreement&lt;/li&gt;
&lt;li&gt;Step 2: Create a Password&lt;/li&gt;
&lt;li&gt;Step 3: Network Info&lt;/li&gt;
&lt;li&gt;Step 4: Log Uploads and Upgrades&lt;/li&gt;
&lt;li&gt;Step 5: Server Migration Service&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Once configuration is complete the connection to AWS and vCenter should show good in the connector configuration.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/aws-sms-cfg-complete.jpeg&#34; alt=&#34;AWS Server Migration Service Configuration Complete&#34;&gt;&lt;/p&gt;
&lt;p&gt;If we then connect to AWS we can see the connector.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/aws-sms-cfg-complete-console.jpeg&#34; alt=&#34;AWS Server Migration Service Complete Console&#34;&gt;&lt;/p&gt;
&lt;p&gt;In order to create the first replication job we need to import the list of vCenter VMs by using the &amp;lsquo;Import server catalog&amp;rsquo; function.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/aws-sms-import.jpeg&#34; alt=&#34;AWS Server Migration Service Import Server Catalog&#34;&gt;&lt;/p&gt;
&lt;p&gt;There is not a default role supplied which the SMS services can use to form AMI&amp;rsquo;s from the uploaded VMware snapshots. To do this download this file &lt;a href=&#34;https://darrylcauldwell.github.io/attachments/trust-policy.json&#34;&gt;trust-policy.json&lt;/a&gt; and this file &lt;a href=&#34;https://darrylcauldwell.github.io/attachments/role-policy.json&#34;&gt;role-policy.json&lt;/a&gt;. Then at a command prompt, go to the directory where you stored the two JSON files, and run the following commands to create the SMS service role:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;aws iam create-role --role-name sms --assume-role-policy-document file://trust-policy.json
aws iam put-role-policy --role-name sms --policy-name sms --policy-document file://role-policy.json
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;how-to-migrate-virtual-machine&#34;&gt;How To: Migrate Virtual Machine&lt;/h2&gt;
&lt;p&gt;Once the vCenter Server Inventory is imported to AWS SMS, and the role is created we can create our first replication job by using the SMS service wizard.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Step 1: Select the servers&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Select the virtual machine(s) you would like to migrate.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Step 2: Configure server-specific settings&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Select the license type for the guest operating system of the virtual server(s) being migrated.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Step 3: Configure replication job settings&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Schedule the replication job, assuming you used the two files about to create the SMS role for IAM service role leave as default &amp;lsquo;sms&amp;rsquo;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Step 4: Review&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Once the job schedules,  the first task the job performs is to create a VMware snapshot, it&amp;rsquo;s important to remember to have enough disk capacity to hold snapshots.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/aws-sms-seed-snapshot.jpeg&#34; alt=&#34;AWS Server Migration Service Seeding Snapshot&#34;&gt;&lt;/p&gt;
&lt;p&gt;The AWS console doesn&amp;rsquo;t update very well, so its best to view the progress via the AWS CLI. First list all of the replication jobs and from this you can find the JobID then to make it easier to read target the output to the specific JobID.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;aws sms get-replication-jobs  
aws sms get-replication-jobs --replication-job-id sms-job-2ca54045  
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;A replication job refers to the server being migrated,  as we mentioned earlier multiple replications can occur for example the initial seed and an incremental.  Therefore within a replication job there might be various replication runs.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;aws sms get-replication-runs --replication-job-id sms-job-2ca54045  
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In the following example we can see this has three runs in the runlist, the initial seed which has completed, an incrememental which has completed, it also has a pending job as I had left the default replication job values to schedule a daily incremental.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/aws-sms-repl-runs.jpeg&#34; alt=&#34;AWS Server Migration Service Replication Runs&#34;&gt;&lt;/p&gt;
&lt;p&gt;When a job is running you would see the state roll through the various stages&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Pending&lt;/li&gt;
&lt;li&gt;Active&lt;/li&gt;
&lt;li&gt;Complete&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;While the job state is in the Active state the statusMessage rolls through the various stages&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Uploading&lt;/li&gt;
&lt;li&gt;Converting&lt;/li&gt;
&lt;li&gt;Preparing&lt;/li&gt;
&lt;li&gt;Completed&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Each run forms a new AMI, each newly created AMIs can then be launched in ec2, so you can for example start from the initial seed replication, one containing all the incrementals or anywhere in between.&lt;/p&gt;
&lt;h2 id=&#34;offical-sms-documentation-links&#34;&gt;Offical SMS Documentation Links&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/server-migration-service/&#34;&gt;Marketing Page&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/blogs/aws/new-aws-server-migration-service/&#34;&gt;AWS Blog&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://docs.aws.amazon.com/ServerMigration/latest/userguide/server-migration.html&#34;&gt;Tech Documentation&lt;/a&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>vRealize Orchestrator 7 (vRO) Install</title>
      <link>https://darrylcauldwell.github.io/post/vro-install/</link>
      <pubDate>Tue, 14 Jun 2016 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/vro-install/</guid>
      <description>
        
          &lt;p&gt;While attempting to setup vRealize Orchestrator 7 at home it soon became clear the documentation isn&amp;rsquo;t great after much flipping between documents and blog posts I got this installed and working. Here I are the steps I followed.&lt;/p&gt;
&lt;h2 id=&#34;deploy-vrealize-orchestrator&#34;&gt;Deploy vRealize Orchestrator&lt;/h2&gt;
&lt;p&gt;Deploy the OVA via web client and specify network details appropriate to your home lab,  ensure a DNS A and PTR record are created for the vRealize Orchestrator appliance.  The Orchestrator client relies on a Java Runtime so while OVA deploys its a good time to install this if its not already.&lt;/p&gt;
&lt;p&gt;Once deployed the various interfaces to vRO can be accessed from the main menu screen https://vro-fqdn:8281/vco/.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/vROstartPage.jpg&#34; alt=&#34;vRO Start Page&#34;&gt;&lt;/p&gt;
&lt;p&gt;From the menu select &amp;lsquo;Orchestrator Control Center&amp;rsquo; from the start menu and authenticate with the account named root with the password you specified during OVA deployment.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/vROcontrolCenter.jpg&#34; alt=&#34;vRO Control Center&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;configure-vcenter-connection&#34;&gt;Configure vCenter Connection&lt;/h2&gt;
&lt;p&gt;The first thing to do once vRealize Orchestrator is deployed is to import the vCenter SSL certitificate. Select the Control Center &amp;lsquo;Manage \ Certificates&amp;rsquo; menu item.  Within trusted certificates tab click &amp;lsquo;Import \ Import from URL&amp;rsquo;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/vROtrustVcenter.jpg&#34; alt=&#34;vRO Trust vCenter&#34;&gt;&lt;/p&gt;
&lt;p&gt;Within this wizard enter the FQDN of your vCenter and at next wizard screen
click Import.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/vROimportCert.jpg&#34; alt=&#34;vRO Import Certificate&#34;&gt;&lt;/p&gt;
&lt;p&gt;I use vCenter as an appliance with embedded Platform Services Controller, I&amp;rsquo;d prefer to manage vRealize Orchestrator using the same Single Sign On account.  To do this use the vRealize Orchestrator Control Center menu option &amp;lsquo;Manage \ Configure Authentication Provider&amp;rsquo;.&lt;/p&gt;
&lt;p&gt;Select &amp;lsquo;Authentication mode&amp;rsquo; to be vSphere,  enter FQDN of vCenter and click Connect.  Your then asked for a User name and password, this account is used to bind to Single Sign On so enter your logon details and click Register. Your then asked to enter an Admin group, start to type Administrator and click the Search button to the right and it should list all available groups from SSO with Administrator in the name.  Select &amp;lsquo;vsphere.local\Administrators&amp;rsquo; and click Save.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/vROauth.jpg&#34; alt=&#34;vRO Authentication Mode&#34;&gt;&lt;/p&gt;
&lt;p&gt;Once added the vRO service needs to be restarted there is a link presented once configuration is saved,  or this can be selected from &amp;lsquo;Mange \ Startup Options&amp;rsquo;.&lt;/p&gt;
&lt;p&gt;You should now be able to open the main menu and start the vRO Client, login with your SSO credentials and start having fun.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/vROclientStart.jpg&#34; alt=&#34;vRO Client Start&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;redirect-syslog-to-log-insight&#34;&gt;Redirect Syslog to Log Insight&lt;/h2&gt;
&lt;p&gt;I use vRealize Log Insight to to centralize all my lab log files. To set Log Insight as a remote syslog use &amp;lsquo;Control Center \ Log \ Logging Integration&amp;rsquo;.  Complete the details of Log Insight server.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/vROlogInsight.jpg&#34; alt=&#34;vRO Log Insight&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;configure-ntp&#34;&gt;Configure NTP&lt;/h2&gt;
&lt;p&gt;I sync time from Active Directory in my homelab,  this is done from the appliance configuration application located https://&lt;!-- raw HTML omitted --&gt;:5480. Within this go to the &amp;lsquo;Admin \ Time Settings&amp;rsquo; menu option and enter the NTP server IP address.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/vROconfigurator.jpg&#34; alt=&#34;vRO Configurator&#34;&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Deploying NSX-V With Ansible</title>
      <link>https://darrylcauldwell.github.io/post/nsx-install-ansible/</link>
      <pubDate>Wed, 08 Jun 2016 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/nsx-install-ansible/</guid>
      <description>
        
          &lt;p&gt;Here I will describe the steps taken to deploy NSX Manager using the &lt;a href=&#34;https://github.com/vmware/nsxansible&#34;&gt;Ansible NSX Module&lt;/a&gt;. The NSX Ansible module is written by VMware and is provided opensource on GitHub. To work properly this depends on the &lt;a href=&#34;https://github.com/vmware/nsxraml&#34;&gt;NSX RAML Specification&lt;/a&gt;, &lt;a href=&#34;https://github.com/vmware/nsxramlclient&#34;&gt;NSX RAML Python Client&lt;/a&gt;, &lt;a href=&#34;https://github.com/vmware/pyvmomi&#34;&gt;vSphere API Python Bindings&lt;/a&gt; and the &lt;a href=&#34;https://www.vmware.com/support/developer/ovf/&#34;&gt;OVF Tool&lt;/a&gt; all being installed on the Ansible server.&lt;/p&gt;
&lt;p&gt;The following assumes you have a working Ansible installation already, and a vSphere environmentto install NSX to. If you don&amp;rsquo;t yet have these you can see how I performed my &lt;a href=&#34;%7B%7Bsite.url%7D%7D/how-to-setup-an-ansible-test-lab-for-windows-managed-nodes-custom-windows-modules/&#34;&gt;Ansible Installation&lt;/a&gt; in this earlier blog post.&lt;/p&gt;
&lt;h2 id=&#34;nsx-raml-specification&#34;&gt;NSX RAML Specification&lt;/h2&gt;
&lt;p&gt;As the NSX REST API changes with each release the REST API Markup Language (RAML) specification for NSX is provided as a different branch of the GitHub repository.  In my environment I will be using NSX 6.2.2 so first I ensure the git client is installed to my Ansible server and then I use this to take a clone of the correct branch.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;yum install git-all
git clone -b 6.2.2 https://github.com/vmware/nsxraml.git /nsxraml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;nsx-raml-python-client&#34;&gt;NSX RAML Python Client&lt;/h2&gt;
&lt;p&gt;The NSX RAML python client is series of functions which can be used standalone or in our case called by the Ansible NSX module.  To install these we need to ensure the &amp;lsquo;Python Package Manger&amp;rsquo; and some other tools are installed and available on our Ansible server.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;yum install python-pip gcc libxslt-devel python-devel pyOpenSSL
pip install --upgrade pip
pip install lxml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once thes pre-requiste components are in place we can then install the NSX RAML python client. Similar to the RAML specification, the client functions are also dependant on version. The version which works with NSX RAML Specification 6.2.2 is Python client 1.0.4.  To install this version from Python package manager we use.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;pip install nsxramlclient&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;1.0.4
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If you have NSX Manager already deployed you can create a session to this using the python client.  First start python by running&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;python
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;then you can run the commands similar to this to create a session.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; nsxramlclient.client &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; NsxClient
nsxraml_file &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/nsxraml/nsxvapi.raml&amp;#39;&lt;/span&gt;
nsxmanager &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;nsx.darrylcauldwell.local&amp;#39;&lt;/span&gt;
nsx_username &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;admin&amp;#39;&lt;/span&gt;
nsx_password &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;VMware!&amp;#39;&lt;/span&gt;
client_session &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; NsxClient(nsxraml_file, nsxmanager, nsx_username, nsx_password, debug&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;you can then see the session by running the following command in python session&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;client_session
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-install-ansible-RAMLclient.jpg&#34; alt=&#34;NSX RAML Client&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;vmware-vsphere-api-python-bindings&#34;&gt;VMware vSphere API Python Bindings&lt;/h2&gt;
&lt;p&gt;As well as the NSX Python client the Ansible NSX Module also depends on the VMware vSphere API Python Bindings (pyVmomi. pyVmomi is the Python SDK for the VMware vSphere API that allows you to manage ESX, ESXi, and vCenter. This is similarly installed with the python package manager using command like.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;pip install pyvmomi
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;ovf-tool&#34;&gt;OVF Tool&lt;/h2&gt;
&lt;p&gt;The final thing to be installed for the NSX Module to operate correctly is the VMware OVF Tool. The OVF tool for Linux version 4.1.0 is &lt;a href=&#34;https://my.vmware.com/group/vmware/details?downloadGroup=OVFTOOL410&amp;amp;productId=491#&#34;&gt;available here&lt;/a&gt;, please note a VMware login is required to get this.&lt;/p&gt;
&lt;p&gt;Once downloaded to the Ansbile server, we need to ensure it has execute attribute and then execute it to start the install, the commands to do this for the current version 4.1.0 are.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;chmod +x VMware-ovftool-4.1.0-2459827-lin.x86_64.bundle
./VMware-ovftool-4.1.0-2459827-lin.x86_64.bundle
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-install-ansible-ovftool.jpg&#34; alt=&#34;OVFTool&#34;&gt;&lt;/p&gt;
&lt;p&gt;Once the install is running you have to agree to EULA, to get to the end of the text, hold down the Space bar. When prompted &lt;em&gt;Do you agree?&lt;/em&gt; type yes.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-install-ansible-ovftool2.jpg&#34; alt=&#34;OVFTool&#34;&gt;&lt;/p&gt;
&lt;p&gt;Once OVF Tool is installed we can use SCP to copy the NSX OVA, VMware-NSX-Manager-6.2.2-3604087.ova, to Ansible server I placed this in folder named /OVAs.&lt;/p&gt;
&lt;h2 id=&#34;ansible-nsx-module&#34;&gt;Ansible NSX Module&lt;/h2&gt;
&lt;p&gt;We already have Git installed for dowlnloading the NSX RAML Specification so we can use this to clone the NSX Ansible repository.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;git clone https://github.com/vmware/nsxansible.git /nsxansible
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;deploy-nsx-manager&#34;&gt;Deploy NSX Manager&lt;/h2&gt;
&lt;p&gt;The NSX Module comes supplied with some example playbooks for performing common tasks, we’ll first take a copy of the example to deploy NSX Manager&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cp /nsxansible/test_deploynsxova.yml /nsxansible/darryl_deploynsxova.yml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We can then edit the contents to match the variables we plan to deploy in environment. While most of playbook contents are environmental specific varibles its worth noting that we run this module against the Ansible server itself as this is where the OVA and ovftool are located so hosts: value will always be localhost.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-install-ansible-NSXmgr.jpg&#34; alt=&#34;Deploy NSX Manager&#34;&gt;&lt;/p&gt;
&lt;p&gt;Once we have our environmental specific entries set we can execute the playbook with Ansible.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;ansible-playbook darryl_deploynsxova.yml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-install-ansible-playbook.jpg&#34; alt=&#34;Deploy NSX Manager Playbook&#34;&gt;&lt;/p&gt;
&lt;p&gt;We see this deploys ‘NSX Manager’ and configures the setting specified in the playbook.&lt;/p&gt;
&lt;h2 id=&#34;deploy-nsx-manager-and-register-with-vcenter-and-sso&#34;&gt;Deploy NSX Manager and register with vCenter and SSO&lt;/h2&gt;
&lt;p&gt;As with any Ansible playbook we can put common variables in a central location and call these from playbooks. An example is provided called answerfile-deployLab.yml. Variable names are overlapped between parts of the NSX Modules, in order that they are unique in the central answer file the names vary but its very easy to match these.&lt;/p&gt;
&lt;p&gt;An example of my playbook to deploy NSX Manager and then register this with vCenter and SSO.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/nsx-install-ansible-mgr-cfg.jpg&#34; alt=&#34;Deploy and Configure NSX Manager Playbook&#34;&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Ansibile NSX Configuration - Infrastructure As Code</title>
      <link>https://darrylcauldwell.github.io/post/nsx-ansible-iac/</link>
      <pubDate>Tue, 07 Jun 2016 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/nsx-ansible-iac/</guid>
      <description>
        
          &lt;p&gt;With the rise of DevOps culture and the ethos of automate all the things. Using test driven development techniques to apply application configuration declaratively has become widespread. The ever closer working relations of developers and infrastructure operations staff to become an application centric delivery and management unit has lead to many benefits.  One of the benefits is the shared empathy for each others pain points and understanding of how each approaches tackling these. It is clear that managing configuration as code has many benefits for consistent repeated delivery of applications.&lt;/p&gt;
&lt;p&gt;Tools which are commonly used for deploying applications with declarative configuration include Puppet, Chef and Ansible. The processes for distributed source control are also mature and with Git, Bitbucket and Apache Subversion there is a DVCS for most use-cases. As we work as one delivery team sharing tools and repositories is natural as with this we can look to deploy our infrastructure and application configuration with a single tool and avoid issues with interoperability and hand off.&lt;/p&gt;
&lt;p&gt;VMware NSX offers many things to many people with this rich feature set comes complexity in configuration.  At VMworld Europe 2015 I was introduced to Yves Fauser and attended his session &lt;a href=&#34;https://vmworld2015.lanyonevents.com/connect/sessionDetail.ww?SESSION_ID=4972&amp;amp;tclass=popup&#34;&gt;‘NET4972 – Incorporating VMware NSX in your DevOps Toolchain – Network Programmability with Python and Ansible‘.&lt;/a&gt;  He had created an [NSX RAML specification]((&lt;a href=&#34;http://github.com/vmware/nsxraml),&#34;&gt;http://github.com/vmware/nsxraml),&lt;/a&gt; a &lt;a href=&#34;http://github.com/vmware/nsxramlclient.&#34;&gt;Python NSX RAML client&lt;/a&gt; he then brings these altogether into a usable form by way of an &lt;a href=&#34;https://github.com/vmware/nsxansible&#34;&gt;NSX Ansible module.&lt;/a&gt;  The &lt;a href=&#34;https://github.com/vmware/nsxansible&#34;&gt;Ansible module&lt;/a&gt; offers examples which give the ability to NSX Manager, configure NSX to vCenter integration, configure VXLAN, deploy NSX Controllers and then deploy some logical switches.&lt;/p&gt;
&lt;p&gt;I explorered this capability in [this follow up post.]({{ site.url }}/deploy-nsx-from-ansible)&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Create VMware Virtual Machine Templates</title>
      <link>https://darrylcauldwell.github.io/post/vsphere-vm-templates/</link>
      <pubDate>Tue, 17 May 2016 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/vsphere-vm-templates/</guid>
      <description>
        
          &lt;p&gt;When creating virtual machine templates I&amp;rsquo;d like to do this consistently as such I&amp;rsquo;ll try and keep this post up to date with the settings I am including.&lt;/p&gt;
&lt;h2 id=&#34;centos-7&#34;&gt;CentOS 7&lt;/h2&gt;
&lt;p&gt;New custom VM named CentOS7, hardware version 11, guest operating system Linux version &amp;lsquo;CentOS 4/5/6/7 (64-bit)&amp;rsquo;. We&amp;rsquo;d like a small template which we expand if required, so single virtual socket with single core, 2GB virtual memory, one VMXNET3 NIC, default LSI Logic Parallel SCSI controller with a thin 16GB hard disk and mount CentOS7 ISO as CD-ROM.&lt;/p&gt;
&lt;p&gt;Power on VM and open console, ensure you change NIC to connected and enter password otherwise leave all as default and install. Now I install common tools to use within lab, so once installed reboot and logon still using remote console.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;yum install open-vm-tools net-tools epel-release gcc git
yum update
cp -f /etc/sysconfig/network-scripts/ifcfg-eth0 /tmp/eth0
sed &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/^HWADDR/d&amp;#34;&lt;/span&gt; /tmp/eth0 &amp;amp;gt; /etc/sysconfig/network-scripts/ifcfg-eth0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Shutdown the virtual machine and convert to template using vCenter.&lt;/p&gt;
&lt;h2 id=&#34;windows-2012-r2&#34;&gt;Windows 2012 R2&lt;/h2&gt;
&lt;p&gt;New custom VM named Win2012R2, hardware version 11, guest operating system Windows version &amp;lsquo;Microsoft Windows Server 2012 (64-bit)&amp;rsquo;. We&amp;rsquo;d like a small template which we expand if required, so single virtual socket with single core, 4GB virtual memory, one VMXNET3 NIC, default LSI Logic SAS SCSI controller with a thin 40GB hard disk and mount Windows 2012 R2 ISO as CD-ROM.&lt;/p&gt;
&lt;p&gt;Power on VM and open console, select Datacenter Edition with GUI and enter password otherwise leave all as default and install. Once installed rebooted logon and perform Typical VMware tools install.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Apply MSDN License Key and Active Windows&lt;/li&gt;
&lt;li&gt;Disable IE Enhanced Security&lt;/li&gt;
&lt;li&gt;Use Windows Update to apply all current patches, repeat until all dependant patches are installed.&lt;/li&gt;
&lt;li&gt;Copy \Sources\SxS folder from CD-ROM to C:\&lt;/li&gt;
&lt;li&gt;As some Updates will update .net we should force the Assemblies to get updated&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;%&lt;/span&gt;windir%\Microsoft.NET\Framework\v4.0.30319\ngen.exe update /force
&lt;span style=&#34;color:#66d9ef&#34;&gt;%&lt;/span&gt;windir%\Microsoft.NET\Framework64\v4.0.30319\ngen.exe update /force&amp;lt;/code&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Shutdown the virtual machine and convert to template using vCenter.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>vCloud Director REST API</title>
      <link>https://darrylcauldwell.github.io/post/vcd-rest/</link>
      <pubDate>Sat, 16 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/vcd-rest/</guid>
      <description>
        
          &lt;p&gt;If you find the vCloud Director GUI a little annoying a nice way to get the information you need is via the REST API. Using the REST API you can gather information (GET), update information (PUT) and call operational methods like (POST).&lt;/p&gt;
&lt;p&gt;There are many ways you would call the REST API,  if you want to control this programmatically you would be aiming to orchestrate a series of curl commands to issue your GET, PUT and POST commands with the parameters you want to achieve the task you need.&lt;/p&gt;
&lt;p&gt;In order to build the syntax for your curl commands there are browser plugins which allow you to work out what you need to do manually.  If you use Chrome the best I’ve found is &lt;a href=&#34;https://chrome.google.com/webstore/detail/postman-rest-client/fdmmgilgnpjigdojojpjoooidkmcomcm&#34;&gt;PostMAN&lt;/a&gt;,  the only thing which annoys me about this is it doesn’t seem to have an option to save your custom header info, so I tend to use Firefox and the &lt;a href=&#34;https://addons.mozilla.org/en-US/firefox/addon/restclient/W0Sqc4ZY642oFbg&amp;amp;bvm=bv.83829542,d.d2s&#34;&gt;RESTClient plugin&lt;/a&gt; and with that you can save favorites and add and remove these as needed quickly and easily.&lt;/p&gt;
&lt;p&gt;I’ll explain remaining of this assuming you are using Firefox RESTclient.&lt;/p&gt;
&lt;p&gt;Within RESTclient click Authentication and choose Basic Authentication then complete form
Username:    user@organization
Password:    password&lt;/p&gt;
&lt;p&gt;Select Remember Me if you want to save this for future use.&lt;/p&gt;
&lt;p&gt;Within RESTclient click Headers choose Custom Header&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;Name:        Accept
Value:       application/*+xml;version&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;5.5
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Click “Save To Favorites“.&lt;/p&gt;
&lt;p&gt;Note where reads 5.5 could read 1.5 or 5.1 if your connecting to earlier versions of vCD.&lt;/p&gt;
&lt;p&gt;Change Method To POST and enter URL https://{vcloud ip}/api/sessions&lt;/p&gt;
&lt;p&gt;Your completed form should look a little like this.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/vcd-sessions.png&#34; alt=&#34;vCloud Director Sessions&#34;&gt;&lt;/p&gt;
&lt;p&gt;This should return a 200 OK and forms your a session token with VCD,  at this point your now authorized to perform any action via REST as your account allows via the GUI.&lt;/p&gt;
&lt;p&gt;To test this you might want to list all vApps,  to do this you would ensure method is set to GET and enter a URL to:
https://{vcloud ip}/api/vApps/query&lt;/p&gt;
&lt;p&gt;For a full list of GET, PUT and POST API calls VMware documents them
&lt;a href=&#34;http://pubs.vmware.com/vcd-55/topic/com.vmware.vcloud.api.reference.doc_55/doc/index.html&#34;&gt;here.&lt;/a&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>DevOps != Products</title>
      <link>https://darrylcauldwell.github.io/post/devops/</link>
      <pubDate>Tue, 06 Oct 2015 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/devops/</guid>
      <description>
        
          &lt;p&gt;The last 10 to 20 years in the enterprise has been defined by increasing capital spending on fixed assets (CapEx) while reducing the cost of staffing and operations (OpEx).  Gartner report the growth of spend on enterprise application software (EAS) is continuing to grow and in 2015 will grow at &lt;a href=&#34;http://www.gartner.com/newsroom/id/3119717&#34;&gt;7.5% to $149.9 Billion&lt;/a&gt;.  According to the &lt;a href=&#34;https://hbr.org/2011/09/why-your-it-project-may-be-riskier-than-you-think/ar/1&#34;&gt;Harvard Business Review&lt;/a&gt; one in six IT projects had an average cost overrun of 200% and a schedule overrun of 70%.&lt;/p&gt;
&lt;p&gt;Some companies who provide solutions to enterprise businesses have continued to use the same delivery model they have used for years,  of investing in products (increase CapEx) and reducing people count and replacing high skilled workers with fewer, low cost, lower skilled workers (reducing OpEx). The current levels of under staffing in IT teams lead to constant firefighting that leaves no energy, time or motivation to conduct fire prevention. A common reason heard for buying product to meet a requirement is that the IT staff don&amp;rsquo;t have the time or skills, but they rarely consider where the skills are created ? Who gave those people the time, scope and resources to develop those skills? Training an upskilling builds employee loyalty, new skills of existing employee allows them to quickly realise business benefit, bringing in new hires with skills which are out of context take longer to realize business benefits.&lt;/p&gt;
&lt;p&gt;Other companies have realized the legacy model is broken and have made pivot to lower CapEx spend by the use of open source products hosted on IaaS in the cloud. The effective use of open source products ran to host production services within the cloud increases complexity and as the products are open source and self supported increases the requirement for a highly skilled and highly motivated workforce. The companies who are choosing to invest in people rather than hardware and products to deliver the requirements of business are excelling in the industry as they have improved service agility. Service agility means they can pivot quickly to quickly deliver new features to there customer,  they can scale out on demand to give the required density at the right time and also give great visibility. The success of these cloud native companies shows that over-investment in people NOT over-investment in products produces real increases in productivity.  The other factor about these companies to note is that with a small workforce of highly skilled engineers everyone is required to cover each other, the developers needed to understand the operational requirements and the operations an intimate knowledge of the requirements of the application.  This close relationship and shared empathy between developer and operator is in essence to me what the DevOps culture is.&lt;/p&gt;
&lt;p&gt;Choosing people over products is not limited to the cloud native application space,  cloud providers make huge investment in hardware and software and the scale at which they work to deliver effectively means they need to draw every ounce of productivity out of there hardware investment.  To do this requires again very highly skilled, highly motivated employeers,  examples of success in this area have been Facebook and there founding of the &lt;a href=&#34;http://www.opencompute.org/about/&#34;&gt;Open Compute Project&lt;/a&gt;, the &lt;a href=&#34;http://research.google.com/pubs/pub43438.html&#34;&gt;Google borg project&lt;/a&gt;,  &lt;a href=&#34;https://aws.amazon.com/about-aws/global-infrastructure/&#34;&gt;AWS&lt;/a&gt; and Azure.&lt;/p&gt;
&lt;p&gt;The growth of the enterprise application software (EAS) and the purchase promise of the EAS product vendors to reduce the cost of ownership through faster performance, better features, better software and usability and see that the enterprise fails to deliver large projects. Then consider the success of cloud native companies and DevOps culture,  it leads us to the conclusion that enterprise IT needs to change fundamentally in how they make decisions.&lt;/p&gt;
&lt;p&gt;We can summaries &amp;lsquo;DevOps = People&amp;rsquo; and therefore &amp;lsquo;DevOps != Products&amp;rsquo;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Configuring Network Core Dump With PowerCLI</title>
      <link>https://darrylcauldwell.github.io/post/core-dump/</link>
      <pubDate>Wed, 17 Jun 2015 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/core-dump/</guid>
      <description>
        
          &lt;p&gt;The VMware vSphere Network Dump Collector service enables a host to transmit diagnostic information via the network to a remote netdump service, which stores it on disk. Network-based coredump collection can be configured in addition to or instead of disk-based coredump collection. This may be useful in stateless environments with no local disk usable for a diagnostic partition.&lt;/p&gt;
&lt;p&gt;vSphere ESXi Dump Collector service pre-packaged with the vSphere vCenter Server Virtual Appliance, and if vCenter on Windows vSphere ESXi Dump Collector typically is installed on same server.&lt;/p&gt;
&lt;p&gt;It is a little bit of a pain to configure this on every server, so I wrote this little script to get all hosts and then configure each ESXi host registered with vCenter to point its core dumps to the vCenter.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;Add-PSSnapin VMware.VimAutomation.Core
$vcenter = &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;
Connect-VIServer $vcenter
&lt;span style=&#34;color:#66d9ef&#34;&gt;foreach&lt;/span&gt;($vmhost &lt;span style=&#34;color:#66d9ef&#34;&gt;in&lt;/span&gt; Get-VMHost){
$esxcli = Get-EsxCli -VMHost $vmhost.Name
$esxcli.system.coredump.network.set($null,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;vmk0&amp;#34;&lt;/span&gt;,$vcenter,6500)
$esxcli.system.coredump.network.set(1)
$esxcli.system.coredump.network.get()
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
        
      </description>
    </item>
    
    <item>
      <title>Log Insight for VMware Integrated OpenStack</title>
      <link>https://darrylcauldwell.github.io/post/vrli-openstack/</link>
      <pubDate>Thu, 23 Apr 2015 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/vrli-openstack/</guid>
      <description>
        
          &lt;p&gt;vRealize Log Insight is not a product I have had much to do with up to now,  but that changed a few days ago when I was asked to perform an evaluation of how Log Insight might help with the management and administration of VMware Integrated OpenStack environment.&lt;/p&gt;
&lt;p&gt;So lets start what is vRealize Log Insight, in essence it is a tool for aggregating the viewing of all the log files from all aspects of your infrastructure. It delivers real-time log management, with machine learning-based Intelligent Grouping, and high performance search. While it is a VMware product it is fully extensible and can receive log files from any product,  the product vendor then writes a Log Insight content pack to give the intelligence to identify good and problem states.&lt;/p&gt;
&lt;p&gt;The environment I was given already had Log Insight 2.0A deployed, some of the content packs I was exploring for VMware Integrated OpenStack required the latest Log Insight 2.5.  Here I detail the &amp;lsquo;how to&amp;rsquo; steps I followed for upgrading Log Insight and then adding the content packs.&lt;/p&gt;
&lt;h2 id=&#34;log-insight-20a-to-25-upgrade&#34;&gt;Log Insight 2.0A to 2.5 Upgrade&lt;/h2&gt;
&lt;p&gt;The OpenStack content pack only supports Log Insight 2.5,  so to install this my first task is to upgrade Log Insight
itself,  this is is surprisingly easy.  Simply obtain a copy of the vRealize Log Insight upgrade bundle .pak file from &lt;a href=&#34;https://my.vmware.com/web/vmware/downloads&#34;&gt;VMware Downloads&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Connect to Log Insight as admin,  once connected select &amp;lsquo;Administration&amp;rsquo; from the menu icon in very top right corner, upload PAK file,  click Upgrade.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/vrli-openstack-LogInsightUpgrade.jpg&#34; alt=&#34;Log Insight Upgrade&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;installing-openstack-log-insight-content-pack&#34;&gt;Installing OpenStack Log Insight Content Pack&lt;/h2&gt;
&lt;p&gt;There are two methods for installing content packs,  the first is via the Log Insight itself,  it has a market place feature which connects to the internet to get the list of available Content Packs you then click install and the tool does the rest.  While my test environment had internet access I could have used this,  but as most production workload is isolated from internet instead I opted for the offline method. The OpenStack content pack is downloadable from &lt;a href=&#34;https://solutionexchange.vmware.com/store/products/openstack-content-pack&#34;&gt;Solutions Exchange&lt;/a&gt;. It comes as a small zip file,  within the zip is a vlcp file,  extract this.&lt;/p&gt;
&lt;p&gt;Connect to Log Insight as admin,  once connected select &amp;lsquo;Content Packs&amp;rsquo; from menu icon in very top right corner,  select &amp;lsquo;Import Content Pack&amp;rsquo;,  you get the option now to install as a content pack (available to all) or into my content (available only to user importing).  Click Browse and find the extracted OpenStack vlcp file and click Import.&lt;/p&gt;
&lt;p&gt;I was surprised to find that the content pack did not require configuring with keystone location or credentials, I assume it picks these up from something VIO adds to vCenter, but it just worked which is great.&lt;/p&gt;
&lt;h2 id=&#34;installing-nsx-log-insight-content-pack&#34;&gt;Installing NSX Log Insight Content Pack&lt;/h2&gt;
&lt;p&gt;VMware Integrated Openstack uses NSX-MH,  so I installed NSX content pack,  it didn&amp;rsquo;t appear to get any data,  I was surprised to find when looking a little closer and speaking to our TAM that the current version of the content pack (v1.0) is NSX-V only.&lt;/p&gt;
&lt;h2 id=&#34;installing-arista-eos-switch-log-insight-content-pack&#34;&gt;Installing Arista-EOS Switch Log Insight Content Pack&lt;/h2&gt;
&lt;p&gt;Our VMware Integrated Openstack uses Arista EOS switches,  these integrate with NSX,  and Arista provide Content Pack, I used the same method as above to add the content pack to Log Insight.&lt;/p&gt;
&lt;p&gt;The Arista EOS switches don&amp;rsquo;t support Log Insight by default but they are extensible and Arista provide a Log Insight agent by way of an rpm file,  this is copied and installed to all of the switch&amp;rsquo;s and the loginsight.yaml file is then updated with the IP address of Log Insight server and the level of logging to perform.&lt;/p&gt;
&lt;h2 id=&#34;exploring-log-insight&#34;&gt;Exploring Log Insight&lt;/h2&gt;
&lt;p&gt;Having the power to look across every log file in the estate from a single pane of glass is hard to quantify until you start to work through an issue. The thing VMware have succeeded in doing with this product is keeping the view as clean and uncluttered as possible but still giving all and more of the required functionality.  All content packs provide a default dashboard view constructed to highlight the areas of there product which they believe would be of interest. Navigation in the dashboard view between content packs is via a menu at the top of the left pane,  once selected the left pane gives all of the sub dashboards you can see here OpenStack provides eleven dashboards one for each project.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/vrli-openstack-LI_OS.png&#34; alt=&#34;Log Insight OpenStack&#34;&gt;&lt;/p&gt;
&lt;p&gt;You can use these dashboards to get a general idea about health,  but also you&amp;rsquo;ll have occurrences where users report an issue and you need to investigate.  Maybe a incident ticket got logged and it took a day or so to come through to you,  the dashboards show default last five minutes,  these can be set to show last hour,  last six hours or last twenty four hours,  but the most useful might be a custom time window.  The custom time window could be used to pick the day the issue occurred and it would update the dashboard to show what was going on in the log files at that time.  Here you might see a spike in events and want to drill in to the detail,  so you can just click on the spike and change to interactive view and it will display all the log entries for all components being managed which relating to that spike.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/vrli-openstack-LI_IV.jpg&#34; alt=&#34;Log Insight Interactive View&#34;&gt;&lt;/p&gt;
&lt;p&gt;Once in the interactive view you have several options in the bottom pane to adjust the view,  the default view is &amp;lsquo;Events&amp;rsquo; as name suggests this lists all event entries.  If you change to &amp;lsquo;Field Table&amp;rsquo; this gives a little more structure to the view by separating out each part into a column.  The &amp;lsquo;Event Types&amp;rsquo; view collapses the Events by Type so if you have like 100 errors,  this view might show that there are only 3x types of error and that 70 are of type 1, 20 type 2 and 10 of type 3.  The &amp;lsquo;Event Trends&amp;rsquo; is as a progression from &amp;lsquo;Events by Type&amp;rsquo; and shows the collapsed view but shows which are trending into decline and which are trending up in occurrence.&lt;/p&gt;
&lt;h2 id=&#34;real-life-usage&#34;&gt;Real Life Usage&lt;/h2&gt;
&lt;p&gt;Its hard to quantify how useful Log Insight can be until you have to work through a proper issue.  Luckily (well maybe not lucky to get a fault) while looking at Log Insight a fault manifested itself to users in OpenStack Horizon that they could not deploy new VM instances.  I opened the Log Insight OpenStack content pack and without any awareness of the components of openstack could see nova had been reporting issues at the time the issues reported. The error messages were very generic and not leading to pointing to the fault so I went to the vSphere content pack and found messages which correlated to the time in nova which showed a ESXi host was having issues with clomd and suggested it needed restarting. CLOMD (Cluster Level Object Manager Daemon) plays a key role in the operation of a VSAN cluster so I checked VSAN dashboard in the content pack and could see other issues.  I then connected to the ESX host restarted clomd and the issue went away,  all this took about 5 minutes.  When I took a step back to think about this,  I had queries the log files of about 20-30 servers and was able to stay focused on the issue and the pattern of the fault rather than on logging on to the servers and finding the log files.  Bear in mind I&amp;rsquo;m not Log Insight expert this was my first day using it and its ease of use coupled with its power makes it a truly wonderful tool for the administrator.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>OpenStack Windows Image</title>
      <link>https://darrylcauldwell.github.io/post/openstack-glance-win/</link>
      <pubDate>Thu, 23 Apr 2015 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/openstack-glance-win/</guid>
      <description>
        
          &lt;p&gt;While looking at OpenStack as the control plane for vSphere it appears there isn&amp;rsquo;t too much detail and I found it tricky to create my first OpenStack image.  Here are the steps I followed.&lt;/p&gt;
&lt;h2 id=&#34;create-vsphere-donor-windows-virtual-machine&#34;&gt;Create vSphere Donor Windows Virtual Machine&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Use vSphere web client wizard to create new hardware v10 virtual machine in vSphere with Thin vHDD&lt;/li&gt;
&lt;li&gt;Attach Windows DVD ISO&lt;/li&gt;
&lt;li&gt;Install Windows to virtual machine&lt;/li&gt;
&lt;li&gt;Disconnect DVD ISO&lt;/li&gt;
&lt;li&gt;Install VMware Tools&lt;/li&gt;
&lt;li&gt;Complete VMware Tools Reboot&lt;/li&gt;
&lt;li&gt;Power Down VM&lt;/li&gt;
&lt;li&gt;Export VM as OVF&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;create-openstack-image&#34;&gt;Create OpenStack Image&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Open OpenStack Console&lt;/li&gt;
&lt;li&gt;Change to your Project in left pane&lt;/li&gt;
&lt;li&gt;Select Manage Compute, Images and Snapshots&lt;/li&gt;
&lt;li&gt;Click Create Image&lt;/li&gt;
&lt;li&gt;Complete form using this as an example,  for Image File,  open the OVF file and select the VMDK you exported earlier&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openstack-glance-win-Image-Create.png&#34; alt=&#34;Openstack Image&#34;&gt;&lt;/p&gt;
&lt;ol start=&#34;6&#34;&gt;
&lt;li&gt;Click Create Image&lt;/li&gt;
&lt;li&gt;Wait while file uploads, it takes a while, you&amp;rsquo;ll be returned to console when it completes&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Note: this updates the file to folder glance_openstack on the datastore glance is configured to use. Once created you can cross ref the file UID with the OpenStack Console.&lt;/p&gt;
&lt;h2 id=&#34;test-openstack-image-works-as-instance&#34;&gt;Test OpenStack Image Works As Instance&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Open OpenStack Console&lt;/li&gt;
&lt;li&gt;Change to your Project in left pane&lt;/li&gt;
&lt;li&gt;Select Manage Compute Instances&lt;/li&gt;
&lt;li&gt;Click Launch Instance in right pane&lt;/li&gt;
&lt;li&gt;Complete Details Form&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openstack-glance-win-InstanceLaunch.png&#34; alt=&#34;Openstack Instance Launch&#34;&gt;&lt;/p&gt;
&lt;ol start=&#34;6&#34;&gt;
&lt;li&gt;Ensure correct Security Group selected on Access and Security Tab&lt;/li&gt;
&lt;li&gt;Ensure correct Network is selected on Networking tab&lt;/li&gt;
&lt;li&gt;Click Launch&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;vsan-abnormality&#34;&gt;VSAN Abnormality&lt;/h2&gt;
&lt;p&gt;If your Image is to go to a VSAN datastore and your using OpenStack Havana the above method will fail, this is because VSAN introduces a new disk type [streamOptimized] (&lt;a href=&#34;http://specs.openstack.org/openstack/nova-specs/specs/kilo/approved/vmware-vsan-support.html&#34;&gt;http://specs.openstack.org/openstack/nova-specs/specs/kilo/approved/vmware-vsan-support.html&lt;/a&gt;) which the UI is not aware of (this is fixed in Icehouse and later).&lt;/p&gt;
&lt;p&gt;In order to import these images you would need to use the OpenStack command line interface.  First open WebUI then  &amp;ldquo;Project -&amp;gt; Manage Compute -&amp;gt; Access &amp;amp; Security&amp;rdquo; and click Download OpenStack RC File.&lt;/p&gt;
&lt;p&gt;SCP the RC file to your Linux jump box /var/tmp and then use&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;source /var/tmp/&amp;lt;filename&amp;gt;.rc
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Enter password when prompted.&lt;/p&gt;
&lt;p&gt;Once you have authenticated,  run script like (substituting name and filename as required.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;glance --insecure --os-endpoint-type internalURL image-create &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;--name Windows2008R2-VM10 &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;--property vmware_disktype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;streamOptimized &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;--property vmware_adaptertype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;lsiLogic &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;--container-format&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;bare --disk-format&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;vmdk &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;--is-public&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;--file&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;/var/tmp/Windows2008R2-VM10-disk1.vmdk&amp;lt;/code&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You should get output like&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/openstack-glance-win-streamOptimized2.png&#34; alt=&#34;Stream Optimized&#34;&gt;&lt;/p&gt;
&lt;p&gt;If you have uploaded an image already and found that its not streamOptimized you can change the attribute.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;glance image-update &amp;lt;image_name or uuid&amp;gt; --property vmware_disktype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;streamOptimized
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
        
      </description>
    </item>
    
    <item>
      <title>Post To Slack From Powershell</title>
      <link>https://darrylcauldwell.github.io/post/slack-powershell/</link>
      <pubDate>Thu, 09 Apr 2015 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/slack-powershell/</guid>
      <description>
        
          &lt;p&gt;Working in a technical team distributed across multiple time zones makes it difficult to collaborate and keep everyone on the same page. I’ve used various communications tools to try and help with this and today the team I am working with started to look at Slack.  Slack seems ideal for our needs as it provides easily searchable discussion forums and has apps available for Mac, Windows, iOS and Android, it has a free usage model with limitations which won’t effect our working and if we grow we can extend to a paid license.&lt;/p&gt;
&lt;p&gt;The other really neat thing is that all its features are fully exposed by its API and it integrates via webhooks with many other applications including GitHub, GoogleDrive and Jira. As we added integrations and started to look at the API documentation as a trial I explored posting messages using the REST api from Powershell. It turned out to be really easy to do,  here are my notes on how you can.&lt;/p&gt;
&lt;h2 id=&#34;how-to&#34;&gt;How To&lt;/h2&gt;
&lt;p&gt;While logged into slack use the following URL &lt;a href=&#34;https://api.slack.com/web#authentication&#34;&gt;https://api.slack.com/web#authentication&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This should take you to screen to issue a OAuth2 token.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/slack-powershell-token.png&#34; alt=&#34;Slack OAuth2 Token&#34;&gt;&lt;/p&gt;
&lt;p&gt;Click Create token and copy the text string for the token. We then need to format the message and call postMessage method with Powershell.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$postSlackMessage = @{token=&amp;quot;&amp;lt;your-token&amp;gt;&amp;quot;;channel=&amp;quot;#general&amp;quot;;txt=&amp;quot;Hello from PowerShell!&amp;quot;;username=&amp;quot;via API&amp;quot;}
Invoke-RestMethod -Uri https://slack.com/api/chat.postMessage -Body $postSlackMessage
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This should return a message like&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;ok   channel   ts                message
--   -------   --                -------
True C04BHJ94Z 1428592795.000059 @&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;text&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;Hello from PowerShe...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You can do everything you want via the API not just post messages,  check out the &lt;a href=&#34;https://api.slack.com/&#34;&gt;API documentation&lt;/a&gt; for the other methods.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Ansible For Windows Managed Nodes</title>
      <link>https://darrylcauldwell.github.io/post/ansible-windows/</link>
      <pubDate>Tue, 27 Jan 2015 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/ansible-windows/</guid>
      <description>
        
          &lt;p&gt;On starting to look at learning using Ansible to manage Windows hosts, first step was to setup a test lab.&lt;/p&gt;
&lt;p&gt;Setup an Ubuntu 14.04 or CentOS 7 and a Windows 2008 R2 virtual machines.&lt;/p&gt;
&lt;h2 id=&#34;install-ansible-ubuntu&#34;&gt;Install Ansible (Ubuntu)&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;apt-get install software-properties-common
apt-add-repository ppa:ansible/ansible
apt-get update
apt-get install ansible
sudo pip install http://github.com/diyan/pywinrm/archive/master.zip#egg&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;pywinrm
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;install-ansible-centos-7-minimal&#34;&gt;Install Ansible (CentOS 7 Minimal)&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;yum update
yum install net-tools
yum install epel-release
yum install ansible
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;configure-winrm-on-windows-2008-r2-guest&#34;&gt;Configure WinRM On Windows 2008 R2 Guest&lt;/h2&gt;
&lt;p&gt;The configuration of Windows managed guests WinRM is automated and available in
&lt;a href=&#34;https://github.com/ansible/ansible/blob/devel/examples/scripts/ConfigureRemotingForAnsible.ps1&#34;&gt;this&lt;/a&gt; powershell script.&lt;/p&gt;
&lt;h2 id=&#34;create-a-working-space-test-your-connectivity&#34;&gt;Create A Working Space Test Your Connectivity&lt;/h2&gt;
&lt;p&gt;Ansible is file based,  so here I create a folder underneath my home directory to store my lab configuration&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;mkdir -p ~/ansible_test/group_vars
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We then create a file for holding hosts in lab and begin editing it&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;vi ~/ansible_test/host
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Add the contents of this in the following format,  adding extra lines with extra IPs as needed&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yml&#34; data-lang=&#34;yml&#34;&gt;[&lt;span style=&#34;color:#ae81ff&#34;&gt;windows]&lt;/span&gt;
&lt;span style=&#34;color:#ae81ff&#34;&gt;&amp;lt;windows server ip address&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We then create a file for holding WinRM connectivity hosts in lab and begin editing it&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;vi /home/&amp;lt;user&amp;gt;/ansible_test/group_vars/windows.yml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Add the contents of this in the following format,  adding extra lines with username and password as needed&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# it is suggested that these be encrypted with ansible-vault:&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# ansible-vault edit group_vars/windows.yml&lt;/span&gt;
ansible_ssh_user: &amp;lt;admin user&amp;gt;
ansible_ssh_pass: &amp;lt;admin user password&amp;gt;
ansible_ssh_port: &lt;span style=&#34;color:#ae81ff&#34;&gt;5986&lt;/span&gt;
ansible_connection: winrm
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once we have these two files setup,  we can look to test connectivity&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cd /home/dcauldwell/ansible_test
ansible windows -i host -m win_ping
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Debugging is not enabled by default,  you might want to append -vvvvv to enable this if you have issue on first connect.&lt;/p&gt;
&lt;p&gt;If you still have issues you can test connectivity using cURL&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;curl -vk -d &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt; -u &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;user:pass&amp;#34;&lt;/span&gt; https://&amp;lt;windows server ip address&amp;gt;:5986/wsman&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;When you havethe win_ping module working,  you can look at running the other modules shipped with the core product a full list can be found here.  Maybe you might gather the Ansible facts using.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;ansible &amp;lt;windows server ip address&amp;gt; -m setup
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;create-a-custom-powershell-module&#34;&gt;Create A Custom Powershell Module&lt;/h2&gt;
&lt;p&gt;On looking at the core modules you might think your a bit limited but its easy to wrapper your existing Powershell logic as an Ansible module.&lt;/p&gt;
&lt;p&gt;I decided to keep all my custom modules in the lab in there own folder and change the module path.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;mkdir -p ~/ansible_test/group_vars/library
export ANSIBLE_LIBRARY&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;~/ansible_test/library/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;An Ansible Powershell module is made up of two files,  one is the ps1 with the script contents and one is py which has description and examples.  The main difference appears to be to get the Powershell console output back to Ansible you need to form as object and convert that object to JSON.  It also appears not required but good practice to set an object to be returned with a changed flag to true or false unsure but believe this logic might be used at runtime to decide whether to call the handler.&lt;/p&gt;
&lt;p&gt;An easy way to create a new module,  is to copy an existing one and rename it this way you get the supporting text and structure.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cp /usr/share/pyshared/ansible/modules/core/windows/win_ping* ~/ansible_test/library/
mv ~/ansible_test/library/win_ping.ps1 ~/ansible_test/library/&amp;lt;new module name&amp;gt;.ps1
mv ~/ansible_test/library/win_ping.py ~/ansible_test/library/&amp;lt;new module name&amp;gt;.py
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;A simple example use case might be if you wanted to call the Get-Host cmdlet to gather Powershell version your ps1 might read.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#!powershell&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# WANT_JSON&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# POWERSHELL_COMMON&lt;/span&gt;
$data = Get-Host | Select Version
$result = New-Object psobject @{
get_host_version = $data
changed = $false
};
Exit-Json $result;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Using the same example your py might read&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;DOCUMENTATION &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&amp;#39;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;---
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;module: get_host
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;version_added: &amp;#34;0.1&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;short_description: Call Get-Host cmdlet.
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;description:
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;- Call Get-Host cmdlet
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
EXAMPLES &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&amp;#39;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;# Test connectivity to a windows host
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;ansible winserver -m get_host
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;# Example from an Ansible Playbook
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;- action: get_host
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once we have these two module files,  we can look to test the new module&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cd /home/dcauldwell/ansible_test
ansible windows -i host -m get_host
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If its working you should get returned the output from Get-Host command&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;dcauldwell@ansible-server:~/ansible_test$ ansible windows -i host -m get_host
192.128.0.60 | success &amp;gt;&amp;gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;changed&amp;#34;&lt;/span&gt;: false,
&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;get_host_version&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Version&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Build&amp;#34;&lt;/span&gt;: -1,
&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Major&amp;#34;&lt;/span&gt;: 4,
&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;MajorRevision&amp;#34;&lt;/span&gt;: -1,
&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Minor&amp;#34;&lt;/span&gt;: 0,
&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;MinorRevision&amp;#34;&lt;/span&gt;: -1,
&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Revision&amp;#34;&lt;/span&gt;: -1
&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;With this technique you should be able to form some simple modules.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Is the future of sysadmin to be an SRE?</title>
      <link>https://darrylcauldwell.github.io/post/devops-sre/</link>
      <pubDate>Thu, 22 Jan 2015 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/devops-sre/</guid>
      <description>
        
          &lt;p&gt;I recently came across the role SRE, I didn&amp;rsquo;t know what this was so researched it a little and found that it refers to Site Reliability Engineers after reading around the subject here is my considered opinion.&lt;/p&gt;
&lt;p&gt;The classic sysadmin role could be defined in generic terms as &amp;ldquo;IT operations staff responsible for designing, building, and maintaining an organization&amp;rsquo;s computer infrastructure&amp;rdquo;. The world of IT is continually growing and changing, we&amp;rsquo;re presently going through technological changes and a move to virutalization and containization of server services, a sysadmin now only needs to manage the hosting platform and can manage by policy applied around the server instance and use light touch operational administration of the each server instance.  As well as this businesses are also changing and attempting to embrace lean methodologies to gain the efficiencies they promise, starting in software engineering using Agile process and now moving to encompass operational management by breaking down the silos between development and operations. A healthy DevOps culture is shown by having working relationships which allows each classical team to see how their work influences and affects the other, and by combining knowledge and effort, produces a more robust, reliable, agile product as a result.&lt;/p&gt;
&lt;p&gt;But what of the next stages when server administration is so light tough and infrastructure is delivered by coded workflow, well then you only need hire people who write code. It is within businesses evolved to this point where the term Site Reliability Engineers (SREs) comes in. These are engineers who know enough about programming languages, data structures and algorithms, and performance to properly review the working of an application to properly instrument, measure and alert on its running. Alongside these application skills they have knowledge of operational management to ensure the software continues to have these capabilities through its operational life which might include resilience of failures component, server and site (cloud provider), scalability to accommodate varying workload levels, and security patch management.&lt;/p&gt;
&lt;p&gt;Over the years I&amp;rsquo;ve spoken to a lot of system administrators have come into their roles as an evolution as well maybe through help desk, various layers of support, or even just running computer systems at home and transitioning those skills into servers at work. It is pretty clear in my mind that the same evolutionary path won&amp;rsquo;t work for the transition into SRE, as the move towards the SRE role requires software engineering skills to understand the application itself these skills are classical and learned in a structured way. I have learned a lot about programmatic structure through working with Powershell however the discipline of a computer scientist or software engineer are still quite distant, programming at any level however is a good starting point to work from, and the more you look at programming and languages the more you understand of a developers view point.&lt;/p&gt;
&lt;p&gt;Today many businesses are on a journey of evolution and right now only a handful are at the point in the journey were SREs are needed.  However right now every infrastructure would benefit from having its systems administrator having better programming skills, as such I will be looking to further advancing and formalizing my programming skills.  Bearing in mind the future I believe all sys admins should do the same!&lt;/p&gt;
&lt;p&gt;Interesting article about the job from a &lt;a href=&#34;%22http://googleforstudents.blogspot.co.uk/2012/06/site-reliability-engineers-worlds-most.html&#34;&gt;Google Site Reliability Engineer&lt;/a&gt;.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Scrum Team Demystified</title>
      <link>https://darrylcauldwell.github.io/post/devops-scrum/</link>
      <pubDate>Tue, 26 Aug 2014 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/devops-scrum/</guid>
      <description>
        
          &lt;p&gt;While I worked with Agile as a software tester when the concept first came out in 2002 shortly afterwards I joined a new company in a new role in Infrastructure, IT operations if you will. My recollection of Agile is that it was not a process at all; rather, it’s a set of principles summarized by the Agile Manifesto.&lt;/p&gt;
&lt;p&gt;This seems like a lifetime ago,  but its finally made a comeback to my work life as I now work in team looking to foster a DevOps culture in our workplace.  A DevOps culture is an extension of Agile culture which rather than focusing purely on application life-cycle management it looks to now encompass server life-cycle management too. It aims to achieve this by breaking down organizational barriers to become a single cohesive team delivering a application service rather than discreet silo team structure.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/devops-scrum.png&#34; alt=&#34;DevOps&#34;&gt;&lt;/p&gt;
&lt;p&gt;While Agile and DevOps are cultural changes and not methodologies in themselves there are methodologies which embody the principles such as Scrum, again there is no formal definition of a Scrum but industry members have formed frameworks such as &lt;a href=&#34;http://www.mountaingoatsoftware.com/agile/scrum&#34;&gt;Mike Cohen&lt;/a&gt;. A scrum team is a strong informal collaboration of engineers and developers, within the loose role construct of a Scrum team.The team ideally are co-located, in same building, or at least same timezone so they can work closely and all be aware of each others work. The other ideal is that business or product owner while not sitting within the Scrum team is very close to them, and the team is given wide discretion to develop and innovate in order to reflect their informal understanding of the customer&amp;rsquo;s real desire which is validated.&lt;/p&gt;
&lt;p&gt;In support of this new way of working you can also use tools which support these frameworks.  One such tool is from Atlassian which includes Jira which is a tracker for team planning, it is used to capture and organize issues, assign work, and follow team activity. Atlassian provide an Agile plugin for Jira to give the schema extensions to give the console the concept of Sprint, Theme, Epic and Stories as a way to organize the issues and work, it also enables all of these things to be measured for velocity with regards to team performance.  At the side of Jira sits Atlassian Confluence essentially a Wiki for the creation of the evolving design documentation.&lt;/p&gt;
&lt;p&gt;I mentioned above Sprint, Theme, Epic and Stories.  My loose definition of these terms stems from Mike Cohn&amp;rsquo;s &lt;a href=&#34;http://www.mountaingoatsoftware.com/agile&#34;&gt;Agile template&lt;/a&gt;. Where Scrum story is a user requirement definition,  a Scrum epic is a large user story, there is no threshold at where a story becomes a Epic it is just a big story,  potentially an Epic is a large story waiting to be more clearly defined and broken down into stories. A Scrum theme is a collection of Stories and \ or Epics. A Scrum sprint is a collection of Epics and \ or Stories which we hope to do within a set time frame. So we might have 100 stories pending,  and if our Sprint window is one week we might say this week we have these people engaged and can therefore complete these 10 stories. In practical terms for a sprint, we therefore draw a loose line in the sand that a Story should be achievable within a Sprint and an Epic a story which spans Sprints. Within Atlassian Jira story dependencies can be formed,  so if a Story hits an issue or hits a block the impact of this can be seen further up the dependency tree.&lt;/p&gt;
&lt;p&gt;As well as managing the tasks and workload with Jira another key part is harnessing automation to give predictable and repeatable delivery of your application service.With the cloud comes the decoupling of operating systems from physical servers, storage and networking,  and with containers the further decoupling of application from operating systems. With self service software defined data center and OpenStack cloud management platform cloud style infrastructure deployments is becoming more accessible to the traditional private data centers too.  With so many configuration items required to deliver a application service within software defined infrastructure as well as the application itself.  It can be useful to harness desired state tooling such as &lt;a href=&#34;https://www.chef.io/chef/&#34;&gt;Chef&lt;/a&gt; and &lt;a href=&#34;http://puppetlabs.com/&#34;&gt;Puppet&lt;/a&gt;, and leveraging distributed version control systems like &lt;a href=&#34;https://github.com/&#34;&gt;GitHub&lt;/a&gt;, to manage, deploy and enforce your configuration.&lt;/p&gt;
&lt;p&gt;A neat video on Jira, Agile, Scrum and Kanban&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=NrHpXvDXVrw&#34;&gt;https://www.youtube.com/watch?v=NrHpXvDXVrw&lt;/a&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Setup Hanlon</title>
      <link>https://darrylcauldwell.github.io/post/hanlon/</link>
      <pubDate>Fri, 04 Apr 2014 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/hanlon/</guid>
      <description>
        
          &lt;p&gt;Since the company I work for CSC got a new CEO then CTO its changed direction and the latest change has been to &lt;a href=&#34;http://www.vdatacloud.com/blogs/2014/05/22/finding-value-in-opensource/&#34;&gt;participate with the Open Source community&lt;/a&gt;.  With this news shortly followed an updated version of a tool our new CTO &lt;a href=&#34;https://twitter.com/DanHushon&#34;&gt;Dan Hushon&lt;/a&gt; worked on at EMC with &lt;a href=&#34;https://twitter.com/lynxbat&#34;&gt;Nicholas Weaver&lt;/a&gt; it was formerly called &lt;a href=&#34;https://github.com/puppetlabs/Razor%22&#34;&gt;Razor&lt;/a&gt; and the new fork is &lt;a href=&#34;https://github.com/csc/Hanlon&#34;&gt;Hanlon&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I chose CentOS 6.5 64bit to host Hanlon and configured this as a VM with two vNICs one normal internet facing and one on a new private vSwitch with no uplinks,  the private is where DHCP\PXE\TFTP will be setup on and where the ESXi VMs will hopefully get built.  All these sit on an nested ESXi 5.0 configured with 12GB of vRAM and access to 1TB of NFS disk running inside VMware Fusion 6 on a Mac.&lt;/p&gt;
&lt;p&gt;I don&amp;rsquo;t work with Linux so some of my commands might be sub optimal, I&amp;rsquo;ll try and record all I use here for reference, and if you see anything I&amp;rsquo;m doing badly please do say.&lt;/p&gt;
&lt;p&gt;First task to the new VM is to start VMware tools installer which mounts the correct ISO,  then install the tools via putty session (or via console).&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;yum -y install perl
mkdir /mnt/cdrom
mount /dev/cdrom /mnt/cdrom
cp /mnt/cdrom/VMwareTools-*.tar.gz /tmp
tar -zxf /tmp/VMwareTools-*.tar.gz -C /tmp
cd /tmp/vmware-tools-distrib/
./vmware-install.pl --default
rm -f /tmp/VMwareTools-*.tar.gz
rm -rf /tmp/vmware-tools-distrib

&lt;span style=&#34;color:#75715e&#34;&gt;# I then changed from DHCP to static IP addressing,  to note shown here are only the lines I changed or added the rest I left as they populated by OS&lt;/span&gt;

vi /etc/sysconfig/network-scripts/ifcfg-eth0
BOOTPROTO&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;none
NETWORK&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&amp;amp;lt;Internet Facing Network Address&amp;amp;gt;
NETMASK&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&amp;amp;lt;Internet Facing Subnet Mask&amp;amp;gt;
IPADDR&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&amp;amp;lt;Internet Facing IP Address&amp;amp;gt;
vi /etc/sysconfig/network-scripts/ifcfg-eth1
BOOTPROTO&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;none
NETWORK&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&amp;amp;lt;Private Network Address&amp;amp;gt;
NETMASK&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&amp;amp;lt;Private Subnet Mask&amp;amp;gt;
IPADDR&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&amp;amp;lt;Private IP Address&amp;amp;gt;

&lt;span style=&#34;color:#75715e&#34;&gt;# My next port of call was to add a DHCP server to the VM, I chose ISC as that was recommended for Razor and appeared simple and well [documented](http://prefetch.net/articles/iscdhcpd.html).&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;## Install DHCP&lt;/span&gt;
yum install dhcp

&lt;span style=&#34;color:#75715e&#34;&gt;## Change DHCP that to listen on eth1&lt;/span&gt;
vi /etc/sysconfig/dhcpd

DHCPDARGS&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;eth1

&lt;span style=&#34;color:#75715e&#34;&gt;## Create a new config file&lt;/span&gt;
vi /etc/dhcp/dhcpd.conf

&lt;span style=&#34;color:#75715e&#34;&gt;## Populate with following (altering with your ID address ranges)&lt;/span&gt;
subnet 172.25.1.0 netmask 255.255.255.0 &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
range 172.25.1.20 172.25.1.50;
option tftp-server-name &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;172.25.1.10&amp;#34;&lt;/span&gt;;
&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; exists user-class and option user-class &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;iPXE&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
filename &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;hanlon.ipxe&amp;#34;&lt;/span&gt;;
&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
filename &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;undionly.kpxe&amp;#34;&lt;/span&gt;;
&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
next-server 172.25.1.10;
&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;## Start DHCP using&lt;/span&gt;
/etc/init.d/dhcpd start
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Test ISC DHCP and option by creating a VM with no OS,  and with only a NIC on the
private network and it should now pickup a PXE address.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/hanlon-PXE-Boot.gif&#34; alt=&#34;Hanlon PXE Boot&#34;&gt;&lt;/p&gt;
&lt;p&gt;It will fail as there is no PXE or TFTP server setup yet on the Hanlon server. So next step is to add a PXE and TFTP server,  so first task is to install it.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;yum -y install tftp-server tftp

&lt;span style=&#34;color:#75715e&#34;&gt;## Enable TFTP&lt;/span&gt;
sed -i &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;s/disable\t\t\t= yes/disable\t\t\t= no/g&amp;#39;&lt;/span&gt; /etc/xinetd.d/tftp
service xinetd restart

&lt;span style=&#34;color:#75715e&#34;&gt;## Install Java&lt;/span&gt;
yum -y install java-1.7.0-openjdk

&lt;span style=&#34;color:#75715e&#34;&gt;## Create MongoDB Repo config file&lt;/span&gt;
vi /etc/yum.repos.d/mongodb.repo

&lt;span style=&#34;color:#75715e&#34;&gt;## Then populate new file with&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;mongodb&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;MongoDB Repository
baseurl&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;http://downloads-distro.mongodb.org/repo/redhat/os/x86_64/
gpgcheck&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
enabled&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;## Install MongoDB from repo&lt;/span&gt;
yum -y install mongodb-org

&lt;span style=&#34;color:#75715e&#34;&gt;## Install Torquebox Ruby Application Platform&lt;/span&gt;
curl -L -O http://torquebox.org/release/org/torquebox/torquebox-dist/3.0.1/torquebox-dist-3.0.1-bin.zip
yum -y install unzip
unzip torquebox-dist-3.0.1-bin.zip -d $HOME
echo &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;export TORQUEBOX_HOME=$HOME/torquebox-3.0.1&amp;#39;&lt;/span&gt; &amp;amp;gt;&amp;amp;gt; ~/.bashrc
echo &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;export JBOSS_HOME=$TORQUEBOX_HOME/jboss&amp;#39;&lt;/span&gt; &amp;amp;gt;&amp;amp;gt; ~/.bashrc
echo &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;export JRUBY_HOME=$TORQUEBOX_HOME/jruby&amp;#39;&lt;/span&gt; &amp;amp;gt;&amp;amp;gt; ~/.bashrc
echo &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;export PATH=$JRUBY_HOME/bin:$PATH&amp;#39;&lt;/span&gt; &amp;amp;gt;&amp;amp;gt; ~/.bashrc
exec $SHELL -l

&lt;span style=&#34;color:#75715e&#34;&gt;## Download Hanlon&lt;/span&gt;
mkdir /opt/hanlon
cd /opt/hanlon
yum -y install git
git clone https://github.com/csc/Hanlon.git

&lt;span style=&#34;color:#75715e&#34;&gt;## Install Requisite Ruby Gems for Hanlon&lt;/span&gt;
cd /opt/hanlon/Hanlon
bundle install
gem update --system

&lt;span style=&#34;color:#75715e&#34;&gt;## Just need now to finalise the configuration of the Hanlon Microkernel, configure TFTP and  iPXE.&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;## Install GCC&lt;/span&gt;
yum -y install gcc gcc-c++

&lt;span style=&#34;color:#75715e&#34;&gt;## Download iPXE &amp;amp; Make Files&lt;/span&gt;
git clone https://github.com/ipxe/ipxe.git
curl -O https://gist.githubusercontent.com/jcpowermac/7cc13ce51816ce5222f4/raw/4384911a921a732e0b85d28ff3485fe18c092ffd/image_comboot.patch
yum -y install patch genisoimage
patch -p0 &amp;lt; image_comboot.patch
cd ipxe/src
make

&lt;span style=&#34;color:#75715e&#34;&gt;## Move new iPXE files to correct place for TFTP&lt;/span&gt;
cd bin
cp undionly.kpxe /var/lib/tftpboot/undionly.kpxe
cp ipxe.pxe /var/lib/tftpboot/ipxe.kpxe
cp ipxe.iso /var/lib/tftpboot/ipxe.iso

&lt;span style=&#34;color:#75715e&#34;&gt;## Get Syslinux files and move to correct place&lt;/span&gt;
curl -O https://www.kernel.org/pub/linux/utils/boot/syslinux/syslinux-6.02.tar.gz
tar -zxvf syslinux-6.02.tar.gz --strip-components &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt; -C /var/lib/tftpboot syslinux-6.02/bios/core/pxelinux.0
tar -zxvf syslinux-6.02.tar.gz --strip-components &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt; -C /var/lib/tftpboot syslinux-6.02/bios/com32/menu/menu.c32

&lt;span style=&#34;color:#75715e&#34;&gt;## Create Hanlon.pxe&lt;/span&gt;
yum -y install wget
wget https://github.com/csc/Hanlon-Microkernel/releases/download/v1.0/hnl_mk_prod-image.1.0.iso&amp;lt;
/opt/hanlon/Hanlon/cli/hanlon image add -t mk -p hnl_mk_prod-image.1.0.iso
/opt/hanlon/Hanlon/cli/hanlon config ipxe &amp;gt; /var/lib/tftpboot/hanlon.ipxe

&lt;span style=&#34;color:#75715e&#34;&gt;## Configure TFTBoot&lt;/span&gt;
mkdir /var/lib/tftpboot/pxelinux.cfg
cat &amp;gt; /var/lib/tftpboot/pxelinux.cfg/default &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;lt;&amp;lt;EOF
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;default menu.c32
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;prompt 0
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;menu title Hanlon Boot Menu
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;timeout 50
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;f1 help.txt
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;f2 version.txt
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;label hanlon-boot
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;menu label Automatic hanlon Node Boot
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;kernel ipxe.lkrn
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;append initrd=hanlon.ipxe
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;label boot-else
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;menu label Bypass hanlon
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;localboot 1
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;EOF&lt;/span&gt;&amp;gt;&amp;gt;

&lt;span style=&#34;color:#75715e&#34;&gt;## Bind TFTP to eth1&lt;/span&gt;
vi /etc/xinetd.d/tftp
add bind &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &amp;lt;ipaddress&amp;gt; of eth1
chkconfig dhcpd on
service xinetd restart

&lt;span style=&#34;color:#75715e&#34;&gt;## Test TFTP is working&lt;/span&gt;
tftp localhost4
get hanlon.ipxe
quit

&lt;span style=&#34;color:#75715e&#34;&gt;## If TFTP Times Out Try Disable Firewall&lt;/span&gt;
service iptables stop
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;At this point you should be able to create a test VM bound to same Host Only network and it should pick up a DHCP address then connect to TFTP server and download and boot an image.&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>HP C7000 Interconnect Bay Mapping</title>
      <link>https://darrylcauldwell.github.io/post/hpe-c7000-interconnects/</link>
      <pubDate>Thu, 27 Mar 2014 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/hpe-c7000-interconnects/</guid>
      <description>
        
          &lt;p&gt;Here I address the most common query people have when using HP C7000 chassis, namely how do the bay
mappings work.&lt;/p&gt;
&lt;h2 id=&#34;half-height-blades&#34;&gt;Half Height Blades&lt;/h2&gt;
&lt;p&gt;HP supply blades which occupy single or double slots,  the single height blades map in the following way.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Device&lt;/th&gt;
&lt;th&gt;Interconnect Bay Mapping&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;OnBoard NIC1&lt;/td&gt;
&lt;td&gt;Bay 1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;OnBoard NIC2&lt;/td&gt;
&lt;td&gt;Bay 2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Mezz1 HBA1&lt;/td&gt;
&lt;td&gt;Bay 3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Mezz1 HBA2&lt;/td&gt;
&lt;td&gt;Bay 4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Mezz2 NIC1&lt;/td&gt;
&lt;td&gt;Bay 5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Mezz2 NIC2&lt;/td&gt;
&lt;td&gt;Bay 6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Mezz2 NIC3&lt;/td&gt;
&lt;td&gt;Bay 7&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Mezz2 NIC4&lt;/td&gt;
&lt;td&gt;Bay 8&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/hpe-c7000-mapping-half.png&#34; alt=&#34;Half Height Blade Mappings&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;full-height-blades&#34;&gt;Full Height Blades&lt;/h2&gt;
&lt;p&gt;For dual height blade server such as BL680c the mappings work the same way although each server has two mappings to each for example slot one maps to ports one and nine in each interconnect bay as opposed to just bay port one if in slot one and port nine if in slot nine.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://darrylcauldwell.github.io/images/hpe-c7000-mapping-full.gif&#34; alt=&#34;Full Height Blade Mappings&#34;&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Configuring Puppet</title>
      <link>https://darrylcauldwell.github.io/post/puppet/</link>
      <pubDate>Mon, 23 Sep 2013 00:00:00 +0000</pubDate>
      
      <guid>https://darrylcauldwell.github.io/post/puppet/</guid>
      <description>
        
          &lt;p&gt;I&amp;rsquo;m a traditional wintel vmware engineer working in the UK in a team focusing on platform configuration automation for virtual and physical Windows hosted solutions. This video of how &lt;a href=&#34;http://www.youtube.com/watch?v=UUgoiwEFe1A&#34;&gt;Puppet can be used to manage Amazon EC2&lt;/a&gt;. Shortly after watching this VMware Hybrid Cloud Services launched and on watching Nicholas Weavers video from PuppetConf 2013](&lt;a href=&#34;http://www.youtube.com/watch?v=tp_1N3RSyUY)&#34;&gt;http://www.youtube.com/watch?v=tp_1N3RSyUY)&lt;/a&gt;. From this point on I decided that I needed to look into Puppet and how it could help me,  on initial looking it became clear that Puppet is traditionally *nix but does function on Windows so I thought I&amp;rsquo;d start here.&lt;/p&gt;
&lt;h2 id=&#34;environmental-summary&#34;&gt;Environmental Summary&lt;/h2&gt;
&lt;p&gt;VMWare Workstation - 8.0.6 build-1035888&lt;br&gt;
Puppet Learning VM (1.5GB vRAM 1x vCPU 4.5GB HDD), &lt;a href=&#34;http://info.puppetlabs.com/download-learning-puppet-VM.html&#34;&gt;Download Here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;puppet-learning-vm---configuration&#34;&gt;Puppet Learning VM - Configuration&lt;/h2&gt;
&lt;p&gt;Once the Puppet Enterprise Learning VM is deployed from the OVF.  Its pretty intuitive setup I only changed to a bridged network connection for vNIC and installed VMware tools.&lt;/p&gt;
&lt;p&gt;VMware tools install command syntax used&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;yum -y install perl
mkdir /mnt/cdrom
mount /dev/cdrom /mnt/cdrom
cp /mnt/cdrom/VMwareTools-*.tar.gz /tmp
umount /mnt/cdrom
tar -zxf /tmp/VMwareTools-*.tar.gz -C /tmp
cd /
./tmp/vmware-tools-distrib/vmware-install.pl --default
rm -f /tmp/VMwareTools-*.tar.gz
rm -rf /tmp/vmware-tools-distrib
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
        
      </description>
    </item>
    
  </channel>
</rss>
